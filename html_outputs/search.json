[{"path":"index.html","id":"section","chapter":"","heading":"","text":"","code":""},{"path":"index.html","id":"r-pour-lépidémiologie-appliquée-et-la-santé-publique","chapter":"","heading":"R pour l’épidémiologie appliquée et la santé publique","text":"Utilisation : Ce manuel été utilisé plus d’un million de fois par 400 000 personnes dans le monde entier.Objectif: Servir de manuel de référence rapide du code R (en ligne et Télécharger le manuel et les données) avec des exemples centrés sur la tâche qui traitent des problèmes épidémiologiques courants.Essayez nos tutoriels interactifs gratuits ou notre cours d’introduction synchrone et virtuel utilisé par les CDC américains, l’OMS et plus de 130 autres agences de santé et programmes de formation à l’épidémiologie sur le terrain dans le monde entier.Langues: Anglais (English), Espagnol (Español), Vietnamien (Tiếng Việt), Japonais (日本), Turc (Türkçe), Francais, Portugais (Português)Rédigé par des épidémiologistes, pour des épidémiologistes \nApplied Epi est une organisation à non lucratif et un mouvement d’épis de première ligne du monde entier. Nous écrivons pendant notre temps libre pour offrir cette ressource à la communauté. Vos encouragements et vos commentaires sont les bienvenus :Visitez notre site web et rejoignez notre liste de contacts.contact@appliedepi.org, tweeter @appliedepi, ou LinkedInSoumettre des problèmes à notre dépôt GithubNous proposons des formations R en direct dispensées par des formateurs ayant des décennies d’expérience en épidémiologie appliquée - envoyez-nous un courriel pour en discuter.","code":""},{"path":"index.html","id":"comment-utiliser-ce-manuel","chapter":"","heading":"Comment utiliser ce manuel","text":"Parcourez les pages de la table des matières ou utilisez la boîte de recherche.Cliquez sur les icônes “copier” pour copier le code.Vous pouvez suivre avec les données d’exemple de le chapitre.Version hors ligneVoir les instructions de la page Télécharger le manuel et les données.","code":""},{"path":"index.html","id":"remmerciements","chapter":"","heading":"Remmerciements","text":"Cet ouvrage est le fruit du travail d’une équipe internationale d’épidémiologistes, qui se sont appuyés sur leur expérience auprès d’organisations telles que les agences sanitaires locales, régionales, provinciales et nationales de divers pays, l’Organisation mondiale de la santé (OMS), Médecins Sans Frontières (MSF), les systèmes hospitaliers et les institutions universitaires.Ce guide n’est pas un produit approuvé par une organisation spécifique. Bien que nous nous soyons efforcés à être précis, nous ne pouvons fournir aucune garantie quant au contenu de ce livre.","code":""},{"path":"index.html","id":"auteurs-et-contributeurs","chapter":"","heading":"Auteurs et contributeurs","text":"Editeur: Neale BatraCommité éditorial Neale Batra, Alex Spina, Amrish Baidjoe, Pat Keating, Henry Laurenson-Schafer, Finlay CampbellAuteurs et autrices: Neale Batra, Alex Spina, Paula Blomquist, Finlay Campbell, Henry Laurenson-Schafer, Isaac Florence, Natalie Fischer, Aminata Ndiaye, Liza Coyer, Jonathan Polonsky, Yurie Izawa, Chris Bailey, Daniel Molling, Isha Berry, Emma Buajitti, Mathilde Mousset, Sara Hollis, Wen Lin, Olivia BoydRelecture: Pat Keating, Annick Lenglet, Margot Charette, Danielly Xavier, Esther Kukielka, Michelle Sloan, Aybüke Koyuncu, Rachel Burke, Kate Kelsey, Berhe Etsay, John Rossow, Mackenzie Zendt, James Wright, Laura Haskins, Flavio Finger, Tim Taylor, Jae Hyoung Tim Lee, Brianna Bradley, Wayne Enanoria, Manual Albela Miranda, Molly Mantus, Pattama Ulrich, Joseph Timothy, Adam Vaughan, Olivia Varsaneux, Lionel Monteiro, Joao MuiangaIllustrations: Calder FongTraduction: Aminata Ndiaye, Anais Legrand, Marie-Amelie Degail-Chabrat, Yves Amevoin, Laura Downham, Lise Grout, Margot Charette, Mathilde Mousset, Noe Guincko, Mor Ndiaye, Elysée Junior, Nerisson Joseph, Bryan Tegomoh, Marcel Woung, Olivia Boyd, Amy Mikhail, Lucie Fournier, Paul-Evans Ehouman, Kelly McCain","code":""},{"path":"index.html","id":"financements","chapter":"","heading":"Financements","text":"Le manuel reçu un financement de soutien via une subvention d’urgence COVID-19 pour le renforcement des capacités de la part de TEPHINET, le réseau mondial des programmes de formation en épidémiologie de terrain (FETP).Le réseau des anciens d’EPIET (EAN) fourni un soutien administratif (Annika Wendland en particulier). EPIET est le programme européen de formation en épidémiologie d’intervention.Nous remercions tout particulièrement le Centre Opérationnel d’Amsterdam de Médecins Sans Frontières (MSF OCA) pour son soutien lors de l’élaboration de ce manuel.Cette publication été soutenue par l’accord de coopération numéro NU2GGH001873, financé par les Centers Disease Control Prevention par le biais de TEPHINET, un programme de “Task Force Global Health”. Son contenu relève de la seule responsabilité des auteurs et ne reflète pas les opinions officielles des Centers Disease Control Prevention, du Department Health Human Services, de Task Force Global Health, Inc. ou de TEPHINET.","code":""},{"path":"index.html","id":"inspirations","chapter":"","heading":"Inspirations","text":"Nous nous sommes inspiré de multiples tutoriels, livres et vignettes développés par la communauté pour développer ce manuel. Ces ressources, sont crédités dans les chapitres respectifs, mais nous souhaitons citer quelques sources d’inspiration générales que nous utilisons de manière récurrente :“R4Epis” project (une collaboration entre MSF et RECON)R Epidemics Consortium (RECON)R Data Science book (R4DS)bookdown: Authoring Books Technical Documents R MarkdownNetlify qui héberge ce site","code":""},{"path":"index.html","id":"conditions-dutilisation-et-contribution","chapter":"","heading":"Conditions d’utilisation et contribution","text":"","code":""},{"path":"index.html","id":"license","chapter":"","heading":"License","text":"Ce document est mis à disposition selon les termes de lalicence Creative Commons Attribution - Pas d’Utilisation Commerciale - Partage dans les Mêmes Conditions 4.0 International (CC -NC-SA 4.0) .N’hésitez pas à utiliser les contenus de ce manuel dans vos cours et formations en épidémiologie, ou à le conseiller à vos étudiants. Si vous avez des questions sur l’utilisation que vous souhaitez en faire, envoyez un courriel à contact@appliedepi.org.","code":""},{"path":"index.html","id":"citation","chapter":"","heading":"Citation","text":"Batra, Neale, et al. Epidemiologist R Handbook. 2021. ","code":""},{"path":"index.html","id":"contribuer","chapter":"","heading":"Contribuer","text":"Si vous souhaitez contribuer à cet ouvrage, veuillez d’abord nous contacter via les tickets (issues) Github ou par courriel. Nous sommes en train de développer un calendrier de mise à jour et un guide du contributeur.Veuillez noter que le projet epiRhandbook est publié avec un code de conduite du contributeur. En contribuant à ce projet, vous acceptez de vous conformer à ses conditions.","code":""},{"path":"editorial_notes.html","id":"editorial_notes","chapter":"1 Notes techniques et choix éditoriaux","heading":"1 Notes techniques et choix éditoriaux","text":"Nous décrivons ici les choix pédagogiques, le style et les décisions éditoriales spécifiques prises lors de l’écriture de ce guide.","code":""},{"path":"editorial_notes.html","id":"approche-et-style","chapter":"1 Notes techniques et choix éditoriaux","heading":"1.1 Approche et style","text":"Le public visé par ce manuel est large. Nous espérons qu’il sera utile aux épidémiologistes novices en R, mais aussi aux utilisateurs expérimentés à la recherche de bonnes pratiques et d’astuces. L’ouvrage doit donc être à la fois accessible et succinct. Notre cherchons à fournir juste assez d’explications textuelles pour qu’une personne débutante en R puisse appliquer le code et comprendre ce qu’il fait.En conséquences de quoi, ce guide est :un ouvrage de référence de code, accompagné d’exemples relativement brefs, et non un manuel complet sur R ou la science des donnéesun guide R à utiliser dans le cadre de l’épidémiologie appliquée, et non un manuel sur les méthodes ou la science de l’épidémiologie appliquéeun document évolutif : les paquets R optimaux pour une tâche donnée changent souvent et nous sommes ouverts à toute discussion sur les paquets à privilégier dans ce manuel.","code":""},{"path":"editorial_notes.html","id":"paquets-r","chapter":"1 Notes techniques et choix éditoriaux","heading":"Paquets R","text":"Tellement de possibilités…Un aspect difficile de l’apprentissage de R est de savoir quel paquet R utiliser pour une tâche donnée. Il n’est pas rare que l’se décarcasse à écrire vingt (cent ?) lignes de code, pour se rendre compte plus tard qu’il existe un paquet R qui donne le même résultat recheré en une seule ligne de commande !Dans ce guide, nous essayons de vous proposer au moins deux façons de réaliser chaque tâche : une méthode éprouvée (probablement dans R de base ou utilisant le tidyverse) et un paquet R spécialement conçu à cet effet. Nous voulons que vous ayez les deux options, au cas où vous ne pourriez pas télécharger un paquet donné ou si celui-ci ne vous convient pas.Pour choisir les paquets à utiliser, nous avons donné la priorité aux paquets R et aux approches qui ont été testés et approuvés par la communauté, qui minimisent le nombre de paquets utilisés dans une session de travail typique, qui sont stables (ne changent pas très souvent) et qui accomplissent la tâche simplement et proprement.Ce manuel donne généralement la priorité aux paquets et fonctions R du méta-paquet tidyverse. Tidyverse est une collection de paquets R conçus pour la science des données, et qui partagent une grammaire et des structures de données sous-jacentes. Tous les paquets du Tidyverse peuvent être installés ou chargés séparément, ou en masse via le paquet tidyverse. Pour en savoir plus, consultez le site Web du tidyverse.Nous proposons également souvent des options de code utilisant R de base (les paquets et fonctions fournis avec R à l’installation). En effet, nous sommes conscients que certains lecteurs de ce livre ne disposent pas d’un accès Internet fiable pour télécharger des paquets supplémentaires.Expliciter quelle fonction appartient à quel paquetIl est souvent frustrant lorsque l’suit un tutoriel R de ne pas savoir de quel paquet provient une fonction (et donc de ne pas pouvoir l’utiliser immédiatement dans notre code) !Dans ce guide, les noms des paquets seront écrits en gras (par exemple dplyr) et les fonctions sont écrites comme ceci : mutate(). Nous nous efforçons d’être explicites quant au paquet dont provient une fonction, soit en faisant référence au paquet dans le texte voisin, soit en spécifiant le paquet explicitement dans le code, comme ceci : dplyr::mutate(). Cela alourdit un petit peu le code, mais rend plus facile la réutilisation du code chez vous.Consultez la page sur les Bases de R pour en savoir plus sur les paquets et les fonctions.","code":""},{"path":"editorial_notes.html","id":"choix-dyn-style-de-code","chapter":"1 Notes techniques et choix éditoriaux","heading":"Choix d’yn style de code","text":"Dans le manuel, nous allons fréquemment à la ligne, ce qui rend notre code “long”. Nous faisons cela pour plusieurs raisons :cela permet d’écrire des commentaires explicatifs avec # adjacents à la commande qu’ils décrivent,généralement, un code plus long (vertical) est plus facile à lire,il est plus facile à lire sur un écran étroit (pas de défilement latéral nécessaire),il est plus facile de savoir quels arguments appartiennent à quelle fonction grâce aux indentations.Par conséquent, un bout de code code qui pourrait être écrit comme ceci :…est écrit comme cela :Le code R n’est généralement pas affecté par les nouvelles lignes ou les indentations. Lorsque vous écrivez dans Rstudio (ou un éditeur décent), l’indentation se fera automatiquement lorsque vous allez à la ligne après une virgule.Nous utilisons beaucoup d’espaces (par exemple n = 1 au lieu de n=1) parce que c’est plus facile à lire pour beaucoup de personnes. Pensez aux gens qui lisent votre code !","code":"\nlinelist %>% group_by(hospital) %>%  # groupe les lignes par hopital\n  slice_max(date, n = 1, with_ties = F) # s'il y a égalité de date, prendre la première\nlinelist %>% \n  group_by(hospital) %>% # groupe les lignes par hopital\n  slice_max(\n    date,                # Garde les lignes avec la date maximun à l'intérieur de chaque groupe\n    n = 1,               # Ne garder que la date maximum\n    with_ties = F)       # S'il y a égalité de date, prendre la première"},{"path":"editorial_notes.html","id":"nomenclature","chapter":"1 Notes techniques et choix éditoriaux","heading":"Nomenclature","text":"Dans ce manuel, nous faisons généralement référence aux “colonnes” et aux “lignes” plutôt qu’aux “variables” et “observations”. Comme l’explique cette introduction aux “données ordonnées”, la plupart des jeux de données statistiques épidémiologiques se composent structurellement de lignes, de colonnes et de valeurs.Les variables contiennent les valeurs qui mesurent le même attribut sous-jacent (comme le groupe d’âge, le résultat ou la date d’apparition des symptomes). Les observations contiennent toutes les valeurs mesurées sur la même unité (par exemple, une personne, un site ou un échantillon de laboratoire). Ces aspects peuvent donc être plus difficiles à définir de manière tangible.Dans les ensembles de données “ordonnés” (tidy data en anglais), chaque colonne est une variable, chaque ligne est une observation et chaque cellule est une valeur unique. Cependant, certains jeux de données que vous rencontrerez ne correspondront pas à ce modèle - un ensemble de données au format “large” peut avoir une variable répartie sur plusieurs colonnes (voir un exemple à la page Transformation long-large). De même, les observations peuvent être réparties sur plusieurs lignes.La majeure partie de ce manuel porte sur le nettoyage et la transformation des données, et il est donc plus pertinent de se référer aux structures de données concrètes que sont les lignes et les colonnes qu’aux observations et aux variables plus abstraites. Les exceptions se produisent principalement dans les pages sur l’analyse des données, où vous verrez davantage de références aux “variables” et aux “observations”.","code":""},{"path":"editorial_notes.html","id":"notes","chapter":"1 Notes techniques et choix éditoriaux","heading":"Notes","text":"Voici les types de notations utilisées dans le guide :NOTE: Ceci est une noteTIP: Ceci est un conseil ou une astuce.CAUTION: Ceci vous invite à bien prêter attention.DANGER: Ceci est un avertissement.","code":""},{"path":"editorial_notes.html","id":"choix-techniques","chapter":"1 Notes techniques et choix éditoriaux","heading":"1.2 Choix techniques","text":"Ci-dessous, nous décrivons les principales décisions concernant le choix des paquets et des fonctions. Si vous n’êtes pas d’accord ou si vous souhaitez proposer un nouvel outil à examiner, veuillez rejoindre/démarrer une conversation sur notre page Github.Tableau des paquets, fonction et autres choix techniques","code":""},{"path":"editorial_notes.html","id":"révisions-majeures","chapter":"1 Notes techniques et choix éditoriaux","heading":"1.3 Révisions majeures","text":"NEWS\nAvec la version 1.0.1, les changements suivants ont été mis en œuvre :Mise à jour vers la version 4.2 de RNettoyage des données : remplacement de {linelist} par {matchmaker}, suppression d’une ligne inutile dans l’exemple case_when().Dates : remplacement de {linelist} guess_date() par {parsedate} parse_date().Pivot : légère mise à jour de pivot_wider()id_cols=`.Analyse d’enquête : remplacement de plot_age_pyramid() par age_pyramid(), légère modification du code du tracé alluvial.Graphiques de chaleur : ajout de ungroup() au chunk agg_weeks.Graphiques interactifs : ajout de ungroup() au chunk qui fait agg_weeks pour que expand() fonctionne comme prévu.Séries temporelles : ajout de data.frame() autour des objets dans toutes les commandes trending::fit() et predict().Analyse des combinaisons : Remplacer case_when() par ifelse() et ajouter le code optionnel across() pour préparer les données.","code":""},{"path":"editorial_notes.html","id":"information-de-session-r-rstudio-paquets","chapter":"1 Notes techniques et choix éditoriaux","heading":"1.4 Information de session (R, RStudio, paquets)","text":"Vous trouverez ci-dessous les informations sur les versions de R, RStudio et les paquets R utilisés lors de la compilation du guide.","code":"\nsessioninfo::session_info()## ─ Session info ───────────────────────────────────────────────────────────────────────\n##  setting  value\n##  version  R version 4.3.0 (2023-04-21 ucrt)\n##  os       Windows 11 x64 (build 22621)\n##  system   x86_64, mingw32\n##  ui       RStudio\n##  language (EN)\n##  collate  English_United States.utf8\n##  ctype    English_United States.utf8\n##  tz       Europe/Berlin\n##  date     2023-05-21\n##  rstudio  2023.03.1+446 Cherry Blossom (desktop)\n##  pandoc   2.19.2 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n## \n## ─ Packages ───────────────────────────────────────────────────────────────────────────\n##  ! package              * version    date (UTC) lib source\n##    abind                * 1.4-5      2016-07-21 [1] CRAN (R 4.3.0)\n##    ada                    2.0-5      2016-05-13 [1] CRAN (R 4.3.0)\n##    adagio                 0.8.5      2022-10-03 [1] CRAN (R 4.3.0)\n##    ade4                   1.7-22     2023-02-06 [1] CRAN (R 4.3.0)\n##    anytime                0.3.9      2020-08-27 [1] CRAN (R 4.3.0)\n##    ape                  * 5.7-1      2023-03-13 [1] CRAN (R 4.3.0)\n##    aplot                  0.1.10     2023-03-08 [1] CRAN (R 4.3.0)\n##    apyramid             * 0.1.3      2023-02-14 [1] CRAN (R 4.3.0)\n##    arm                    1.13-1     2022-08-28 [1] CRAN (R 4.3.0)\n##    askpass                1.1        2019-01-13 [1] CRAN (R 4.3.0)\n##    assertive.base         0.0-9      2021-02-08 [1] CRAN (R 4.3.0)\n##    assertive.properties   0.0-5      2022-04-21 [1] CRAN (R 4.3.0)\n##    assertive.types        0.0-3      2016-12-30 [1] CRAN (R 4.3.0)\n##    assertthat             0.2.1      2019-03-21 [1] CRAN (R 4.3.0)\n##    aweek                * 1.0.3      2022-10-06 [1] CRAN (R 4.3.0)\n##    backports              1.4.1      2021-12-13 [1] CRAN (R 4.3.0)\n##    base64enc              0.1-3      2015-07-28 [1] CRAN (R 4.3.0)\n##    bayestestR           * 0.13.1     2023-04-07 [1] CRAN (R 4.3.0)\n##    BiocManager          * 1.30.20    2023-02-24 [1] CRAN (R 4.3.0)\n##    bit                  * 4.0.5      2022-11-15 [1] CRAN (R 4.3.0)\n##    bit64                  4.0.5      2020-08-30 [1] CRAN (R 4.3.0)\n##    blob                   1.2.4      2023-03-17 [1] CRAN (R 4.3.0)\n##    bookdown               0.34       2023-05-09 [1] CRAN (R 4.3.0)\n##    boot                 * 1.3-28.1   2022-11-22 [2] CRAN (R 4.3.0)\n##    broom                * 1.0.4      2023-03-11 [1] CRAN (R 4.3.0)\n##    broom.helpers          1.13.0     2023-03-28 [1] CRAN (R 4.3.0)\n##    bslib                  0.4.2      2022-12-16 [1] CRAN (R 4.3.0)\n##    cachem                 1.0.8      2023-05-01 [1] CRAN (R 4.3.0)\n##    callr                  3.7.3      2022-11-02 [1] CRAN (R 4.3.0)\n##    car                    3.1-2      2023-03-30 [1] CRAN (R 4.3.0)\n##    carData                3.0-5      2022-01-06 [1] CRAN (R 4.3.0)\n##    cellranger             1.1.0      2016-07-27 [1] CRAN (R 4.3.0)\n##    ciTools                0.6.1      2020-10-25 [1] CRAN (R 4.3.0)\n##    class                  7.3-21     2023-01-23 [2] CRAN (R 4.3.0)\n##    classInt               0.4-9      2023-02-28 [1] CRAN (R 4.3.0)\n##    cli                    3.6.1      2023-03-23 [1] CRAN (R 4.3.0)\n##    clipr                  0.8.0      2022-02-22 [1] CRAN (R 4.3.0)\n##    cmprsk                 2.2-11     2022-01-06 [1] CRAN (R 4.3.0)\n##    coarseDataTools        0.6-6      2021-12-09 [1] CRAN (R 4.3.0)\n##    coda                   0.19-4     2020-09-30 [1] CRAN (R 4.3.0)\n##    codetools              0.2-19     2023-02-01 [2] CRAN (R 4.3.0)\n##    colorspace             2.1-0      2023-01-23 [1] CRAN (R 4.3.0)\n##    commonmark             1.9.0      2023-03-17 [1] CRAN (R 4.3.0)\n##    correlation          * 0.8.4      2023-04-06 [1] CRAN (R 4.3.0)\n##    corrr                * 0.4.4      2022-08-16 [1] CRAN (R 4.3.0)\n##    cowplot              * 1.1.1      2020-12-30 [1] CRAN (R 4.3.0)\n##    crayon                 1.5.2      2022-09-29 [1] CRAN (R 4.3.0)\n##    crosstalk              1.2.0      2021-11-04 [1] CRAN (R 4.3.0)\n##    crul                   1.4.0      2023-05-17 [1] CRAN (R 4.3.0)\n##    curl                   5.0.0      2023-01-12 [1] CRAN (R 4.3.0)\n##    data.table           * 1.14.8     2023-02-17 [1] CRAN (R 4.3.0)\n##    datawizard           * 0.7.1      2023-04-03 [1] CRAN (R 4.3.0)\n##    DBI                  * 1.1.3      2022-06-18 [1] CRAN (R 4.3.0)\n##    deldir                 1.0-9      2023-05-17 [1] CRAN (R 4.3.0)\n##    Deriv                  4.1.3      2021-02-24 [1] CRAN (R 4.3.0)\n##    desc                   1.4.2      2022-09-08 [1] CRAN (R 4.3.0)\n##    DiagrammeR           * 1.0.10     2023-05-18 [1] CRAN (R 4.3.0)\n##    dichromat              2.0-0.1    2022-05-02 [1] CRAN (R 4.3.0)\n##    digest                 0.6.31     2022-12-11 [1] CRAN (R 4.3.0)\n##    distcrete            * 1.0.3      2017-11-23 [1] CRAN (R 4.3.0)\n##    distributional         0.3.2      2023-03-22 [1] CRAN (R 4.3.0)\n##    doBy                 * 4.6.16     2023-01-18 [1] CRAN (R 4.3.0)\n##    doParallel             1.0.17     2022-02-07 [1] CRAN (R 4.3.0)\n##    downlit                0.4.2      2022-07-05 [1] CRAN (R 4.3.0)\n##    dplyr                * 1.1.2      2023-04-20 [1] CRAN (R 4.3.0)\n##    dsr                  * 0.2.2      2019-08-23 [1] CRAN (R 4.3.0)\n##    DT                   * 0.28       2023-05-18 [1] CRAN (R 4.3.0)\n##    e1071                  1.7-13     2023-02-01 [1] CRAN (R 4.3.0)\n##    easystats            * 0.6.0      2022-11-29 [1] CRAN (R 4.3.0)\n##    ecmwfr               * 1.5.0      2023-01-19 [1] CRAN (R 4.3.0)\n##    effectsize           * 0.8.3      2023-01-28 [1] CRAN (R 4.3.0)\n##    ellipsis               0.3.2      2021-04-29 [1] CRAN (R 4.3.0)\n##    Epi                  * 2.47.1     2023-04-25 [1] CRAN (R 4.3.0)\n##    epicontacts          * 1.2.0      2023-05-21 [1] Github (reconhub/epicontacts@7df53e5)\n##    epidict                0.0.0.9001 2023-05-21 [1] Github (R4EPI/epidict@9cf5a53)\n##    EpiEstim             * 2.2-4      2021-01-07 [1] CRAN (R 4.3.0)\n##    epikit               * 0.1.5      2023-02-15 [1] CRAN (R 4.3.0)\n##    EpiNow2              * 1.3.5      2023-04-27 [1] CRAN (R 4.3.0)\n##    epitabulate            0.0.0.9007 2023-05-21 [1] Github (R4EPI/epitabulate@56370b8)\n##    epitrix              * 0.4.0      2023-01-13 [1] CRAN (R 4.3.0)\n##    etm                    1.1.1      2020-09-08 [1] CRAN (R 4.3.0)\n##    evaluate               0.21       2023-05-05 [1] CRAN (R 4.3.0)\n##    evd                    2.3-6.1    2022-07-04 [1] CRAN (R 4.3.0)\n##    fabletools           * 0.3.3      2023-04-04 [1] CRAN (R 4.3.0)\n##    FactoClass             1.2.7      2018-10-01 [1] CRAN (R 4.3.0)\n##    fansi                  1.0.4      2023-01-22 [1] CRAN (R 4.3.0)\n##    farver                 2.1.1      2022-07-06 [1] CRAN (R 4.3.0)\n##    fastLink             * 0.6.0      2020-04-29 [1] CRAN (R 4.3.0)\n##    fastmap                1.1.1      2023-02-24 [1] CRAN (R 4.3.0)\n##    feasts               * 0.3.1      2023-03-22 [1] CRAN (R 4.3.0)\n##    ff                   * 4.0.9      2023-01-25 [1] CRAN (R 4.3.0)\n##    fitdistrplus           1.1-11     2023-04-25 [1] CRAN (R 4.3.0)\n##    flexdashboard        * 0.6.1      2023-01-23 [1] CRAN (R 4.3.0)\n##    flextable            * 0.9.1      2023-04-02 [1] CRAN (R 4.3.0)\n##    fontBitstreamVera      0.1.1      2017-02-01 [1] CRAN (R 4.3.0)\n##    fontLiberation         0.1.0      2016-10-15 [1] CRAN (R 4.3.0)\n##    fontquiver             0.2.1      2017-02-01 [1] CRAN (R 4.3.0)\n##    forcats              * 1.0.0      2023-01-29 [1] CRAN (R 4.3.0)\n##    foreach                1.5.2      2022-02-02 [1] CRAN (R 4.3.0)\n##    forecast             * 8.21       2023-02-27 [1] CRAN (R 4.3.0)\n##    foreign                0.8-84     2022-12-06 [2] CRAN (R 4.3.0)\n##    formatR                1.14       2023-01-17 [1] CRAN (R 4.3.0)\n##    formattable          * 0.2.1      2021-01-07 [1] CRAN (R 4.3.0)\n##    Formula              * 1.2-5      2023-02-24 [1] CRAN (R 4.3.0)\n##    fracdiff               1.5-2      2022-10-31 [1] CRAN (R 4.3.0)\n##    frailtypack          * 3.5.0      2021-12-20 [1] CRAN (R 4.3.0)\n##    fs                   * 1.6.2      2023-04-25 [1] CRAN (R 4.3.0)\n##    futile.logger          1.4.3      2016-07-10 [1] CRAN (R 4.3.0)\n##    futile.options         1.0.1      2018-04-20 [1] CRAN (R 4.3.0)\n##    future                 1.32.0     2023-03-07 [1] CRAN (R 4.3.0)\n##    future.apply           1.11.0     2023-05-21 [1] CRAN (R 4.3.0)\n##    gdtools                0.3.3      2023-03-27 [1] CRAN (R 4.3.0)\n##    generics               0.1.3      2022-07-05 [1] CRAN (R 4.3.0)\n##    gfonts                 0.2.0      2023-01-08 [1] CRAN (R 4.3.0)\n##    ggExtra              * 0.10.0     2022-03-23 [1] CRAN (R 4.3.0)\n##    ggforce              * 0.4.1      2022-10-04 [1] CRAN (R 4.3.0)\n##    ggfun                  0.0.9      2022-11-21 [1] CRAN (R 4.3.0)\n##    gghighlight          * 0.4.0      2022-10-16 [1] CRAN (R 4.3.0)\n##    ggnewscale           * 0.4.8      2022-10-06 [1] CRAN (R 4.3.0)\n##    ggplot2              * 3.4.2      2023-04-03 [1] CRAN (R 4.3.0)\n##    ggplotify              0.1.0      2021-09-02 [1] CRAN (R 4.3.0)\n##    ggpubr               * 0.6.0      2023-02-10 [1] CRAN (R 4.3.0)\n##    ggrepel              * 0.9.3      2023-02-03 [1] CRAN (R 4.3.0)\n##    ggsignif               0.6.4      2022-10-13 [1] CRAN (R 4.3.0)\n##    ggtext                 0.1.2      2022-09-16 [1] CRAN (R 4.3.0)\n##    ggtree               * 3.8.0      2023-04-25 [1] Bioconductor\n##    ggupset              * 0.3.0      2020-05-05 [1] CRAN (R 4.3.0)\n##    globals                0.16.2     2022-11-21 [1] CRAN (R 4.3.0)\n##    glue                   1.6.2      2022-02-24 [1] CRAN (R 4.3.0)\n##    grates               * 1.0.1      2023-04-02 [1] CRAN (R 4.3.0)\n##    gridExtra              2.3        2017-09-09 [1] CRAN (R 4.3.0)\n##    gridGraphics           0.5-1      2020-12-13 [1] CRAN (R 4.3.0)\n##    gridtext               0.1.5      2022-09-16 [1] CRAN (R 4.3.0)\n##    gt                     0.9.0      2023-03-31 [1] CRAN (R 4.3.0)\n##    gtable                 0.3.3      2023-03-21 [1] CRAN (R 4.3.0)\n##    gtools                 3.9.4      2022-11-27 [1] CRAN (R 4.3.0)\n##    gtsummary            * 1.7.1      2023-04-27 [1] CRAN (R 4.3.0)\n##    haven                  2.5.2      2023-02-28 [1] CRAN (R 4.3.0)\n##    here                 * 1.0.1      2020-12-13 [1] CRAN (R 4.3.0)\n##    highcharter          * 0.9.4      2022-01-03 [1] CRAN (R 4.3.0)\n##    highr                  0.10       2022-12-22 [1] CRAN (R 4.3.0)\n##    hms                    1.1.3      2023-03-21 [1] CRAN (R 4.3.0)\n##    htmltools              0.5.5      2023-03-23 [1] CRAN (R 4.3.0)\n##    htmlwidgets            1.6.2      2023-03-17 [1] CRAN (R 4.3.0)\n##    httpcode               0.3.0      2020-04-10 [1] CRAN (R 4.3.0)\n##    httpuv                 1.6.11     2023-05-11 [1] CRAN (R 4.3.0)\n##    httr                   1.4.6      2023-05-08 [1] CRAN (R 4.3.0)\n##    i2extras             * 0.2.1      2023-03-17 [1] CRAN (R 4.3.0)\n##    igraph                 1.4.2      2023-04-07 [1] CRAN (R 4.3.0)\n##    imputeTS             * 3.3        2022-09-09 [1] CRAN (R 4.3.0)\n##    incidence              1.7.3      2020-11-04 [1] CRAN (R 4.3.0)\n##    incidence2           * 2.0.0      2023-03-17 [1] CRAN (R 4.3.0)\n##    inline                 0.3.19     2021-05-31 [1] CRAN (R 4.3.0)\n##    insight              * 0.19.1     2023-03-18 [1] CRAN (R 4.3.0)\n##    ipred                  0.9-14     2023-03-09 [1] CRAN (R 4.3.0)\n##    isoband                0.2.7      2022-12-20 [1] CRAN (R 4.3.0)\n##    iterators              1.0.14     2022-02-05 [1] CRAN (R 4.3.0)\n##    janitor              * 2.2.0      2023-02-02 [1] CRAN (R 4.3.0)\n##    jpeg                   0.1-10     2022-11-29 [1] CRAN (R 4.3.0)\n##    jquerylib              0.1.4      2021-04-26 [1] CRAN (R 4.3.0)\n##    jsonlite               1.8.4      2022-12-06 [1] CRAN (R 4.3.0)\n##    kableExtra           * 1.3.4      2021-02-20 [1] CRAN (R 4.3.0)\n##    KernSmooth             2.23-20    2021-05-03 [2] CRAN (R 4.3.0)\n##    km.ci                  0.5-6      2022-04-06 [1] CRAN (R 4.3.0)\n##    KMsurv                 0.1-5      2012-12-03 [1] CRAN (R 4.3.0)\n##    knitr                  1.42       2023-01-25 [1] CRAN (R 4.3.0)\n##    labeling               0.4.2      2020-10-20 [1] CRAN (R 4.3.0)\n##    labelled               2.11.0     2023-04-11 [1] CRAN (R 4.3.0)\n##    lambda.r               1.2.4      2019-09-18 [1] CRAN (R 4.3.0)\n##    later                  1.3.1      2023-05-02 [1] CRAN (R 4.3.0)\n##    lattice                0.21-8     2023-04-05 [2] CRAN (R 4.3.0)\n##    lava                   1.7.2.1    2023-02-27 [1] CRAN (R 4.3.0)\n##    lazyeval               0.2.2      2019-03-15 [1] CRAN (R 4.3.0)\n##    leafem                 0.2.0      2022-04-16 [1] CRAN (R 4.3.0)\n##    leaflet                2.1.2      2023-03-10 [1] CRAN (R 4.3.0)\n##    leaflet.providers      1.9.0      2019-11-09 [1] CRAN (R 4.3.0)\n##    leafsync               0.1.0      2019-03-05 [1] CRAN (R 4.3.0)\n##    lifecycle              1.0.3      2022-10-07 [1] CRAN (R 4.3.0)\n##    listenv                0.9.0      2022-12-16 [1] CRAN (R 4.3.0)\n##    lme4                   1.1-33     2023-04-25 [1] CRAN (R 4.3.0)\n##    lmtest               * 0.9-40     2022-03-21 [1] CRAN (R 4.3.0)\n##    loo                    2.6.0      2023-03-31 [1] CRAN (R 4.3.0)\n##    lpSolve                5.6.18     2023-02-01 [1] CRAN (R 4.3.0)\n##    lubridate            * 1.9.2      2023-02-10 [1] CRAN (R 4.3.0)\n##    lwgeom                 0.2-11     2023-01-14 [1] CRAN (R 4.3.0)\n##    magrittr             * 2.0.3      2022-03-30 [1] CRAN (R 4.3.0)\n##    markdown               1.7        2023-05-16 [1] CRAN (R 4.3.0)\n##    MASS                 * 7.3-58.4   2023-03-07 [2] CRAN (R 4.3.0)\n##    matchmaker           * 0.1.1      2020-02-21 [1] CRAN (R 4.3.0)\n##    Matrix               * 1.5-4      2023-04-04 [2] CRAN (R 4.3.0)\n##    MatrixModels           0.5-1      2022-09-11 [1] CRAN (R 4.3.0)\n##    matrixStats            0.63.0     2022-11-18 [1] CRAN (R 4.3.0)\n##    mcmc                   0.9-7      2020-03-21 [1] CRAN (R 4.3.0)\n##    MCMCpack               1.6-3      2022-04-13 [1] CRAN (R 4.3.0)\n##    memoise                2.0.1      2021-11-26 [1] CRAN (R 4.3.0)\n##    mgcv                   1.8-42     2023-03-02 [2] CRAN (R 4.3.0)\n##    mice                 * 3.15.0     2022-11-19 [1] CRAN (R 4.3.0)\n##    microbenchmark         1.4.10     2023-04-28 [1] CRAN (R 4.3.0)\n##    mime                   0.12       2021-09-28 [1] CRAN (R 4.3.0)\n##    miniUI                 0.1.1.1    2018-05-18 [1] CRAN (R 4.3.0)\n##    minqa                  1.2.5      2022-10-19 [1] CRAN (R 4.3.0)\n##    mitools                2.4        2019-04-26 [1] CRAN (R 4.3.0)\n##    modelbased           * 0.8.6      2023-01-13 [1] CRAN (R 4.3.0)\n##    munsell                0.5.0      2018-06-12 [1] CRAN (R 4.3.0)\n##    naniar               * 1.0.0      2023-02-02 [1] CRAN (R 4.3.0)\n##    networkD3            * 0.4        2017-03-18 [1] CRAN (R 4.3.0)\n##    nlme                   3.1-162    2023-01-31 [2] CRAN (R 4.3.0)\n##    nloptr                 2.0.3      2022-05-26 [1] CRAN (R 4.3.0)\n##    nnet                   7.3-18     2022-09-28 [2] CRAN (R 4.3.0)\n##    numDeriv               2016.8-1.1 2019-06-06 [1] CRAN (R 4.3.0)\n##    officer              * 0.6.2      2023-03-28 [1] CRAN (R 4.3.0)\n##    openssl                2.0.6      2023-03-09 [1] CRAN (R 4.3.0)\n##    OpenStreetMap        * 0.3.4      2019-05-31 [1] CRAN (R 4.3.0)\n##    openxlsx               4.2.5.2    2023-02-06 [1] CRAN (R 4.3.0)\n##    pacman                 0.5.1      2019-03-11 [1] CRAN (R 4.3.0)\n##    parallelly             1.35.0     2023-03-23 [1] CRAN (R 4.3.0)\n##    parameters           * 0.21.0     2023-04-19 [1] CRAN (R 4.3.0)\n##    parsedate            * 1.3.1      2022-10-27 [1] CRAN (R 4.3.0)\n##    patchwork            * 1.1.2      2022-08-19 [1] CRAN (R 4.3.0)\n##    performance          * 0.10.3     2023-04-07 [1] CRAN (R 4.3.0)\n##    PerformanceAnalytics * 2.0.4      2020-02-06 [1] CRAN (R 4.3.0)\n##    PHEindicatormethods  * 2.0.1      2023-05-05 [1] CRAN (R 4.3.0)\n##    pillar                 1.9.0      2023-03-22 [1] CRAN (R 4.3.0)\n##    pkgbuild               1.4.0      2022-11-27 [1] CRAN (R 4.3.0)\n##    pkgconfig              2.0.3      2019-09-22 [1] CRAN (R 4.3.0)\n##    plotly               * 4.10.1     2022-11-07 [1] CRAN (R 4.3.0)\n##    plotrix                3.8-2      2021-09-08 [1] CRAN (R 4.3.0)\n##    plyr                   1.8.8      2022-11-11 [1] CRAN (R 4.3.0)\n##    png                    0.1-8      2022-11-29 [1] CRAN (R 4.3.0)\n##    polyclip               1.10-4     2022-10-20 [1] CRAN (R 4.3.0)\n##    polyCub                0.8.1      2022-11-28 [1] CRAN (R 4.3.0)\n##    prettyunits            1.1.1      2020-01-24 [1] CRAN (R 4.3.0)\n##    processx               3.8.1      2023-04-18 [1] CRAN (R 4.3.0)\n##    prodlim                2023.03.31 2023-04-02 [1] CRAN (R 4.3.0)\n##    progressr              0.13.0     2023-01-10 [1] CRAN (R 4.3.0)\n##    projections          * 0.6.0      2023-03-23 [1] CRAN (R 4.3.0)\n##    promises               1.2.0.1    2021-02-11 [1] CRAN (R 4.3.0)\n##    proxy                  0.4-27     2022-06-09 [1] CRAN (R 4.3.0)\n##    ps                     1.7.5      2023-04-18 [1] CRAN (R 4.3.0)\n##    purrr                * 1.0.1      2023-01-10 [1] CRAN (R 4.3.0)\n##    quadprog               1.5-8      2019-11-20 [1] CRAN (R 4.3.0)\n##    Quandl                 2.11.0     2021-08-11 [1] CRAN (R 4.3.0)\n##    quantmod             * 0.4.22     2023-04-07 [1] CRAN (R 4.3.0)\n##    quantreg               5.95       2023-04-08 [1] CRAN (R 4.3.0)\n##    R.methodsS3            1.8.2      2022-06-13 [1] CRAN (R 4.3.0)\n##    R.oo                   1.25.0     2022-06-12 [1] CRAN (R 4.3.0)\n##    R.utils                2.12.2     2022-11-11 [1] CRAN (R 4.3.0)\n##    R6                     2.5.1      2021-08-19 [1] CRAN (R 4.3.0)\n##    ragg                   1.2.5      2023-01-12 [1] CRAN (R 4.3.0)\n##    raster                 3.6-20     2023-03-06 [1] CRAN (R 4.3.0)\n##    RColorBrewer         * 1.1-3      2022-04-03 [1] CRAN (R 4.3.0)\n##    Rcpp                 * 1.0.10     2023-01-22 [1] CRAN (R 4.3.0)\n##  D RcppParallel           5.1.7      2023-02-27 [1] CRAN (R 4.3.0)\n##    readr                * 2.1.4      2023-02-10 [1] CRAN (R 4.3.0)\n##    readxl               * 1.4.2      2023-02-09 [1] CRAN (R 4.3.0)\n##    RecordLinkage        * 0.4-12.4   2022-11-08 [1] CRAN (R 4.3.0)\n##    remotes                2.4.2      2021-11-30 [1] CRAN (R 4.3.0)\n##    report               * 0.5.7      2023-03-22 [1] CRAN (R 4.3.0)\n##    repr                   1.1.6      2023-01-26 [1] CRAN (R 4.3.0)\n##    reprex                 2.0.2      2022-08-17 [1] CRAN (R 4.3.0)\n##    reshape2               1.4.4      2020-04-09 [1] CRAN (R 4.3.0)\n##    rgdal                  1.6-6      2023-04-18 [1] CRAN (R 4.3.0)\n##    rio                  * 0.5.29     2021-11-22 [1] CRAN (R 4.3.0)\n##  D rJava                  1.0-6      2021-12-10 [1] CRAN (R 4.3.0)\n##    rlang                  1.1.1      2023-04-28 [1] CRAN (R 4.3.0)\n##    rlist                  0.4.6.2    2021-09-03 [1] CRAN (R 4.3.0)\n##    rmarkdown              2.21       2023-03-26 [1] CRAN (R 4.3.0)\n##    rootSolve              1.8.2.3    2021-09-29 [1] CRAN (R 4.3.0)\n##    rpart                  4.1.19     2022-10-21 [2] CRAN (R 4.3.0)\n##    rprojroot              2.0.3      2022-04-02 [1] CRAN (R 4.3.0)\n##    RSQLite              * 2.3.1      2023-04-03 [1] CRAN (R 4.3.0)\n##    rstan                  2.21.8     2023-01-17 [1] CRAN (R 4.3.0)\n##    rstantools             2.3.1      2023-03-30 [1] CRAN (R 4.3.0)\n##    rstatix              * 0.7.2      2023-02-01 [1] CRAN (R 4.3.0)\n##    rstudioapi             0.14       2022-08-22 [1] CRAN (R 4.3.0)\n##    runner                 0.4.3      2023-03-21 [1] CRAN (R 4.3.0)\n##    rvest                  1.0.3      2022-08-19 [1] CRAN (R 4.3.0)\n##    s2                     1.1.4      2023-05-17 [1] CRAN (R 4.3.0)\n##    sass                   0.4.6      2023-05-03 [1] CRAN (R 4.3.0)\n##    scales               * 1.2.1      2022-08-20 [1] CRAN (R 4.3.0)\n##    scatterplot3d          0.3-44     2023-05-05 [1] CRAN (R 4.3.0)\n##    see                  * 0.7.5      2023-03-23 [1] CRAN (R 4.3.0)\n##    SemiCompRisks        * 3.4        2021-02-03 [1] CRAN (R 4.3.0)\n##    sessioninfo            1.2.2      2021-12-06 [1] CRAN (R 4.3.0)\n##    sf                   * 1.0-12     2023-03-19 [1] CRAN (R 4.3.0)\n##    shiny                * 1.7.4      2022-12-15 [1] CRAN (R 4.3.0)\n##    sitrep               * 0.2.3      2023-05-21 [1] Github (r4epi/sitrep@b96906b)\n##    skimr                * 2.1.5      2022-12-23 [1] CRAN (R 4.3.0)\n##    slider               * 0.3.0      2022-11-16 [1] CRAN (R 4.3.0)\n##    snakecase              0.11.0     2019-05-25 [1] CRAN (R 4.3.0)\n##    sp                   * 1.6-0      2023-01-19 [1] CRAN (R 4.3.0)\n##    SparseM                1.81       2021-02-18 [1] CRAN (R 4.3.0)\n##    spatstat.data          3.0-1      2023-03-12 [1] CRAN (R 4.3.0)\n##    spatstat.geom          3.2-1      2023-05-09 [1] CRAN (R 4.3.0)\n##    spatstat.utils         3.0-3      2023-05-09 [1] CRAN (R 4.3.0)\n##    spData               * 2.2.2      2023-03-01 [1] CRAN (R 4.3.0)\n##    spdep                * 1.2-8      2023-02-28 [1] CRAN (R 4.3.0)\n##    srvyr                * 1.2.0      2023-02-21 [1] CRAN (R 4.3.0)\n##    StanHeaders            2.26.25    2023-05-17 [1] CRAN (R 4.3.0)\n##    stars                * 0.6-1      2023-04-06 [1] CRAN (R 4.3.0)\n##    statmod                1.5.0      2023-01-06 [1] CRAN (R 4.3.0)\n##    stinepack              1.4        2018-07-30 [1] CRAN (R 4.3.0)\n##    stringdist           * 0.9.10     2022-11-07 [1] CRAN (R 4.3.0)\n##    stringi                1.7.12     2023-01-11 [1] CRAN (R 4.3.0)\n##    stringr              * 1.5.0      2022-12-02 [1] CRAN (R 4.3.0)\n##    survC1               * 1.0-3      2021-02-10 [1] CRAN (R 4.3.0)\n##    surveillance         * 1.21.1     2023-05-19 [1] CRAN (R 4.3.0)\n##    survey               * 4.2-1      2023-05-03 [1] CRAN (R 4.3.0)\n##    survival             * 3.5-5      2023-03-12 [2] CRAN (R 4.3.0)\n##    survminer            * 0.4.9      2021-03-09 [1] CRAN (R 4.3.0)\n##    survMisc               0.5.6      2022-04-07 [1] CRAN (R 4.3.0)\n##    svglite                2.1.1      2023-01-10 [1] CRAN (R 4.3.0)\n##    systemfonts            1.0.4      2022-02-11 [1] CRAN (R 4.3.0)\n##    terra                  1.7-29     2023-04-22 [1] CRAN (R 4.3.0)\n##    textshaping            0.3.6      2021-10-13 [1] CRAN (R 4.3.0)\n##    tibble               * 3.2.1      2023-03-20 [1] CRAN (R 4.3.0)\n##    tidyquant            * 1.0.7      2023-03-31 [1] CRAN (R 4.3.0)\n##    tidyr                * 1.3.0      2023-01-24 [1] CRAN (R 4.3.0)\n##    tidyselect             1.2.0      2022-10-10 [1] CRAN (R 4.3.0)\n##    tidytree               0.4.2      2022-12-18 [1] CRAN (R 4.3.0)\n##    tidyverse            * 2.0.0      2023-02-22 [1] CRAN (R 4.3.0)\n##    timechange             0.2.0      2023-01-11 [1] CRAN (R 4.3.0)\n##    timeDate               4022.108   2023-01-07 [1] CRAN (R 4.3.0)\n##    tinytex                0.45       2023-04-18 [1] CRAN (R 4.3.0)\n##    tmap                 * 3.3-3      2022-03-02 [1] CRAN (R 4.3.0)\n##    tmaptools            * 3.1-1      2021-01-19 [1] CRAN (R 4.3.0)\n##    treeio               * 1.24.0     2023-04-25 [1] Bioconductor\n##    trending             * 0.1.0      2023-04-03 [1] CRAN (R 4.3.0)\n##    truncnorm              1.0-9      2023-03-20 [1] CRAN (R 4.3.0)\n##    tseries                0.10-54    2023-05-02 [1] CRAN (R 4.3.0)\n##    tsibble              * 1.1.3      2022-10-09 [1] CRAN (R 4.3.0)\n##    TTR                  * 0.24.3     2021-12-12 [1] CRAN (R 4.3.0)\n##    tweenr                 2.0.2      2022-09-06 [1] CRAN (R 4.3.0)\n##    tzdb                   0.4.0      2023-05-12 [1] CRAN (R 4.3.0)\n##    units                * 0.8-2      2023-04-27 [1] CRAN (R 4.3.0)\n##    UpSetR               * 1.4.0      2019-05-22 [1] CRAN (R 4.3.0)\n##    urca                   1.3-3      2022-08-29 [1] CRAN (R 4.3.0)\n##    utf8                   1.2.3      2023-01-31 [1] CRAN (R 4.3.0)\n##    uuid                   1.1-0      2022-04-19 [1] CRAN (R 4.3.0)\n##    vctrs                  0.6.2      2023-04-19 [1] CRAN (R 4.3.0)\n##    viridis                0.6.3      2023-05-03 [1] CRAN (R 4.3.0)\n##    viridisLite            0.4.2      2023-05-02 [1] CRAN (R 4.3.0)\n##    visdat                 0.6.0      2023-02-02 [1] CRAN (R 4.3.0)\n##    visNetwork           * 2.1.2      2022-09-29 [1] CRAN (R 4.3.0)\n##    vistime              * 1.2.3      2022-10-16 [1] CRAN (R 4.3.0)\n##    warp                   0.2.0      2020-10-21 [1] CRAN (R 4.3.0)\n##    webshot              * 0.5.4      2022-09-26 [1] CRAN (R 4.3.0)\n##    withr                  2.5.0      2022-03-03 [1] CRAN (R 4.3.0)\n##    wk                     0.7.3      2023-05-06 [1] CRAN (R 4.3.0)\n##    writexl              * 1.4.2      2023-01-06 [1] CRAN (R 4.3.0)\n##    xfun                   0.39       2023-04-20 [1] CRAN (R 4.3.0)\n##    XML                    3.99-0.14  2023-03-19 [1] CRAN (R 4.3.0)\n##    xml2                   1.3.4      2023-04-27 [1] CRAN (R 4.3.0)\n##    xtable               * 1.8-4      2019-04-21 [1] CRAN (R 4.3.0)\n##    xts                  * 0.13.1     2023-04-16 [1] CRAN (R 4.3.0)\n##    yaml                   2.3.7      2023-01-23 [1] CRAN (R 4.3.0)\n##    yardstick            * 1.2.0      2023-04-21 [1] CRAN (R 4.3.0)\n##    yulab.utils            0.0.6      2022-12-20 [1] CRAN (R 4.3.0)\n##    zip                    2.3.0      2023-04-17 [1] CRAN (R 4.3.0)\n##    zoo                  * 1.8-12     2023-04-13 [1] CRAN (R 4.3.0)\n## \n##  [1] C:/Users/neale/AppData/Local/R/win-library/4.3\n##  [2] C:/Program Files/R/R-4.3.0/library\n## \n##  D ── DLL MD5 mismatch, broken installation.\n## \n## ──────────────────────────────────────────────────────────────────────────────────────"},{"path":"download_book_data.html","id":"download_book_data","chapter":"2 Télécharger le manuel et les données","heading":"2 Télécharger le manuel et les données","text":"","code":""},{"path":"download_book_data.html","id":"download_offline","chapter":"2 Télécharger le manuel et les données","heading":"2.1 Télécharger le manuel hors-ligne","text":"Vous pouvez télécharger la version hors-ligne de ce manuel en tant que fichier HTML afin de pouvoir le visualiser dans votre navigateur Web même si vous n’avez plus accès à Internet. Si vous envisagez d’utiliser le manuel Epi R hors ligne, voici quelques éléments à prendre en compte :Lorsque vous ouvrez le fichier, le chargement des images et de la table des matières peut prendre une minute ou deux.Le manuel hors ligne une mise en page légèrement différente : une très longue page avec la table des matières à gauche. Pour rechercher des termes spécifiques, utilisez Ctrl + F (Cmd + F).Consultez la page Paquets conseillés pour vous aider à installer les paquets R appropriés avant de perdre votre connexion à Internet.Installez notre paquet R epirhandbook qui contient toutes les données utilisées dans les exemples (le processus d’installation est décrit ci-dessous).Il y deux façons de télécharger le manuel :","code":""},{"path":"download_book_data.html","id":"utiliser-le-lien-de-téléchargement","chapter":"2 Télécharger le manuel et les données","heading":"Utiliser le lien de téléchargement","text":"Pour un accès rapide, cliquez à droite ce lien et sélectionnez “Enregistrer le lien sous”.Si vous êtes sur un Mac, utilisez Cmd + clic. Si vous êtes sur un téléphone portable, appuyez sur le lien et maintenez-le enfoncé, puis sélectionnez “Enregistrer le lien”. Le manuel sera téléchargé sur votre appareil. Si un écran contenant un code HTML brut apparaît, assurez-vous d’avoir suivi les instructions ci-dessus ou essayez l’option 2.","code":""},{"path":"download_book_data.html","id":"utiliser-notre-paquet-r","chapter":"2 Télécharger le manuel et les données","heading":"Utiliser notre paquet R","text":"Nous avons développé un paquet R appelé epirhandbook. Il comprend une fonction download_book() qui télécharge le fichier du guide depuis notre dépôt Github sur votre ordinateur.Ce package contient également une fonction get_data() qui télécharge toutes les données utilisées dans les chapitres sur votre ordinateur.Exécutez le code suivant pour installer notre paquet R epirhandbook à partir du dépôt Github appliedepi. Ce paquet n’est pas sur le CRAN, donc utilisez la fonction spéciale p_install_gh() du paquet pacman pour l’installer depuis Github.Maintenant, importer le paquet pour l’utiliser dans votre session R actuelle :Ensuite, exécutez la fonction du paquet download_book() (avec des parenthèses vides) pour télécharger le manuel sur votre ordinateur. En supposant que vous êtes dans RStudio, une fenêtre apparaîtra pour vous permettre de sélectionner un emplacement de sauvegarde.","code":"\n# installer la dernière version du paquet epirhandbook\npacman::p_install_gh(\"appliedepi/epirhandbook\")\n# Importer le paquet pour pouvoir l'utiliser dans la session ouverte\npacman::p_load(epirhandbook)\n# télécharger la version html du manuel localement\ndownload_book()"},{"path":"download_book_data.html","id":"télécharger-les-données","chapter":"2 Télécharger le manuel et les données","heading":"2.2 Télécharger les données","text":"Pour pouvoir reproduire les exemples au fur et à mesure sur votre ordinateur, vous pouvez télécharger les données et les fichiers générés.","code":""},{"path":"download_book_data.html","id":"utiliser-notre-paquet-r-1","chapter":"2 Télécharger le manuel et les données","heading":"Utiliser notre paquet R","text":"Une fois le paquet téléchargé et importé dans votre session R (voir section au-dessus) utilisez la fonction get_data() du paquet pour obtenir les données d’exemple sur votre ordinateur. Exécutez get_data(\"\") pour obtenir toutes les données d’exemple, ou fournissez un nom de fichier spécifique et une extension entre guillemets pour récupérer un seul fichier.Techniquement, toutes les données ont déjà été téléchargées avec le paquet, et doivent simplement être transférées dans un dossier de votre ordinateur. Une fenêtre pop-apparaîtra, vous permettant de sélectionner un emplacement de dossier de sauvegarde. Nous vous suggérons de créer un nouveau dossier “data” car il y environ 30 fichiers (y compris les données d’exemple et les sorties générées par les exemples).Une fois que vous avez utilisé get_data() pour enregistrer un fichier sur votre ordinateur, vous devrez encore l’importer dans R. Voir la page Importer et exporter des données pour plus de détails.Si vous le souhaitez, vous pouvez consulter toutes les données utilisées dans ce manuel dans le “dossier données” de notre dépôt Github.","code":"\n# enregistrer toutes les données dans un dossier sur votre ordinateur\nget_data(\"all\")\n\n# enregistrer les données linelist dans un dossiet sur votre ordinateur\nget_data(file = \"linelist_cleaned.rds\")"},{"path":"download_book_data.html","id":"téléchargement-manuel","chapter":"2 Télécharger le manuel et les données","heading":"Téléchargement manuel","text":"Vous pouvez télécharger les données fichier par fichier à partir de notre dépôt Github via un lien ou une commande R spécifique au fichier. Certains types de fichiers ont un bouton de téléchargement, tandis que d’autres peuvent être téléchargés via une commande R.","code":""},{"path":"download_book_data.html","id":"liste-de-cas-linelist","chapter":"2 Télécharger le manuel et les données","heading":"Liste de cas (linelist)","text":"Il s’agit d’une linelist pour une épidémie d’Ebola fictive, développée par notre équipe à partir du jeu de données d’exemple ebola_sim du paquet outbreaks.Cliquer pour télécharger les données brutes (.xlsx). La liste de cas “brute” est une feuille de calcul Excel contenant des données désordonnées. Utilisez-la pour suivre la page Nettoyer les données et fonctions essentielles.Cliquer pour télécharger les données brutes (.xlsx). La liste de cas “brute” est une feuille de calcul Excel contenant des données désordonnées. Utilisez-la pour suivre la page Nettoyer les données et fonctions essentielles.Cliquer pour télécharger la linelist nettoyée (.rds). Utilisez ce fichier pour toutes les autres pages de ce manuel qui utilisent la linelist. Un fichier .rds est un type de fichier spécifique à R qui préserve les classes de colonnes. Cela garantit que vous n’aurez qu’un nettoyage minimal à faire après avoir importé les données dans R.Cliquer pour télécharger la linelist nettoyée (.rds). Utilisez ce fichier pour toutes les autres pages de ce manuel qui utilisent la linelist. Un fichier .rds est un type de fichier spécifique à R qui préserve les classes de colonnes. Cela garantit que vous n’aurez qu’un nettoyage minimal à faire après avoir importé les données dans R.Autres fichiers linelist :Cliquer pour télécharger la version nettoyée de la linelist sous format ExcelCliquer pour télécharger la version nettoyée de la linelist sous format ExcelUne partie de la page sur le nettoyage des données utilise un “dictionnaire de nettoyage” (fichier .csv). Vous pouvez le charger directement dans R en exécutant les commandes suivantes :Une partie de la page sur le nettoyage des données utilise un “dictionnaire de nettoyage” (fichier .csv). Vous pouvez le charger directement dans R en exécutant les commandes suivantes :","code":"\npacman::p_load(rio) # installer/importer le paquet **rio**\n\n# importer le fichier directement depuis github\ncleaning_dict <- import(\"https://github.com/appliedepi/epiRhandbook_fr/raw/main/data/case_linelists/cleaning_dict.csv\")"},{"path":"download_book_data.html","id":"data_malaria","chapter":"2 Télécharger le manuel et les données","heading":"Cas de paludisme","text":"Ces données sont des comptages fictifs de cas de paludisme par groupe d’âge, établissement et jour. Un fichier .rds est un type de fichier spécifique à R qui préserve les classes de colonnes. Cela garantit que vous n’aurez qu’un nettoyage minimal à faire après avoir importé les données dans R.\nClick download\nles comptages de de cas de paludisme (.rds file)\n","code":""},{"path":"download_book_data.html","id":"données-sur-léchelle-de-likert","chapter":"2 Télécharger le manuel et les données","heading":"Données sur l’échelle de Likert","text":"Il s’agit de données fictives issues d’une enquête de type Likert, utilisées dans la page Pyramides démographiques et échelles de Likert. Vous pouvez charger ces données directement dans R en exécutant les commandes suivantes :","code":"\npacman::p_load(rio)  # installer/importer le paquet **rio**\n\n# importer le fichier directement depuis github\nlikert_data <- import(\"https://github.com/appliedepi/epiRhandbook_fr/raw/main/data/likert_data.csv\")"},{"path":"download_book_data.html","id":"flexdashboard","chapter":"2 Télécharger le manuel et les données","heading":"Flexdashboard","text":"Vous trouverez ci-dessous des liens vers le fichier associé à la page Tableaux de bord avec R Markdown:Pour télécharger le fichier RMarkdown (.Rmd) du tableau de bord sur les épidémies, faites un clic droit sur ce lien (Cmd+clic pour Mac) et sélectionnez “Enregistrer le lien sous”.Pour télécharger le tableau de bord HTML, cliquez avec le bouton droit de la souris sur ce lien. (Cmd + clic pour Mac) et sélectionnez “Enregistrer le lien sous”.","code":""},{"path":"download_book_data.html","id":"recherche-des-contacts","chapter":"2 Télécharger le manuel et les données","heading":"recherche des contacts","text":"La page Recherche des contacts présente une analyse des données de recherche des contacts, à l’aide d’exemples de données provenant de Go.Data. Les données utilisées dans cette page peuvent être téléchargées sous forme de fichiers .rds en cliquant sur les liens suivants :\nCliquer pour télécharger\nles données d’investigation des cas (.rds file)\n\nCliquer pour télécharger\nles données d’enregistrement des contacts (.rds file)\n\nCliquer pour télécharger\nles données de suivi des contacts (.rds file)\nNOTE: Les données structurées de recherche des contacts provenant d’autres logiciels (par exemple KoBo, DHIS2 Tracker, CommCare) peuvent être organisées differement. Si vous souhaitez contribuer à l’élaboration d’un échantillon de données ou d’un contenu alternatif pour cette page, veuillez nous contacter.TIP: Si vous déployez Go.Data et souhaitez vous connecter à l’API de votre instance, consultez la page Importation et exportation, (section API) et la Communauté de pratique Go.Data.","code":""},{"path":"download_book_data.html","id":"sig","chapter":"2 Télécharger le manuel et les données","heading":"SIG","text":"Les fichiers Shapefiles comportent de nombreux sous-fichiers, chacun avec une extension de fichier différente. Un fichier aura l’extension “.shp”, mais d’autres peuvent avoir “.dbf”, “.prj”, etc.La page Notions de base sur les SIG fournit des liens vers le site Web Humanitarian Data Exchange où vous pouvez télécharger les fichiers de forme directement sous forme de fichiers zippés.Par exemple, les données des locations des établissements de santé peuvent être téléchargées ici. Téléchargez “hotosm_sierra_leone_health_facilities_points_shp.zip”. Une fois enregistré sur votre ordinateur, décompressez le dossier. Vous verrez plusieurs fichiers avec des extensions différentes (par exemple, “.shp”, “.prj”, “.shx”); tous ces fichiers doivent être enregistrés dans le même dossier sur votre ordinateur. Ensuite, pour importer dans R, fournissez le chemin et le nom du fichier “.shp” à st_read() du paquet sf (comme décrit dans la page Notions de base sur les SIG).Si vous suivez l’option 1 pour télécharger toutes les données de l’exemple (via notre paquet R epirhandbook), tous les shapefiles sont inclus.Vous pouvez également télécharger les fichiers Shapefile à partir du dossier “data” du manuel R sur Github (voir le sous-dossier “gis”). Cependant, sachez que vous devrez télécharger chaque sous-fichier individuellement sur votre ordinateur. Dans Github, cliquez sur chaque fichier et téléchargez-les en cliquant sur le bouton “Télécharger”. Ci-dessous, vous pouvez voir comment le fichier de forme “sle_adm3” se compose de plusieurs fichiers, chacun devant être téléchargé depuis Github.","code":""},{"path":"download_book_data.html","id":"arbres-phylogénétiques","chapter":"2 Télécharger le manuel et les données","heading":"Arbres phylogénétiques","text":"La page sur les arbres phylogénétiques utilise un fichier Newick pour l’arbre phylogénétique construit à partir du séquençage du génome entier de 299 échantillons de Shigella sonnei et des données d’échantillons correspondantes (converties en fichier texte). Les échantillons belges et les données résultantes sont aimablement fournis par le CNR belge pour Salmonella et Shigella dans le cadre d’un projet mené par un boursier EUPHEM de l’ECDC, et seront également publiés dans un manuscrit. Les données internationales sont disponibles sur des bases de données publiques (ncbi) et ont déjà été publiées.Pour télécharger le fichier de l’arbre phylogénétique “Shigella_tree.txt”, cliquez avec le bouton droit de la souris sur ce lien (Cmd+click Mac) et sélectionnez “Enregistrer le lien sous”.Pour télécharger le fichier “sample_data_Shigella_tree.csv” contenant des informations supplémentaires sur chaque échantillon, cliquez avec le bouton droit de la souris sur ce lien (Cmd+clic pour Mac) et sélectionnez “Enregistrer le lien sous”.Pour voir le nouveau sous-arbre créé, cliquez avec le bouton droit de la souris sur ce lien (Cmd+clic pour Mac) et sélectionnez “Enregistrer le lien sous”. Le fichier .txt sera téléchargé sur votre ordinateur.Vous pouvez ensuite importer les fichiers .txt avec read.tree() du paquet ape, comme expliqué dans le chapitre concerné.","code":"\nape::read.tree(\"Shigella_tree.txt\")"},{"path":"download_book_data.html","id":"standardization","chapter":"2 Télécharger le manuel et les données","heading":"Standardization","text":"Pour la page sur la standardisation des données, vous pouvez charger les données directement depuis notre dépôt Github sur internet dans votre session R avec les commandes suivantes :","code":"\n# installer/importer le paquet **rio**\npacman::p_load(rio) \n\n##############\n# Pays A\n##############\n# import des données démographiques du pays depuis github\nA_demo <- import(\"https://github.com/appliedepi/epiRhandbook_fr/raw/main/data/standardization/country_demographics.csv\")\n\n# import des données de mortalité du pays depuis github\nA_deaths <- import(\"https://github.com/appliedepi/epiRhandbook_fr/raw/main/data/standardization/deaths_countryA.csv\")\n\n\n\n##############\n# Pays B\n##############\n# import des données démographiques du pays depuis github\nB_demo <- import(\"https://github.com/appliedepi/epiRhandbook_fr/raw/main/data/standardization/country_demographics_2.csv\")\n\n# import des données de mortalité du pays depuis github\nB_deaths <- import(\"https://github.com/appliedepi/epiRhandbook_fr/raw/main/data/standardization/deaths_countryB.csv\")\n\n\n###############\n# Population de référence\n###############\n# import depuis Github\nstandard_pop_data <- import(\"https://github.com/appliedepi/epiRhandbook_fr/raw/main/data/standardization/world_standard_population_by_sex.csv\")"},{"path":"download_book_data.html","id":"data_outbreak","chapter":"2 Télécharger le manuel et les données","heading":"Séries temporelles et détection des épidémies","text":"Voir la page sur les séries temporelles et la détection des épidémies. Nous utilisons les cas de campylobacter rapportés en Allemagne de 2002 à 2011, tels que disponibles dans le paquet R surveillance. (note cet ensemble de données été adapté de l’original, en ce sens que 3 mois de données ont été supprimés à partir de la fin de 2011 à des fins de démonstration).\nCliquer pour télécharger\n Campylobacter en Allemagne (.xlsx)\nNous utilisons également les données climatiques de l’Allemagne entre 2002 et 2011 (température en degrés Celsius et précipitations en millimètres). Ces données ont été téléchargées à partir d’un jeu de données dérivé des données produites par le satellite Copernicus (UE) à l’aide du paquet ecmwfr. Vous devrez télécharger toutes ces données et les importer avec stars::read_stars() comme expliqué dans la page sur les séries temporelles.\nCliquer pour télécharger\n Climat Allemagne 2002 (.nc file)\n\nCliquer pour télécharger\n Climat Allemagne 2003 (.nc file)\n\nCliquer pour télécharger\n Climat Allemagne 2004 (.nc file)\n\nCliquer pour télécharger\n Climat Allemagne 2005 (.nc file)\n\nCliquer pour télécharger\n Climat Allemagne 2006 (.nc file)\n\nCliquer pour télécharger\n Climat Allemagne 2007 (.nc file)\n\nCliquer pour télécharger\n Climat Allemagne 2008 (.nc file)\n\nCliquer pour télécharger\n Climat Allemagne 2009 (.nc file)\n\nCliquer pour télécharger\n Climat Allemagne 2010 (.nc file)\n\nCliquer pour télécharger\n Climat Allemagne 2011 (.nc file)\n","code":""},{"path":"download_book_data.html","id":"data_survey","chapter":"2 Télécharger le manuel et les données","heading":"Analyse d’enquêtes","text":"Pour la page analyse d’enquête, nous utilisons des données d’enquêtes de mortalité fictives basées sur les modèles d’enquête MSF OCA. Ces données fictives ont été générées dans le cadre du projet “R4Epis”.\nCliquer pour télécharger\n Données d’enquête fictives (.xlsx)\n\nCliquer pour télécharger\n Données d’enquête fictives (dictionnaire) (.xlsx)\n\nCliquer pour télécharger\n Données d’enquête fictives (données de population) (.xlsx)\n","code":""},{"path":"download_book_data.html","id":"data_shiny","chapter":"2 Télécharger le manuel et les données","heading":"Shiny","text":"La page sur les tableaux de bord avec Shiny illustre la construction d’une application simple pour afficher les données sur le paludisme.Pour télécharger les fichiers R qui produisent l’app Shiny :Vous pouvez \ncliquer ici pour télécharger le fichier app.R qui contient à la fois le code de l’interface utilisateur et du serveur pour l’application Shiny..Vous pouvez \ncliquer ici pour télécharger le fichier facility_count_data.rds qui contient les données sur le paludisme pour l’application Shiny. Notez que vous devrez peut-être l’enregistrer dans un dossier “data” pour que les chemins de fichier () fonctionnent correctement.Vous pouvez \ncliquer ici pour télécharger le fichier global.R qui doit être exécuté avant l’ouverture de l’app, comme expliqué dans la page.Vous pouvez \ncliquer ici pour télécharger le fichier plot_epicurve.R dont l’exécution est lancée par le script global.R. Notez que vous devrez peut-être le stocker dans un dossier “funcs” pour que les chemins de fichier () fonctionnent correctement.","code":""},{"path":"rbasics.html","id":"rbasics","chapter":"3 R - les bases","heading":"3 R - les bases","text":"Bienvenue !Cette page passe en revue les éléments essentiels de R. Elle n’pas pour d’être un tutoriel complet, mais elle fournit les bases et peut être utile pour rafraîchir votre mémoire. La section Ressources pour l’apprentissage renvoie à des didacticiels plus complets.Certaines parties de cette page ont été adaptées avec l’autorisation du projet R4Epis.Voir la page sur la transition R pour des conseils sur le passage de STATA, SAS ou Excel à R.","code":""},{"path":"rbasics.html","id":"pourquoi-utiliser-r","chapter":"3 R - les bases","heading":"3.1 Pourquoi utiliser R ?","text":"Comme indiqué sur le site Web du projet R, R est un langage de programmation et un environnement pour le calcul statistique et les graphiques. Il est très polyvalent, extensible et axé sur la communauté.CoûtL’utilisation de R est gratuite ! Il existe une forte éthique dans la communauté du matériel gratuit et open-source.ReproductibilitéLa gestion et l’analyse de vos données par le biais d’un langage de programmation (par rapport à Excel ou à un autre outil essentiellement manuel) améliore la reproductibilité, facilite la détection des erreurs et allège votre charge de travail.CommunautéLa communauté des utilisateurs de R est énorme et collaborative. De nouveaux paquets et outils destinés à résoudre des problèmes concrets sont développés quotidiennement et approuvés par la communauté des utilisateurs. À titre d’exemple, R-Ladies est une organisation mondiale dont la mission est de promouvoir la diversité des genres dans la communauté R, et c’est l’une des plus grandes organisations d’utilisateurs de R. Elle probablement un chapitre près de chez vous !","code":""},{"path":"rbasics.html","id":"termes-clés","chapter":"3 R - les bases","heading":"3.2 Termes clés","text":"RStudio - RStudio est une interface utilisateur graphique (GUI) qui facilite l’utilisation de R. Pour en savoir plus, consultez la section RStudio.Objets - Tout ce que vous stockez dans R - les jeu de données, les variables, une liste de noms de villages, un population total d’habitants, et même les résultats tels que les graphiques - sont des objets auxquels attribue un nom et qui peuvent être référencés dans des commandes ultérieures. Pour en savoir plus, consultez la section Objets.Fonctions - Une fonction est une opération de code qui accepte des entrées et renvoie une sortie transformée. Pour en savoir plus, consultez la section Fonctions.Paquets - Un paquet R est un ensemble de fonctions partageables. Pour en savoir plus, consultez la section Packages.Scripts - Un script est le fichier document qui contient vos commandes. Pour en savoir plus, consultez la section Scripts","code":""},{"path":"rbasics.html","id":"learning","chapter":"3 R - les bases","heading":"3.3 Ressources pour l’apprentissage","text":"","code":""},{"path":"rbasics.html","id":"ressources-au-sein-de-rstudio","chapter":"3 R - les bases","heading":"Ressources au sein de RStudio","text":"Documentation d’aideRecherchez dans l’onglet “Aide” de RStudio la documentation sur les paquets R et les fonctions spécifiques. Cet onglet se trouve dans le volet qui contient également les fichiers, les graphiques et les paquets (généralement dans le volet inférieur à droit). Comme raccourci, vous pouvez également taper le nom d’un paquet ou d’une fonction dans la console R après un point d’interrogation pour ouvrir la page d’aide correspondante. N’incluez pas les parenthèses.Par exemple : ?filter ou ?diagrammeR.Tutoriels interactifsIl existe plusieurs façons d’apprendre R de manière interactive dans RStudio.RStudio lui-même offre un volet Tutoriel qui est alimenté par le paquet R learnr. Il suffit d’installer ce paquet et d’ouvrir un tutoriel via le nouvel onglet “Tutorial” dans le volet supérieur droit de RStudio (qui contient également les onglets Environnement et Historique).Le paquet R swirl propose des cours interactifs dans la console R. Installez et chargez ce paquet, puis lancez la commande swirl() (parenthèses vides) dans la console R. Vous verrez apparaître des invites dans la console. Répondez en tapant dans la console. Elle vous guidera à travers un cours de votre choix.","code":""},{"path":"rbasics.html","id":"fiches-daide-mémoire","chapter":"3 R - les bases","heading":"Fiches d’aide-mémoire","text":"Il existe de nombreuses fiches d’aide-mémoire au format PDF disponibles sur le site Web de RStudio, par exemple :Facteurs avec le paquet forcatsDates et heures avec le paquet lubridateChaînes de caractères avec le paquet stringrOpérations itératives avec le paquet purrrImportation de donnéesAide-mémoire pour la transformation des données avec le paquet\ndplyrR Markdown (pour créer des documents comme PDF, Word,\nPowerpoint…)Shiny (pour créer des applications Web interactives)Visualisation de données avec le paquet ggplot2Cartographie (SIG)Paquet leaflet (cartes interactives)Python avec R (paquet reticulate)Il existe également une ressource R en ligne spécialement destinée aux utilisateurs d’Excel.","code":""},{"path":"rbasics.html","id":"twitter","chapter":"3 R - les bases","heading":"Twitter","text":"R possède une communauté Twitter dynamique où vous pouvez apprendre des astuces, des raccourcis et des nouvelles - suivez ces comptes :Suivez-nous ! @epiRhandbookR Function Day @rfuntionaday est une ressource incroyableR pour la science des données\n@rstats4dsRStudio @RStudioConseils sur RStudio@rstudiotipsR-Bloggers @RbloggersR-ladies @RLadiesGlobalHadley Wickham @hadleywickhamAussi :#epitwitter et #rstats","code":""},{"path":"rbasics.html","id":"ressources-gratuites-en-ligne","chapter":"3 R - les bases","heading":"Ressources gratuites en ligne","text":"Un texte définitif est le livre R Data Science de Garrett Grolemund et Hadley Wickham.Le site Web du projet R4Epis vise à “développer des outils standardisés de nettoyage, d’analyse et de rapport des données pour couvrir les types courants d’épidémies et d’enquêtes auprès de la population qui seraient menées dans le cadre d’une réponse d’urgence de MSF”. Vous y trouverez des supports de formation aux bases de R, des modèles de rapports RMarkdown sur les épidémies et les enquêtes, ainsi que des tutoriels pour vous aider à les configurer.","code":""},{"path":"rbasics.html","id":"langues-autres-que-langlais","chapter":"3 R - les bases","heading":"Langues autres que l’anglais","text":"Materiales de RStudio en EspañolIntroduction à R et au tidyverse (Francais)","code":""},{"path":"rbasics.html","id":"installation","chapter":"3 R - les bases","heading":"3.4 Installation","text":"","code":""},{"path":"rbasics.html","id":"r-et-rstudio","chapter":"3 R - les bases","heading":"R et RStudio","text":"Comment installer RVisitez ce site Web https://www.r-project.org/ et téléchargez la dernière version de R adaptée à votre ordinateur.Comment installer RStudioVisitez ce site Web https://rstudio.com/products/rstudio/download/ et téléchargez la dernière version de bureau gratuite de RStudio adaptée à votre ordinateur.Autorisations requisesNotez que vous devez installer R et RStudio sur un lecteur sur lequel vous avez des droits de lecture et d’écriture. Sinon, votre capacité à installer des paquets R (ce qui arrive fréquemment) sera affectée. Si vous rencontrez des problèmes, essayez d’ouvrir RStudio en faisant un clic droit sur l’icône et en sélectionnant “Exécuter en tant qu’administrateur”. Vous trouverez d’autres conseils sur la page R sur les lecteurs réseau.Comment mettre à jour R et RStudioVotre version de R est imprimée dans la Console R au démarrage. Vous pouvez également exécuter sessionInfo().Pour mettre à jour R, allez sur le site web mentionné ci-dessus et réinstallez R. Alternativement, vous pouvez utiliser le paquet installr (sous Windows) en exécutant installr::updateR(). Cela ouvrira des boîtes de dialogue pour vous aider à télécharger la dernière version de R et à mettre à jour vos paquets vers la nouvelle version de R. Plus de détails peuvent être trouvés dans la documentation de installr.Sachez que l’ancienne version de R existera toujours sur votre ordinateur. Vous pouvez temporairement exécuter une ancienne version (ancienne “installation”) de R en cliquant sur “Outils” -> “Options globales” dans RStudio et en choisissant une version de R. Cela peut être utile si vous voulez utiliser un paquet qui n’pas été mis à jour pour fonctionner sur la version la plus récente de R.Pour mettre à jour RStudio, vous pouvez aller sur le site Web ci-dessus et retélécharger RStudio. Une autre option consiste à cliquer sur “Aide” -> “Vérifier les mises à jour” dans RStudio, mais cela peut ne pas montrer les toutes dernières mises à jour.Pour savoir quelles versions de R, RStudio ou des paquets ont été utilisées lors de la réalisation de ce manuel, consultez la page sur Notes techniques et choix éditoriaux.","code":""},{"path":"rbasics.html","id":"autres-logiciels-que-vous-pourriez-avoir-besoin-dinstaller","chapter":"3 R - les bases","heading":"Autres logiciels que vous pourriez avoir besoin d’installer","text":"TinyTeX (pour la compilation d’un document RMarkdown au format PDF)Pandoc (pour compiler des documents RMarkdown)RTools (pour construire des paquets pour R)phantomjs (pour enregistrer des images fixes de réseaux animés, tels que des chaînes de transmission)","code":""},{"path":"rbasics.html","id":"tinytex","chapter":"3 R - les bases","heading":"TinyTex","text":"TinyTex est une distribution LaTeX personnalisée, utile lorsqu’essaie de produire des PDF à partir de R. Voir https://yihui.org/tinytex/ pour plus d’informations.Pour installer TinyTex à partir de R :","code":"\ninstall.packages('tinytex')\ntinytex::install_tinytex()\n\n# pour désinstaller TinyTeX, lancez tinytex::uninstall_tinytex()"},{"path":"rbasics.html","id":"pandoc","chapter":"3 R - les bases","heading":"Pandoc","text":"Pandoc est un convertisseur de document, un logiciel séparé de R. Il est fourni avec RStudio et ne devrait pas avoir besoin d’être téléchargé. Il aide le processus de conversion de documents Rmarkdown à des formats comme .pdf et ajoute des fonctionnalités complexes.","code":""},{"path":"rbasics.html","id":"rtools","chapter":"3 R - les bases","heading":"RTools","text":"RTools est une collection de logiciels permettant de construire des paquets pour R.Installer à partir de ce site web :\nhttps://cran.r-project.org/bin/windows/Rtools/","code":""},{"path":"rbasics.html","id":"phantomjs","chapter":"3 R - les bases","heading":"phantomjs","text":"Cet outil est souvent utilisé pour faire des “captures d’écran” despages web. Par exemple, lorsque vous faites une chaîne de transmission avec le paquet epicontacts, un fichier HTML interactif et dynamique est produit. Si vous voulez une image statique, il peut être utile d’utiliser le paquet webshot pour automatiser ce processus. Cela nécessite le programme externe “phantomjs”. Vous pouvez installer phantomjs via le paquet webshot avec la commande webshot::install_phantomjs().","code":""},{"path":"rbasics.html","id":"rstudio","chapter":"3 R - les bases","heading":"3.4.1 RStudio","text":"","code":""},{"path":"rbasics.html","id":"orientation-de-rstudio","chapter":"3 R - les bases","heading":"Orientation de RStudio","text":"D’abord, ouvrez RStudio. Comme leurs icônes peuvent être très similaires, assurez-vous que vous ouvrez bien RStudio et non pas R.Pour que RStudio fonctionne, vous devez également avoir R installé sur l’ordinateur (voir ci-dessus pour les instructions d’installation).RStudio est une interface (GUI) pour une utilisation plus facile de R. Vous pouvez considérer R comme le moteur d’un véhicule, qui effectue le travail crucial, et RStudio comme le corps du véhicule (avec les sièges, les accessoires, etc.) qui vous aide à utiliser le moteur pour avancer ! Vous pouvez consulter la fiche technique complète de l’interface utilisateur de RStudio (PDF) iciPar défaut, RStudio affiche quatre volets rectangulaires.TIP: Si votre RStudio n’affiche qu’un seul volet gauche, c’est parce que vous n’avez pas encore de scripts ouverts.Le volet sourceCe volet, par défaut en haut à gauche, est un espace pour éditer, exécuter et enregistrer vos scripts. Les scripts contiennent les commandes que vous souhaitez exécuter. Ce volet peut également afficher des ensembles de données (cadres de données) pour les visualiser.Pour les utilisateurs de Stata, ce volet est similaire aux fenêtres -file et Data Editor.Le volet Console RLa console R, qui est par défaut le volet gauche ou inférieur gauche de R Studio, est le siège du “moteur” R. C’est là que les commandes sont réellement exécutées et que les sorties non graphiques et les messages d’erreur/d’avertissement apparaissent. Vous pouvez saisir et exécuter directement des commandes dans la console R, mais sachez que ces commandes ne sont pas enregistrées comme c’est le cas lorsque vous exécutez des commandes à partir d’un script.Si vous êtes familier avec Stata, la console R ressemble à la fenêtre de commande et à la fenêtre des résultats.Le volet EnvironnementCe volet, situé par défaut en haut à droite, est le plus souvent utilisé pour afficher de brefs résumés des objets de l’environnement R dans la session en cours. Ces objets peuvent inclure des ensembles de données importés, modifiés ou créés, des paramètres que vous avez définis (par exemple, une semaine épi spécifique pour l’analyse), ou des vecteurs ou des listes que vous avez définis pendant l’analyse (par exemple, les noms des régions). Vous pouvez cliquer sur la flèche à côté du nom d’un cadre de données pour voir ses variables.Dans Stata, cette fenêtre est très similaire à celle du gestionnaire de variables.Ce volet contient également l’onglet “Historique” où vous pouvez voir les commandes que vous avez exécutées précédemment. Il comporte également un onglet “Tutoriel” où vous pouvez suivre des tutoriels R interactifs si vous avez installé le paquet learnr. En outre, il existe un volet “Connexions” pour les connexions aux bases de données externes. Si vous avez lié le répertoire actif à un dépôt sur Github, il y aura également un volet “Git”.Volets Graphiques, visionneuse, paquets et aideLe volet inférieur droit comprend plusieurs onglets importants. Les graphiques de tracé typiques, y compris les cartes, s’affichent dans le volet Tracé. Les sorties interactives ou HTML s’affichent dans le volet Visionneuse. Le volet Aide permet d’afficher la documentation et les fichiers d’aide. Le volet Fichiers est un navigateur qui peut être utilisé pour ouvrir ou supprimer des fichiers. Le volet Paquets vous permet de voir, d’installer, de mettre à jour, de supprimer, de charger/décharger des paquets R et de voir quelle version du paquet vous avez. Pour en savoir plus sur les paquets, consultez la section paquets ci-dessous.Ce volet contient les équivalents Stata des fenêtres Plots Manager et Project Manager.","code":""},{"path":"rbasics.html","id":"paramètres-rstudio","chapter":"3 R - les bases","heading":"Paramètres RStudio","text":"Modifiez les paramètres et l’apparence de RStudio dans le menu déroulant Outiles, en sélectionnant Options globales. Vous pouvez y modifier les paramètres par défaut, y compris l’apparence/couleur de fond.RedémarrageSi votre R se fige, vous pouvez redémarrer R en allant dans le menu Session et en cliquant sur “Redémarrer R”. Cela vous évite de devoir fermer et ouvrir RStudio. Tout ce qui se trouve dans votre environnement R sera supprimé lorsque vous ferez cela.","code":""},{"path":"rbasics.html","id":"raccourcis-clavier","chapter":"3 R - les bases","heading":"Raccourcis clavier","text":"Vous trouverez ci-dessous quelques raccourcis clavier très utiles. Vous trouverez tous les raccourcis clavier pour Windows, Max et Linux sur la deuxième page de ce fichier technique par RStudio.TIP: Utilisez votre touche de tabulation lorsque vous tapez pour activer la fonctionnalité de complétion automatique de RStudio. Cela peut éviter les fautes d’orthographe. Appuyez sur la touche Tab pendant la saisie pour produire un menu déroulant de fonctions et d’objets probables, en fonction de ce que vous avez tapé jusqu’à présent.","code":""},{"path":"rbasics.html","id":"functions","chapter":"3 R - les bases","heading":"3.5 Fonctions","text":"Les fonctions sont au cœur de l’utilisation de R. Les fonctions vous permettent d’effectuer des tâches et des opérations. De nombreuses fonctions sont installées avec R, beaucoup d’autres sont disponibles à télécharger dans des paquets (expliqués dans la section paquets), et vous pouvez même écrire vos propres fonctions personnalisées !Cette section de base sur les fonctions explique :Ce qu’est une fonction et comment elle fonctionneCe que sont les paramètres des fonctionsComment obtenir de l’aide pour comprendre une fonctionUne note rapide sur la syntaxe : Dans ce manuel, les fonctions sont écrites en code-texte avec des parenthèses vides, comme ceci : filter(). Comme expliqué dans la section paquets, les fonctions sont téléchargées dans des paquets. Dans ce manuel, les noms de paquets sont écrits en gras, comme dplyr. Parfois, dans le code d’exemple, vous pouvez voir le nom de la fonction lié explicitement au nom de son paquet avec deux points de suspension (::) comme ceci : dplyr::filter(). Le de ce lien est expliqué dans la section sur les paquets.","code":""},{"path":"rbasics.html","id":"fonctions-simples","chapter":"3 R - les bases","heading":"Fonctions simples","text":"Une fonction est comme une machine qui reçoit des entrées, effectue une action avec ces entrées, et produit une sortie. La nature de la sortie dépend de la fonction.Les fonctions opèrent généralement sur un objet placé entre les parenthèses de la fonction. Par exemple, la fonction sqrt() calcule la racine carrée d’un nombre :L’objet fourni à une fonction peut également être une colonne dans un jeu de données (voir la section Objets pour plus de détails sur tous les types d’objets). Comme R peut stocker plusieurs jeux de données, vous devrez spécifier à la fois le jeu de données et la colonne. Une façon de le faire est d’utiliser la notation $ pour lier le nom du jeu de données et le nom de la colonne (dataset$column). Dans l’exemple ci-dessous, la fonction summary() est appliquée à la colonne numérique age du jeu de données linelist, et la sortie est un résumé des valeurs numériques et manquantes de la colonne.NOTE: En coulisses, une fonction représente un code supplémentaire complexe qui été regroupé pour l’utilisateur dans une seule commande simple.","code":"\nsqrt(49)## [1] 7\n# Imprimez les statistiques sommaires de la colonne 'age' dans le jeu de données 'linelist'.\nsummary(linelist$age)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n##    0.00    6.00   13.00   16.07   23.00   84.00      86"},{"path":"rbasics.html","id":"fonctions-à-paramètres-multiples","chapter":"3 R - les bases","heading":"Fonctions à paramètres multiples","text":"Les fonctions demandent souvent plusieurs entrées, appelées paramètres, situées entre les parenthèses de la fonction, généralement séparées par des virgules.Certains paramètres sont obligatoires pour que la fonction\nfonctionne correctement, d’autres sont facultatifsLes paramètres facultatifs ont des valeurs par défautLes paramètres peuvent prendre des entrées de type caractère,\nnumérique, logique (VRAI/FAUX) et autres.Voici une fonction fictive amusante, appelée oven_bake() (cuisson au four), comme exemple d’une fonction typique. Elle prend un objet comme entrée (par exemple un jeu de données, ou dans cet exemple “pâte”) et effectue des opérations sur celui-ci comme spécifié par des paramètres supplémentaires (minutes = et température =). La sortie peut être imprimée sur la console, ou sauvegardée comme un objet en utilisant l’opérateur d’affectation <-.Dans un exemple plus réaliste, la commande age_pyramid() ci-dessous produit un graphique de pyramide des âges basé sur des groupes d’âge définis et une colonne de division binaire, comme le genre gender. La fonction reçoit trois paramètres entre parenthèses, séparés par des virgules. Les valeurs fournies aux paramètres établissent linelist comme le cadre de données à utiliser, age_cat5 comme la colonne à compter, et gender comme la colonne binaire à utiliser pour diviser la pyramide par couleur.La commande ci-dessus peut être écrite de manière équivalente comme ci-dessous, dans un style plus long avec une nouvelle ligne pour chaque argument. Ce style peut être plus facile à lire, et plus facile d’écrire des “commentaires” avec # pour expliquer chaque partie (commenter abondamment est une bonne pratique !). Pour exécuter cette commande plus longue, vous pouvez souligner la commande entière et cliquer sur “Run”, ou simplement placer votre curseur sur la première ligne et appuyer simultanément sur les touches Ctrl et Enter.La première moitié d’une affectation de paramètre (par exemple data =) n’pas besoin d’être spécifiée si les paramètres sont écrits dans un ordre spécifique (spécifié dans la documentation de la fonction). Le code ci-dessous produit exactement la même pyramide que ci-dessus, parce que la fonction attend l’ordre des paramètres : cadre de données, le variable age_group, puis le variable split_by.Une commande age_pyramid() plus complexe pourrait inclure les paramètres optionnels pour :Afficher les proportions au lieu des nombres (définissez proportional = TRUE (vrai) quand la valeur par défaut est FALSE (faux))Spécifier les deux couleurs à utiliser (pal = est l’abréviation de “palette” et est fourni avec un vecteur de deux noms de couleurs. Voir la page objets pour savoir comment la fonction c() fabrique un vecteur).NOTE: Pour les paramètres que vous spécifiez avec les deux parties du paramètre (par exemple proportional = TRUE), leur ordre parmi tous les paramètres n’pas d’importance.","code":"\n# Créer une pyramide des âges\nage_pyramid(data = linelist, age_group = \"age_cat5\", split_by = \"gender\")\n# Créer une pyramide des âges\nage_pyramid(\n  data = linelist,        # utiliser la liste linéaire des cas\n  age_group = \"age_cat5\", # fournir une colonne de groupe d'âge\n  split_by = \"gender\"     # utiliser la colonne genre pour les deux côtés de la pyramide\n  )\n# Cette commande produira exactement le même graphique que ci-dessus\nage_pyramid(linelist, \"age_cat5\", \"gender\")\nage_pyramid(\n  linelist,                    # utiliser la liste linéaire des cas\n  \"age_cat5\",                  # colonne de groupe d'âge\n  \"gender\",                    # répartition par genre\n  proportional = TRUE,         # pourcentage au lieu du nombre\n  pal = c(\"orange\", \"purple\")  # couleurs\n  )"},{"path":"rbasics.html","id":"ecrire-des-fonctions","chapter":"3 R - les bases","heading":"Ecrire des fonctions","text":"R est un langage orienté autour des fonctions, vous devez donc vous sentir capable d’écrire vos propres fonctions. La création de fonctions présente plusieurs avantages :Faciliter la programmation modulaire - la séparation du code en morceaux indépendants et gérablesRemplacer le copier-coller répétitif, qui peut être source d’erreursDonner des noms mémorisables aux morceaux de codeL’écriture d’une fonction est traitée en détail à la page Écriture de fonctions.","code":""},{"path":"rbasics.html","id":"packages","chapter":"3 R - les bases","heading":"3.6 Paquets","text":"Les paquets contiennent des fonctions.Un paquet en R est un ensemble partageable de code et de documentation qui contient des fonctions prédéfinies. Les utilisateurs de la communauté R développent en permanence des packages répondant à des problèmes spécifiques; donc il est probable que l’un d’entre eux puisse vous aider dans votre travail ! Vous allez installer et utiliser des centaines de paquets dans votre utilisation de R.À l’installation, R contient des paquets et des fonctions “de base” qui effectuent des tâches élémentaires communes. Mais de nombreux utilisateurs de R créent des fonctions spécialisées, qui sont vérifiées par la communauté R et que vous pouvez télécharger en tant que paquet pour votre propre usage. Dans ce manuel, les noms des paquets sont écrits en gras. L’un des aspects les plus difficiles de R est qu’il existe souvent de nombreuses fonctions ou paquets parmi lesquels peut choisir pour effectuer une tâche donnée.","code":""},{"path":"rbasics.html","id":"installer-et-charger","chapter":"3 R - les bases","heading":"Installer et charger","text":"Les fonctions sont contenues dans des paquets qui peuvent être téléchargés (“installés”) sur votre ordinateur à partir d’Internet. Une fois qu’un paquet est téléchargé, il est stocké dans votre “bibliothèque”. Vous pouvez alors accéder aux fonctions qu’il contient pendant votre séance R actuelle en “chargeant” le paquet.Pensez à R comme votre bibliothèque personnelle : Lorsque vous téléchargez un paquet, votre bibliothèque gagne un nouveau livre de fonctions, mais chaque fois que vous voulez utiliser une fonction de ce livre, vous devez emprunter (“charger”) ce livre dans votre bibliothèque.En résumé : pour utiliser les fonctions disponibles dans un paquet R, deux étapes doivent être mises en œuvre :Le paquet doit être installé (une fois), etLe paquet doit être chargé (à chaque séance R)","code":""},{"path":"rbasics.html","id":"votre-bibliothèque","chapter":"3 R - les bases","heading":"Votre bibliothèque","text":"Votre “bibliothèque” est en fait un dossier sur votre ordinateur, contenant un dossier pour chaque paquet qui été installé. Déterminez où R est installé sur votre ordinateur, et cherchez un dossier appelé “win-library”. Par exemple : R\\win-library\\4.0 (4.0 est la version de R). Notez que vous aurez une bibliothèque différente pour chaque version de R que vous avez téléchargée.Vous pouvez imprimer le chemin d’accès à votre bibliothèque en entrant.libPaths() (parenthèses vides). Ceci devient particulièrement important si vous travaillez avec R sur des lecteurs réseau.","code":""},{"path":"rbasics.html","id":"installer-à-partir-du-cran","chapter":"3 R - les bases","heading":"Installer à partir du CRAN","text":"Le plus souvent, les utilisateurs de R téléchargent des paquets depuis CRAN. CRAN (Comprehensive R Archive Network) est un entrepôt public en ligne de paquets R qui ont été publiés par des membres de la communauté R.Vous vous inquiétez des virus et de la sécurité lorsque vous téléchargez un paquet depuis CRAN ? Lisez cet\narticle à ce sujet.","code":""},{"path":"rbasics.html","id":"comment-installer-et-charger","chapter":"3 R - les bases","heading":"Comment installer et charger","text":"Dans ce manuel, nous suggérons d’utiliser le paquet pacman (abréviation de “package manager” en anglais). Il offre une fonction pratique p_load() qui installera un paquet si nécessaire et le chargera pour l’utiliser dans la séance R actuelle.La syntaxe est assez simple. Il suffit de lister les noms des paquets entre les parenthèses de p_load(), séparés par des virgules.La commande ci-dessous installera les paquets rio, tidyverse, et s’ils ne sont pas encore installés, et les chargera pour les utiliser. Cela rend l’approche p_load() pratique et concise si vous partagez des scripts avec d’autres personnes. Notez que les noms des paquets sont sensibles à la casse.Notez que nous avons utilisé la syntaxe pacman::p_load() qui écrit explicitement le nom du paquet (pacman) avant le nom de la fonction (p_load()), reliés par deux deux points ::. Cette syntaxe est utile car elle charge également le paquet pacman (en supposant qu’il soit déjà installé).Il existe d’autres fonctions R de base que vous verrez souvent. La fonction R de base pour installer un paquet est install.packages(). Le nom du paquet à installer doit être fourni entre les parenthèses et entre guillemets. Si vous voulez installer plusieurs paquets en une seule commande, ils doivent être listés dans un vecteur de caractères c().Remarque : cette commande installe un paquet, mais ne le charge pas pour l’utiliser dans la séance en cours.L’installation peut également être effectuée par pointer-cliquer en allant dans le panneau “Packages” de RStudio, en cliquant sur “Installer” et en recherchant le nom du paquet souhaité.La fonction base de R pour charger un paquet à utiliser (après qu’il ait été installé) est library(). Elle ne peut charger qu’un seul paquet à la fois (une autre raison d’utiliser p_load()). Vous pouvez fournir le nom du paquet avec ou sans guillemets.Pour vérifier si un paquet est installé et/ou chargé, vous pouvez afficher le panneau des paquets dans RStudio. Si le paquet est installé, il est affiché avec son numéro de version. Si sa case est cochée, il est chargé pour la séance en cours.Installation depuis GithubParfois, vous avez besoin d’installer un paquet qui n’est pas encore disponible sur CRAN. Ou peut-être que le paquet est disponible sur CRAN mais que vous voulez la version de développement avec de nouvelles fonctionnalités qui ne sont pas encore proposées dans la version CRAN publiée, plus stable. Ces versions sont souvent hébergées sur le site Web github.com dans un “dépôt” de code libre et public. Pour en savoir plus sur Github, consultez la page du manuel intitulée Version control et collaboration avec GitHub.Pour télécharger des paquets R depuis Github, vous pouvez utiliser la fonction p_load_gh() de pacman, qui installera le paquet si nécessaire, et le chargera pour l’utiliser dans votre séance R actuelle. Les alternatives à l’installation incluent l’utilisation des paquets remotes ou devtools. Pour en savoir plus sur toutes les fonctions de pacman, consultez la documentation du paquet.Pour installer à partir de Github, vous devez fournir plus d’informations. Vous devez fournir :L’ID Github (nom d’utilisateur) du propriétaire du dépôt.Le nom du dépôt qui contient le paquet.(facultatif) Le nom de la “branche” (version de développement spécifique) que vous souhaitez télécharger.Dans les exemples ci-dessous, le premier mot entre guillemets est l’ID Github du propriétaire du dépôt. Après la barre oblique est le nom du dépôt (typiquement le nom du paquet).Si vous voulez installer à partir d’une “branche” (version) autre que la branche principale, ajoutez le nom de la branche après un “@”, après le nom du dépôt.S’il n’y pas de différence entre la version Github et la version sur votre ordinateur, aucune action ne sera entreprise. Vous pouvez “forcer” une réinstallation en utilisant p_load_current_gh() avec le paramètre update = TRUE. Lisez plus sur pacman dans cette vignette en ligneInstallation à partir d’un ZIP ou d’un TARVous pouvez installer le paquet à partir d’une URL :Ou bien, le télécharger sur votre ordinateur dans un fichier zippé :Option 1 : utiliser install_local() du paquet remotes.Option 2 : en utilisant install.packages() du R de base, en fournissant le chemin d’accès au fichier ZIP et en définissant type = \"source\" et repos = NULL.","code":"\n# Installer (si nécessaire) et charger les paquets pour l'utilisation\npacman::p_load(rio, tidyverse, here)\n# Installer un seul paquet avec la base R\ninstall.packages(\"tidyverse\")\n\n# Installer plusieurs paquets avec la base R\ninstall.packages(c(\"tidyverse\", \"rio\", \"here\"))\n# Charger des paquets à utiliser, avec la base R\nlibrary(tidyverse)\nlibrary(rio)\nlibrary(here)\n# Installer/charger le paquet epicontacts depuis son dépôt Github\np_load_gh(\"reconhub/epicontacts\")\n# Installer la branche \"timeline\" du paquet epicontacts depuis Github\np_load_gh(\"reconhub/epicontacts@timeline\")\npackageurl <- \"https://cran.r-project.org/src/contrib/Archive/dsr/dsr_0.2.2.tar.gz\"\ninstall.packages(packageurl, repos = NULL, type = \"source\")\nremotes::install_local(\"~/Downloads/dplyr-master.zip\")\ninstall.packages(\"~/Downloads/dplyr-master.zip\", \n                 type = \"source\", \n                 repos = NULL)"},{"path":"rbasics.html","id":"syntaxe-du-code","chapter":"3 R - les bases","heading":"Syntaxe du code","text":"Pour plus de clarté dans ce manuel, les fonctions sont parfois précédées du nom de leur paquet en utilisant le symbole :: de la manière suivante : nom_du_paquet::nom_de_la_fonction().Une fois qu’un paquet est chargé pour une séance, ce style explicite n’est plus nécessaire. peut simplement utiliser nom_de_la_fonction(). Cependant, écrire le nom du paquet est utile lorsqu’un nom de fonction est commun et peut exister dans plusieurs paquets (par exemple, plot()). L’écriture du nom du paquet chargera également le paquet s’il n’est pas déjà chargé.","code":"\n# Cette commande utilise le paquet \"rio\" et sa fonction \"import()\" pour importer un jeu de données\nlinelist <- rio::import(\"linelist.xlsx\", which = \"Sheet1\")"},{"path":"rbasics.html","id":"aide-sur-les-fonctions","chapter":"3 R - les bases","heading":"Aide sur les fonctions","text":"Pour en savoir plus sur une fonction, vous pouvez la rechercher dans l’onglet Aide du RStudio en bas à droite. Vous pouvez également lancer une commande comme ?thefunctionname (mettez le nom de la fonction après un point d’interrogation) et la page d’aide apparaîtra dans le volet d’aide. Enfin, essayez de rechercher des ressources en ligne.","code":""},{"path":"rbasics.html","id":"mettre-à-jour-les-paquets","chapter":"3 R - les bases","heading":"Mettre à jour les paquets","text":"Vous pouvez mettre à jour les paquets en les réinstallant. Vous pouvez également cliquer sur le bouton vert “Update” dans votre panneau “RStudio Packages” pour voir quels paquets ont de nouvelles versions à installer. Sachez que votre ancien code peut avoir besoin d’être mis à jour s’il y une révision majeure du fonctionnement d’une fonction !","code":""},{"path":"rbasics.html","id":"supprimer-des-paquets","chapter":"3 R - les bases","heading":"Supprimer des paquets","text":"Utilisez p_delete() de pacman, ou remove.packages() de base R. Alternativement, allez chercher le dossier qui contient votre bibliothèque et supprimez manuellement le dossier.","code":""},{"path":"rbasics.html","id":"dépendances","chapter":"3 R - les bases","heading":"Dépendances","text":"Les paquets dépendent souvent d’autres paquets pour fonctionner. Ceux-ci sont appelés dépendances. Si une dépendance ne s’installe pas, le paquet qui en dépend peut également ne pas s’installer.Voir les dépendances d’un paquet avec p_depends(), et voir quels paquets en dépendent avec p_depends_reverse().","code":""},{"path":"rbasics.html","id":"fonctions-masquées","chapter":"3 R - les bases","heading":"Fonctions masquées","text":"Il n’est pas rare que deux paquets ou plus contiennent le même nom de fonction. Par exemple, le paquet dplyr possède une fonction\nfilter(), mais le paquet stats aussi. La fonction filter() par défaut dépend de l’ordre dans lequel ces paquets sont chargés pour la première fois dans la séance R - le dernier sera la fonction par défaut de la commande filter().Vous pouvez vérifier l’ordre dans votre panneau Environnement de R Studio - cliquez sur la liste déroulante pour “Global Environment” et voyez l’ordre des paquets. Les fonctions des paquets inférieurs dans cette liste déroulante masqueront les fonctions du même nom dans les paquets qui apparaissent plus haut dans la liste déroulante. Lors du premier chargement d’un paquet, R vous avertira dans la console si le masquage se produit, mais il est facile de ne pas le voir.Voici comment vous pouvez corriger le masquage :Spécifiez le nom du paquet dans la commande. Par exemple, utilisez dplyr::filter()Réorganisez l’ordre dans lequel les paquets sont chargés (par exemple, dans p_load()), et démarrez une nouvelle séance R.","code":""},{"path":"rbasics.html","id":"détacher-décharger","chapter":"3 R - les bases","heading":"Détacher / décharger","text":"Pour détacher (décharger) un paquet, utilisez cette commande, avec le nom correct du paquet et un seul deux-points. Notez que cela peut ne pas résoudre le masquage.","code":"\ndetach(package:NOM_DU_PAQUET_ICI, unload = TRUE)"},{"path":"rbasics.html","id":"installer-une-ancienne-version","chapter":"3 R - les bases","heading":"Installer une ancienne version","text":"Consultez ce guide pour installer une ancienne version d’un paquet particulier.","code":""},{"path":"rbasics.html","id":"paquets-suggérés","chapter":"3 R - les bases","heading":"Paquets suggérés","text":"Voir la page Paquets suggérés pour une liste de paquets que nous recommandons pour l’épidémiologie quotidienne.","code":""},{"path":"rbasics.html","id":"scripts","chapter":"3 R - les bases","heading":"3.7 Scripts","text":"Les scripts sont une partie fondamentale de la programmation. Ce sont des documents qui contiennent vos commandes (par exemple, des fonctions pour créer et modifier des jeux de données, imprimer des visualisations, etc). Vous pouvez sauvegarder un script et l’exécuter à nouveau ultérieurement. Le stockage et l’exécution de vos commandes à partir d’un script présentent de nombreux avantages (par rapport à la saisie des commandes une par une dans la “ligne de commande” de la console R) :Portabilité : vous pouvez partager votre travail avec d’autres personnes en leur envoyant vos scriptsReproductibilité : pour que vous et les autres sachiez exactement ce que vous avez faitContrôle de version : pour que vous puissiez suivre les modifications apportées par vous-même ou par vos collèguesCommentaire/annotation : pour expliquer à vos collègues ce que vous avez fait","code":""},{"path":"rbasics.html","id":"commentaire","chapter":"3 R - les bases","heading":"Commentaire","text":"Dans un script, vous pouvez également annoter (“commenter”) votre code R. Les commentaires sont utiles pour expliquer à vous-même et aux autres lecteurs ce que vous faites. Vous pouvez ajouter un commentaire en tapant le symbole dièse (#) et en écrivant votre commentaire après. Le texte commenté apparaîtra dans une couleur différente de celle du code R.Tout code écrit après le # ne sera pas exécuté. Par conséquent, placer un # avant le code est également un moyen utile de bloquer temporairement une ligne de code (“commenter”) si vous ne souhaitez pas la supprimer). Vous pouvez mettre en commentaire plusieurs lignes à la fois en les soulignant et en appuyant sur Ctrl+Shift+c (Cmd+Shift+c sur Mac).Vous trouverez ci-dessous quelques conseils essentiels pour commenter et annoter votre code :Commentez ce que vous faites et pourquoi vous le faitesDécoupez votre code en sections logiquesAccompagnez votre code d’une description textuelle étape par étape de ce que vous faites (par exemple, des étapes numérotées).","code":"\n# Un commentaire peut être sur une ligne par lui-même, ex.:\n# Importer des données:\nlinelist <- import(\"linelist_raw.xlsx\") %>% # un commentaire peut aussi venir après le code\n     # filter(age > 50)\n     # Il peut aussi être utilisé pour désactiver une ligne de code\ncount()"},{"path":"rbasics.html","id":"style","chapter":"3 R - les bases","heading":"Style","text":"Il est important d’être conscient de votre style de codage, surtout si vous travaillez en équipe. Nous préconisons le tidyverse guide de style. Il existe également des paquets tels que styler et lintr qui vous aident à vous conformer à ce style.Quelques points très basiques pour rendre votre code lisible pour les autres:Lorsque vous nommez des objets, n’utilisez que des lettres minuscules, des chiffres et des traits de soulignement _, par exemple mes_donneesUtilisez fréquemment des espaces, y compris autour des opérateurs, par exemple n = 1 et age_nouveau <- age_vieillesse + 3.","code":""},{"path":"rbasics.html","id":"exemple-de-script","chapter":"3 R - les bases","heading":"Exemple de script","text":"Vous trouverez ci-dessous un exemple d’un court script R. N’oubliez pas que plus vous expliquerez succinctement votre code dans les commentaires, plus vos collègues vous apprécieront !","code":""},{"path":"rbasics.html","id":"r-markdown","chapter":"3 R - les bases","heading":"R markdown","text":"Un script R markdown est un type de script R dans lequel le script lui-même devient un document de sortie (PDF, Word, HTML, Powerpoint, etc.). Ce sont des outils incroyablement utiles et polyvalents, souvent utilisés pour créer des rapports dynamiques et automatisés. Même ce site Web et ce manuel sont produits à l’aide de scripts R markdown !Il convient de noter que les utilisateurs débutants de R peuvent également utiliser R Markdown - ne vous laissez pas intimider !Pour en savoir plus, consultez la page du manuel consacrée aux rapports avec R Markdown.","code":""},{"path":"rbasics.html","id":"carnets-de-notes-r","chapter":"3 R - les bases","heading":"Carnets de notes R","text":"Il n’y pas de différence entre écrire dans un Rmarkdown et un R notebook. Cependant, l’exécution du document diffère légèrement. Voir ce site pour plus de détails.","code":""},{"path":"rbasics.html","id":"shiny","chapter":"3 R - les bases","heading":"Shiny","text":"Les applications/sites web Shiny sont contenus dans un script, qui doit être nommé app.R. Ce fichier comporte trois éléments :Une interface utilisateur (ui)Une fonction serveurUn appel à la fonction shinyAppConsultez la page du manuel sur les teableaux de bord avec Shiny, ou ce tutoriel en ligne : Tutoriel ShinyAuparavant, le fichier ci-dessus était divisé en deux fichiers (ui.R et server.R).","code":""},{"path":"rbasics.html","id":"repli-du-code","chapter":"3 R - les bases","heading":"Repli du code","text":"Vous pouvez replier des portions de code pour rendre votre script plus facile à lire.Pour ce faire, créez un en-tête de texte avec #, écrivez votre en-tête, et faites-le suivre d’au moins 4 tirets (-), hachages (#) ou égaux (=). Lorsque vous aurez fait cela, une petite flèche apparaîtra dans la “gouttière” à gauche (près du numéro de ligne). Vous pouvez cliquer sur cette flèche et sur le code situé en dessous jusqu’à ce que l’en-tête suivant se réduise et qu’une icône à double flèche apparaisse à sa place.Pour développer le code, cliquez à nouveau sur la flèche dans la gouttière ou sur l’icône à double flèche. Il existe également des raccourcis clavier, comme expliqué dans la section RStudio de cette page.En créant des en-têtes avec #, vous activerez également la table des matières au bas de votre script (voir ci-dessous) que vous pouvez utiliser pour naviguer dans votre script. Vous pouvez créer des sous-titres en ajoutant d’autres symboles, par exemple # pour les titres primaires, ## pour les titres secondaires et ### pour les titres tertiaires.Vous trouverez ci-dessous deux versions d’un exemple de script. À gauche, l’original avec des en-têtes commentés. À droite, quatre tirets ont été écrits après chaque en-tête, les rendant ainsi repliables. Deux d’entre eux ont été réduits, et vous pouvez voir que la table des matières en bas de page affiche maintenant chaque section.D’autres zones de code qui sont automatiquement éligibles pour le pliage incluent les régions “accolées” avec des parenthèses { } telles que les définitions de fonctions ou les blocs conditionnels (instructions “else”). Vous pouvez en savoir plus sur le pliage du code sur le site RStudio.","code":""},{"path":"rbasics.html","id":"répertoire-de-travail","chapter":"3 R - les bases","heading":"3.8 Répertoire de travail","text":"Le répertoire de travail est l’emplacement du dossier racine utilisé par R pour votre travail - où R recherche et enregistre les fichiers par défaut. Par défaut, il enregistrera de nouveaux fichiers et sorties à cet emplacement et recherchera ici des fichiers (par exemple, des ensembles de données).Le répertoire de travail apparaît dans le texte gris en haut du volet de la console RStudio. Vous pouvez également imprimer le répertoire de travail actuel en exécutant getwd() (laissez les parenthèses vides).","code":""},{"path":"rbasics.html","id":"approche-recommandée","chapter":"3 R - les bases","heading":"Approche recommandée","text":"Voir la page sur projets R pour plus de détails sur notre approche recommandée pour gérer votre répertoire de travail.Un moyen commun, efficace et sans problème de gérer votre répertoire de travail et vos chemins de fichier consiste à combiner ces trois éléments dans un flux de travail du projets R orienté comme expliqué ci-dessous:Un projet R pour stocker tous vos fichiers (voir page sur projets R)Le paquet pour localiser les fichiers (voir page sur importer et exporter)Le paquet rio pour importer ou exporter des fichiers (voir page sur importer et exporter)","code":""},{"path":"rbasics.html","id":"définir-le-répertoire-de-travail-par-commande","chapter":"3 R - les bases","heading":"Définir le répertoire de travail par commande","text":"Jusqu’à récemment, de nombreuses personnes apprenant R ont appris à commencer leurs scripts avec une commande setwd(). Veuillez plutôt envisager d’utiliser un flux de travail orienté par projets R et lire les raisons de ne pas utiliser setwd().En bref, votre travail devient spécifique à votre ordinateur, les chemins de fichier utilisés pour importer et exporter des fichiers deviennent “cassants”, ce qui entrave gravement la collaboration et l’utilisation de votre code sur tout autre ordinateur. Heureusement il existe des alternatives faciles!Comme indiqué ci-dessus, bien que nous ne recommandons pas cette approche dans la plupart des cas, vous pouvez utiliser la commande setwd() avec le chemin du fichier de dossier souhaité dans les citations, par exemple:DANGER: Définition d’un répertoire de travail avec setwd() peut être “cassant” si le chemin de fichier est spécifique à un ordinateur. Au lieu de cela, utilisez des chemins de fichier par rapport à un répertoire racine du projet R (avec le paquet ).","code":"\nsetwd(\"C:/Documents/R Files/My analysis\")"},{"path":"rbasics.html","id":"définir-manuellement-le-répertoire-de-travail","chapter":"3 R - les bases","heading":"Définir manuellement le répertoire de travail","text":"Pour définir le répertoire de travail manuellement (l’équivalent graphique du setwd()), cliquez sur le menu déroulant “Session” et accédez à “Set Working Directory”, puis “Choose Directory”. Cela définira le répertoire de travail pour cette scéance spécifique de R. Remarque: Si vous utilisez cette approche, vous devrez le faire manuellement chaque fois que vous ouvrez Rstudio.","code":""},{"path":"rbasics.html","id":"définir-le-répertoire-de-travail-dans-un-projet-r","chapter":"3 R - les bases","heading":"Définir le répertoire de travail dans un projet R","text":"Si vous utilisez un projet R, le répertoire de travail sera par défaut dans le dossier racine du projet R qui contient le fichier .rproj. Cela s’appliquera si vous ouvrez RStudio en cliquant sur le projet R (le fichier avec l’extension .rproj).","code":""},{"path":"rbasics.html","id":"répertoire-de-travail-dans-un-script-r-markdown","chapter":"3 R - les bases","heading":"3.8.1 Répertoire de travail dans un script R Markdown","text":"Dans un script R Markdown, le répertoire de travail par défaut est le dossier ou le fichier RMarkdown (.rmd) est enregistré. Si vous utilisez un projet R et le paquet , cela ne s’applique pas et le répertoire de travail sera (), comme expliqué dans la page projets R.Si vous souhaitez modifier le répertoire de travail d’une dossier RMarkdown autonome (qui ne fait pas partie d’un projet R), et vous utilisez setwd(), cela ne s’appliquera qu’à ce morceau de code spécifique. Pour modifier tous les morceaux de code dans une dossier RMarkdown, modifiez le morceau de configuration pour ajouter le paramètre root.dir =, comme ci-dessous:Il est beaucoup plus facile d’utiliser simplement le script RMarkdown dans un projet R et d’utiliser le paquet .","code":"\nknitr::opts_knit$set(root.dir = 'desired/directorypath')"},{"path":"rbasics.html","id":"fournir-des-chemins-de-fichier","chapter":"3 R - les bases","heading":"Fournir des chemins de fichier","text":"La source de frustration la plus commune pour un débutant R (au moins sur un ordinateur avec Windows) est de saisir un chemin de fichier pour importer ou exporter des données. Il existe une explication approfondie sur la meilleure façon de saisir les chemins de fichier de saisie dans la page importer et exporter, mais voici quelques points clés:Chemins cassésVous trouverez ci-dessous un exemple de chemin de fichier “absolute” avec un “adresse complète”. Ceux-ci se casseront probablement s’ils sont utilisés par un autre ordinateur. Une exception est si vous utilisez un dossier sur un réseau partagé.Direction de la barre obliqueSi vous saisissez un chemin de fichier, soyez conscient de la direction des barres obliques. Utilisez des barres obliques vers l’avant (/) pour séparer les composants, par exemple Data/Provincial.csv. Le défaut pour les ordinateurs avec Windows est de séparer les composants du chemin avec des barres obliques en arrière (\\\\). Vous devrez donc modifier la direction de chaque barre oblique. Si vous utilisez le paquet comme décrit dans la page projets R, la direction des barres obliques n’est pas un problème.Chemins de fichiers relatifsNous recommandons généralement de utiliser des fichiers avec chemins “relatifs” - c’est-à-dire le chemin par rapport à la racine de votre projet R. Vous pouvez le faire en utilisant le paquet comme expliqué dans la page projets R. Un chemin de fichiers relatif peut ressembler à ceci:Même si vous utilisez des chemins de fichiers relatifs dans un projet R, vous pouvez toujours utiliser des chemins absolus pour importer/exporter des données en dehors de votre projet R.","code":"C:/Utilisateurs/Nom/Document/Logiciels analytiques/R/Projets/Analyse2019/data/mars2019.csv\n# Importer csv Linelist à partir de données/listes linéare/propres/sous-dossiers d'un projet R\n\nlinelist <- import(here(\"data\", \"clean\", \"linelists\", \"marin_country.csv\"))"},{"path":"rbasics.html","id":"objets","chapter":"3 R - les bases","heading":"3.9 Objets","text":"Tout dans R est un objet, et R est une langue “orienté sur l’objet”. Les sections suivantes expliquent:Comment créer des objets (<-)Types d’objets (par exemple, trames de données, vecteurs ..)Comment accéder à des sous-parties d’objets (par exemple, des variables dans un jeu de données)Classes d’objets (ex. numérique, logique, nombres entieres, double, caractère, facteur)","code":""},{"path":"rbasics.html","id":"tout-est-un-objet","chapter":"3 R - les bases","heading":"Tout est un objet","text":"Cette section est adaptée du projet R4Epis.Tout ce que vous stockez dans R - des ensembles de données, des variables, une liste de noms de villages, un nombre total de population, même des sorties telles que des graphiques - sont des objets qui sont attribués à un nom et peuvent être référencés dans les commandes ultérieures.Un objet existe lorsque vous lui avez attribué une valeur (voir la section d’attribution ci-dessous). Lorsqu’une valeur lui est attribuée, l’objet apparaît dans l’environnement (voir le volet supérieur droit de RStudio). Il peut alors être exploité, manipulé, modifié et redéfini.","code":""},{"path":"rbasics.html","id":"définir-des-objets--","chapter":"3 R - les bases","heading":"Définir des objets (<-)","text":"Créez des objets en leur attribuant une valeur avec l’opérateur <-. Vous pouvez considérer l’opérateur d’affectation<- comme les mots “est défini comme”. Les commandes d’affectation suivent généralement un ordre standard:nom_objet <- valeur (ou processus/calcul qui produit une valeur)Par exemple, vous souhaiterez peut-être enregistrer la semaine de rapport épidémiologique en cours en tant qu’objet de référence dans le code ultérieur. Dans cet exemple, l’objet semaine_en_cours est créé lorsqu’il reçoit la valeur \"2018-W10\" (les guillemets en font une valeur de caractère). L’objet semaine_en_cours apparaîtra alors dans le volet Environnement de RStudio (en haut à droite) et pourra être référencé dans les commandes ultérieures.Voir les commandes R et leur sortie dans les cases ci-dessous.NOTE: Notez que le [1] dans la sortie de la console R indique simplement que vous visualisez le premier élément de la sortieATTENTION: La valeur d’un objet peut être écrasée à tout moment en exécutant une commande d’affectation pour redéfinir sa valeur. Ainsi, l’ordre d’exécution des commandes est très important.La commande suivante redéfinira la valeur de semaine_en_cours:Signe égal =Vous verrez également des signes égal dans le code R:Un double signe égal == entre deux objets ou valeurs pose une question logique: “est-ce égal à cela?”.Vous verrez également des signes égal dans les fonctions utilisées pour spécifier les valeurs des arguments d’un fonction (lisez-les dans les sections ci-dessous), par exemple max(age, na.rm = TRUE).Vous pouvez utiliser un seul signe égal = à la place de <- pour créer et définir des objets, mais cela est déconseillé. Vous pouvez lire pourquoi cela est déconseillé ici.Ensembles de donnéesLes ensembles de données sont également des objets (généralement des «dataframes») et doivent recevoir des noms lors de leur importation. Dans le code ci-dessous, l’objet linelist est créé et reçoit la valeur d’un fichier CSV importé avec le paquet rio et sa fonction import().Vous pouvez en savoir plus sur l’importation et l’exportation d’ensembles de données dans la section sur importer et exporter.ATTENTION: Une note rapide sur la dénomination des objets:Les noms d’objets ne doivent pas contenir d’espaces, mais vous devez utiliser un trait de soulignement (_) ou un point (.) au lieu d’un espace.Les noms d’objets sont sensibles à la casse (lettres majuscules et minuscules; ce qui signifie que Dataset_A est différent de dataset_A).Les noms d’objets doivent commencer par une lettre (ne peuvent pas commencer par un chiffre comme 1, 2 ou 3).Les sortiesLes sorties telles que les tableaux et les tracés fournissent un exemple de la façon dont les sorties peuvent être enregistrées en tant qu’objets ou simplement imprimées sans être enregistrées. Un tableau croisé du sexe et du résultat à l’aide de la fonction R base table() peut être imprimé directement sur la console R (sans être enregistré).La même table peut également être enregistrée en tant qu’objet nommé. Ensuite, éventuellement, il peut être imprimé.ColonnesLes colonnes d’un ensemble de données sont également des objets et peuvent être définies, écrasées et créées comme décrit ci-dessous dansla section sur les colonnes.Vous pouvez utiliser l’opérateur d’affectation de base R pour créer une nouvelle colonne. Ci-dessous, la nouvelle colonne bmi (indice de masse corporelle) est créée, et pour chaque ligne la nouvelle valeur est le résultat d’une opération mathématique sur la valeur de la ligne dans les colonnes wt_kg et ht_cm.Cependant, dans ce manuel, nous mettons l’accent sur une approche différente de la définition des colonnes, qui utilise la fonction mutate() du package dplyr et piping avec l’opérateur pipe (%>%). La syntaxe est plus facile à lire et il y d’autres avantages expliqués dans la page nettoyage de donnees et fonctions essentielles.Vous pouvez lire plus sur piping dans la section “Piping” ci-dessous.","code":"\n# Créer l'objet semaine_en_cours en lui attribuant une valeur:\nsemaine_en_cours <- \"2018-W10\"   \n\n# Imprime la valeur actuelle de l'objet semaine_en_cours dans la console:\nsemaine_en_cours## [1] \"2018-W10\"\n# Attribuer une NOUVELLE valeur à l'objet semaine_en_cours:\nsemaine_en_cours <- \"2018-W51\"\n\n# Afficher la valeur actuelle de semaine_en_cours dans la console:\nsemaine_en_cours## [1] \"2018-W51\"\n# <<linelist>> est créée et reçoit la valeur du fichier CSV importé:\nlinelist <- import(\"my_linelist.csv\")\n# Imprimé sur la console R uniquement:\ntable(linelist$gender, linelist$outcome)##    \n##     Death Recover\n##   f  1227     953\n##   m  1228     950\n# Enregistrer:\ngen_out_table <- table(linelist$gender, linelist$outcome)\n\n# Imprimer:\ngen_out_table##    \n##     Death Recover\n##   f  1227     953\n##   m  1228     950\n# Créer une nouvelle colonne \"bmi\" en utilisant la syntaxe de base R:\nlinelist$bmi <- linelist$wt_kg / (linelist$ht_cm/100)^2\n# Créer une nouvelle colonne \"bmi\" en utilisant la syntaxe dplyr:\nlinelist <- linelist %>% \n  mutate(bmi = wt_kg / (ht_cm/100)^2)"},{"path":"rbasics.html","id":"structure-dobjet","chapter":"3 R - les bases","heading":"Structure d’objet","text":"Les objets peuvent être une seule donnée (par exemple, “mon_numéro <-24”), ou ils peuvent être constitués de données structurées.Le graphique ci-dessous est emprunté à ce tutoriel R en ligne. Il montre certaines structures de données courantes et leurs noms. Les données spatiales ne sont pas incluses dans cette image, qui sont abordées dans la page bases de GIS.En épidémiologie (et en particulier en épidémiologie de terrain), vous rencontrerez le plus souvent des trames de données et des vecteurs:Notez que pour créer un vecteur “autonome” (ne faisant pas partie d’un bloc de données), la fonction c() est utilisée pour combiner les différents éléments. Par exemple, si vous créez un vecteur de couleurs à appliquer à l’échelle de couleurs d’un tracé:vector_of_colors <- c(\"blue\", \"red2\", \"orange\", \"grey\")","code":""},{"path":"rbasics.html","id":"classes-dobjets","chapter":"3 R - les bases","heading":"Classes d’objets","text":"Tous les objets stockés dans R ont une classe qui indique à R comment gérer l’objet. Il existe de nombreuses classes possibles, mais les plus courantes incluent:Vous pouvez tester la classe d’un objet en fournissant son nom à la fonction class(). Remarque : vous pouvez référencer une colonne spécifique dans un jeu de données en utilisant la notation «$» pour séparer le nom du jeu de données et le nom de la colonne.Parfois, une colonne sera automatiquement convertie dans une classe différente par R. Attention à cela ! Par exemple, si vous avez un vecteur ou une colonne de nombres, mais qu’une valeur de caractère est insérée; toute la colonne deviendra un caractère de classe.Un exemple courant de ceci est lors de la manipulation d’un bloc de données afin d’imprimer un tableau. Si vous faites une ligne totale et essayez de coller/coller ensemble des pourcentages dans la même cellule que des nombres (par exemple 23 (40%)), le toute la colonne numérique ci-dessus sera convertie en caractère et ne pourra plus être utilisée pour des calculs mathématiques. Parfois, vous devrez convertir des objets ou des colonnes dans une autre classe.Convertit en classe “facteur”Remarque: la redéfinition de l’ordre\ndes niveaux de valeur nécessite des\narguments supplémentairesDe même, il existe des fonctions base R pour vérifier si un objet EST d’une classe spécifique, comme .numeric(), .character(), .double(), .facteur(), .integer()Voici plus de matériel en ligne sur les classes et les structures de données dans R.","code":"\n# La classe doit être une trame de données ou un tibble:\nclass(linelist)         ## [1] \"data.frame\"\n# La classe doit être numérique:\nclass(linelist$age)## [1] \"numeric\"\n# La classe doit être caractère:\nclass(linelist$gender)## [1] \"character\"\n# Définir le vecteur avec des numéros:\nnum_vector <- c(1,2,3,4,5) \n\n# Le vecteur est de classe \"numérique\":\nclass(num_vector)          ## [1] \"numeric\"\n# Convertir le troisième élément en caractère:\nnum_vector[3] <- \"three\"   \n\n# Le vecteur est maintenant de classe \"caractère\"\nclass(num_vector)          ## [1] \"character\""},{"path":"rbasics.html","id":"colonnesvariables","chapter":"3 R - les bases","heading":"Colonnes/Variables ($)","text":"Une colonne dans un bloc de données est techniquement un “vecteur” (voir tableau ci-dessus) - une série de valeurs qui doivent toutes être de la même classe (caractère, numérique, logique, etc.).Un vecteur peut exister indépendamment d’un bloc de données, par exemple un vecteur de noms de colonnes que vous souhaitez inclure en tant que variables explicatives dans un modèle. Pour créer un vecteur “autonome”, utilisez la fonction c() comme ci-dessous:Les colonnes d’un bloc de données sont également des vecteurs et peuvent être appelées, référencées, extraites ou créées à l’aide du symbole $. Le symbole $ relie le nom de la colonne au nom de son bloc de données. Dans ce manuel, nous essayons d’utiliser le mot “colonne” au lieu de “variable”.En tapant le nom de la trame de données suivi de $, vous verrez également un menu déroulant de toutes les colonnes de la trame de données. Vous pouvez les faire défiler à l’aide de votre touche fléchée, en sélectionner une avec votre touche Entrée et éviter les fautes d’orthographe !CONSEIL AVANCÉ: Certains objets plus complexes (par exemple, une liste ou un objet epicontacts) peuvent avoir plusieurs niveaux accessibles via plusieurs signes dollar. Par exemple epicontacts$linelist$date_onset","code":"\n# Définir le vecteur autonome des valeurs de classe caractère:\nvar_explicatives <- c(\"gender\", \"fever\", \"chills\", \"cough\", \"aches\", \"vomit\")\n\n# Affiche les valeurs dans ce vecteur nommé:\nvar_explicatives## [1] \"gender\" \"fever\"  \"chills\" \"cough\"  \"aches\"  \"vomit\"\n# Récupérer la longueur du vecteur age:\nlength(linelist$age) # (l'âge est une colonne dans le bloc de données nomé \"linelist\")"},{"path":"rbasics.html","id":"accèsindex-avec-crochets","chapter":"3 R - les bases","heading":"Accès/index avec crochets ([ ])","text":"Vous devrez peut-être afficher des parties d’objets, également appelées “indexation”, ce qui se fait souvent à l’aide des crochets [ ]. L’utilisation de $ sur une trame de données pour accéder à une colonne est également un type d’indexation.Les crochets fonctionnent également pour renvoyer des parties spécifiques d’une sortie renvoyée, comme la sortie d’une fonction summary():Les crochets fonctionnent également sur les blocs de données pour afficher des lignes et des colonnes spécifiques. Vous pouvez le faire en utilisant la syntaxe dataframe[lignes, colonnes]:Notez que vous pouvez également réaliser l’indexation des lignes/colonnes ci-dessus sur les blocs de données et les tibbles en utilisant la syntaxe dplyr (fonctions filter() pour les lignes et select() pour les colonnes). Pour en savoir plus sur ces fonctions principales, consultez la page sur le nettoyage de deonnees et fonctions essentielles.Pour filtrer en fonction du “numéro de ligne”, vous pouvez utiliser la fonction dplyr row_number() avec des parenthèses ouvertes dans le cadre d’une instruction de filtrage logique. Vous utiliserez souvent l’opérateur %% et une plage de nombres dans le cadre de cette instruction logique, comme indiqué ci-dessous. Pour voir les premières N lignes, vous pouvez également utiliser la fonction spéciale dplyr head().Lors de l’indexation d’un objet de classe list, les crochets simplesretournent toujours avec la classe list, même si un seul objet est retourné. Les crochets doubles, cependant, peuvent être utilisés pour accéder à un seul élément et renvoyer une classe différente de la liste.Les parenthèses peuvent également être écrites les unes après les autres, comme illustré ci-dessous.Cette explication visuelle de l’indexation des listes, avec des poivrières est humoristique et utile.Voici à quoi ressemble la liste lorsqu’elle est imprimée sur la console. Voyez comment il y deux éléments nommés:hôpitaux, un vecteur de caractèresadresses, une trame de données d’adressesMaintenant, nous extrayons, en utilisant diverses méthodes:","code":"\n# Définir le vecteur:\nmon_vecteur <- c(\"a\", \"b\", \"c\", \"d\", \"e\", \"f\")\n\n# Imprimer le 5ème élément:\nmon_vecteur[5]## [1] \"e\"\n# Tout le résumé\nsummary(linelist$age)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n##    0.00    6.00   13.00   16.07   23.00   84.00      86\n# Juste le deuxième élément du résumé, avec le nom (en utilisant uniquement des crochets simples)\nsummary(linelist$age)[2]## 1st Qu. \n##       6\n# Juste le deuxième élément, sans nom (en utilisant des doubles crochets)\nsummary(linelist$age)[[2]]## [1] 6\n# Extraire un élément par son nom, sans afficher le nom\nsummary(linelist$age)[[\"Median\"]]## [1] 13\n# Afficher une ligne spécifique (2) du jeu de données, avec toutes les colonnes \n# (n'oubliez pas la virgule!)\nlinelist[2,]\n\n# Afficher toutes les lignes, mais une seule colonne:\nlinelist[, \"date_onset\"]\n\n# Afficher les valeurs de la ligne 2 et des colonnes 5 à 10:\nlinelist[2, 5:10]\n\n# Afficher les valeurs de la ligne 2 et des colonnes 5 à 10 et 18:\nlinelist[2, c(5:10, 18)]\n\n# Afficher les lignes 2 à 20 et des colonnes spécifiques:\nlinelist[2:20, c(\"date_onset\", \"outcome\", \"age\")]\n\n# Afficher les lignes et les colonnes en fonction de critères\n# *** Notez que le dataframe doit toujours être nommé dans les critères!\nlinelist[linelist$age > 25 , c(\"date_onset\", \"outcome\", \"age\")]\n\n# Utilisez View() pour voir les sorties dans le volet RStudio Viewer (plus facile à lire)\n# *** Notez le \"V\" majuscule dans la fonction View()\nView(linelist[2:20, \"date_onset\"])\n\n# Enregistrer en tant que nouvel objet:\nnew_table <- linelist[2:20, c(\"date_onset\")]\n# Afficher les 100 premières lignes:\nlinelist %>% \n     head(100)\n\n# Afficher la ligne 5 uniquement:\nlinelist %>% \n     filter(row_number() == 5)\n\n# Afficher les lignes 2 à 20 et trois colonnes spécifiques \n# (notez qu'aucun guillemet n'est nécessaire sur les noms de colonne)\nlinelist %>% \n     filter(row_number() %in% 2:20) %>% \n     select(date_onset, issue, age)\n# définir la liste des démos\nma_liste <- list(\n   # Le premier élément de la liste est un vecteur de caractères:\n   hopitaux = c(\"Central\", \"Empire\", \"Santa Anna\"),\n  \n   # Le deuxième élément de la liste est une trame de données d'adresses:\n   adresses = data.frame(\n     rue = c(\"145 Medical Way\", \"1048 Brown Ave\", \"999 El Camino\"),\n     ville = c(\"Andover\", \"Hamilton\", \"El Paso\")\n     )\n   )\nma_liste## $hopitaux\n## [1] \"Central\"    \"Empire\"     \"Santa Anna\"\n## \n## $adresses\n##               rue    ville\n## 1 145 Medical Way  Andover\n## 2  1048 Brown Ave Hamilton\n## 3   999 El Camino  El Paso\n# Cela renvoie l'élément dans la classe \"list\" - le nom de l'élément est toujours affiché:\nma_liste[1] ## $hopitaux\n## [1] \"Central\"    \"Empire\"     \"Santa Anna\"\n# Cela ne renvoie que le vecteur de caractères (sans nom):\nma_liste[[1]]## [1] \"Central\"    \"Empire\"     \"Santa Anna\"\n# Vous pouvez également indexer par le nom de l'élément de la liste:\nma_liste[[\"hopitaux\"]]## [1] \"Central\"    \"Empire\"     \"Santa Anna\"\n# Cela renvoie le troisième élément du vecteur de caractères \"hôpitaux\":\nma_liste[[1]][3] ## [1] \"Santa Anna\"\n# Cela renvoie la première colonne (\"rue\") de la trame de données d'adresse:\nma_liste[[2]][1]##               rue\n## 1 145 Medical Way\n## 2  1048 Brown Ave\n## 3   999 El Camino"},{"path":"rbasics.html","id":"supprimer-des-objets","chapter":"3 R - les bases","heading":"Supprimer des objets","text":"Vous pouvez supprimer des objets individuels de votre environnement R en mettant le nom dans la fonction rm() (sans guillemets):Vous pouvez supprimer tous les objets (vider votre espace de travail) en exécutant:","code":"\nrm(nom_objet)\nrm(list = ls(all = TRUE))"},{"path":"rbasics.html","id":"tuyauterie-piping","chapter":"3 R - les bases","heading":"3.10 Tuyauterie / “Piping” (%>%)","text":"Deux approches générales pour travailler avec des objets sont:Pipes/tidyverse - les tuyaux envoient un objet d’une fonction à\nl’autre - l’accent est mis sur l’action, pas sur l’objetDéfinir les objets intermédiaires - un objet est redéfini encore\net encore - l’accent est mis sur l’objet","code":""},{"path":"rbasics.html","id":"tuyaux-pipes","chapter":"3 R - les bases","heading":"Tuyaux / Pipes","text":"Expliqué simplement, l’opérateur pipe (%>%) passe une sortie intermédiaire d’une fonction à la suivante. \nVous pouvez penser que cela signifie “alors”. De nombreuses fonctions\npeuvent être liées avec %>%.Le tuyau met l’accent sur une séquence d’actions, et non sur l’objet sur lequel les actions sont effectuéesLes tuyaux sont plus efficaces lorsqu’une séquence d’actions doit être effectuée sur un objetLes tuyaux proviennent du paquet magrittr, qui est automatiquement inclus dans les paquets dplyr et tidyverseLes tuyaux peuvent rendre le code plus propre et plus facile à lire, plus intuitifEn savoir plus sur cette approche dans le tidyverse guide de styleVoici un faux exemple de comparaison, utilisant des fonctions fictives pour “faire un gâteau”. Tout d’abord, la méthode du tuyau:Voici un autre lien décrivant l’utilitaire de tuyaux.La tuyauterie n’est pas une fonction de base en R. Pour utiliser la tuyauterie, le paquet magrittr doit être installé et chargé (cela se fait généralement en chargeant le paquet tidyverse ou dplyr qui l’inclut). Vous pouvez en savoir plus sur la tuyauterie dans la documentation de magrittr.Notez que, tout comme les autres commandes R, les tuyaux peuvent être utilisés pour afficher simplement le résultat ou pour enregistrer/réenregistrer un objet, selon que l’opérateur d’affectation <- est impliqué ou non. Voir les deux exemplaires ci-dessous:%<>%\nIl s’agit d’un “tuyau d’affectation” du paquet magrittr, qui transmet un objet en avant et redéfinit également l’objet. Il doit\nêtre le premier opérateur pipe de la chaîne. C’est un raccourci. Les deux commandes ci-dessous sont équivalentes:","code":"\n# Un faux exemple de comment faire cuire un gâteau en utilisant la syntaxe de tuyauterie:\n\ngateau <- farine %>% # pour définir le gâteau, commencez par la farine, puis...\n     # ajouter des oeufs\n     add(oeufs) %>% \n     # ajouter de l'huile\n     add(huile) %>% \n     # ajouter de l'eau\n     add(eau) %>% \n     # mélanger ensemble avec cuillère pour 2 minutes:\n     mix_together(\n          ustensil = \"spoon\",\n          minutes = 2) %>%\n     # cuire à 200 degrés centigrade pour 35 minutes:\n     bake(\n          degrees = 200, \n          system = \"centigrade\",\n          minute = 35) %>%\n     # laissez-le refroidir\n     let_cool() \n# Créer ou écraser un objet, en le définissant sous \n# forme de nombres agrégés par catégorie d'âge (non imprimé)\nlinelist_summary <- linelist %>% \n  count(age_cat)\n# Imprimez le tableau des comptes dans la console, mais ne l'enregistrez pas:\nlinelist %>% \n  count(age_cat)##   age_cat    n\n## 1     0-4 1095\n## 2     5-9 1095\n## 3   10-14  941\n## 4   15-19  743\n## 5   20-29 1073\n## 6   30-49  754\n## 7   50-69   95\n## 8     70+    6\n## 9    <NA>   86\n# Utilisez l'opérateur d'affectation:\nlinelist <- linelist %>%\n  filter(age > 50)\n\n# Utilisez le tuyau d'affectation:\nlinelist %<>% filter(age > 50)"},{"path":"rbasics.html","id":"définir-les-objets-intermédiaires","chapter":"3 R - les bases","heading":"Définir les objets intermédiaires","text":"Cette approche de modification des objets ou trammes de données peut\nêtre meilleure si:Vous devez manipuler plusieurs objetsIl y des étapes intermédiaires qui sont significatives et méritent\ndes noms d’objets séparésDes risques:Créer de nouveaux objets pour chaque étape signifie créer beaucoup\nd’objets. Si vous utilisez le mauvais, vous ne vous en rendrez\npeut-être pas compte!Nommer tous les objets peut prêter à confusionLes erreurs peuvent ne pas être facilement détectablesSoit nommer chaque objet intermédiaire, soit écraser l’original, soit\ncombiner toutes les fonctions ensemble. Tous viennent avec leurs propres\nrisques.Vous trouverez ci-dessous le même exemple de faux “gâteau” que ci-dessus, mais en utilisant ce style:Combinez toutes les fonctions ensemble - c’est difficile à lire :","code":"\n# un faux exemple de comment faire un gâteau en utilisant cette méthode \n# (définissant des objets intermédiaires):\n\n# Ajouter le farine et les oeufs:\npate_1 <- left_join(farine, oeufs)\n\n# Ajouter l'huile:\npate_2 <- left_join (pate_1, huile)\n\n# Ajouter l'eau:\npate_3 <- left_join(pate_2, eau)\n\n# Melange tous ensemble:\npate_4 <- mix_together(object = pate_3, \n                       ustensil = \"spoon\", \n                       minutes = 2)\n\n# Cuire le gâteau dans le four:\ngateau <-bake(object = pate_4, \n              degrees = 200, \n              system = \"centigrade\", \n              minutes = 35)\n\n# Laissez-le à refroidir:\ngateau <- laisse_refroidir(gateau)\n# Un exemple de combinaison/imbrication de plusieurs fonctions - difficile à lire:\ngateau <- let_cool(bake(mix_together(pate_3, \n                                     utensil = \"spoon\", \n                                     minutes = 2), \n                        degrees = 200, \n                        system = \"centigrade\",\n                        minutes = 35))"},{"path":"rbasics.html","id":"operators","chapter":"3 R - les bases","heading":"3.11 Opérateurs clés et fonctions","text":"Cette section détaille les opérateurs dans R, tels que:Opérateurs définitionnelsOpérateurs relationnels (inférieur à, égal aussi..)Opérateurs logiques (et, ou…)Gestion des valeurs manquantesOpérateurs et fonctions mathématiques (+/-, >, sum(), median(),\n…)L’opérateur %%","code":""},{"path":"rbasics.html","id":"opérateurs-daffectation","chapter":"3 R - les bases","heading":"Opérateurs d’affectation","text":"<-L’opérateur d’affectation de base dans R est <-. Tel que nom_objet <- valeur.\nCet opérateur d’affectation peut également être écrit comme =. Nous vous conseillons d’utiliser <- pour une utilisation générale de R.Nous conseillons également d’entourer ces opérateurs d’espaces, pour\nplus de lisibilité.<<-Si Fonctions d’écriture, ou si vous utilisez R de\nmanière interactive avec des scripts sourcés, vous devrez peut-être\nutiliser cet opérateur d’affectation <<- (de base R). Cet\nopérateur est utilisé pour définir un objet dans un environnement R «\nparent » supérieur. Voir ceci référence en ligne.%<>%Il s’agit d’un “tuyau d’affectation” du paquet magrittr, qui dirige un objet vers l’avant et redéfinit également l’objet. Il doit être le premier opérateur pipe de la chaîne. Il s’agit d’un raccourci.%<+%Ceci est utilisé pour ajouter des données aux arbres phylogénétiques avec le package ggtree. Voir la page sur les arbres phylogénétiques ou ce livre de ressources en ligne.","code":""},{"path":"rbasics.html","id":"opérateurs-relationnels-et-logiques","chapter":"3 R - les bases","heading":"Opérateurs relationnels et logiques","text":"Les opérateurs relationnels comparent les valeurs et sont souvent\nutilisés lors de la définition de nouvelles variables et de\nsous-ensembles des blocs de données. Voici les opérateurs relationnels\ncourants dans R:FALSE (parce que R est\nsensible à la casse)Notez que == (double\négal) est différent de\n= (simple égal), qui\nagit comme l’opérateur\nd’affectation <-FALSEvoir page sur valeur\nmanquanteLes opérateurs logiques, tels que ET et OU, sont souvent utilisés pour\nconnecter des opérateurs relationnels et créer des critères plus\ncomplexes. Les instructions complexes peuvent nécessiter des parenthèses\n( ) pour le regroupement et l’ordre d’application.Par exemple, ci-dessous, nous avons une liste linéaire avec deux\nvariables que nous voulons utiliser pour créer notre définition de cas,\nresultat_tdr, un résultat d’un test rapide, et autres_cas_menage,\nqui nous dira s’il y d’autres cas dans le ménage. La commande\nci-dessous utilise la fonction case_when() pour créer la nouvelle\nvariable case_def telle que:Notez que R est sensible à la casse, donc “Positif” est différent de\n“positif”…","code":"\nlinelist_propre <- linelist %>%\n  mutate(case_def = case_when(\n    is.na(resultat_tdr) & is.na(autres_cas_menage)             ~ NA_character_,\n    resultat_tdr == \"Positive\"                                 ~ \"Confirmé\",\n    resultat_tdr != \"Positive\" & other_cases_in_home == \"Oui\"  ~ \"Probable\",\n    TRUE                                                       ~ \"Suspect\"\n  ))"},{"path":"rbasics.html","id":"valeurs-manquantes","chapter":"3 R - les bases","heading":"Valeurs manquantes","text":"Dans R, les valeurs manquantes sont représentées par la valeur spéciale\nNA (une valeur “réservée”) (lettres majuscules N et - pas entre\nguillemets). Si vous importez des données qui enregistrent des données\nmanquantes d’une autre manière (par exemple, 99, “Missing” ou .), vous\npouvez recoder ces valeurs en “NA”. La procédure à suivre est expliquée\ndans la page importer et exporter.Pour tester si une valeur est NA, utilisez la fonction spéciale .na(), qui renvoie TRUE ou FALSE.En savoir plus sur les valeurs manquantes, infinies, NULL et\nimpossibles dans la page sur les valeur manquantes.\nDécouvrez comment convertir les valeurs manquantes lors de l’importation\nde données dans la page sur importer et exporter.","code":"\n# 2 cas positives, un suspect et un inconnu:\nresultat_tdr <- c(\"Positive\", \"Suspect\", \"Positive\", NA)   \n\n# Verifier si il y' a des valeurs manquantes:\nis.na(resultat_tdr)## [1] FALSE FALSE FALSE  TRUE"},{"path":"rbasics.html","id":"mathématiques-et-statistiques","chapter":"3 R - les bases","heading":"Mathématiques et statistiques","text":"Tous les opérateurs et fonctions de cette page sont automatiquement\ndisponibles en utilisant base R.","code":""},{"path":"rbasics.html","id":"opérateurs-mathématiques","chapter":"3 R - les bases","heading":"Opérateurs mathématiques","text":"Ceux-ci sont souvent utilisés pour effectuer des additions, des\ndivisions, pour créer de nouvelles colonnes, etc. Vous trouverez\nci-dessous des opérateurs mathématiques courants dans R. Que vous\nmettiez des espaces autour des opérateurs n’est pas important.","code":""},{"path":"rbasics.html","id":"fonctions-mathématiques","chapter":"3 R - les bases","heading":"Fonctions mathématiques","text":"Remarque: pour round(), les digits = spécifient le nombre de\ndécimales placées. Utilisez signif() pour arrondir à un nombre de\nchiffres significatifs.","code":""},{"path":"rbasics.html","id":"notation-scientifique","chapter":"3 R - les bases","heading":"Notation scientifique","text":"La probabilité d’utilisation de la notation scientifique dépend de la\nvaleur de l’option “scipen”.D’après la documentation de ?options: scipen est une pénalité à\nappliquer lors de la décision d’imprimer des valeurs numériques en\nnotation fixe ou exponentielle. Les valeurs positives tendent vers la\nnotation fixe et négatives vers la notation scientifique: la notation\nfixe sera préférée à moins qu’elle ne soit plus large de plus de\n‘scipen’.S’il est réglé sur un nombre faible (par exemple 0), il sera toujours\n“allumé”. Pour “désactiver” la notation scientifique dans votre session\nR, définissez-la sur un nombre très élevé, par exemple:","code":"\n# Désactiver la notation scientifique\noptions(scipen = 999)"},{"path":"rbasics.html","id":"arrondi","chapter":"3 R - les bases","heading":"Arrondi","text":"DANGER: round() utilise “l’arrondi du banquier” qui arrondit à partir de 0,5 uniquement si le nombre supérieur est pair. Utilisez round_half_up() de janitor pour arrondir systématiquement les moitiés au nombre entier le plus proche. Voir cette explication","code":"\n# Fonction d'arrondi avec R de base:\nround(c(2.5, 3.5))## [1] 2 4\n# Fonction d'arrondi du paquet \"janitor\":\njanitor::round_half_up(c(2.5, 3.5))## [1] 3 4"},{"path":"rbasics.html","id":"fonctions-statistiques","chapter":"3 R - les bases","heading":"Fonctions statistiques","text":"ATTENTION: Les fonctions ci-dessous incluront par défaut les valeurs manquantes dans les calculs. Les valeurs manquantes entraîneront une sortie de NA, sauf si l’argument na.rm = TRUE est spécifié. Cela peut être écrit en raccourci comme na.rm = T.Remarques:*quantile(): x est le vecteur numérique à examiner et probs = est un vecteur numérique avec des probabilités comprises entre 0 et 1,0, par exemple c(0,5, 0,8, 0,85)**summary(): donne un résumé sur un vecteur numérique comprenant la moyenne, la médiane et les centiles communsDANGER: Si vous fournissez un vecteur de nombres à l’une des fonctions ci-dessus, assurez-vous d’envelopper les nombres dans c().","code":"\n# Si vous fournissez des nombres bruts à une fonction, \n# enveloppez-les dans c():\n\n# !!! ERREUR !!!\nmean(1, 6, 12, 10, 5, 0)      ## [1] 1\n# CORRECT\nmean(c(1, 6, 12, 10, 5, 0)) ## [1] 5.666667"},{"path":"rbasics.html","id":"autres-fonctions-utiles","chapter":"3 R - les bases","heading":"Autres fonctions utiles","text":"","code":""},{"path":"rbasics.html","id":"in","chapter":"3 R - les bases","heading":"%in%","text":"Un opérateur très utile pour faire correspondre les valeurs et pour évaluer rapidement si une valeur se trouve dans un vecteur ou une trame de données:Pour demander si une valeur n’est pas %% un vecteur, placez un point d’exclamation (!) devant l’instruction logique:%% est très utile lors de l’utilisation de la fonction dplyr case_when(). Vous pouvez définir un vecteur précédemment, puis le référencer ultérieurement. Par exemple:Remarque: Si vous souhaitez détecter une chaîne partielle, en utilisant peut-être str_detect() de stringr, il n’acceptera pas un vecteur de caractères tel que c(\"1\", \"Oui\", \"oui\", \"y \"). Au lieu de cela, il doit recevoir une expression régulière - une chaîne condensée avec des barres OU, telle que “1|Oui|oui|y”. Par exemple, str_detect(hospitalisé, \"1|Oui|oui|y\"). Voir la page sur les caractères et les chaîne de caractères pour plus d’informations.Vous pouvez convertir un vecteur de caractères en une expression\nrégulière nommée avec cette commande:","code":"\nmon_vecteur <- c(\"a\", \"b\", \"c\", \"d\")\n\"a\" %in% mon_vecteur## [1] TRUE\n\"h\" %in% mon_vecteur## [1] FALSE\n# Pour nier, mettre une exclamation devant:\n!\"a\" %in% mon_vecteur## [1] FALSE\n!\"h\" %in% mon_vecteur## [1] TRUE\naffirmative <- c(\"1\", \"Yes\", \"YES\", \"yes\", \"y\", \"Y\", \"oui\", \"Oui\", \"Si\")\n\nlinelist <- linelist %>% \n  mutate(enfant_hospitalise = case_when(\n    hospitalise %in% affirmative & age < 18 ~ \"Hospitalized Child\",\n    TRUE                                    ~ \"Not\"))\naffirmative <- c(\"1\", \"Yes\", \"YES\", \"yes\", \"y\", \"Y\", \"oui\", \"Oui\", \"Si\")\naffirmative## [1] \"1\"   \"Yes\" \"YES\" \"yes\" \"y\"   \"Y\"   \"oui\" \"Oui\" \"Si\"\n# Condenser à: \naffirmative_str_search <- paste0(affirmative, collapse = \"|\")  # option avec R de base\naffirmative_str_search <- str_c(affirmative, collapse = \"|\")   # option avec le paquet stringr\n\naffirmative_str_search## [1] \"1|Yes|YES|yes|y|Y|oui|Oui|Si\""},{"path":"rbasics.html","id":"erreurs-et-avertissements","chapter":"3 R - les bases","heading":"3.12 Erreurs et avertissements","text":"Cette section explique :La différence entre les erreurs et les avertissementsConseils généraux de syntaxe pour l’écriture de code RAides au codeLes erreurs et avertissements courants ainsi que des conseils de dépannage sont disponibles sur la page erreurs frequentes.","code":""},{"path":"rbasics.html","id":"erreur-contre-avertissement","chapter":"3 R - les bases","heading":"Erreur contre avertissement","text":"Lorsqu’une commande est exécutée, la console R peut afficher des messages d’avertissement ou d’erreur en texte rouge.Un avertissement signifie que R terminé votre commande, mais dû prendre des mesures supplémentaires ou produit une sortie inhabituelle dont vous devez être conscient.Un avertissement signifie que R terminé votre commande, mais dû prendre des mesures supplémentaires ou produit une sortie inhabituelle dont vous devez être conscient.Une erreur signifie que R n’pas pu terminer votre commande.Une erreur signifie que R n’pas pu terminer votre commande.Cherchez des indices:Le message d’erreur/d’avertissement inclura souvent un numéro de ligne pour le problème.Le message d’erreur/d’avertissement inclura souvent un numéro de ligne pour le problème.Si un objet “est inconnu” ou “introuvable”, vous l’avez peut-être mal orthographié, vous avez oublié d’appeler un package avec library() ou vous avez oublié de relancer votre script après avoir apporté des modifications.Si un objet “est inconnu” ou “introuvable”, vous l’avez peut-être mal orthographié, vous avez oublié d’appeler un package avec library() ou vous avez oublié de relancer votre script après avoir apporté des modifications.Si tout le reste échoue, copiez le message d’erreur dans Google avec quelques termes clés - il y de fortes chances que quelqu’un d’autre ait déjà travaillé dessus!","code":""},{"path":"rbasics.html","id":"conseils-généraux-sur-la-syntaxe","chapter":"3 R - les bases","heading":"Conseils généraux sur la syntaxe","text":"Quelques points à retenir lors de l’écriture de commandes dans R, pour éviter les erreurs et les avertissements:Fermez toujours les parenthèses - astuce: comptez le nombre de “(” et de parenthèses fermantes “)” pour chaque bloc de codeÉvitez les espaces dans les noms de colonnes et d’objets. Utilisez le trait de soulignement ( _ ) ou les points ( . ) à la placeGardez une trace et n’oubliez pas de séparer les arguments d’une fonction par des virgulesR est sensible à la casse, ce qui signifie que Variable_A est différent de Variable_a","code":""},{"path":"rbasics.html","id":"aides-au-code","chapter":"3 R - les bases","heading":"Aides au code","text":"N’importe quel script (RMarkdown ou autre) donnera des indices lorsque vous avez fait une erreur. Par exemple, si vous avez oublié d’écrire une virgule là où c’est nécessaire, ou de fermer une parenthèse, RStudio lèvera un drapeau sur cette ligne, sur le côté droit du script, pour vous avertir.","code":""},{"path":"transition_to_r.html","id":"transition_to_r","chapter":"4 Transition vers R","heading":"4 Transition vers R","text":"Nous vous proposons ci-dessous quelques conseils et ressources si vous êtes en train de passer à R.R été introduit à la fin des années 1990 et depuis pris une ampleur considérable. Ses capacités sont si étendues que les alternatives commerciales ont réagi aux développements de R afin de rester compétitives! (lire cet article comparant R, SPSS, SAS, STATA et Python).En outre, R est beaucoup plus facile à apprendre qu’il y dix ans. Auparavant, R avait la réputation d’être difficile pour les débutants. C’est désormais beaucoup plus facile grâce à des interfaces utilisateur conviviales comme RStudio, à un code intuitif comme le tidyverse et à de nombreuses ressources didactiques.Ne vous sentez pas intimidé - venez découvrir le monde de R!","code":""},{"path":"transition_to_r.html","id":"de-excel","chapter":"4 Transition vers R","heading":"4.1 De Excel","text":"Passer directement d’Excel à R est un objectif tout à fait réalisable. Cela peut sembler décourageant, mais vous pouvez le faire!Il est vrai qu’une personne ayant de solides compétences en Excel peut effectuer des activités très avancées dans Excel seul - même en utilisant des outils de script comme VBA. Excel est utilisé dans le monde entier et constitue un outil essentiel pour un épidémiologiste. Cependant, le compléter avec R peut améliorer et étendre considérablement vos méthodes de travail.","code":""},{"path":"transition_to_r.html","id":"bénéfices","chapter":"4 Transition vers R","heading":"Bénéfices","text":"Vous constaterez que l’utilisation de R offre d’immenses avantages en termes de gain de temps, d’analyses plus cohérentes et plus précises, de reproductibilité, de partage et de correction plus rapide des erreurs. Comme tout nouveau logiciel, il y une “courbe” d’apprentissage dans laquelle vous devez investir du temps pour vous familiariser. Les bénéfices seront significatifs et un immense champ de nouvelles possibilités s’ouvrira à vous avec R.Excel est un logiciel bien connu qui peut être facile à utiliser pour un débutant afin de produire des analyses et des visualisations simples par “pointer-cliquer”. En comparaison, il faut parfois quelques semaines pour se familiariser avec les fonctions et l’interface de R. Cependant, R évolué au cours des dernières années pour devenir beaucoup plus facile à utiliser pour les débutants.De nombreux flux de travail Excel reposent sur la mémoire et la répétition - les risques d’erreur sont donc nombreux. En outre, le nettoyage des données, la méthodologie d’analyse et les équations utilisées sont généralement cachés. Un nouveau collègue peut avoir besoin de beaucoup de temps pour apprendre ce que fait un classeur Excel et comment le réparer. Avec R, toutes les étapes sont explicitement écrites dans le script et peuvent être facilement visualisées, modifiées, corrigées et appliquées à d’autres ensembles de données.Pour commencer votre transition d’Excel à R, vous devez adapter votre état d’esprit sur quelques points importants:","code":""},{"path":"transition_to_r.html","id":"données-ordonnées-tidy-data","chapter":"4 Transition vers R","heading":"Données ordonnées (“Tidy” data)","text":"Utilisez des données “ordonnées” lisibles par une machine plutôt que des données désordonnées “lisibles par l’homme”. Il existe trois exigences principales pour les données “ordonnées”, comme l’explique ce tutoriel “tidy” data avec R:Chaque variable doit avoir sa propre colonneChaque observation doit avoir sa propre ligneChaque valeur doit avoir sa propre celluleAux utilisateurs d’Excel - pensez au rôle que les tableaux Excel jouent pour normaliser les données et rendre le format plus compréhensible.Un exemple de données “ordonnées” serait la liste linéaire (linelist) utilisée dans ce manuel - chaque variable est contenue dans une colonne, chaque observation (un cas) sa propre ligne, et chaque valeur est dans une seule cellule. Ci-dessous, vous pouvez visualiser les 50 premières lignes de la liste linéaire.:La principale raison pour laquelle rencontre des données non ordonnées est que de nombreuses feuilles de calcul Excel sont conçues pour être lues facilement par des humains et non par des machines/logiciels.Pour vous aider à voir la différence, voici quelques exemples fictifs de données non ordonnées qui privilégient la lisibilité humaine à la lisibilité machine.:Problèmes: Dans la feuille de calcul ci-dessus, il y des cellules fusionnées qui ne sont pas facilement digérées par R. La ligne qui doit être considérée comme “l’en-tête” n’est pas claire. Un dictionnaire basé sur les couleurs se trouve à droite et les valeurs des cellules sont représentées par des couleurs - ce qui n’est pas non plus facilement interprété par R (ni par les humains atteints de daltonisme !). En outre, différents éléments d’information sont combinés dans une seule cellule (plusieurs organisations partenaires travaillant dans un même domaine, ou le statut ” à confirmer ” dans la même cellule que ” partenaire D “).Problèmes: Dans la feuille de calcul ci-dessus, il y de nombreuses lignes et colonnes vides supplémentaires dans l’ensemble de données - cela causera des problèmes de nettoyage dans R. De plus, les coordonnées GPS sont réparties sur deux lignes pour un centre de traitement donné. Par ailleurs, les coordonnées GPS sont dans deux formats différents!Les ensembles de données “ordonnées” ne sont peut-être pas aussi lisibles à l’œil nu, mais ils facilitent grandement le nettoyage et l’analyse des données ! Les données ordonnées peuvent être stockées sous différents formats, par exemple “long” ou “large” (voir la page sur les Données pivotées), mais les principes ci-dessus sont toujours respectés.","code":""},{"path":"transition_to_r.html","id":"functions-1","chapter":"4 Transition vers R","heading":"Functions","text":"Le mot “fonction” en R est peut-être nouveau, mais le concept existe aussi dans Excel sous la forme de formules. Les formules dans Excel requièrent également une syntaxe précise (par exemple, le placement des points-virgules et des parenthèses). Tout ce que vous avez à faire est d’apprendre quelques nouvelles fonctions et comment elles fonctionnent ensemble dans R.","code":""},{"path":"transition_to_r.html","id":"scripts-1","chapter":"4 Transition vers R","heading":"Scripts","text":"Au lieu de cliquer sur des boutons et de faire glisser des cellules, vous allez écrire chaque étape et procédure dans un “script”.\nLes utilisateurs d’Excel connaissent peut-être les “macros VBA” qui utilisent également une approche de script.Le script R est constitué d’instructions étape par étape, ce qui permet à tout collègue de lire le script et de voir facilement les étapes que vous avez suivies. Cela permet également de corriger les erreurs ou les calculs imprécis. Voir la section Bases de R sur les scripts pour des exemples.Voici un exemple de script R:","code":""},{"path":"transition_to_r.html","id":"ressources-excel-à-r","chapter":"4 Transition vers R","heading":"Ressources Excel à R","text":"Voici quelques liens vers des tutoriels pour vous aider à passer d’Excel à R:R vs. ExcelCours RStudio en R pour les utilisateurs d’Excel","code":""},{"path":"transition_to_r.html","id":"intéraction-r-excel","chapter":"4 Transition vers R","heading":"Intéraction R-Excel","text":"R dispose de moyens robustes pour importer des classeurs Excel, travailler avec les données, exporter/enregistrer des fichiers Excel et travailler avec les nuances des feuilles Excel.Il est vrai que certaines des mises en forme Excel les plus esthétiques peuvent se perdre dans la traduction (par exemple, l’italique, le texte latéral, etc.). Si votre flux de travail nécessite le passage de documents entre R et Excel tout en conservant le formatage Excel original, essayez des packages comme openxlsx.","code":""},{"path":"transition_to_r.html","id":"de-stata","chapter":"4 Transition vers R","heading":"4.2 De Stata","text":"Passer de Stata à RDe nombreux épidémiologistes apprennent d’abord à utiliser Stata, et le passage à R peut sembler intimidant. Cependant, si vous êtes un utilisateur de Stata à l’aise, le passage à R est certainement plus facile à gérer que vous ne le pensez. Bien qu’il existe quelques différences essentielles entre Stata et R dans la façon dont les données peuvent être créées et modifiées, ainsi que dans la façon dont les fonctions d’analyse sont mises en œuvre - après avoir appris ces différences clés, vous serez en mesure de traduire vos compétences.Vous trouverez ci-dessous quelques traductions clés entre Stata et R, qui pourront vous être utiles lors de la lecture de ce guide.Notes généralesLe fichier d’accès au travailImportation et visualisation des donnéesManipulation de données de baseAnalyse descriptiveBien que cette liste donne un aperçu des bases de la conversion des commandes Stata en R, elle n’est pas complète. Il existe de nombreuses autres ressources intéressantes pour les utilisateurs de Stata qui passent à R:https://dss.princeton.edu/training/RStata.pdfhttps://clanfear.github.io/Stata_R_Equivalency/docs/r_stata_commands.htmlhttp://r4stats.com/books/r4stata/","code":""},{"path":"transition_to_r.html","id":"de-sas","chapter":"4 Transition vers R","heading":"4.3 De SAS","text":"Passer de SAS à RSAS est couramment utilisé dans les agences de santé publique et les domaines de recherche universitaires. Bien que la transition vers une nouvelle langue soit rarement un processus simple, la compréhension des principales différences entre SAS et R peut vous aider à commencer à naviguer dans cette nouvelle langue en utilisant votre langue maternelle.\nVous trouverez ci-dessous les principales traductions en matière de gestion des données et d’analyse descriptive entre SAS et R.Notes généralesLe fichier d’accès au travailImportation et visualisation des donnéesManipulation de données de baseAucune procédure spéciale n’est nécessaire pour créer une variable. Les nouvelles variables sont créées simplement en tapant le nom de la nouvelle variable, suivi d’un signe égal, puis d’une expression pour la valeur. Générez de nouvelles variables en utilisant la fonction mutate(). Voir la page Nettoyage des données et fonctions de base pour plus de détails sur toutes les fonctions dplyr ci-dessous.\nLes variables sont renommées en utilisant rename *ancien_nom=nouveau_nom*|Les colonnes peuvent être renommées à l’aide de la fonction rename(nouveau_nom = ancien_nom)\nLes variables sont conservées en utilisant **keep**=nom_variable|Les colonnes peuvent être sélectionnées en utilisant la fonction select() avec le nom de la colonne entre parenthèses.\nLes variables sont supprimées à l’aide de la fonction **drop**=nom_variable|Les colonnes peuvent être supprimées à l’aide de la fonction select() avec le nom de la colonne entre parenthèses après le signe moins.\nLes variables factorielles peuvent être étiquetées dans l’étape de données (Data Step) en utilisant l’instruction Label. L’étiquetage des valeurs peut être fait en convertissant la colonne en classe factorielle et en spécifiant les niveaux. Voir la page sur les Facteurs. Les noms de colonnes ne sont généralement pas étiquetés.\nLes enregistrements sont sélectionnés à l’aide des instructions ou dans l’étape de données (Data Step). Les enregistrements sont sélectionnés à l’aide de la fonction filter() avec plusieurs conditions de sélection séparées soit par un opérateur (&), soit par une virgule.\nLes ensembles de données sont combinés en utilisant l’instruction Merge dans l’étape Data Step. Les jeux de données à fusionner doivent d’abord être triés à l’aide de la procédure Proc Sort. Le package `dplyr offre quelques fonctions pour fusionner les jeux de données. Voir la page Joindre des données pour plus de détails.Analyse descriptiveQuelques ressources utiles:R SAS SPSS Users (2011)SAS R, Second Edition (2014)","code":""},{"path":"transition_to_r.html","id":"interopérabilité-des-données","chapter":"4 Transition vers R","heading":"4.4 Interopérabilité des données","text":"Voir la page Import et export pour des détails sur comment le package rio peut importer et experter des fichiers tels que des fichiers STATA .dta, des fichiers SAS .xpt et.sas7bdat, des fichiers SPSS .por et.sav, et plusieurs autres.","code":""},{"path":"suggested_packages.html","id":"suggested_packages","chapter":"5 Paquets conseillés","heading":"5 Paquets conseillés","text":"Vous trouverez ci-dessous une longue liste de paquets suggérés réaliser des tâches utiles lors d’analyses épidémiologies en R. Vous pouvez copier ce code, l’exécuter, et tous ces paquets seront installés à partir du CRAN et chargés pour être utilisés dans la session R actuelle. Si un paquet est déjà installé, il sera importé pour être utilisé mais pas réinstallé.Vous pouvez modifier le code avec les symboles # pour exclure les paquets que vous ne voulez pas.noter :Installez le paquet pacman avant d’exécuter le code ci-dessous. Vous pouvez le faire avec install.packages(\"pacman\"). Dans ce guide, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire et l’importe dans la session R actuelle. Vous pouvez également charger des paquets qui sont déjà installés avec library() depuis base R.Dans le code ci-dessous, les paquets qui sont inclus lors de l’installation/de l’import d’un autre paquet sont indiqués par une indentation et un dièse. Par exemple, ggplot2 est listé sous tidyverse.Si plusieurs paquets ont des fonctions portant le même nom, un masquage peut se produire lorsque la fonction du paquet le plus récemment chargé prend le dessus. Pour en savoir plus, consultez la page sur les bases de R. Vous pouvez utiliser le paquet conflicted pour gérer de tels conflits de manière explicite.Voir la section sur les bases de R sur les paquets pour plus d’informations sur pacman et le masquage.Pour voir les versions de R, RStudio et les paquets R utilisés lors de la production de ce manuel, voir la page sur les Notes techniques et choix éditoriaux.","code":""},{"path":"suggested_packages.html","id":"paquets-disponibles-sur-le-cran","chapter":"5 Paquets conseillés","heading":"5.1 Paquets disponibles sur le CRAN","text":"","code":"\n##############################################\n# Liste de paquets R utiles en épidémiologie #\n##############################################\n\n# Ce script utilise la fonction p_load() du paquet **pacman**, \n# qui installe le paquet si ce dernier n'est pas encore installé sur\n# l'ordinateur, et l'importe dans la session active pour l'utiliser \n# s'il est déjà installé.\n\n\n# S'assure de l'installation du paquet \"pacman\".\nif (!require(\"pacman\")) install.packages(\"pacman\")\n\n\n#  Paquets du CRAN\n##############################\npacman::p_load(\n     \n     # Apprendre R\n     ############\n     learnr,   # tutos interactifs dans le volet tutos de RStudio\n     swirl,    # tutoriels interactifs dans la console R\n        \n     # Gestion des projets et des dossiers\n     #############################\n     here,     # chemins de fichiers relatifs au dossier racine du projet R\n     rio,      # import/export de nombreux types de données\n     openxlsx, # import/export de classeurs Excel à feuilles multiples \n     \n     # Installation et gestion des paquets\n     ################################\n     pacman,   # installation et importation des paquets\n     renv,     # gérer les versions des paquets lors de collaborations\n     remotes,  # installer des paquets provenant de Github\n     \n     # Paquets généralistes pour gérer les données\n     #########################\n     tidyverse,    # méta-paquet qui comprend de nombreux paquets pour le traitement et la présentation des données.\n          # dplyr : gestion des données\n          # tidyr : gestion des données\n          # ggplot2 : visualisation de données\n          # stringr : travailler avec des chaînes de caractères et des caractères\n          # forcats : travailler avec des facteurs \n          # lubridate : travailler avec des dates\n          # purrr : itération et travail avec des listes\n\n     linelist,     # nettoyage de linelists\n     naniar,       # évaluation des données manquantes\n     \n     # Statistiques\n     ############\n     janitor,      # nettoyage des données\n     gtsummary,    # création de tableaux descriptifs et statistiques\n     rstatix,      # exécution rapide de tests et de résumés statistiques\n     broom,        # nettoyage des résultats des régressions\n     lmtest,       # likelihood-ratio tests\n     easystats,\n          # parameters, # alternative pour ordonner les résultats des régressions\n          # see,        # alternative pour visualiser les forest plots\n     \n     # modélisation épidémiologique\n     ###################\n     epicontacts,    # Analyse des réseaux de transmission\n     EpiNow2,        # Estimation de Rt\n     EpiEstim,       # Estimation Rt\n     projections,    # Projections d'incidence\n     incidence2,     # Création d'épicurves et traitement des données d'incidence\n     i2extras,       # Fonctions supplémentaires pour le paquet incidence2\n     epitrix,        # Fonctions epi utiles\n     distcrete,      # Distributions discrètes de délais\n     \n     \n     # graphiques - general\n     #################\n     #ggplot2,     # inclus dans tidyverse\n     cowplot,      # combinaison de graphiques  \n     patchwork,  # combinaison de graphiques (alternative à cowplot)     \n     RColorBrewer, # échelles de couleurs\n     ggnewscale,   # pour ajouter des couches supplémentaires de schémas de couleurs\n\n     # graphiques - types spécifiques\n     ########################\n     DiagrammeR,  # diagrammes utilisant le langage DOT\n     incidence2,  # courbes épidémiques\n     gghighlight, # mettre en évidence un sous-ensemble\n     ggrepel,     # étiquettes intelligentes\n     plotly,      # graphiques interactifs\n     gganimate,   # graphiques animés \n     \n\n     # SIG\n     ######\n     sf,            # pour gérer les données spatiales en utilisant un format Simple Feature\n     tmap,          # pour produire des cartes simples, fonctionne à la fois pour les cartes interactives et statiques\n     OpenStreetMap, # pour ajouter la carte de base OSM dans la carte ggplot\n     spdep,         # statistiques spatiales \n     \n     # Rapports automatisés\n     #################\n     rmarkdown,     # produit des PDFs, des documents Word, des Powerpoints, et des fichiers HTML\n     reportfactory, # auto-organisation des sorties R Markdown\n     officer,       # création de documents word et powerpoints (alternative à Rmarkdown)\n     \n     # Tableaux de bord\n     ############\n     flexdashboard, # création de tableaux de bord (syntaxe Rmarkdown)\n     shiny,         # applications web interactives\n     \n     # Créer des tableaux pour présenter des résultats\n     #########################\n     knitr,       # Génération de rapports R Markdown et tableaux html\n     flextable,   # Tableaux HTML\n     # DT,        # Tableaux HTML (alternative)\n     # gt,        # Tableaux HTML (alternative)\n     # huxtable,  # Tableaux HTML (alternative) \n     \n     # Phylogenetique\n     ###############\n     ggtree,  # visualisation et annotation d'arbres phylogénétiques\n     ape,     # analyse phylogénétique et évolutive\n     treeio,  # visualision des fichiers phylogénétiques\n \n)"},{"path":"suggested_packages.html","id":"paquets-hébergés-sur-github","chapter":"5 Paquets conseillés","heading":"5.2 Paquets hébergés sur Github","text":"Vous trouverez ci-dessous les commandes pour installer des paquets directement depuis leur répertoire sur Github.La version de développement de epicontacts contient la possibilité de faire des arbres de transmission avec un axe x temporel.Le paquet epirhandbook contient toutes les données d’exemple pour ce manuel et peut être utilisé pour télécharger la version hors ligne du manuel.","code":"\n# Paquets à télécharger depuis Github (non disponibles sur CRAN)\n##########################################################\n\n# Version de développement d'epicontacts (pour les chaînes de transmission avec un axe x temporel)\npacman::p_install_gh(\"reconhub/epicontacts@timeline\")\n\n# Le paquet pour ce manuel, qui comprend toutes les données d'exemple \npacman::p_install_gh(\"appliedepi/epirhandbook\")"},{"path":"r_projects.html","id":"r_projects","chapter":"6 Projets R","heading":"6 Projets R","text":"Un projet R permet de regrouper votre travail dans un dossier portable et autonome. l’intérieur du projet, tous les scripts, fichiers de données, figures/sorties et historiques pertinents sont stockés dans des sous-dossiers et, surtout, le répertoire de travail est le dossier racine du projet.","code":""},{"path":"r_projects.html","id":"utilisation-suggérée","chapter":"6 Projets R","heading":"6.1 Utilisation suggérée","text":"Une façon courante, efficace et sans probléme d’utiliser R consiste à combiner ces 3 éléments. Un projet de travail discret est hébergélé dans un projet R. Chaque élément est décrit dans les sections ci-dessous.Un projet R\nUn environnement de travail autonome avec des dossiers pour les données, les scripts, les résultats, etc.\nUn environnement de travail autonome avec des dossiers pour les données, les scripts, les résultats, etc.Le paquet pour les chemins de fichiers relatifs\nLes chemins de fichiers sont écrits par rapport au dossier racine du projet R - voir Importation et exportation pour plus d’informations.\nLes chemins de fichiers sont écrits par rapport au dossier racine du projet R - voir Importation et exportation pour plus d’informations.Le paquet rio pour les importations/exportations\nimport() et export() traitent tout type de fichier par son extension (par exemple .csv, .xlsx, .png).\nimport() et export() traitent tout type de fichier par son extension (par exemple .csv, .xlsx, .png).","code":""},{"path":"r_projects.html","id":"créer-un-projet-r","chapter":"6 Projets R","heading":"6.2 Créer un projet R","text":"Pour créer un projet R, sélectionnez “Nouveau projet” dans le menu Fichier.Si vous voulez créer un nouveau dossier pour le projet, sélectionnez “Nouveau répertoire” et indiquez où vous voulez qu’il soit créé.Si vous voulez créer le projet dans un dossier existant, cliquez sur “Répertoire existant” et indiquez le dossier.Si vous voulez cloner un dépôt Github, sélectionnez la troisiéme option “Version Control” et ensuite “Git”. Voir la page contrôle de version et collaboration avec Git et Github pour plus de détails.Le projet R que vous créez se présente sous la forme d’un dossier contenant un fichier .Rproj. Ce fichier est un raccourci et probablement la principale façon d’ouvrir votre projet. Vous pouvez également ouvrir un projet en sélectionnant “Ouvrir un projet” dans le menu Fichier. Alternativement, sur le côté supérieur droit de RStudio, vous verrez une icône de projet R et un menu déroulant des projets R disponibles.Pour quitter un projet R, vous pouvez soit ouvrir un nouveau projet, soit fermer le projet (Fichier - Fermer le projet).","code":""},{"path":"r_projects.html","id":"changer-de-projet","chapter":"6 Projets R","heading":"Changer de projet","text":"Pour passer d’un projet à l’autre, cliquez sur l’icône et le menu déroulant du projet R tout en haut à droite de RStudio. Vous verrez les options Fermer le projet, Ouvrir le projet, et une liste de projets récents.","code":""},{"path":"r_projects.html","id":"paramétres","chapter":"6 Projets R","heading":"Paramétres","text":"Il est généralement conseillé de démarrer RStudio à chaque fois avec une “ardoise propre” - c’est-à-dire avec votre espace de travail non préservé de votre session précédente. Cela signifie que vos objets et résultats ne persisteront pas d’une session à l’autre (vous devrez les recréer en exécutant vos scripts). C’est une bonne chose, car cela vous obligera à écrire de meilleurs scripts et à éviter les erreurs à long terme.Pour configurer RStudio de maniére à ce qu’il fasse “table rase” à chaque démarrage :Sélectionnez “Options du projet” dans le menu Outils.Dans l’onglet “Général”, configurez RStudio pour ne pas restaurer les .RData dans l’espace de travail au démarrage, et pour ne pas sauvegarder l’espace de travail en .RData à la sortie.","code":""},{"path":"r_projects.html","id":"organisation","chapter":"6 Projets R","heading":"Organisation","text":"Il est courant d’avoir des sous-dossiers dans votre projet. Pensez à avoir des dossiers tels que “données”, “scripts”, “figures”, “présentations”. Vous pouvez ajouter des dossiers de la même maniére que vous ajouteriez un nouveau dossier sur votre ordinateur. Vous pouvez également consulter la page sur les Interactions avec les répertoires pour apprendre à créer de nouveaux dossiers à l’aide de commandes R.","code":""},{"path":"r_projects.html","id":"contrôle-de-version","chapter":"6 Projets R","heading":"Contrôle de version","text":"Pensez à un systéme de contrôle de version. Cela pourrait étre quelque chose d’aussi simple que d’avoir des dates sur les noms des scripts (par exemple “transmission_analysis_2020-10-03.R”) et un dossier “archive”. Vous pouvez également envisager d’avoir un texte d’en-téte commenté en haut de chaque script avec une description, des balises, des auteurs et un journal des modifications.Une méthode plus complexe consisterait à utiliser Github ou une plateforme similaire pour le contrôle de version. Voir la page contrôle de version et collaboration avec Git et Github.Une astuce : vous pouvez effectuer une recherche dans l’ensemble d’un projet ou d’un dossier à l’aide de l’outil “Rechercher dans les fichiers” (menu édition). Il peut rechercher et même remplacer des chaînes de caractères dans plusieurs fichiers.","code":""},{"path":"r_projects.html","id":"exemples","chapter":"6 Projets R","heading":"6.3 Exemples","text":"Voici quelques exemples d’importation/exportation/sauvegarde utilisant () à partir d’un projet R. Pour en savoir plus sur l’utilisation du paquet , consultez la page Import export.Importer linelist_raw.xlsx du dossier “data” de votre projet RExportation de l’objet R linelist en tant que “my_linelist.rds” dans le dossier “clean” du dossier “data” de votre projet R.Enregistrement du tracé le plus récemment imprimé sous le nom de “epicurve_2021-02-15.png” dans le dossier “epicurves” du dossier “outputs” de votre projet R.","code":"\nlinelist <- import(here(\"data\", \"linelist_raw.xlsx\"))\nexport(linelist, here(\"data\",\"clean\", \"my_linelist.rds\"))\nggsave(here(\"outputs\", \"epicurves\", \"epicurve_2021-02-15.png\"))"},{"path":"r_projects.html","id":"ressources","chapter":"6 Projets R","heading":"6.4 Ressources","text":"Page web de RStudio sur l’utilisation de projets R","code":""},{"path":"import_export.html","id":"import_export","chapter":"7 Importer et exporter des données","heading":"7 Importer et exporter des données","text":"Sur cette page, nous décrivons les moyens de localiser, d’importer et d’exporter des fichiers :Utilisation du package rio pour import() et export() de manière flexible de nombreux types de fichiersUtilisation du package rio pour import() et export() de manière flexible de nombreux types de fichiersUtilisation du package pour localiser des fichiers relatifs à la racine d’un projet R - pour prévenir des complications liées aux chemins d’accès de fichiers qui sont spécifiques à un ordinateurUtilisation du package pour localiser des fichiers relatifs à la racine d’un projet R - pour prévenir des complications liées aux chemins d’accès de fichiers qui sont spécifiques à un ordinateurDes scénarios d’importation spécifiques, tels que :\nFeuilles d’Excel spécifiques\nEn-têtes désordonnés et lignes sautées\nFeulles de calcul Google\nÀ partir des données publiées sur les sites web\nAvec des APIs\nImporter le plus récent fichier\nDes scénarios d’importation spécifiques, tels que :Feuilles d’Excel spécifiquesFeuilles d’Excel spécifiquesEn-têtes désordonnés et lignes sautéesEn-têtes désordonnés et lignes sautéesFeulles de calcul GoogleFeulles de calcul GoogleÀ partir des données publiées sur les sites webÀ partir des données publiées sur les sites webAvec des APIsAvec des APIsImporter le plus récent fichierImporter le plus récent fichierSaisie manuelle des donnéesSaisie manuelle des donnéesType de fichier spécifique à R tels que RDS et RDataType de fichier spécifique à R tels que RDS et RDataExportation/sauvegarde des fichiers et des graphiquesExportation/sauvegarde des fichiers et des graphiques","code":""},{"path":"import_export.html","id":"aperçu","chapter":"7 Importer et exporter des données","heading":"7.1 Aperçu","text":"Lorsque vous importez un “jeu de données” dans R, vous créez généralement un nouvel objet appelé data frame dans votre environnement R et vous le définissez comme un fichier importé (par exemple Excel, CSV, TSV, RDS) qui se trouve dans votre répertoire de dossiers à un certain chemin d’accès au fichier.Vous pouvez importer/exporter de nombreux types de fichiers, y compris ceux créés par d’autres programmes statistiques (SAS, STATA, SPSS). Vous pouvez également vous connecter à des bases de données relationnelles.R même ses propres formats de données :Un fichier RDS (.rds) stocke un seul objet R tel qu’un dataframe. Ils sont utiles pour stocker des données nettoyées, car ils conservent les classes de colonnes R. Pour en savoir plus, consultez cette section.Un fichier RData (.Rdata) peut être utilisé pour stocker plusieurs objets, voire un espace de travail R complet. Pour en savoir plus, consultez cette section.","code":""},{"path":"import_export.html","id":"le-package-rio","chapter":"7 Importer et exporter des données","heading":"7.2 Le package rio","text":"Le paquet R que nous recommandons est : rio. Le nom “rio” est une abréviation de “R /O” (input/output).Ses fonctions import() et export() peuvent traiter de nombreux types de fichiers différents (par exemple .xlsx, .csv, .rds, .tsv). Lorsque vous fournissez un chemin d’accès au fichier à l’une de ces fonctions (y compris l’extension de fichier comme “.csv”), rio lira l’extension et utilisera le bon outil pour importer ou exporter le fichier.L’alternative à l’utilisation de rio est d’utiliser les fonctions de nombreux autres packages, chacun d’entre eux étant spécifique à un type de fichier. Par exemple, read.csv() (base R), read.xlsx() (openxlsx package), et write_csv() (readr pacakge), etc. Ces alternatives peuvent être difficiles à mémoriser, alors qu’utiliser import() et export() de rio est facile.Les fonctions import() et export() de rio utilisent le package et la fonction appropriés pour un fichier donné, en se basant sur son extension. Consultez la fin de cette page pour un tableau complet des paquets/fonctions que rio utilise en arrière-plan. Il peut également être utilisé pour importer des fichiers STATA, SAS, et SPSS, parmi des dizaines d’autres types de fichiers.L’importation/exportation de shapefile nécessite d’autres packages, tel que détaillé dans la page sur Introduction aux SIG.","code":""},{"path":"import_export.html","id":"here","chapter":"7 Importer et exporter des données","heading":"7.3 Le package here","text":"Le package et sa fonction () permettent d’indiquer facilement à R où trouver et enregistrer vos fichiers - en fait, il construit les chemins d’accès aux fichiers.Utilisé en conjonction avec un projet R, vous permet de décrire l’emplacement des fichiers dans votre projet R par rapport au répertoire racine du projet R (le dossier de niveau supérieur). Cela est utile lorsque le projet R peut être partagé ou accessible par plusieurs personnes/ordinateurs. Cela évite les complications dues aux chemins d’accès aux fichiers uniques sur différents ordinateurs (par exemple \"C:/Users/Laura/Documents...\" en “commençant” le chemin d’accès à un endroit commun pour tous les utilisateurs (la racine du projet R).Voici comment () fonctionne dans un projet R :Lorsque le package est chargé pour la première fois dans le projet R, il place un petit fichier appelé “.” dans le dossier racine de votre projet R comme “repère” ou “ancre”.Dans vos scripts, pour référencer un fichier dans les sous-dossiers du projet R, vous utilisez la fonction () pour construire le chemin d’accès au fichier en relation avec cette ancrePour construire le chemin d’accès au fichier, écrivez les noms des dossiers au-delà de la racine, entre guillemets, séparés par des virgules, et terminez par le nom du fichier et son extension, comme indiqué ci-dessous.Les chemins d’accès () peuvent être utilisés à la fois pour l’importation et l’exportation.Par exemple, ci-dessous, la fonction import() reçoit un chemin d’accès construit avec ().La commande (\"data\", \"linelists\", \"ebola_linelist.xlsx\") fournit en fait le chemin d’accès complet au fichier qui est unique à l’ordinateur de l’utilisateur :L’avantage est que la commande R utilisant () peut être exécutée avec succès sur n’importe quel ordinateur accédant au projet R.TIP: Si vous n’êtes pas certaine de l’emplacement de la racine “”, exécutez la fonction () avec des parenthèses vides.Plus d’informations sur le package ici en cliquant sur ce lien.","code":"\nlinelist <- import(here(\"data\", \"linelists\", \"ebola_linelist.xlsx\"))\"C:/Users/Laura/Documents/my_R_project/data/linelists/ebola_linelist.xlsx\""},{"path":"import_export.html","id":"chemins-daccès-aux-fichiers","chapter":"7 Importer et exporter des données","heading":"7.4 Chemins d’accès aux fichiers","text":"Lorsque vous importez ou exportez des données, vous devez fournir un chemin d’accès au fichier. Vous pouvez le faire de trois manières différentes:Recommandé: fournir un chemin d’accès “relatif” avec le package hereFournir le chemin d’accès “complet” / “absolu”Sélection manuelle des fichiers","code":""},{"path":"import_export.html","id":"chemins-daccès-relatifs","chapter":"7 Importer et exporter des données","heading":"Chemins d’accès “relatifs”","text":"Dans R, les chemins d’accès “relatifs” consistent en un chemin d’accès relatif à la racine d’un projet R. Ils permettent d’obtenir des chemins d’accès plus simples qui peuvent fonctionner sur différents ordinateurs (par exemple, si le projet R se trouve sur un disque partagé ou est envoyé par courrier électronique). Comme décrit ci-dessus, les chemins de fichiers relatifs sont facilités par l’utilisation du package .Voici un exemple de chemin d’accès relatif construit avec (). Nous supposons que le travail se trouve dans un projet R qui contient un sous-dossier “data” et dans celui-ci un sous-dossier “linelists”, dans lequel se trouve le fichier .xlsx qui nous intéresse.","code":"\nlinelist <- import(here(\"data\", \"linelists\", \"ebola_linelist.xlsx\"))"},{"path":"import_export.html","id":"chemins-daccès-absolus","chapter":"7 Importer et exporter des données","heading":"Chemins d’accès “absolus”","text":"Les chemins d’accès absolus ou “complets” peuvent être fournis à des fonctions comme import() mais ils sont “fragiles” car ils sont uniques à l’ordinateur spécifique de l’utilisateur et donc non recommandés.Vous trouverez ci-dessous un exemple de chemin d’accès absolu à un fichier. Dans l’ordinateur de Laura, il existe un dossier “analysis”, un sous-dossier “data” et un sous-dossier “linelists”, dans lequel se trouve le fichier .xlsx en question.Quelques points à noter concernant les chemins d’accès absolus aux fichiers:Évitez les chemins d’accès absolus parce qu’ils vont interrompre le script si ils sont utilisés sur un autre ordinateur différentUtilisez des barres obliques (/), comme dans l’exemple ci-dessus (remarque : ce n’est PAS l’option par défaut pour les chemins d’accès aux fichiers de Windows).Les chemins de fichiers qui commencent par des doubles barres obliques (par exemple, “//…”) ne seront probablement pas reconnus par R et produiront une erreur. Pensez à déplacer votre travail sur un lecteur “nommé” ou “lettré” qui commence par une lettre (par exemple “J :” ou “C :”). Voir la page sur les Interactions avec les répertoires pour plus de détails sur cette question.Un scénario dans lequel les chemins de fichier absolus peuvent être appropriés est celui où vous voulez importer un fichier d’un lecteur partagé qui le même chemin d’accès complet pour tous les utilisateurs.TIP: Pour convertir rapidement tous les \\ à /, surlignez le code d’intérêt, utilisez Ctrl+f (avec Windows), sélectionnez l’option “Dans la sélection”, et ensuite utilisez la fonction remplacement pour les convertir.","code":"\nlinelist <- import(\"C:/Users/Laura/Documents/analysis/data/linelists/ebola_linelist.xlsx\")"},{"path":"import_export.html","id":"sélectionner-les-fichier-manuellement","chapter":"7 Importer et exporter des données","heading":"Sélectionner les fichier manuellement","text":"Vous pouvez importer des données de façon manuelle via une de ces méthodes:Dans le volet Environnement de RStudio, cliquez sur “Import Dataset”, et sélectionnez le type de donnéesCliquez sur File / Import Dataset / (sélectionnez le type de données)Pour une sélection manuelle complète, utilisez la commande file.choose() de la base R (en laissant les parenthèses vides) pour d’éclencher l’apparition d’une fenêtre pop-qui permet à l’utilisateur de sélectionner manuellement le fichier sur son ordinateur. Par exemple :TIP: Il est possible que la fenêtre pop-apparaisse DERRIÈRE votre fenêtre de RStudio.","code":"\n# Sélection manuelle d'un fichier. Lorsque cette commande est exécutée, une fenêtre POP-UP apparaîtra.\n\n# Le chemin du fichier sélectionné sera fourni à la commande import().\n\nmy_data <- import(file.choose())"},{"path":"import_export.html","id":"importer-des-données","chapter":"7 Importer et exporter des données","heading":"7.5 Importer des données","text":"Il est assez simple d’utiliser import() pour importer un ensemble des données. Il suffit de fournir le chemin d’accès au fichier (y compris le nom et l’extension du fichier) entre guillemets. Si vous utilisez () pour construire le chemin d’accès au fichier, suivez les insTIPtions ci-dessus. Voici quelques exemples:Importation d’un fichier csv situé dans votre “répertoire de travail” ou dans le dossier racine du projet R:Importation de la première feuille d’un Excel qui se trouve dans les sous-dossiers “data” et “linelists” du projet R (le chemin du fichier construit à l’aide de ()):Importing d’un data frame (un fichier .rds) à l’aide d’un chemin d’accès absolu:","code":"\nlinelist <- import(\"linelist_cleaned.csv\")\nlinelist <- import(here(\"data\", \"linelists\", \"linelist_cleaned.xlsx\"))\nlinelist <- import(\"C:/Users/Laura/Documents/tuberculosis/data/linelists/linelist_cleaned.rds\")"},{"path":"import_export.html","id":"feuilles-spécifiques-dexcel","chapter":"7 Importer et exporter des données","heading":"Feuilles spécifiques d’Excel","text":"Par défaut, si vous fournissez un fichier Excel (.xlsx) à import(), la première feuille du fichier sera importée. Si vous voulez importer une feuille spécifique, incluez le nom de la feuille dans l’argument =. Par exemple:Si vous utilisez la méthode () pour fournir un chemin d’accès relatif à import(), vous pouvez toujours indiquer une feuille spécifique en ajoutant l’argument = après les parenthèses de fermeture de la fonction ().Pour exporter un data frame à partir de R vers une feuille Excel spécifique tout en gardant inchangé le reste du fichier Excel, vous devrez importer, modifier et exporter avec un package alternatif spécifique pour cet objectif tel que openxlsx. Pour davantage d’information consultez la page Interactions avec les répertoires ou cette page github.Si votre fichier Excel est .xlsb (fichier Excel en format binaire) il est possible que vous ne puissiez pas l’importer en utilisant rio. Envisagez de le réenregistrer en format .xlsx, ou bien en utilisant un package tel que readxlsb qui fut conçu à cet effet.","code":"\nmy_data <- import(\"my_excel_file.xlsx\", which = \"Sheetname\")# Demonstration: importing a specific Excel sheet when using relative pathways with the 'here' package\nlinelist_raw <- import(here(\"data\", \"linelist.xlsx\"), which = \"Sheet1\")`  "},{"path":"import_export.html","id":"import_missing","chapter":"7 Importer et exporter des données","heading":"Données manquantes","text":"Vous pouvez désigner la ou les valeurs de votre ensemble de données qui doivent être considérées comme manquantes. Comme expliqué dans la page Données manquantes, la valeur dans R pour les données manquantes est NA, mais peut-être que l’ensemble de données que vous voulez importer utilise 99, “Manquant”, ou juste un espace vide “” à la place.Utilisez l’argument na = avec import() et fournissez la ou les valeurs entre guillemets (même si ce sont des nombres). Vous pouvez spécifier plusieurs valeurs en les incluant dans un vecteur, en utilisant c() comme indiqué ci-dessous.Ici, la valeur “99” dans le jeu de données est considéré comme manquant et converti à NA dans R.Ici, toutes les valeurs “Missing”, “” (cellule vide), ou ” ” (espace unique) dans l’ensemble de données importées sont converties en NA dans R.","code":"\nlinelist <- import(here(\"data\", \"my_linelist.xlsx\"), na = \"99\")\nlinelist <- import(here(\"data\", \"my_linelist.csv\"), na = c(\"Missing\", \"\", \" \"))"},{"path":"import_export.html","id":"sauter-des-lignes","chapter":"7 Importer et exporter des données","heading":"Sauter des lignes","text":"Parfois, vous pouvez vouloir éviter d’importer une ligne de données. Vous pouvez le faire avec l’argument skip = si vous utilisez import() de rio sur un fichier .xlsx ou .csv. Indiquez le nombre de lignes que vous souhaitez ignorer.Malheureusement, skip = n’accepte qu’une seule valeur entière, pas une plage (par exemple, “2:10” ne fonctionne pas). Pour sauter l’importation de lignes spécifiques qui ne sont pas consécutives à partir du haut, pensez à importer plusieurs fois et à utiliser bind_rows() de dplyr. Voir l’exemple ci-dessous pour sauter seulement la ligne 2.","code":"\nlinelist_raw <- import(\"linelist_raw.xlsx\", skip = 1)  # n'importe pas la ligne d'en-tête"},{"path":"import_export.html","id":"gérer-une-deuxième-ligne-den-tête","chapter":"7 Importer et exporter des données","heading":"Gérer une deuxième ligne d’en-tête","text":"Parfois, vos données peuvent avoir une deuxième ligne, par exemple s’il s’agit d’une ligne de “dictionnaire de données” comme indiqué ci-dessous. Cette situation peut être problématique car elle peut entraîner l’importation de toutes les colonnes en tant que classe “caractère”.Voici un exemple de ce type d’ensemble de données (la première ligne étant le dictionnaire de données).","code":""},{"path":"import_export.html","id":"supprimez-la-deuxième-ligne-den-tête","chapter":"7 Importer et exporter des données","heading":"Supprimez la deuxième ligne d’en-tête","text":"Pour supprimer la deuxième ligne d’en-tête, vous devrez probablement importer les données deux fois.Importez les données afin de stocker les bons noms des colonnes.Importez à nouveau les données, en sautant les deux premières lignes (en-tête et deuxième ligne).Reliez les noms corrects sur le cadre de données réduit.L’argument exact utilisé pour relier les bons noms de colonnes dépend du type de fichier de données (.csv, .tsv, .xlsx, etc.). Ceci est dû au fait que rio utilise une fonction différente pour les différents types de fichiers (voir le tableau ci-dessus).Pour les documents Excel: (col_names =)Pour les fichiers CSV: (col.names =)Option de secours - changer les noms des colonnes à l’aide d’une commande additionnelle","code":"\n# importer pour la première fois; stocker les noms des colonnes\nlinelist_raw_names <- import(\"linelist_raw.xlsx\") %>% names()  # stocker les bons noms des colonnes\n\n# importer pour la deuxième fois; sauter la deuxième ligne, et assigner les noms des colonnes à l'argument col_names =\nlinelist_raw <- import(\"linelist_raw.xlsx\",\n                       skip = 2,\n                       col_names = linelist_raw_names\n                       ) \n# importer pour la première fois; stocker les noms des colonnes\nlinelist_raw_names <- import(\"linelist_raw.csv\") %>% names() # save true column names\n\n# notez que l'argument pour les fichiers CSV est 'col.names = '\nlinelist_raw <- import(\"linelist_raw.csv\",\n                       skip = 2,\n                       col.names = linelist_raw_names\n                       ) \n# attribuer/supprimer des en-têtes en utilisant la fonction de base 'colnames()'\ncolnames(linelist_raw) <- linelist_raw_names"},{"path":"import_export.html","id":"créer-un-dictionnaire-de-données","chapter":"7 Importer et exporter des données","heading":"Créer un dictionnaire de données","text":"Bonus! Si vous avez une deuxième ligne qui est un dictionnaire de données, vous pouvez facilement créer un dictionnaire de données approprié à partir de celle-ci. Cette astuce est adaptée de cet article.","code":"\ndict <- linelist_2headers %>%             # début: liste des case avec le dictionnaire en première ligne\n  head(1) %>%                             # garder seulement les noms des colonnes et la premièere ligne étant le dictionnaire                \n  pivot_longer(cols = everything(),       # pivoter toutes les colonnes au format long\n               names_to = \"Column\",       # définir de nouveaux noms pour les colonnes\n               values_to = \"Description\")"},{"path":"import_export.html","id":"combiner-les-deux-lignes-den-tête","chapter":"7 Importer et exporter des données","heading":"Combiner les deux lignes d’en-tête","text":"Dans certains cas, lorsque votre ensemble de données brutes comporte deux lignes d’en-tête (ou plus précisément, la deuxième ligne de données est un en-tête secondaire), vous pouvez souhaiter les “combiner” ou ajouter les valeurs de la deuxième ligne d’en-tête à la première ligne d’en-tête.La commande ci-dessous définit les noms des colonnes du cadre de données comme la combinaison (collage) des premiers en-têtes (vrais) avec la valeur située immédiatement en dessous (dans la première ligne).","code":"\nnames(my_data) <- paste(names(my_data), my_data[1, ], sep = \"_\")"},{"path":"import_export.html","id":"feuille-de-calcul-google","chapter":"7 Importer et exporter des données","heading":"Feuille de calcul Google","text":"Vous pouvez importer des données à partir d’une feuille de calcul Google en ligne avec le paquet googlesheet4 et en authentifiant votre accès à la feuille de calcul.Ci-dessous, une feuille de calcul Google de démonstration est importée et sauvegardée. Cette commande peut vous demander de confirmer l’authentification de votre compte Google. Suivez les insTIPtions et les fenêtres contextuelles de votre navigateur Internet pour accorder aux packages API Tidyverse les autorisations de modifier, créer et supprimer vos feuilles de calcul dans Google Drive.La feuille ci-dessous est “consultable par toute personne ayant le lien” et vous pouvez essayer de l’importer.La feuille ci-dessous est “consultable par toute personne ayant le lien” et vous pouvez essayer de l’importer.Un autre package, googledrive, propose des fonctions utiles pour écrire, modifier et supprimer des feuilles Google. Par exemple, en utilisant les fonctions gs4_create() et sheet_write() trouvées dans ce package.Voici d’autres tutoriels en ligne utiles:Tutoriel de base sur l’importation de feuilles de calcul Google sheetstutoriel plus détailléintéraction entre googlesheets4 et tidyverse","code":"\npacman::p_load(\"googlesheets4\")\nGsheets_demo <- read_sheet(\"https://docs.google.com/spreadsheets/d/1scgtzkVLLHAe5a6_eFQEwkZcc14yFUx1KgOMZ4AKUfY/edit#gid=0\")\nGsheets_demo <- read_sheet(\"1scgtzkVLLHAe5a6_eFQEwkZcc14yFUx1KgOMZ4AKUfY\")"},{"path":"import_export.html","id":"fichiers-multiples---importation-exportation-fractionnement-combinaison","chapter":"7 Importer et exporter des données","heading":"7.6 Fichiers multiples - importation, exportation, fractionnement, combinaison","text":"Consultez la page Itération, boucles et listes pour obtenir des exemples sur la manière d’importer et de combiner plusieurs fichiers, ou plusieurs fichiers de classeur Excel. Cette page contient également des exemples sur la façon de diviser un cadre de données en plusieurs parties et d’exporter chacune d’entre elles séparément, ou en tant que feuilles nommées dans un classeur Excel.","code":""},{"path":"import_export.html","id":"import_github","chapter":"7 Importer et exporter des données","heading":"7.7 Importer de Github","text":"L’importation de données directement de Github dans R peut être très facile ou nécessiter quelques étapes, selon le type de fichier. Voici quelques approches:","code":""},{"path":"import_export.html","id":"fichiers-csv","chapter":"7 Importer et exporter des données","heading":"Fichiers CSV","text":"Il peut être facile d’importer un fichier .csv directement de Github dans R avec une commande R.Allez sur le repo Github, localisez le fichier qui vous intéresse et cliquez dessus.Cliquez sur le bouton “Raw” (vous verrez alors les données csv “brutes”, comme indiqué ci-dessous)Copiez l’adresse URLPlacez l’URL entre guillemets dans la commande R import()","code":""},{"path":"import_export.html","id":"fichiers-xlsx","chapter":"7 Importer et exporter des données","heading":"Fichiers XLSX","text":"Il se peut que vous ne puissiez pas visualiser les données “brutes” pour certains fichiers (e.x. .xlsx, .rds, .nwk, .shp)Allez sur le repo Github, localisez le fichier qui vous intéresse et cliquez dessus.Cliquez sur le bouton “Download”, comme indiqué ci-dessousSauvegardez le fichier sur votre ordinateur, et importez-le dans R","code":""},{"path":"import_export.html","id":"shapefiles","chapter":"7 Importer et exporter des données","heading":"Shapefiles","text":"Les fichiers Shapefiles comportent de nombreux sous-fichiers, chacun avec une extension de fichier différente. Un fichier aura l’extension “.shp”, mais d’autres peuvent avoir “.dbf”, “.prj”, etc. Pour télécharger un shapefile à partir de Github, vous devrez télécharger chacun des fichiers de sous-composants individuellement, et les enregistrer dans le même dossier sur votre ordinateur. Dans Github, cliquez sur chaque fichier individuellement et téléchargez-les en cliquant sur le bouton ” Download “.Une fois enregistré sur votre ordinateur, vous pouvez importer le shapefile comme indiqué sur la page Bases de SIG st_read() du paquet sf. Il vous suffit de fournir le chemin d’accès et le nom du fichier ” .shp “, à condition que les fichiers associés se trouvent dans le même dossier sur votre ordinateur.Ci-dessous, vous pouvez voir comment le shapefile “sle_adm3” se compose de plusieurs fichiers, chacun devant être téléchargé depuis Github.","code":""},{"path":"import_export.html","id":"entrée-de-données-de-façon-manuelle","chapter":"7 Importer et exporter des données","heading":"7.8 Entrée de données de façon manuelle","text":"","code":""},{"path":"import_export.html","id":"entrée-par-lignes","chapter":"7 Importer et exporter des données","heading":"Entrée par lignes","text":"Utilisez la fonction tribble du paquet tibble du tidyverse, ici un référence tibble en ligneNotez que les en-têtes de colonne commencent par une tilde (~). Notez également que chaque colonne ne doit contenir qu’une seule classe de données (caractère, numérique, etc.). Vous pouvez utiliser des tabulations, des espaces et de nouvelles lignes pour rendre la saisie des données plus intuitive et plus lisible. Les espaces ne comptent pas entre les valeurs, mais chaque ligne est représentée par une nouvelle ligne de code. Par exemple:Et maintenant nous affichons le nouveau jeu de données:","code":"\n# create the dataset manually by row\nmanual_entry_rows <- tibble::tribble(\n  ~colA, ~colB,\n  \"a\",   1,\n  \"b\",   2,\n  \"c\",   3\n  )"},{"path":"import_export.html","id":"entrée-par-colonnes","chapter":"7 Importer et exporter des données","heading":"Entrée par colonnes","text":"Étant donné qu’un cadre de données est constitué de vecteurs (colonnes verticales), l’approche de base de la création manuelle de cadres de données dans R prévoit que vous définissiez chaque colonne, puis que vous les reliiez entre elles. Cela peut être contre-intuitif en épidémiologie, car nous pensons généralement à nos données en lignes (comme ci-dessus).ATTENTION: Tous les vecteurs doivent avoir la même longueur (même nombre de valeurs).Les vecteurs peuvent ensuite être liés entre eux à l’aide de la fonction data.frame():Et maintenant nous affichons le nouveau jeu de données:","code":"\n# define each vector (vertical column) separately, each with its own name\nPatientID <- c(235, 452, 778, 111)\nTreatment <- c(\"Yes\", \"No\", \"Yes\", \"Yes\")\nDeath     <- c(1, 0, 1, 0)\n# combiner les colonnes dans un cadre de données, en référençant les noms de vecteurs\nmanual_entry_cols <- data.frame(PatientID, Treatment, Death)"},{"path":"import_export.html","id":"collage-à-partir-du-presse-papiers","chapter":"7 Importer et exporter des données","heading":"Collage à partir du presse-papiers","text":"Si vous copiez des données d’un autre endroit et que vous les avez dans votre presse-papiers, vous pouvez essayer l’une des deux méthodes ci-dessous :partir du package clipr, vous pouvez utiliser read_clip_tbl() pour importer comme un cadre de données, ou simplement read_clip() pour importer comme un vecteur de caractères. Dans les deux cas, laissez les parenthèses vides.Vous pouvez aussi facilement exporter vers le presse-papiers de votre système avec clipr. Voir la section ci-dessous sur l’Exportation.Alternativement, vous pouvez utiliser la fonction read.table() de base R avec file = \"clipboard\") pour importer comme un cadre de données:","code":"\nlinelist <- clipr::read_clip_tbl()  # importe le presse-papiers actuel comme cadre de données\nlinelist <- clipr::read_clip()      # importations en tant que vecteur de caractères\ndf_from_clipboard <- read.table(\n  file = \"clipboard\",  # specify this as \"clipboard\"\n  sep = \"t\",           # separator could be tab, or commas, etc.\n  header=TRUE)         # if there is a header row"},{"path":"import_export.html","id":"importer-le-fichier-le-plus-récent","chapter":"7 Importer et exporter des données","heading":"7.9 Importer le fichier le plus récent","text":"Il arrive souvent que vous receviez des mises à jour quotidiennes de vos ensembles de données. Dans ce cas, vous voudrez écrire un code qui importe le fichier le plus récent. Nous présentons ci-dessous deux façons d’aborder cette question:Sélection du fichier en fonction de la date figurant dans le nom du fichierSélection du fichier sur la base des métadonnées du fichier (dernière modification)","code":""},{"path":"import_export.html","id":"dates-dans-le-nom-du-fichier","chapter":"7 Importer et exporter des données","heading":"Dates dans le nom du fichier","text":"Cette approche repose sur trois prémisses:Vous faites confiance aux dates dans les noms de fichiersLes dates sont numériques et apparaissent généralement dans le même format (par exemple, année, mois, jour)Il n’y pas d’autres chiffres dans le nom du fichierNous vous expliquerons chaque étape, puis nous vous les montrerons combinées à la fin.Tout d’abord, utilisez dir() de base R pour extraire uniquement les noms de fichiers pour chaque fichier dans le dossier qui vous intéresse. Pour plus de détails sur dir(), consultez la page sur Interactions avec les répertoires. Dans cet exemple, le dossier concerné est le dossier ” linelists ” situé dans le dossier ” example ” situé dans ” data ” au sein du projet R.Une fois que vous avez ce vecteur de noms, vous pouvez en extraire les dates en appliquant str_extract() de stringr en utilisant cette expression régulière. Elle extrait tous les nombres dans le nom de fichier (y compris tout autre caractère au milieu comme les tirets ou les barres obliques). Vous pouvez en savoir plus sur stringr à la page Caractères et chaînes de caractères.En supposant que les dates sont généralement écrites dans le même format (par exemple, Année puis Mois puis Jour) et que les années ont 4 chiffres, vous pouvez utiliser les fonctions de conversion flexibles de lubridate (ymd(), dmy(), ou mdy()) pour les convertir en dates. Pour ces fonctions, les tirets, les espaces ou les barres obliques n’ont pas d’importance, seul l’ordre des chiffres compte. Pour en savoir plus, consultez la page Manipuler les dates.La fonction R base .max() peut alors être utilisée pour retourner la position de l’index (par exemple, 1ère, 2ème, 3ème, …) de la valeur maximale de la date. Le dernier fichier est correctement identifié comme étant le 6ème fichier - “case_linelist_2020-10-08.xlsx”.Si nous condensons toutes ces commandes, le code complet pourrait ressembler à ce qui suit. Notez que le . de la dernière ligne est un caractère de remplacement pour l’objet pipé à ce point de la séquence de pipelines. ce stade, la valeur est simplement le nombre 6. Celui-ci est placé entre doubles crochets pour extraire le 6ème élément du vecteur de noms de fichiers produit par dir().Vous pouvez maintenant utiliser ce nom pour terminer le chemin de fichier relatif, avec ():Et vous pouvez maintenant importer le dernier fichier:","code":"\nlinelist_filenames <- dir(here(\"data\", \"example\", \"linelists\")) # get file names from folder\nlinelist_filenames                                              # print## [1] \"20201007linelist.csv\"          \"case_linelist_2020-10-02.csv\" \n## [3] \"case_linelist_2020-10-03.csv\"  \"case_linelist_2020-10-04.csv\" \n## [5] \"case_linelist_2020-10-05.csv\"  \"case_linelist_2020-10-08.xlsx\"\n## [7] \"case_linelist20201006.csv\"\nlinelist_dates_raw <- stringr::str_extract(linelist_filenames, \"[0-9].*[0-9]\") # extract numbers and any characters in between\nlinelist_dates_raw  # print## [1] \"20201007\"   \"2020-10-02\" \"2020-10-03\" \"2020-10-04\" \"2020-10-05\" \"2020-10-08\"\n## [7] \"20201006\"\nlinelist_dates_clean <- lubridate::ymd(linelist_dates_raw)\nlinelist_dates_clean## [1] \"2020-10-07\" \"2020-10-02\" \"2020-10-03\" \"2020-10-04\" \"2020-10-05\" \"2020-10-08\"\n## [7] \"2020-10-06\"\nindex_latest_file <- which.max(linelist_dates_clean)\nindex_latest_file## [1] 6\n# Charger les packages\npacman::p_load(\n  tidyverse,         # data management\n  stringr,           # work with strings/characters\n  lubridate,         # work with dates\n  rio,               # import / export\n  here,              # relative file paths\n  fs)                # directory interactions\n\n# extraire le nom de fichier du dernier fichier\nlatest_file <- dir(here(\"data\", \"example\", \"linelists\")) %>%  # noms du fichier du sous-dossier \"linelists\"          \n  str_extract(\"[0-9].*[0-9]\") %>%                  # extraire les dates (nombres)\n  ymd() %>%                                        # convertir les nombres en dates (assumant le format année-mois-jour)\n  which.max() %>%                                  # obtenir l'index de la date maximale (dernier fichier)\n  dir(here(\"data\", \"example\", \"linelists\"))[[.]]              # retourne le nom de fichier de la dernière liste de diffusion\n\nlatest_file  # imprimer le nom du dernier fichier## [1] \"case_linelist_2020-10-08.xlsx\"\nhere(\"data\", \"example\", \"linelists\", latest_file) \n# import\nimport(here(\"data\", \"example\", \"linelists\", latest_file)) # import "},{"path":"import_export.html","id":"utiliser-linformation-du-fichier","chapter":"7 Importer et exporter des données","heading":"Utiliser l’information du fichier","text":"Si vos fichiers n’ont pas de date dans leur nom (ou si vous ne faites pas confiance à ces dates), vous pouvez essayer d’extraire la date de dernière modification à partir des métadonnées du fichier. Utilisez les fonctions du paquet fs pour examiner les informations des métadonnées de chaque fichier, qui comprennent l’heure de dernière modification et le chemin d’accès au fichier.Ci-dessous, nous fournissons le dossier d’intérêt à la fonction dir_info() de fs. Dans ce cas, le dossier d’intérêt se trouve dans le projet R dans le dossier “data”, le sous-dossier “example”, et son sous-dossier “linelists”. Le résultat est un cadre de données avec une ligne par fichier et des colonnes pour modification_time, path, etc. Vous pouvez voir un exemple visuel de ceci dans la page sur Interactions avec les répertoires.Nous pouvons trier ce cadre de données de fichiers par la colonne modification_time, et ensuite ne garder que la ligne (fichier) la plus haute/la plus récente avec la fonction base de R head(). Ensuite, nous pouvons extraire le chemin d’accès de ce dernier fichier uniquement avec la fonction dplyr pull() sur la colonne path. Enfin, nous pouvons passer ce chemin de fichier à import(). Le fichier importé est enregistré sous le nom de latest_file.","code":"\nlatest_file <- dir_info(here(\"data\", \"example\", \"linelists\")) %>%  # collecte des informations sur tous les fichiers du répertoire\n  arrange(desc(modification_time)) %>%      # trier par temps de modification\n  head(1) %>%                               # ne conserver que le fichier le plus récent\n  pull(path) %>%                            # extraire uniquement le chemin du fichier\n  import()                                  # importer le fichier"},{"path":"import_export.html","id":"import_api","chapter":"7 Importer et exporter des données","heading":"7.10 APIs","text":"Une “interface de programmation automatisée” (API) peut être utilisée pour demander directement des données à un site web. Les API sont un ensemble de règles qui permettent à une application logicielle d’interagir avec une autre. Le client (vous) envoie une “requête” et reçoit une “réponse” contenant du contenu. Les packages R httr et jsonlite peuvent faciliter ce processus.Chaque site Web compatible avec l’API possède sa propre documentation et ses propres spécificités avec lesquelles il faut se familiariser. Certains sites sont accessibles au public et peuvent être consultés par n’importe qui. D’autres, comme les plates-formes avec des identifiants et des références d’utilisateur, nécessitent une authentification pour accéder à leurs données.Il va sans dire qu’il est nécessaire de disposer d’une connexion Internet pour importer des données via l’API. Nous donnerons brièvement des exemples d’utilisation des API pour importer des données, et nous vous renverrons à d’autres ressources.Note : rappelons que les données peuvent être affichées* sur un site web sans API, ce qui peut être plus facile à récupérer. Par exemple, un fichier CSV affiché peut être accessible simplement en fournissant l’URL du site à import() comme décrit dans la section sur importation de Github.*","code":""},{"path":"import_export.html","id":"requête-http","chapter":"7 Importer et exporter des données","heading":"Requête HTTP","text":"L’échange d’API se fait le plus souvent par le biais d’une requête HTTP. HTTP, qui signifie Hypertext Transfer Protocol, est le format sous-jacent d’une demande/réponse entre un client et un serveur. Les données d’entrée et de sortie exactes peuvent varier en fonction du type d’API, mais le processus est le même : une “demande” (souvent une requête HTTP) de la part de l’utilisateur, contenant souvent une requête, suivie d’une “réponse”, contenant des informations d’état sur la demande et éventuellement le contenu demandé.Voici quelques éléments d’une requête HTTP:L’URL du point de terminaison de l’APILa “Méthode” (ou “Verbe”)En-têteCorpsLa “méthode” de la requête HTTP est l’action que vous voulez effectuer. Les deux méthodes HTTP les plus courantes sont GET et POST mais d’autres peuvent inclure PUT, DELETE, PATCH, etc. Lorsque vous importez des données dans R, il est très probable que vous utilisiez la méthode GET.Après votre requête, votre ordinateur recevra une “réponse” dans un format similaire à celui que vous avez envoyé, comprenant l’URL, l’état HTTP (l’état 200 est ce que vous voulez !), le type de fichier, la taille et le contenu souhaité. Vous devrez ensuite analyser cette réponse et la transformer en un cadre de données exploitable dans votre environnement R.","code":""},{"path":"import_export.html","id":"packages-1","chapter":"7 Importer et exporter des données","heading":"Packages","text":"Le package httr fonctionne bien pour traiter les requêtes HTTP dans R. Il nécessite peu de connaissances préalables sur les API Web et peut être utilisé par des personnes moins familières avec la terminologie du développement logiciel. En outre, si la réponse HTTP est un fichier .json, vous pouvez utiliser jsonlite pour analyser la réponse.","code":"\n# load packages\npacman::p_load(httr, jsonlite, tidyverse)"},{"path":"import_export.html","id":"données-disponibles-au-public","chapter":"7 Importer et exporter des données","heading":"Données disponibles au public","text":"Voici un exemple de requête HTTP, emprunté à un tutoriel du site Trafford Data Lab. Ce site propose plusieurs autres ressources pour apprendre et des exercices API.Scénario : Nous souhaitons importer une liste des établissements de restauration rapide de la ville de Trafford, au Royaume-Uni. Les données sont accessibles à partir de l’API de la Food Standards Agency, qui fournit des données sur l’évaluation de l’hygiène alimentaire au Royaume-Uni.Voici les paramètres de notre requête :Verbe HTTP: GETURL du point d’accès à l’API: http://api.ratings.food.gov.uk/EstablishmentsParamètres sélectionnés: name, address, longitude, latitude, businessTypeId, ratingKey, localAuthorityIdEn-tête: “x-api-version”, 2Format(s) des données: JSON, XMLDocumentation: http://api.ratings.food.gov.uk/helpLe code R serait le suivant:Vous pouvez maintenant nettoyer et utiliser le cadre de données response, qui contient une ligne par établissement de restauration rapide.","code":"\n# préparer la requête\npath <- \"http://api.ratings.food.gov.uk/Establishments\"\nrequest <- GET(url = path,\n             query = list(\n               localAuthorityId = 188,\n               BusinessTypeId = 7844,\n               pageNumber = 1,\n               pageSize = 5000),\n             add_headers(\"x-api-version\" = \"2\"))\n\n# Vérifier s'il y a une erreur de serveur (\"200\" est bon !)\nrequest$status_code\n\n# soumettre la requête, analyser la réponse et la convertir en un cadre de données\nresponse <- content(request, as = \"text\", encoding = \"UTF-8\") %>%\n  fromJSON(flatten = TRUE) %>%\n  pluck(\"establishments\") %>%\n  as_tibble()"},{"path":"import_export.html","id":"authentification-requise","chapter":"7 Importer et exporter des données","heading":"Authentification requise","text":"Certaines API nécessitent une authentification, c’est-à-dire que vous devez prouver votre identité pour pouvoir accéder à des données restreintes. Pour importer ces données, vous devrez peut-être d’abord utiliser une méthode POST pour fournir un nom d’utilisateur, un mot de passe ou un code. Vous obtiendrez alors un jeton d’accès, qui pourra être utilisé pour les demandes ultérieures par la méthode GET afin de récupérer les données souhaitées.Vous trouverez ci-dessous un exemple d’interrogation de données à partir de Go.Data, qui est un outil d’investigation des épidémies. Go.Data utilise une API pour toutes les interactions entre le frontal web et les applications pour smartphones utilisées pour la collecte des données. Go.Data est utilisé dans le monde entier. Comme les données sur les épidémies sont sensibles et que vous ne devez pouvoir accéder qu’aux données concernant votre épidémie, une authentification est requise.Vous trouverez ci-dessous un exemple de code R utilisant httr et jsonlite pour se connecter à l’API Go.Data afin d’importer des données sur le suivi des contacts de votre épidémie.ATTENTION: Si vous importez de grandes quantités de données à partir d’une API nécessitant une authentification, il se peut que le délai d’attente soit dépassé. Pour éviter cela, récupérez à nouveau l’access_token avant chaque requête GET de l’API et essayez d’utiliser des filtres ou des limites dans la requête.TIP: La fonction fromJSON() du package jsonlite ne désimbrique pas complètement la première fois qu’elle est exécutée, donc vous aurez probablement encore des éléments de liste dans votre tibble résultant. Vous aurez besoin de désimbriquer davantage certaines variables, en fonction de l’imbrication de votre fichier .json. Pour plus d’informations à ce sujet, consultez la documentation du package jsonlite, notamment la fonction flatten(). {style=“color: darkgreen;”}Pour plus de détails, consultez la documentation sur LoopBack Explorer, la page Suivi des contacts ou les astuces API sur Go.Data Github repositoryVous pouvez en savoir plus sur le package httr hereCette section aussi été informée par ce tutoriel et ce tutoriel.","code":"\n# définir les informations d'identification pour l'autorisation\nurl <- \"https://godatasampleURL.int/\"           # url d'instance valide de Go.Data\nusername <- \"username\"                          # nom d'utilisateur valide Go.Data \npassword <- \"password\"                          # mot de passe Go,Data valide \noutbreak_id <- \"xxxxxx-xxxx-xxxx-xxxx-xxxxxxx\"  # identifiant d'épidémie Go.Data valide\n\n# obtenir le jeton d'accès\nurl_request <- paste0(url,\"api/oauth/token?access_token=123\") # define base URL request\n\n# préparer la requête\nresponse <- POST(\n  url = url_request,  \n  body = list(\n    username = username,    # utiliser le nom d'utilisateur et le mot de passe enregistrés ci-dessus pour l'autorisation                              \n    password = password),                                       \n    encode = \"json\")\n\n# exécuter la demande et analyser la réponse\ncontent <-\n  content(response, as = \"text\") %>%\n  fromJSON(flatten = TRUE) %>%          # aplatir les JSON imbriqués\n  glimpse()\n\n# Sauvegarder le jeton d'accès de la réponse\naccess_token <- content$access_token    # sauvegarder le jeton d'accès pour permettre les appels API suivants\n\n# importer les contacts de l'épidémie\n# Utiliser le jeton d'accès \nresponse_contacts <- GET(\n  paste0(url,\"api/outbreaks/\",outbreak_id,\"/contacts\"),          # obtenir (GET) la requête\n  add_headers(\n    Authorization = paste(\"Bearer\", access_token, sep = \" \")))\n\njson_contacts <- content(response_contacts, as = \"text\")         # convertir en texte JSON\n\ncontacts <- as_tibble(fromJSON(json_contacts, flatten = TRUE))   # aplatir JSON en tibble"},{"path":"import_export.html","id":"exporter","chapter":"7 Importer et exporter des données","heading":"7.11 Exporter","text":"","code":""},{"path":"import_export.html","id":"avec-le-package-rio","chapter":"7 Importer et exporter des données","heading":"Avec le package rio","text":"Avec rio, vous pouvez utiliser la fonction export() de manière très similaire à import(). Donnez d’abord le nom de l’objet R que vous voulez sauvegarder (par exemple linelist) et ensuite entre guillemets mettez le chemin du fichier où vous voulez sauvegarder le fichier, en incluant le nom de fichier désiré et l’extension de fichier. Par exemple :Cette opération permet de sauvegarder le cadre de données linelist comme un classeur Excel dans le répertoire de travail/ dossier racine du projet :Vous pouvez enregistrer le même cadre de données comme un fichier csv en changeant l’extension. Par exemple, nous l’enregistrons également dans un chemin de fichier construit avec () :","code":"\nexport(linelist, \"my_linelist.xlsx\") # will save to working directory\nexport(linelist, here(\"data\", \"clean\", \"my_linelist.csv\"))"},{"path":"import_export.html","id":"vers-le-presse-papiers","chapter":"7 Importer et exporter des données","heading":"Vers le presse-papiers","text":"Pour exporter un cadre de données vers le “presse-papiers” de votre ordinateur (pour ensuite le coller dans un autre logiciel comme Excel, Google Spreadsheets, etc.) vous pouvez utiliser write_clip() du paquet clipr.","code":"\n# exporter le cadre de données de la liste de cas vers le presse-papiers de votre système\nclipr::write_clip(linelist)"},{"path":"import_export.html","id":"import_rds","chapter":"7 Importer et exporter des données","heading":"7.12 Documents RDS","text":"Outre les fichiers .csv, .xlsx, etc., vous pouvez également exporter/enregistrer des cadres de données R sous forme de fichiers .rds. Il s’agit d’un format de fichier spécifique à R, très utile si vous savez que vous allez retravailler les données exportées dans R.Les classes de colonnes sont stockées, de sorte que vous n’avez pas à refaire le nettoyage lors de l’importation (avec un fichier Excel ou même un fichier CSV, cela peut être un casse-tête !) C’est aussi un fichier plus petit, ce qui est utile pour l’exportation et l’importation si votre ensemble de données est grand.Par exemple, si vous travaillez dans une équipe d’épidémiologie et que vous devez envoyer des fichiers à une équipe SIG pour la cartographie, et qu’ils utilisent également R, envoyez-leur simplement le fichier .rds ! Toutes les classes de colonnes sont alors conservées et ils ont moins de travail à faire.","code":"\nexport(linelist, here(\"data\", \"clean\", \"my_linelist.rds\"))"},{"path":"import_export.html","id":"import_rdata","chapter":"7 Importer et exporter des données","heading":"7.13 Fichiers Rdata et listes","text":"Les fichiers .Rdata peuvent stocker plusieurs objets R - par exemple plusieurs cadres de données, des résultats de modèles, des listes, etc. Cela peut être très utile pour consolider ou partager un grand nombre de vos données pour un projet donné.Dans l’exemple ci-dessous, plusieurs objets R sont stockés dans le fichier exporté “my_objects.Rdata”:Note : si vous essayez d’importer une liste, utilisez import_list() de rio pour l’importer avec la sTIPture et le contenu originaux complets.","code":"\nrio::export(my_list, my_dataframe, my_vector, \"my_objects.Rdata\")\nrio::import_list(\"my_list.Rdata\")"},{"path":"import_export.html","id":"sauvegarde-des-graphiques","chapter":"7 Importer et exporter des données","heading":"7.14 Sauvegarde des graphiques","text":"Les insTIPtions sur la façon de sauvegarder les tracés, tels que ceux créés par ggplot(), sont discutées en profondeur dans la page bases de ggplot.En bref, lancez ggsave(\"my_plot_filepath_and_name.png\") après avoir imprimé votre tracé. Vous pouvez soit fournir un objet de tracé sauvegardé à l’argument plot =, ou seulement spécifier le chemin du fichier de destination (avec l’extension du fichier) pour sauvegarder le tracé le plus récemment affiché. Vous pouvez aussi contrôler le width =, height =, units =, et dpi =.L’enregistrement d’un graphe de réseau, tel qu’un arbre de transmission, est abordé dans la page Chaînes de transmission.","code":""},{"path":"import_export.html","id":"ressources-1","chapter":"7 Importer et exporter des données","heading":"7.15 Ressources","text":"Le Manuel pour Importer/ExporterChapitre sur l’importaiton de données de R 4 Data ScienceDocumation pour ggsave()Voici un tableau tiré de la vignette en ligne de rio. Pour chaque type de données, il indique : l’extension de fichier attendue, le package que rio utilise pour importer ou exporter les données, et si cette fonctionnalité est incluse dans la version installée par défaut de rio.","code":""},{"path":"cleaning_data.html","id":"cleaning_data","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"8 Nettoyage de données et fonctions essentielles","text":"Cette page présente les étapes courantes du processus de “nettoyage” d’un jeu de données, et apporte également des explications sur l’utilisation de nombreuses fonctions essentielles dans le traitement des données R.Pour expliquer le nettoyage des données, cette page commence par l’importation d’un jeu de données brutes de cas dénommé linelist, et présente le processus de nettoyage étape par étape. Dans le code R, cela se manifeste par une chaîne “pipe”, qui fait référence à l’opérateur “pipe” %>% qui fait passer un jeu de données d’une opération à l’autre.","code":""},{"path":"cleaning_data.html","id":"fonctions-principales","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Fonctions principales","text":"Ce manuel met l’accent sur l’utilisation des fonctions provenant du package tidyverse, appartenant à la famille des packages de R. L’essentiel des fonctions de R présentées dans cette page sont listées ci-dessous.Beaucoup de ces fonctions appartiennent au package R dplyr, qui fournit des fonctions “verbes” pour résoudre les problèmes de manipulation des données (le nom fait référence à un “dataframe”- plier. dplyr fait partie de la famille de packages R tidyverse (qui qui consiste de ggplot2, tidyr, stringr, tibble, purrr, magrittr, et forcats entre autres).Si vous souhaitez comparer ces fonctions aux commandes de Stata ou de SAS, consultez la page Transition vers R.Vous pouvez rencontrer une méthode alternative de gestion des données à partir du package R data.table avec des opérateurs comme := et l’utilisation fréquente de crochets [ ]. Cette approche et cette syntaxe sont brièvement expliquées dans la page Data Table.","code":""},{"path":"cleaning_data.html","id":"nomenclature-1","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Nomenclature","text":"Dans ce manuel, nous faisons généralement référence aux “colonnes” et aux “lignes” au lieu des “variables” et des “observations”. Comme l’explique cet introduction sur “tidy data”, la plupart des jeux de données statistiques épidémiologiques sont sous le format de lignes, de colonnes et de valeurs.Les variables contiennent les valeurs qui mesurent le même attribut sous-jacent (comme le groupe d’âge, le résultat ou la date d’apparition). Les observations contiennent toutes les valeurs mesurées sur la même unité (par exemple, une personne, un site ou un échantillon de laboratoire). Ces aspects peuvent donc être plus difficiles à définir de manière précise.Dans les jeux de données “tidy”, chaque colonne est une variable, chaque ligne est une observation et chaque cellule est une valeur unique. Cependant, certains jeu de données que vous rencontrerez ne correspondront pas à ce format - un jeu de données “étendu” (ou “large”) peut avoir une variable répartie sur plusieurs colonnes (voir un exemple dans la page Pivoter les données). De même, les observations peuvent être réparties sur plusieurs lignes.La majeure partie de ce manuel porte sur la gestion et la transformation des données, et il est donc plus pertinent de se référer aux structures de données concrètes que sont les lignes et les colonnes qu’aux observations et aux variables plus abstraites. Les exceptions se produisent principalement dans les pages sur l’analyse des données, où vous verrez davantage de références aux variables et aux observations.","code":""},{"path":"cleaning_data.html","id":"méthodologie-de-nettoyage","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"8.1 Méthodologie de nettoyage","text":"Cette page passe en revue les étapes importantes du nettoyage, en les ajoutant séquentiellement à une “chaîne de nettoyage”.Dans l’analyse épidémiologique et le traitement des données, les étapes de nettoyage sont souvent effectuées de manière séquentielle, reliées entre elles. En R, cela se manifeste souvent sous la forme d’un “pipeline” de nettoyage, où le jeu de données brutes est passé ou “pipé” d’une étape de nettoyage à une autre.De telles chaînes utilisent les fonctions “verbes” de dplyr et l’opérateur pipe %>% de magrittr. Ce pipe commence avec les données “brutes” (“linelist_raw.xlsx”) et se termine avec un dataframe “propre” (linelist) qui peut être utilisé, enregistré, exporté, etc.Dans un pipeline de nettoyage, l’ordre des étapes est important. Les étapes de nettoyage peuvent inclure :Importation des donnéesNettoyage ou modification des noms de colonnesDéduplicationCréation et transformation de colonnes (par exemple, recodage ou normalisation des valeurs).Sélection ou ajout de lignes","code":""},{"path":"cleaning_data.html","id":"charger-les-packages","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"8.2 Charger les packages","text":"Ces lignes de code chargent les paquets nécessaires aux analyses. Dans ce guide, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire puis l’importe pour l’utiliser. Vous pouvez également charger les paquets installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les paquets R.","code":"\npacman::p_load(\n  rio,        # importation données  \n  here,       # chemins d'accès relatifs aux fichiers  \n  janitor,    # nettoyage des données et tables\n  lubridate,  # manipuler les dates\n  epikit,     # age_categories() fonction\n  matchmaker, # nettoyage basé sur un dictionnaire\n  tidyverse   # manipulation et visualisation  des donnees \n)"},{"path":"cleaning_data.html","id":"import-data","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"8.3 Import data","text":"","code":""},{"path":"cleaning_data.html","id":"import","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Import","text":"Ici, nous importons le fichier Excel “brut” de cas linelist en utilisant la fonction import() du package rio. Cet dernier gère de manière flexible de nombreux types de fichiers (par exemple, .xlsx, .csv, .tsv, .rds). Importation et exportation des données pour plus d’informations et des conseils sur les situations inhabituelles (par exemple, sauter des lignes, définir des valeurs manquantes, importer des feuilles Google, etc.)Pour reproduire les étapes, cliquer pour télécharger le jeu de données “brutes” linelist (comme fichier .xlsx).Si votre jeu de données est important et prend beaucoup de temps à s’importer, il peut valloir le coup de séparer la commande d’importation des étapes de nettoyage, pour que que la donnée “brute” soit enregistré dans un dataframe distinct. Cela permet également de comparer facilement les versions originales et nettoyées.Ci-dessous, nous importons le fichier Excel brut et le sauvegardons dans le dataframe linelist_raw. Nous supposons que le fichier est situé dans votre répertoire de travail ou à la racine de votre projet R, et donc aucun sous-dossier n’est spécifié dans le chemin du fichier.Vous pouvez visualiser les 50 premières lignes du dataframe ci-dessous. Remarque : la fonction de base de R head(n) vous permet de visualiser uniquement les n premières lignes dans la console R.","code":"\nlinelist_raw <- import(\"linelist.xlsx\")"},{"path":"cleaning_data.html","id":"vue-densemble","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Vue d’ensemble","text":"Vous pouvez utiliser la fonction skim() du package skimr pour obtenir une vue d’ensemble du dataframe (voir la page sur les Tableaux descriptifs pour plus d’informations). Les colonnes sont résumées par classe/type, telles que “chaîne de caractère”, “numérique”… Note : “POSIXct” est un type de classe de date brute (voir Working dates).\nTable 8.1: Data summary\nVariable type: characterVariable type: numericVariable type: POSIXct","code":"\nskimr::skim(linelist_raw)"},{"path":"cleaning_data.html","id":"noms-de-colonnes","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"8.4 Noms de colonnes","text":"En R, les noms de colonnes sont la valeur “d’en-tête” ou la “première cellule” d’une colonne. Ils sont utilisés pour faire référence aux colonnes dans le code et servent de labels par défaut dans les figures.D’autres logiciels statistiques tels que SAS et STATA utilisent des “labels” qui représentent un format plus long et détaillé des noms de colonnes plus courts existants. Bien que R offre la possibilité d’ajouter des étiquettes de colonne aux données, cela n’est pas mis en avant en pratique. Pour rendre les noms de colonne explicites et descriptifs pour les figures, ajuste généralement leur affichage dans les commandes de qui créent les graphiques (par exemple, les titres des axes ou des légendes d’une graphique, ou les en-têtes de colonne dans un tableau imprimé - voir la section section échelles de la page Astuces de ggplot et les pages Tableaux pour la présentation). Si vous souhaitez attribuer des étiquettes de colonne dans les données, lisez la suite en ligne ici et ici.Comme les noms de colonnes sur R sont utilisés très souvent, ils doivent avoir une syntaxe “propre”. Nous suggérons ce qui suit :Noms courtsPas d’espaces (remplacez-les par des traits de soulignement _ )Pas de caractères inhabituels (&, #, <, >, …)Nomenclature homogène (par exemple, toutes les colonnes de date nommées comme date_apparition, date_rapport, date_mort…)Les noms des colonnes de linelist_raw sont affichés ci-dessous en utilisant la fonction names() de base R. peut voir qu’initialement :Certains noms contiennent des espaces (par exemple date d'infection)Des motifs de noms différents sont utilisés pour les dates (date onset vs. infection date).Il doit y avoir un même nom attribué pour les deux dernières colonnes du fichier .xlsx. Nous le savons parce que le nom de deux colonnes fusionnées (“merged_header”) été attribué par R à la première colonne, et que la deuxième colonne s’est vue attribuer un nom fictif “…28” (puisqu’elle était alors vide et qu’il s’agit de la 28ième colonne).REMARQUE: Pour faire référence à un nom de colonne qui comprend des espaces, entourez le nom de contre-tirets, par exemple : linelist$`'\\x60infection date\\x60'`. Notez que sur votre clavier, le contre-tiret (`) est différent du guillemet simple (’).","code":"\nnames(linelist_raw)##  [1] \"case_id\"         \"generation\"      \"infection date\"  \"date onset\"     \n##  [5] \"hosp date\"       \"date_of_outcome\" \"outcome\"         \"gender\"         \n##  [9] \"hospital\"        \"lon\"             \"lat\"             \"infector\"       \n## [13] \"source\"          \"age\"             \"age_unit\"        \"row_num\"        \n## [17] \"wt_kg\"           \"ht_cm\"           \"ct_blood\"        \"fever\"          \n## [21] \"chills\"          \"cough\"           \"aches\"           \"vomit\"          \n## [25] \"temp\"            \"time_admission\"  \"merged_header\"   \"...28\""},{"path":"cleaning_data.html","id":"labels","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Labels","text":"D’autres logiciels statistiques tels que SAS ont des labels de variables.","code":""},{"path":"cleaning_data.html","id":"nettoyage-automatique","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Nettoyage automatique","text":"La fonction clean_names() du package janitor normalise les noms de colonnes et les rend uniques en effectuant les opérations suivantes :Convertit tous les noms pour qu’ils ne soient composés que de underscores (sous-tiret/tiret “bas”/tiret 8), de chiffres et de lettres.Les caractères accentués sont translittérés en ASCII (par exemple, le o allemand avec tréma devient “o”, le “enye” espagnol devient “n”).La préférence de capitalisation pour les nouveaux noms de colonnes peut être spécifiée en utilisant l’argument case = (“snake” est le défaut, les alternatives incluent “phrase”, “title”, “small_camel”…)Vous pouvez spécifier des remplacements de noms spécifiques en fournissant un vecteur à l’argument replace = (par exemple, replace = c(onset = \"date_of_onset\"))Pour en savoir plus, voici la vignette en ligne. .Ci-dessous, le pipeline de nettoyage commence par utiliser clean_names() sur le dataframe contenant les données brutes.NOTE: le dernier nom de colonne “…28” est changé pour devenir “x28”.","code":"\n# pipe le jeu de données brutes à travers clean_names(), puis assigne le resultat à un nouveau dataframe, \"linelist\"  \nlinelist <- linelist_raw %>% \n  janitor::clean_names()\n\n# voir les nouveaux noms de colonnes\nnames(linelist)##  [1] \"case_id\"         \"generation\"      \"infection_date\"  \"date_onset\"     \n##  [5] \"hosp_date\"       \"date_of_outcome\" \"outcome\"         \"gender\"         \n##  [9] \"hospital\"        \"lon\"             \"lat\"             \"infector\"       \n## [13] \"source\"          \"age\"             \"age_unit\"        \"row_num\"        \n## [17] \"wt_kg\"           \"ht_cm\"           \"ct_blood\"        \"fever\"          \n## [21] \"chills\"          \"cough\"           \"aches\"           \"vomit\"          \n## [25] \"temp\"            \"time_admission\"  \"merged_header\"   \"x28\""},{"path":"cleaning_data.html","id":"nettoyage-manuel-des-noms","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Nettoyage manuel des noms","text":"Il est souvent nécessaire de renommer les colonnes manuellement, même après l’étape de normalisation ci-dessus. Ci-dessous, le changement de nom est effectué en utilisant la fonction rename() du package dplyr, dans une chaine de commandes pipées. rename() utilise le style NEW = OLD - le nouveau nom de colonne est donné avant l’ancien nom de colonne.Ci-dessous, une commande de re-nommage est ajoutée au pipeline de nettoyage. Des espaces ont été ajoutés stratégiquement pour aligner le code afin de faciliter la lecture.Vous pouvez maintenant voir que les noms des colonnes ont été modifiés :","code":"\n# NETTOYAGE: enchainement de commandes  'PIPE'  (debute avec la donnée brute  et suivi de  pipes avec les commandes pour le nettoyage)\n##################################################################################\nlinelist <- linelist_raw %>%\n    \n    # standardiser la syntaxe des noms de colonnes \n    janitor::clean_names() %>% \n    \n    # renommer manuellement les noms de colonnes\n           # Nouveau noms             # Ancien noms\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome)##  [1] \"case_id\"              \"generation\"           \"date_infection\"      \n##  [4] \"date_onset\"           \"date_hospitalisation\" \"date_outcome\"        \n##  [7] \"outcome\"              \"gender\"               \"hospital\"            \n## [10] \"lon\"                  \"lat\"                  \"infector\"            \n## [13] \"source\"               \"age\"                  \"age_unit\"            \n## [16] \"row_num\"              \"wt_kg\"                \"ht_cm\"               \n## [19] \"ct_blood\"             \"fever\"                \"chills\"              \n## [22] \"cough\"                \"aches\"                \"vomit\"               \n## [25] \"temp\"                 \"time_admission\"       \"merged_header\"       \n## [28] \"x28\""},{"path":"cleaning_data.html","id":"renommer-par-la-position-des-colonnes","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Renommer par la position des colonnes","text":"Vous pouvez également renommer par position de colonne, au lieu du nom de colonne, par exemple :","code":"\n#rename(newNameForFirstColumn  = 1,\n       #newNameForSecondColumn = 2)"},{"path":"cleaning_data.html","id":"renommer-via-select-et-summarise","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Renommer via select() et summarise()","text":"Comme raccourci, vous pouvez aussi renommer les colonnes dans les fonctions dplyr select() et summarise(). select() est utilisé pour ne garder que certaines colonnes (et est couvert plus loin dans cette page). La fonction summarise() est traitée dans les pages Regroupement des données et Tableaux descriptifs. Ces fonctions utilisent également le format nouveau_nom = ancien_nom. Voici un exemple :","code":"\nlinelist_raw %>% \n  select(# NOUVEAU nom             # ANCIEN nom\n         date_infection       = `infection date`,    # renommer and CONSEVER  que  ces colonnes\n         date_hospitalisation = `hosp date`)"},{"path":"cleaning_data.html","id":"autres-challenges","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Autres challenges","text":"","code":""},{"path":"cleaning_data.html","id":"fichiers-excels-sans-noms-de-colonnes","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"fichiers excels sans noms de colonnes","text":"R ne peut pas travailler sur des jeux de données qui n’ont pas de noms de colonne (en-têtes). Ainsi, si vous importez un jeu de données Excel contenant des données mais pas d’en-tête de colonne, R remplira les en-têtes avec des noms tels que “…1” ou “…2”. Le chiffre représente le numéro de la colonne (par exemple, si la quatrième colonne de l’ensemble de données n’pas d’en-tête, R la nommera “…4”).Vous pouvez nettoyer ces noms manuellement en faisant référence à leur numéro de position (voir l’exemple ci-dessus), ou au nom qui leur est attribué (linelist_raw$...1).","code":""},{"path":"cleaning_data.html","id":"fusion-des-noms-de-colonnes-et-de-cellules-sur-excel","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Fusion des noms de colonnes et de cellules sur Excel","text":"La fusion de cellules dans un fichier Excel est un phénomène courant lors de la réception de données. Comme expliqué dans Transition vers R, les cellules fusionnées peuvent être agréables pour la lecture humaine des données, mais ne sont pas des “tidy data” et posent de nombreux problèmes pour la lecture automatique des données. R ne peut pas prendre en compte les cellules fusionnées.Rappelez aux personnes chargées de la saisie des données que les données lisibles par l’homme ne sont pas les mêmes que celles lisibles par la machine. Efforcez-vous de former les utilisateurs aux principes des [Tidy Data] (https://r4ds..co.nz/tidy-data.html). Dans la mesure du possible, essayez de modifier les procédures pour que les données arrivent dans un format tidy, sans cellules fusionnées.Chaque variable doit avoir sa propre colonne.Chaque observation doit avoir sa propre ligne.Chaque valeur doit avoir sa propre cellule.Lorsque vous utilisez la fonction import() de rio, la valeur d’une cellule fusionnée sera assignée à la première cellule et les cellules suivantes seront vides.Une solution pour gérer les cellules fusionnées est d’importer les données avec la fonction readWorkbook() du package openxlsx. Définissez l’argument fillMergedCells = TRUE. Cela donne la valeur d’une cellule fusionnée à toutes les cellules de la plage de fusion.DANGERS: Si les noms de colonnes sont fusionnés avec readWorkbook(), vous vous retrouverez avec des noms de colonnes en double, que vous devrez corriger manuellement - R ne fonctionne pas bien avec des noms de colonnes en double ! Vous pouvez les renommer en faisant référence à leur position (par exemple colonne 5), comme expliqué dans la section sur le nettoyage manuel des noms de colonnes.","code":"\nlinelist_raw <- openxlsx::readWorkbook(\"linelist_raw.xlsx\", fillMergedCells = TRUE)"},{"path":"cleaning_data.html","id":"sélectionner-ou-réorganiser-les-colonnes","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"8.5 Sélectionner ou réorganiser les colonnes","text":"Utilisez select() de dplyr pour sélectionner les colonnes que vous voulez conserver, et pour spécifier leur ordre dans le cadre de données.Avertissement: Dans les exemples ci-dessous, le dataframe linelist est modifié avec select() et affiché, mais pas enregistré. Ceci est pour les besoins de la démonstration. Les noms de colonnes modifiés sont renvoyés en passant (pipe)le dataframe dans names().Voici TOUS les noms de colonnes dans la liste de lignes à ce stade de la chaîne de nettoyage :.","code":"\nnames(linelist)##  [1] \"case_id\"              \"generation\"           \"date_infection\"      \n##  [4] \"date_onset\"           \"date_hospitalisation\" \"date_outcome\"        \n##  [7] \"outcome\"              \"gender\"               \"hospital\"            \n## [10] \"lon\"                  \"lat\"                  \"infector\"            \n## [13] \"source\"               \"age\"                  \"age_unit\"            \n## [16] \"row_num\"              \"wt_kg\"                \"ht_cm\"               \n## [19] \"ct_blood\"             \"fever\"                \"chills\"              \n## [22] \"cough\"                \"aches\"                \"vomit\"               \n## [25] \"temp\"                 \"time_admission\"       \"merged_header\"       \n## [28] \"x28\""},{"path":"cleaning_data.html","id":"conserver-des-colonnes","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Conserver des colonnes","text":"Selectionner uniquement les colonnes que vous voulez conserverMettez leurs noms dans la commande select(), sans guillemets. Elles apparaîtront dans le dataframe dans l’ordre que vous avez indiqué. Notez que si vous incluez une colonne qui n’existe pas, R retournera une erreur (voir l’utilisation de any_of() ci-dessous si vous ne voulez pas d’erreur dans cette situation).","code":"\n# jeu de donnée linelist est pipé  à travers la commande select() et names() affiche les noms de colones\nlinelist %>% \n  select(case_id, date_onset, date_hospitalisation, fever) %>% \n  names()  # affiche le nom des colonnes## [1] \"case_id\"              \"date_onset\"           \"date_hospitalisation\"\n## [4] \"fever\""},{"path":"cleaning_data.html","id":"clean_tidyselect","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"fonction d’aide “tidyselect”","text":"Ces fonctions d’aide existent pour faciliter la spécification des colonnes à conserver, à éliminer ou à transformer. Elles sont issues du package tidyselect, qui est inclus dans tidyverse et qui sous-tend la façon dont les colonnes sont sélectionnées dans les fonctions dplyr.Par exemple, si vous voulez réordonner les colonnes, everything() est une fonction utile qui correspond à “toutes les autres colonnes non encore mentionnées”. La commande ci-dessous déplace les colonnes date_onset et date_hospitalisation au début (à gauche) du jeu de donnée, mais conserve toutes les autres colonnes par la suite. Notez que everything() est écrit avec des parenthèses vides :Voici d’autres fonctions d’aide “tidyselect” qui fonctionnent également dans les fonctions dplyr comme select(), across(), et summarise() :everything() - toutes les autres colonnes non mentionnéeslast_col() - la dernière colonnewhere() - applique une fonction à toutes les colonnes et sélectionne celles qui sont VRAIES.contains() - colonnes contenant une chaîne de caractères.\nExemple : select(contains(\"time\")).\nExemple : select(contains(\"time\")).starts_with() - correspond à un préfixe spécifié.\nExemple : select(starts_with(\"date_\")).\nExemple : select(starts_with(\"date_\")).ends_with() - correspond à un suffixe spécifié.\nexemple : select(ends_with(\"_post\"))\nexemple : select(ends_with(\"_post\"))matches() - pour appliquer une expression régulière (regex)\nexemple : select(matches(\"[pt]al\"))\nexemple : select(matches(\"[pt]al\"))num_range() - une plage numérique comme x01, x02, x03any_of() - correspond si la colonne existe mais ne renvoie pas d’erreur si elle n’est pas trouvée.\nExemple : select(any_of(date_onset, date_death, cardiac_arrest)).\nExemple : select(any_of(date_onset, date_death, cardiac_arrest)).De plus, utilisez des opérateurs normaux tels que c() pour lister plusieurs colonnes, : pour des colonnes consécutives, ! pour l’opposé, & pour , et | pour .Utilisez () pour spécifier des critères logiques pour les colonnes. Si vous fournissez une fonction dans (), n’incluez pas les parenthèses vides de la fonction. La commande ci-dessous sélectionne les colonnes de la classe Numeric.Utilisez contains() pour ne sélectionner que les colonnes dont le nom contient une chaîne de caractères donnée. ends_with() et starts_with() apportent plus de nuances.La fonction matches() fonctionne de la même manière que contains() mais peut lui fournir une expression régulière (voir la page sur les Caractères et chaînes de caractères), comme plusieurs chaînes de caractères séparées par des barres à l’intérieur des parenthèses :AVERTISSEMENT: Si un nom de colonne que vous fournissez spécifiquement n’existe pas dans les données, il peut retourner une erreur et arrêter votre code. Pensez à utiliser any_of() pour citer des colonnes qui peuvent ou non exister, particulièrement utile dans les sélections négatives (enlever).Une seule de ces colonnes existe, mais aucune erreur n’est produite et le code continue sans arrêter votre chaîne de nettoyage.","code":"\n# deplacer les colonnes data_onset et date_hospilisation au debut du jeu de donnée\nlinelist %>% \n  select(date_onset, date_hospitalisation, everything()) %>% \n  names()##  [1] \"date_onset\"           \"date_hospitalisation\" \"case_id\"             \n##  [4] \"generation\"           \"date_infection\"       \"date_outcome\"        \n##  [7] \"outcome\"              \"gender\"               \"hospital\"            \n## [10] \"lon\"                  \"lat\"                  \"infector\"            \n## [13] \"source\"               \"age\"                  \"age_unit\"            \n## [16] \"row_num\"              \"wt_kg\"                \"ht_cm\"               \n## [19] \"ct_blood\"             \"fever\"                \"chills\"              \n## [22] \"cough\"                \"aches\"                \"vomit\"               \n## [25] \"temp\"                 \"time_admission\"       \"merged_header\"       \n## [28] \"x28\"\n# selectionner les colonnes de classe Numeric\nlinelist %>% \n  select(where(is.numeric)) %>% \n  names()## [1] \"generation\" \"lon\"        \"lat\"        \"row_num\"    \"wt_kg\"      \"ht_cm\"     \n## [7] \"ct_blood\"   \"temp\"\n# Selectionner des colonnes qui contiennent une caractere defini\nlinelist %>% \n  select(contains(\"date\")) %>% \n  names()## [1] \"date_infection\"       \"date_onset\"           \"date_hospitalisation\"\n## [4] \"date_outcome\"\n# searched for multiple character matches\n#  rechercher plusieurs caracteres \nlinelist %>% \n  select(matches(\"onset|hosp|fev\")) %>%   # noter le symbole de OR  \"|\"\n  names()## [1] \"date_onset\"           \"date_hospitalisation\" \"hospital\"            \n## [4] \"fever\"\nlinelist %>% \n  select(any_of(c(\"date_onset\", \"village_origin\", \"village_detection\", \"village_residence\", \"village_travel\"))) %>% \n  names()## [1] \"date_onset\""},{"path":"cleaning_data.html","id":"supprimer-colonnes","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Supprimer colonnes","text":"Indiquez les colonnes à supprimer en plaçant un symbole moins “-” devant le nom de la colonne (par exemple, select(-outcome)), ou un vecteur de noms de colonnes (comme ci-dessous). Toutes les autres colonnes seront conservées.Vous pouvez également supprimer une colonne en utilisant la syntaxe R base, en la définissant comme NULL. Par exemple :","code":"\nlinelist %>% \n  select(-c(date_onset, fever:vomit)) %>% #supprimer la colonne date_onset et tout les colonnes allant de fever à vomit\n  names()##  [1] \"case_id\"              \"generation\"           \"date_infection\"      \n##  [4] \"date_hospitalisation\" \"date_outcome\"         \"outcome\"             \n##  [7] \"gender\"               \"hospital\"             \"lon\"                 \n## [10] \"lat\"                  \"infector\"             \"source\"              \n## [13] \"age\"                  \"age_unit\"             \"row_num\"             \n## [16] \"wt_kg\"                \"ht_cm\"                \"ct_blood\"            \n## [19] \"temp\"                 \"time_admission\"       \"merged_header\"       \n## [22] \"x28\"\nlinelist$date_onset <- NULL   \n# supprimer colonne avec la syntaxe native de R"},{"path":"cleaning_data.html","id":"autres","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Autres","text":"select() peut aussi être utilisé comme une commande indépendante (pas dans une chaîne de tuyaux). Dans ce cas, le premier argument est le dataframe original sur lequel veut travailler.","code":"\n# creer un nouvelle donnée linelist avec des colonnes  id et age-related\nlinelist_age <- select(linelist, case_id, contains(\"age\"))\n\n# afficher les noms de colonnes\nnames(linelist_age)## [1] \"case_id\"  \"age\"      \"age_unit\""},{"path":"cleaning_data.html","id":"ajouter-à-la-chaine-de-commande-pipé","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"ajouter à la chaine de commande pipé","text":"Dans la linelist_raw, il y quelques colonnes dont nous n’avons pas besoin : row_num, merged_header, et x28. Nous les supprimons avec une commande select() dans la chaîne de nettoyage :","code":"\n# NETTOYAGE: enchainement de commandes  'PIPE'  (debute avec la donnée brute  et le  pipes avec les commandes pour le nettoyage)\n##################################################################################\n\n\n# Debuter le processus de Nettoyage pipé \n###########################\nlinelist <- linelist_raw %>%\n    \n     # standardiser le syntaxe des noms de colonnes\n    janitor::clean_names() %>% \n    \n    \n     # renommer manuellement les colonnes\n           # NOUVEAU nom            # ANCIEN nom\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    \n     # CI DESSUS LES ETAPES DU NETTOYAGE DEJA ABORDEES EN AMONT \n    #####################################################\n\n    # supprimer des colonnes\n    select(-c(row_num, merged_header, x28))"},{"path":"cleaning_data.html","id":"deduplication","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"8.6 Deduplication","text":"Voir la page du manuel sur la déduplication pour de nombreuses options sur la façon de dédupliquer les données. Seul un exemple très simple de déduplication de lignes est présenté ici.Le package dplyr offre la fonction distinct(). Cette fonction examine chaque ligne et réduit le dataframe à seulement les lignes uniques. C’est-à-dire qu’elle supprime les lignes qui sont à 100% des doublons.Lors de l’évaluation des lignes dupliquées, elle prend en compte un eventail de colonnes defini - par défaut, elle considère toutes les colonnes. Comme le montre la page dediée à la déduplication, vous pouvez ajuster cet eventail de colonnes afin que l’unicité des lignes ne soit évaluée que par rapport à certaines colonnes.Dans cet exemple simple, nous ajoutons simplement la commande vide distinct() à la chaîne de commande pipé. Cela permet de s’assurer qu’il n’y pas de lignes qui sont des doublons à 100% d’autres lignes (évaluées sur toutes les colonnes).Nous commençons avec nrow(linelist) lignes dans linelist.Après la déduplication, il y nrow(linelist) lignes. Toutes les lignes supprimées auraient été des doublons à 100% d’autres lignes.Ci-dessous, la commande distinct() est ajoutée à la chaîne de nettoyage :","code":"\nlinelist <- linelist %>% \n  distinct()\n# NETTOYAGE: enchainement de commandes  'PIPE'  (debute avec la donnée brute  et le  pipe avec les commandes pour le nettoyage)\n##################################################################################\n\n# Debuter le processus de Nettoyage pipé \n\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardiser le syntaxe des noms de colonnes\n    janitor::clean_names() %>% \n    \n    # Renommer manuellement les noms de colonnes\n           # Nouveau nom             # Ancien nom\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # supprimer les colonnes\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # CI DESSUS LES ETAPES DU NETTOYAGE DEJA ABORDEES EN AMONT \n    #####################################################\n    \n    # Supprimer les doublons\n    distinct()"},{"path":"cleaning_data.html","id":"creation-et-transformation-de-colonne","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"8.7 Creation et transformation de colonne","text":"Nous recommandons d’utiliser la fonction mutate() du package dplyr pour ajouter une nouvelle colonne, ou pour modifier une colonne existante.Vous trouverez ci-dessous un exemple de création d’une nouvelle colonne avec mutate(). La syntaxe est la suivante : mutate(nouveau_nom_de_colonne = valeur ou transformation).Dans Stata, ceci est similaire à la commande generate, mais la fonction mutate() de R peut également être utilisée pour modifier une colonne existante.","code":""},{"path":"cleaning_data.html","id":"nouvelles-colonnes","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Nouvelles colonnes","text":"La commande mutate() la plus basique pour créer une nouvelle colonne peut ressembler à ceci. Elle crée une nouvelle colonne new_col dont la valeur dans chaque ligne est 10.Vous pouvez également référencer des valeurs dans d’autres colonnes, pour effectuer des calculs. Ci-dessous, une nouvelle colonne bmi est créée pour contenir l’indice de masse corporelle (IMC) pour chaque cas - tel que calculé en utilisant la formule IMC = kg/m^2, en utilisant la colonne ht_cm et la colonne wt_kg.Si vous créez plusieurs nouvelles colonnes, séparez-les par une virgule et une nouvelle ligne. Vous trouverez ci-dessous des exemples de nouvelles colonnes, y compris celles qui sont constituées de valeurs provenant d’autres colonnes combinées à l’aide de str_glue() du package stringr (voir la page sur Caractères et chaînes de caractères.Examinez les nouvelles colonnes. À des fins de démonstration, seules les nouvelles colonnes et les colonnes utilisées pour les créer sont affichées :CONSEILS: Une variante de mutate() est la fonction transmute(). Cette fonction ajoute une nouvelle colonne comme mutate(), mais supprime également toutes les autres colonnes que vous ne mentionnez pas entre ses parenthèses..","code":"\nlinelist <- linelist %>% \n  mutate(new_col = 10)\nlinelist <- linelist %>% \n  mutate(bmi = wt_kg / (ht_cm/100)^2)\nnew_col_demo <- linelist %>%                       \n  mutate(\n    new_var_dup    = case_id,             \n    # nouveau colonne= dupliquer ou copier une autre colonne existante\n    new_var_static = 7,                   # nouveau colonne = meme valeur sur toute les lignes\n    new_var_static = new_var_static + 5,  \n    # On peut ecraser une colonne et le recreer par un calcul  utilisant d'autres variables\n    new_var_paste  = stringr::str_glue(\"{hospital} on ({date_hospitalisation})\") # nouveau colonne = pasting together values from other columns\n    # regrouper les valeurs de differentes  colonnes\n    ) %>% \n  select(case_id, hospital, date_hospitalisation, contains(\"new\"))        \n# montrer seulement les nouveaux colonnes  pour besoin de demonstration\n# CACHER POUR LECTEUR\n# Supprimer les nouveaux colonnes demo créees en haut\n# linelist <- linelist %>% \n#   select(-contains(\"new_var\"))"},{"path":"cleaning_data.html","id":"convertir-la-classe-des-colonnes","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Convertir la classe des colonnes","text":"Les colonnes contenant des valeurs qui sont des dates, des nombres ou des valeurs logiques (VRAI/FAUX) ne se comporteront comme prévu que si elles sont dans la classe appropriée. Il y une différence entre “2” de classe caractère et 2 de classe numérique !Il existe des moyens de définir la classe des colonnes avec les commandes d’importation, mais cela est souvent fastidieux. Consultez la section Bases de R sur les classes d’objets pour en savoir plus sur la conversion de la classe des objets et des colonnes.Tout d’abord, effectuons quelques vérifications sur les colonnes importantes pour voir si elles sont de la bonne classe. Nous avons également vu cela au début lorsque nous avons lancé skim().Actuellement, la classe de la colonne age est un caractère. Pour effectuer des analyses quantitatives, nous avons besoin que ces nombres soient reconnus comme numériques !La classe de la colonne date_onset est aussi un caractère ! Pour effectuer des analyses, ces dates doivent être reconnues comme des dates!Pour résoudre ce problème, utilisez la capacité de mutate() pour redéfinir une colonne avec une transformation. Nous définissons la colonne comme elle-même, mais convertie en une classe différente. Voici un exemple de base, convertissons ou assurerons nous que la colonne age est de classe Numeric :De la même manière, vous pouvez utiliser .character() et .logical(). Pour convertir en classe Factor, vous pouvez utiliser factor() de base R ou as_factor() de forcats. Pour en savoir plus, consultez la page Facteurs.Vous devez faire attention lorsque vous convertissez en classe Date. Plusieurs méthodes sont expliquées sur la page Manipuler les dates. En général, les valeurs brutes de la date doivent toutes être dans le même format pour que la conversion fonctionne correctement (par exemple “MM/JJ/AAAA”, ou “JJ MM AAAA”). Après la conversion en classe Date, vérifiez vos données pour confirmer que chaque valeur été convertie correctement.","code":"\nclass(linelist$age)## [1] \"character\"\nclass(linelist$date_onset)## [1] \"character\"\nlinelist <- linelist %>% \n  mutate(age = as.numeric(age))"},{"path":"cleaning_data.html","id":"données-groupées","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Données groupées","text":"Si votre dataframe est déjà groupée (voir la page sur Travailler sur des données groupées), mutate() peut se comporter différemment que si la base de données n’est pas groupée. Toutes les fonctions de résumé, comme mean(), median(), max(), etc. seront calculées par groupe, et non par toutes les lignes.Pour en savoir plus sur l’utilisation de mutate () sur des blocs de données groupés, consultez la documentation tidyverse mutate.","code":"\n# Normalisation de l'age en fonction la moyenne\nlinelist %>% \n  mutate(age_norm = age / mean(age, na.rm=T))\n\n\n# Normalisation de l'age en fonction de la moyenne du jeu donne groupe  à partir de la colonne hospital\nlinelist %>% \n  group_by(hospital) %>% \n  mutate(age_norm = age / mean(age, na.rm=T))"},{"path":"cleaning_data.html","id":"clean_across","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Transformer plusieurs colonnes","text":"Souvent, pour écrire un code concis, vous voulez appliquer la même transformation à plusieurs colonnes à la fois. Une transformation peut être appliquée à plusieurs colonnes à la fois en utilisant la fonction across() du package dplyr (également contenu dans le package tidyverse). across() peut être utilisé avec n’importe quelle fonction dplyr, mais est couramment utilisé dans select(), mutate(), filter(), ou summarise(). Voir comment il est appliqué à summarise() dans la page sur les Tableaux descriptifs.Spécifiez les colonnes à l’argument .cols = et la ou les fonctions à appliquer à .fns =. Tout argument supplémentaire à fournir à la fonction .fns peut être inclus après une virgule, toujours dans across().","code":""},{"path":"cleaning_data.html","id":"across-selection-de-colonne","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"across() selection de colonne","text":"Spécifiez les colonnes à l’argument .cols =. Vous pouvez les nommer individuellement, ou utiliser les fonctions d’aide “tidyselect”. Spécifiez la fonction en argument .fns =. Notez qu’en utilisant le mode fonction démontré ci-dessous, la fonction est écrite sans ses parenthèses ( ).Ici, la transformation .character() est appliquée à des colonnes spécifiques nommées dans across().Les fonctions d’aide “tidyselect” sont disponibles pour vous aider à spécifier les colonnes. Elles sont détaillées ci-dessus dans la section sur la sélection et le réordonnancement des colonnes, et elles incluent : everything(), last_col(), (), starts_with(), ends_with(), contains(), matches(), num_range() et any_of().Voici un exemple de la façon dont peut changer toutes les colonnes en classe de caractères :Convertissez en caractères toutes les colonnes dont le nom contient la chaîne “date” (notez le placement des virgules et des parenthèses) :Ci-dessous, un exemple de mutation des colonnes qui sont actuellement de classe POSIXct (une classe de date brute qui montre les timestamps) - en d’autres termes, où la fonction .POSIXct() évalue à TRUE. Ensuite, nous voulons appliquer la fonction .Date() à ces colonnes pour les convertir en une classe normale de Date.Notez que dans across(), nous utilisons également la fonction () car .POSIXct est évalué à TRUE ou FALSE.Notez que .POSIXct() fait partie du paquet lubridate. D’autres fonctions “” similaires comme .character(), .numeric(), et .logical() sont issues de base R.","code":"\nlinelist <- linelist %>% \n  mutate(across(.cols = c(temp, ht_cm, wt_kg), .fns = as.character))\n# Changer toutes les colonnes en classe caractère\nlinelist <- linelist %>% \n  mutate(across(.cols = everything(), .fns = as.character))\n# Changer toutes les colonnes en classe caractère\nlinelist <- linelist %>% \n  mutate(across(.cols = contains(\"date\"), .fns = as.character))\nlinelist <- linelist %>% \n  mutate(across(.cols = where(is.POSIXct), .fns = as.Date))"},{"path":"cleaning_data.html","id":"fonction-across","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"fonction across()","text":"Vous pouvez lire la documentation avec ?across pour des détails sur la façon de fournir des fonctions à across(). Quelques points récapitulatifs : il y plusieurs façons de spécifier la ou les fonctions à exécuter sur une colonne et vous pouvez même définir vos propres fonctions :Vous pouvez fournir le nom de la fonction seul (par exemple mean ou .character)Vous pouvez fournir la fonction dans le style purrr (par exemple ~ mean(.x, na.rm = TRUE)) (voir [cette page][#iteration])Vous pouvez spécifier plusieurs fonctions en fournissant une liste (par exemple, list(mean = mean, n_miss = ~ sum(.na(.x))).\nSi vous fournissez plusieurs fonctions, plusieurs colonnes transformées seront retournées par colonne d’entrée, avec des noms uniques dans le format col_fn. Vous pouvez ajuster la façon dont les nouvelles colonnes sont nommées avec l’argument .names = en utilisant la syntaxe glue (voir la page sur Caractères et chaînes de caractères) où {.col} et {.fn} sont des raccourcis pour la colonne d’entrée et la fonction.\nSi vous fournissez plusieurs fonctions, plusieurs colonnes transformées seront retournées par colonne d’entrée, avec des noms uniques dans le format col_fn. Vous pouvez ajuster la façon dont les nouvelles colonnes sont nommées avec l’argument .names = en utilisant la syntaxe glue (voir la page sur Caractères et chaînes de caractères) où {.col} et {.fn} sont des raccourcis pour la colonne d’entrée et la fonction.Voici quelques ressources en ligne sur l’utilisation de across() : creator Hadley Wickham’s thoughts/rationale","code":""},{"path":"cleaning_data.html","id":"coalesce","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"coalesce()","text":"Cette fonction dplyr trouve la première valeur non manquante à chaque position. Elle “remplit” les valeurs manquantes avec la première valeur disponible dans l’ordre que vous spécifiez.Voici un exemple En dehors du contexte de dataframe : Disons que vous avez deux vecteurs, l’un contenant le village de détection du patient et l’autre contenant le village de résidence du patient. Vous pouvez utiliser coalesce pour choisir la première valeur non manquante pour chaque indice :Cela fonctionne de la même manière si vous fournissez des colonnes de cadre de données : pour chaque ligne, la fonction attribuera la nouvelle valeur de la colonne avec la première valeur non manquante dans les colonnes que vous avez fournies (dans l’ordre fourni).Il s’agit d’un exemple d’opération “ligne par ligne”. Pour des calculs par rangée plus complexes, voir la section ci-dessous sur les calculs par rangée.","code":"\nvillage_detection <- c(\"a\", \"b\", NA,  NA)\nvillage_residence <- c(\"a\", \"c\", \"a\", \"d\")\n\nvillage <- coalesce(village_detection, village_residence)\nvillage    # print## [1] \"a\" \"b\" \"a\" \"d\"\nlinelist <- linelist %>% \n  mutate(village = coalesce(village_detection, village_residence))"},{"path":"cleaning_data.html","id":"mathématique-cumulative","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"mathématique cumulative","text":"Si vous voulez qu’une colonne reflète somme/moy/min/max cumulée etc. pour les differntes observations du dataframe, utilisez les fonctions suivantes :cumsum() renvoie la somme cumulée, comme indiqué ci-dessous :Ceci peut être utilisé dans un dataframe lors de la création d’une nouvelle colonne. Par exemple, pour calculer le nombre cumulé de cas par jour dans une épidémie, envisagez un code comme celui-ci :Voici les 10 premières rangées :Voir la page sur les Courbes épidémiques pour savoir comment tracer l’incidence cumulée avec l’épicurve.Voir aussi :cumsum(), cummean(), cummin(), cummax(), cumany(), cumall().","code":"\nsum(c(2,4,15,10))     # retourne un nombre unique## [1] 31\ncumsum(c(2,4,15,10))  # renvoie la somme cumulé a chaque élémenet parcouru du vecteur ## [1]  2  6 21 31\ncumulative_case_counts <- linelist %>%  # Commencons avec la donnne linelist \n  count(date_onset) %>%                 # Creons une colonne 'n' qui totalise le nombre de ligne par jour   \n  mutate(cumulative_cases = cumsum(n))  #  nouveau colonne representant la somme cumulée par ligne\nhead(cumulative_case_counts, 10)##    date_onset n cumulative_cases\n## 1  2012-04-15 1                1\n## 2  2012-05-05 1                2\n## 3  2012-05-08 1                3\n## 4  2012-05-31 1                4\n## 5  2012-06-02 1                5\n## 6  2012-06-07 1                6\n## 7  2012-06-14 1                7\n## 8  2012-06-21 1                8\n## 9  2012-06-24 1                9\n## 10 2012-06-25 1               10"},{"path":"cleaning_data.html","id":"utiliser-les-fonctions-base-de-r","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Utiliser les fonctions base de R","text":"Pour définir une nouvelle colonne (ou redéfinir une colonne) en utilisant base R, écrivez le nom du cadre de données, relié par $, à la nouvelle colonne (ou à la colonne à modifier). Utilisez l’opérateur d’affectation <- pour définir la ou les nouvelles valeurs. N’oubliez pas que lorsque vous utilisez base R, vous devez à chaque fois spécifier le nom du dataframe avant le nom de la colonne (par exemple, dataframe$column). Voici un exemple de création de la colonne bmi en utilisant base R :","code":"\nlinelist$bmi = linelist$wt_kg / \n     (linelist$ht_cm /100) ^ 2"},{"path":"cleaning_data.html","id":"ajouter-à-la-chaine-de-commande-pipé-1","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Ajouter à la chaine de commande pipé","text":"Au-dessous, une nouvelle colonne est ajoutée à la chaîne de tuyaux et certaines classes sont converties.","code":"\n# NETTOYAGE: enchainement de commandes  'PIPE'  (debute avec la donnée brute  et le  pipes avec les commandes pour le nettoyage)\n##################################################################################\n\n# Debuter le processus de Nettoyage pipé\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardiser le syntaxe des noms de colonnes\n    janitor::clean_names() %>% \n    \n    # renommer manuellement les noms de colonnes\n           # Nouveau nom             # ANCIEN nom\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # supprimer colonne\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # supprimer les doublons\n    distinct() %>% \n  \n    \n    # CI DESSUS LES ETAPES DU NETTOYAGE DEJA ABORDEES EN AMONT \n    ###################################################\n    # ajouter un nouveau colonne\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %>% \n  \n    # convertir les classes des colonnes\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) "},{"path":"cleaning_data.html","id":"re-coder-les-valeurs","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"8.8 Re-coder les valeurs","text":"Voici quelques situations dans lesquelles vous devez recoder (modifier) des valeurs :pour modifier une valeur spécifique (par exemple, une date dont l’année ou le format est incorrect)pour uniformiser des valeurs dont l’orthographe n’est pas la mêmepour créer une nouvelle colonne de valeurs catégoriellespour créer une nouvelle colonne de catégories numériques (par exemple, des catégories d’âge).","code":""},{"path":"cleaning_data.html","id":"valeurs-spécifiques","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Valeurs spécifiques","text":"Pour modifier les valeurs manuellement, vous pouvez utiliser la fonction recode() au sein de la fonction mutate().Imaginez qu’il y ait une date érronée dans les données (par exemple “2014-14-15”) : vous pouvez corriger la date manuellement dans les données brutes, ou vous pouvez operer le changement dans le pipeline de nettoyage via mutate() et recode(). Cette dernière solution est plus transparente et reproductible pour toute autre personne cherchant à comprendre ou à répéter votre analyse.La ligne mutate() ci-dessus peut être lue comme : “muter la colonne date_onset pour qu’elle soit égale à la colonne date_onset recodée de façon à ce que l’ancienne Valeur soit changée en Nouvelle Valeur”. Notez que ce modèle (Ancienne = Nouvelle) pour recode() est l’opposé de la plupart des modèles R (new = old). La communauté de développement de R travaille à la révision de ce modèle.Voici un autre exemple de recodage de plusieurs valeurs dans une même colonne.Dans linelist, les valeurs de la colonne “hospital” doivent être nettoyées. Il y plusieurs orthographes différentes et de nombreuses valeurs manquantes.La commande recode() ci-dessous redéfinit la colonne “hospital” comme la colonne actuelle “hospital”, mais avec les changements de recode spécifiés. N’oubliez pas les virgules après chacun d’eux !Nous voyons maintenant que les orthographes de la colonne hospital ont été corrigées et consolidées :CONSEIL: Le nombre d’espaces avant et après un signe égal n’pas d’importance. Rendez votre code plus facile à lire en alignant le signe = pour toutes ou la plupart des lignes. En outre, envisagez d’ajouter une ligne de commentaires afin de clarifier pour les futurs lecteurs quel côté est l’ANCIEN et quel côté est le NOUVEAU. CONSEIL: Parfois, une valeur de caractère vide existe dans un jeu de donnée (non reconnue comme la valeur de R pour les manquants - NA). Vous pouvez référencer cette valeur avec deux guillemets sans espace entre eux (““).","code":"\n# Corriger  les valeurs erronnées                   # ancienne valeur        # nouvelle valeur\nlinelist <- linelist %>% \n  mutate(date_onset = recode(date_onset, \"2014-14-15\" = \"2014-04-15\"))\ntable(linelist$hospital, useNA = \"always\")  ## \n##                      Central Hopital                     Central Hospital \n##                                   11                                  457 \n##                           Hospital A                           Hospital B \n##                                  290                                  289 \n##                     Military Hopital                    Military Hospital \n##                                   32                                  798 \n##                     Mitylira Hopital                    Mitylira Hospital \n##                                    1                                   79 \n##                                Other                         Port Hopital \n##                                  907                                   48 \n##                        Port Hospital St. Mark's Maternity Hospital (SMMH) \n##                                 1756                                  417 \n##   St. Marks Maternity Hopital (SMMH)                                 <NA> \n##                                   11                                 1512\n# Afficher un tableau avec toutes les valeurs uniques y compris les les valeurs manquantes\nlinelist <- linelist %>% \n  mutate(hospital = recode(hospital,\n                # Pour reference: ANCIEN =NOUVEAU\n                      \"Mitylira Hopital\"  =\"Military Hospital\",\n                      \"Mitylira Hospital\" =\"Military Hospital\",\n                      \"Military Hopital\"  =\"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      ))\ntable(linelist$hospital, useNA = \"always\")## \n##                     Central Hospital                           Hospital A \n##                                  468                                  290 \n##                           Hospital B                    Military Hospital \n##                                  289                                  910 \n##                                Other                        Port Hospital \n##                                  907                                 1804 \n## St. Mark's Maternity Hospital (SMMH)                                 <NA> \n##                                  428                                 1512"},{"path":"cleaning_data.html","id":"par-logique","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"par logique","text":"Nous démontrons ci-dessous comment recoder les valeurs d’une colonne en utilisant la logique et les conditions :Utiliser replace(), ifelse() et if_else() pour une logique simple.Utilisation de case_when() pour une logique plus complexe.","code":""},{"path":"cleaning_data.html","id":"logique-simple","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Logique simple","text":"","code":""},{"path":"cleaning_data.html","id":"replace","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"replace()","text":"Pour recoder avec des critères logiques simples, vous pouvez utiliser replace() dans mutate(). replace() est une fonction de base R. Utilisez une condition logique pour spécifier les lignes à changer . La syntaxe générale est la suivante :mutate(col_a_change = replace(col_a_changer, condition sur les lignes, nouvelle valeur)).Une situation courante pour utiliser replace() est la modification d’une seule valeur dans une ligne, en utilisant un identifiant propre à une ligne . Ci-dessous, le sexe est changé en “Female” dans la ligne où la colonne case_id est “2195”.La commande équivalente utilisant la syntaxe base R et les crochets d’indexation [ ] est presenté ci-dessous. Elle se lit comme suit : “Changez la valeur de la colonne gender du dataframe linelist (pour les lignes où la colonne case_id de linelist la valeur ‘2195’) en ‘Female’”.","code":"\n# Exemple : Changer en \"Female\" le genre pour une observation definie\nlinelist <- linelist %>% \n  mutate(gender = replace(gender, case_id == \"2195\", \"Female\"))\nlinelist$gender[linelist$case_id == \"2195\"] <- \"Female\""},{"path":"cleaning_data.html","id":"ifelse-et-if_else","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"ifelse() et if_else()","text":"Une autre fonction pour la logique simple est ifelse() et son partenaire if_else(). Cependant, dans la plupart des cas de recodage, il est plus clair d’utiliser case_when() (détaillé ci-dessous). Ces commandes “else” sont des versions simplifiées d’une instruction de programmation et else. La syntaxe générale est la suivante :ifelse(condition, valeur à renvoyer si la condition vaut VRAI, valeur à renvoyer si la condition vaut FAUX).Ci-dessous, la colonne source_known est définie. Sa valeur dans une ligne donnée est définie comme “connue” si la valeur de la colonne source de cette ligne n’est pas manquante. Si la valeur de la colonne source est manquante, alors la valeur de la colonne source_known est définie comme “inconnue”.if_else() est une version spéciale de dplyr qui gère les dates. Notez que si la valeur “true” est une date, la valeur “false” doit aussi être une date, d’où l’utilisation de la valeur spéciale “NA_real_” au lieu de “NA”.Évitez d’enchaîner les commandes ifelse… utilisez plutôt case_when()! case_when() est beaucoup plus facile à lire et vous ferez moins d’erreurs.En dehors du contexte d’un dataframe, si vous voulez qu’un objet utilisé dans votre code change de valeur, pensez à utiliser switch() une fonction base de R.","code":"\nlinelist <- linelist %>% \n  mutate(source_known = ifelse(!is.na(source), \"known\", \"unknown\"))\n# Creer une colonne nommé date of death qui a comme valeur NA si le patient n'est pas mort\nlinelist <- linelist %>% \n  mutate(date_death = if_else(outcome == \"Death\", date_outcome, NA_real_))"},{"path":"cleaning_data.html","id":"clean_case_when","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Logique complexe","text":"Utilisez la fonction case_when() de dplyr si vous effectuez un recodage dans de nombreux nouveaux groupes, ou si vous devez utiliser des instructions logiques complexes pour recoder des valeurs. Cette fonction évalue chaque ligne du cadre de données, détermine si les lignes répondent aux critères spécifiés et attribue la nouvelle valeur correcte.Les commandes case_when() sont des instructions qui ont un côté droit (CD) et un côté gauche (CG) séparés par un “tilde” ~. Les critères logiques se trouvent dans la partie gauche et les valeurs d’application dans la partie droite de chaque instruction. Les déclarations sont séparées par des virgules.Par exemple, ici nous utilisons les colonnes age et age_unit pour créer une colonne age_years :Lorsque chaque ligne des données est évaluée, les critères sont appliqués/évalués dans l’ordre où les instructions case_when() sont écrites - de haut en bas. Si le premier critère est évalué à TRUE pour une ligne donnée, la valeur CD est attribuée, et les autres critères ne sont même pas testés pour cette ligne. Il est donc préférable d’écrire les critères les plus restrictifs en premier, et les plus généraux en dernier. Une ligne de données qui ne répond à aucun des critères de droite se verra attribuer la valeur “NA” (manquante).Parfois, vous pouvez écrire une instruction finale qui attribue une valeur pour tous les autres scénarios non décrits par l’une des lignes précédentes. Pour faire cela, placez TRUE sur le côté gauche, ce qui permettra de capturer toute ligne qui ne répond à aucun des critères précédents. Le côté droit de cette déclaration pourrait se voir attribuer une valeur comme “vérifiez-moi !” ou manquante.Voici un autre exemple de case_when() utilisé pour créer une nouvelle colonne avec la classification du patient, selon une définition de cas pour les cas confirmés et suspectés :DANGER: Les valeurs du côté droit doivent toutes être de la même classe - soit numérique, caractère, date, logique, etc. Pour attribuer des valeurs manquantes (NA), Il est dnas certaine situation important d’utiliser des variantes spéciales de NA telles que NA_character_, NA_real_ (pour les numériques ou POSIX), et .Date(NA). Pour en savoir plus, lisez Manipuler les dates.","code":"\nlinelist <- linelist %>% \n  mutate(age_years = case_when(\n            age_unit == \"years\"  ~ age,       # Si l'age est donné en années\n            age_unit == \"months\" ~ age/12,    # si l'age est donnée en mois, divise par 12\n            is.na(age_unit)      ~ age))      # Si l'unite d'age est une valeur maquante, garde comme années\n                                              # toute valeur non prise en compte par ces conditions seront consideres commme valeur NA (manquante)\nlinelist <- linelist %>% \n     mutate(case_status = case_when(\n          \n          # si le patient a fait un test de laboratoire et le test est positif,\n          # il est marqué comme un cas confirmé \n          ct_blood < 20                   ~ \"Confirmed\",\n          \n          # étant donné qu'un patient n'a pas de résultat de laboratoire positif,\n          # si le patient a une \"source\" (lien épidémiologique) ET a de la fièvre, \n          # alors il est considéré comme un cas suspect\n          !is.na(source) & fever == \"yes\" ~ \"Suspect\",\n          \n          # tout autre patient non traité ci-dessus \n          # est marqué pour un suivi\n          TRUE                            ~ \"To investigate\"))"},{"path":"cleaning_data.html","id":"valeurs-manquantes-1","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Valeurs manquantes","text":"Vous trouverez ci-dessous des fonctions spéciales pour le traitement des valeurs manquantes dans le cadre du nettoyage des données.Voir la page sur les Données manquantes pour des conseils plus détaillés sur l’identification et la gestion des valeurs manquantes. Par exemple, la fonction .na() qui teste logiquement l’absence de données.replace_na()Pour changer les valeurs manquantes (NA) en une valeur spécifique, telle que “Missing”, utilisez la fonction dplyr replace_na() dans mutate(). Notez que cette fonction est utilisée de la même manière que recode ci-dessus - le nom de la variable doit être mentionnée dans replace_na().fct_explicit_na()C’est une fonction du package forcats qui permet de manipuler les colonnes de la classe Factor. Les facteurs constitue la facon dont R gère les valeurs ordonnées telles que c(\"Premier\", \"Deuxieme\", \"Troisieme\") ou pour définir l’ordre dans lequel les valeurs (par exemple les hôpitaux) apparaissent dans les tableaux et les graphiques. Voir la page sur les Facteurs.Si vos données sont de la classe Factor et que vous essayez de convertir NA en “Missing” en utilisant replace_na(), vous obtiendrez cette erreur : invalid factor level, NA generated. Vous avez essayé d’ajouter “Missing” comme valeur, alors qu’il n’était pas défini comme un niveau possible du facteur, et il été rejeté.La façon la plus simple de résoudre ce problème est d’utiliser la fonction fct_explicit_na() du package forcats qui convertit une colonne en classe facteur , et convertit les valeurs NA en caractère “(Missing)”.Une alternative plus lente serait d’ajouter le niveau du facteur en utilisant fct_expand() et ensuite de convertir les valeurs manquantes.na_if()Pour convertir une valeur spécifique en NA, utilisez la fonction na_if() de dplyr. La commande ci-dessous effectue l’opération inverse de replace_na(). Dans l’exemple ci-dessous, toutes les valeurs de “Missing” dans la colonne hospital sont converties en NA.Remarque : na_if() ne peut pas être utilisé pour des critères logiques (par exemple “toutes les valeurs > 99”) - utilisez replace() ou case_when() pour cela :","code":"\nlinelist <- linelist %>% \n  mutate(hospital = replace_na(hospital, \"Missing\"))\nlinelist %>% \n  mutate(hospital = fct_explicit_na(hospital))\nlinelist <- linelist %>% \n  mutate(hospital = na_if(hospital, \"Missing\"))\n# remplacer les temperature superieure à 40 par NA\nlinelist <- linelist %>% \n  mutate(temp = replace(temp, temp > 40, NA))\n\n# Convert onset dates earlier than 1 Jan 2000 to missing\n# Convertir en valeur manquante toutes dates d'appartion  avant le 1 Jan 2000 \nlinelist <- linelist %>% \n  mutate(date_onset = replace(date_onset, date_onset > as.Date(\"2000-01-01\"), NA))"},{"path":"cleaning_data.html","id":"dictionnaire-contenant-les-parametres-de-nettoyage","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Dictionnaire contenant les parametres de nettoyage","text":"Utilisez le package matchmaker et sa fonction match_df() pour nettoyer un dataframe avec un dictionnaire de nettoyage.Créez un dictionnaire de nettoyage avec 3 colonnes :\nUne colonne “” (la valeur incorrecte)\nUne colonne “” (la valeur correcte)\nUne colonne spécifiant la colonne pour laquelle les changements doivent être appliqués (ou “.global” pour appliquer à toutes les colonnes).\nUne colonne “” (la valeur incorrecte)Une colonne “” (la valeur correcte)Une colonne spécifiant la colonne pour laquelle les changements doivent être appliqués (ou “.global” pour appliquer à toutes les colonnes).Remarque : les entrées du dictionnaire .global seront remplacées par les entrées du dictionnaire spécifiques à la colonne.Importez le fichier du dictionnaire dans R. Cet exemple peut être téléchargé via les instructions de la page Télécharger le manuel et les données.Pipez le jeu de donnée brute linelist à match_df(), en spécifiant à dictionary = le dataframe du dictionnaire de nettoyage.L’argument = doit être le nom de la colonne du dictionnaire qui contient les “anciennes” valeurs, l’argument = doit être la colonne du dictionnaire qui contient les “nouvelles” valeurs correspondantes, et la troisième colonne indique la colonne dans laquelle effectuer le changement. Utilisez .global dans la colonne = pour appliquer un changement à toutes les colonnes. Une quatrième colonne de dictionnaire order peut être utilisée pour spécifier l’ordre des facteurs des nouvelles valeurs.\nVous trouverez plus de détails dans la documentation du package en exécutant ?match_df. Notez que l’exécution de cette fonction peut prendre beaucoup de temps pour un grand jeu de données.Maintenant, faites défiler vers la droite pour voir comment les valeurs ont changé - en particulier le genre(de minuscule à majuscule), et toutes les colonnes de symptômes ont été transformées de oui/non à 1/0.Notez que les noms de vos colonnes dans le dictionnaire de nettoyage doivent correspondre aux noms à ce stade dans votre script de nettoyage. Voir cette référence en ligne pour le package linelist pour plus de détails.","code":"\ncleaning_dict <- rio::import(\"cleaning_dict.csv\")\nlinelist <- linelist %>% # fournissez ou pipez votre jeu de données\n     matchmaker::match_df(\n          dictionary = cleaning_dict, # nom de votre dictionnaire\n          from = \"from\", # colonne avec les valeurs à remplacer (par défaut, col 1)\n          to = \"to\", # colonne avec les valeurs finales (par défaut col 2)\n          by = \"col\", # colonne avec les noms de colonnes (par défaut col 3)\n  )"},{"path":"cleaning_data.html","id":"ajouter-à-la-chaine-de-commande-pipé-2","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Ajouter à la chaine de commande pipé","text":"Ci dessous quelques nouveaux colonnes et des transformations operes sur les colonnes existantes sont implementés dans la chaine pipé.","code":"\n# NETTOYAGE: enchainement de commandes  'PIPE'  (debute avec la donnée brute  et le  pipe avec les commandes pour le nettoyage)\n##################################################################################\n\n# Debuter le processus de Nettoyage pipé\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardiser la syntaxe des noms de colonnes\n    janitor::clean_names() %>% \n    \n    # renommer manuellement les noms de colonnes\n           # Nouveau nom             # Ancien nom\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # supprimer colonne\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # supprimer les doublon\n    distinct() %>% \n  \n    # ajouter colonne\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %>%     \n\n    # convertir les classes des colonnes\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %>% \n    \n    # ajout colonnes: Delai de l'apparition de la maladie et  l'hospitalisation\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %>% \n    \n   # CI DESSUS LES ETAPES DU NETTOYAGE DEJA ABORDEES EN AMONT\n   ###################################################\n\n    # Nettoyer les  valeurs de la colonne hospital \n    mutate(hospital = recode(hospital,\n                      # ANCIEN = NOUVEAU\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %>% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %>% \n\n    # creer une colonne  age_years  (à partir des solonnes  age et age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age))"},{"path":"cleaning_data.html","id":"num_cats","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"8.9 Classes numeriques","text":"Nous décrivons ici quelques approches spéciales pour créer des catégories à partir de colonnes numériques. Les exemples les plus courants sont les catégories d’âge, les groupes de valeurs de laboratoire, etc. Nous discuterons ici :age_categories(), du paquet epikit.cut(), du package base Rcase_when()Les ruptures quantiles avec quantile() et ntile().","code":""},{"path":"cleaning_data.html","id":"revoir-la-distribution","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Revoir la distribution","text":"Pour cet exemple, nous allons créer une colonne age_cat en utilisant la colonne age_years.Tout d’abord, examinez la distribution de vos données, afin de définir limites appropriés. Voir la page sur les bases de ggplot.ATTENTION: Parfois, les variables numériques sont importées en tant que classe “character”. Cela se produit s’il y des caractères non numériques dans certaines des valeurs, par exemple une entrée de “2 mois” pour l’âge, ou (en fonction des paramètres par defaut de R) si une virgule est utilisée à la place des décimales (par exemple “4,5” pour signifier quatre ans et demi)..","code":"\n# Verifions la class de la colonne age_years\nclass(linelist$age_years)## [1] \"numeric\"\n# examine the distribution\nhist(linelist$age_years)\nsummary(linelist$age_years, na.rm=T)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n##    0.00    6.00   13.00   16.04   23.00   84.00     107"},{"path":"cleaning_data.html","id":"age_categories","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"age_categories()","text":"Avec le packagge epikit, vous pouvez utiliser la fonction age_categories() pour catégoriser et étiqueter facilement les colonnes numériques (noté que cette fonction peut aussi être appliquée à des variables non numériques d’âge). En guise de bonus, la colonne de sortie est automatiquement une variable categorielle ordonnée.Voici les entrées requises :Un tableau numérique (colonne)L’argument breakers = - fournit un vecteur numérique de points de rupture pour les nouveaux groupes.Tout d’abord, l’exemple le plus simple :Les valeurs de bornes que vous spécifiez sont par défaut les limites inférieures - c’est-à-dire qu’elles sont incluses dans le groupe “supérieur” / les groupes sont “ouverts” du côté inférieur/gauche. Comme indiqué ci-dessous, vous pouvez ajouter 1 à chaque valeur de rupture pour obtenir des groupes ouverts en haut/à droite.Vous pouvez ajuster la façon dont les étiquettes sont affichées avec separator =. La valeur par défaut est “-”.Vous pouvez ajuster la façon dont les numéros supérieurs sont traités, avec l’argument ceiling =. Pour définir une coupure supérieure, mettez ceiling = TRUE. Dans cette utilisation, la valeur de rupture la plus élevée fournie est un “plafond” et une catégorie “XX+” n’est pas créée. Toutes les valeurs supérieures à la valeur de rupture la plus élevée (ou à upper =, s’il est défini) sont classées dans la catégorie NA. Voici un exemple avec ceiling = TRUE, de sorte qu’il n’y pas de catégorie XX+ et que les valeurs supérieures à 70 (la valeur de rupture la plus élevée) sont classées comme NA.Alternativement, au lieu de breakers =, vous pouvez fournir tous les lower =, upper =, et = :lower = Le nombre le plus bas que vous voulez prendre en compte - la valeur par défaut est 0upper = Le nombre le plus élevé que vous voulez considérerby = Le nombre d’années entre les groupesConsultez la page d’aide de la fonction pour plus de détails (entrez ?age_categories dans la console R).","code":"\n# Exemple basique\n################\npacman::p_load(epikit)                    # chargerle  package\n\nlinelist <- linelist %>% \n  mutate(\n    age_cat = age_categories(             # creer un nouveau colonne\n      age_years,                            # colonne numerique pour  concevoir des groupes\n      breakers = c(0, 5, 10, 15, 20,        # les  bornes\n                   30, 40, 50, 60, 70)))\n\n# afficher le tableau\ntable(linelist$age_cat, useNA = \"always\")## \n##   0-4   5-9 10-14 15-19 20-29 30-39 40-49 50-59 60-69   70+  <NA> \n##  1227  1223  1048   827  1216   597   251    78    27     7   107\n# Inclure les bornes superieures pour les memes classes\n############################################\nlinelist <- linelist %>% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      breakers = c(0, 6, 11, 16, 21, 31, 41, 51, 61, 71)))\n\n# afficher le tableau\ntable(linelist$age_cat, useNA = \"always\")## \n##   0-5  6-10 11-15 16-20 21-30 31-40 41-50 51-60 61-70   71+  <NA> \n##  1469  1195  1040   770  1149   547   231    70    24     6   107\n# Avec l'argument ceiling definit comme  TRUE\n##########################\nlinelist <- linelist %>% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      breakers = c(0, 5, 10, 15, 20, 30, 40, 50, 60, 70),\n      ceiling = TRUE)) # 70 is le plafond, toute valeur au dela  devient  NA\n\n# afficher le tableau\ntable(linelist$age_cat, useNA = \"always\")## \n##   0-4   5-9 10-14 15-19 20-29 30-39 40-49 50-59 60-70  <NA> \n##  1227  1223  1048   827  1216   597   251    78    28   113\nlinelist <- linelist %>% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      lower = 0,\n      upper = 100,\n      by = 10))\n\n# afficher tableau\ntable(linelist$age_cat, useNA = \"always\")## \n##   0-9 10-19 20-29 30-39 40-49 50-59 60-69 70-79 80-89 90-99  100+  <NA> \n##  2450  1875  1216   597   251    78    27     6     1     0     0   107"},{"path":"cleaning_data.html","id":"cut","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"cut()","text":"cut() est une alternative à age_categories() présente dans les packages de base de R , vous verrez pourquoi age_categories() été développé pour simplifier ce processus. Quelques différences notoires avec age_categories() sont :Vous n’avez pas besoin d’installer/charger un autre packageVous pouvez spécifier si les groupes sont ouverts/fermés à droite/à gauche.Vous devez fournir vous-même des étiquettes précisesSi vous voulez que 0 soit inclus dans le groupe le plus bas, vous devez le spécifier.La syntaxe de base de cut() est de fournir d’abord la colonne numérique à découper (age_years), puis l’argument breaks, qui est un vecteur numérique c() de points de rupture. En utilisant cut(), la colonne résultante est un facteur ordonné.Par défaut, la catégorisation se produit de sorte que le côté droit/supérieur est “ouvert” et inclusif (et le côté gauche/inférieur est “fermé” ou exclusif). C’est le comportement opposé de la fonction age_categories(). Les étiquettes par défaut utilisent la notation “(, B]”, ce qui signifie que n’est pas inclus mais que B l’est. **Inversez ce comportement en fournissant l’argument right = TRUE.Ainsi, par défaut, les valeurs “0” sont exclues du groupe le plus bas, et catégorisées comme NA ! Les valeurs “0” pourraient être des nourrissons codés comme ayant l’âge 0, alors faites attention ! Pour changer cela, ajoutez l’argument include.lowest = TRUE pour que toutes les valeurs “0” soient incluses dans le groupe le plus bas. L’étiquette générée automatiquement pour la catégorie la plus basse sera alors “[],B]”. Notez que si vous incluez l’argument include.lowest = TRUE et right = TRUE, l’inclusion extrême s’appliquera maintenant à la valeur et à la catégorie du point de rupture haut, et non à la plus basse.Vous pouvez fournir un vecteur d’étiquettes personnalisées en utilisant l’argument labels =. Comme ils sont écrits manuellement, faites très attention à ce qu’ils soient exacts ! Vérifiez votre travail en utilisant des tableaux croisés, comme décrit ci-dessous.Voici un exemple de cut() appliqué à age_years pour créer la nouvelle variable age_cat :**Vérifiez que chaque valeur d’âge été affectée à la bonne catégorie en croisant les colonnes numériques et de catégorie. Examinez l’attribution des valeurs limites (par exemple 15, si les catégories voisines sont 10-15 et 16-20).Réétiquetage des valeurs NA .Vous pouvez vouloir attribuer aux valeurs NA une étiquette telle que “Missing”. Comme la nouvelle colonne est de la classe Factor (valeurs restreintes), vous ne pouvez pas simplement la muter avec replace_na(), car cette valeur sera rejetée. la place, utilisez fct_explicit_na() de forcats comme expliqué dans la page Facteurs.Créer des seuils de rupture et des étiquettesPour une manière rapide de faire des pauses et de labelliser des vecteurs, utilisez quelque chose comme ci-dessous. Voir la page Bases de R pour les références sur seq() et rep().Lisez plus sur cut() dans sa page d’aide en entrant ?cut dans la console R.","code":"\n# Creons une nouvelle variable en decoupant par interval la variable numerique age\n\n#La valeur de la borne inferieure est exclu mais la borne superieu est inclue dans chaque groupe\nlinelist <- linelist %>% \n  mutate(\n    age_cat = cut(\n      age_years,\n      breaks = c(0, 5, 10, 15, 20,\n                 30, 50, 70, 100),\n      include.lowest = TRUE         # inclu le 0 dans le premier interval crée\n      ))\n\n# Representer dans un tableau les nombres d'observations en fonction des categories créee\ntable(linelist$age_cat, useNA = \"always\")## \n##    [0,5]   (5,10]  (10,15]  (15,20]  (20,30]  (30,50]  (50,70] (70,100]     <NA> \n##     1469     1195     1040      770     1149      778       94        6      107\n# Cross tabulation of the numeric and category columns. \n# tableau croisé entre les colonnes numeriques et categorielles\ntable(\"Numeric Values\" = linelist$age_years,   # names specified in table for clarity.\n      \"Categories\"     = linelist$age_cat,\n      useNA = \"always\")                        ##                     Categories\n## Numeric Values       [0,5] (5,10] (10,15] (15,20] (20,30] (30,50] (50,70] (70,100] <NA>\n##   0                    136      0       0       0       0       0       0        0    0\n##   0.0833333333333333     1      0       0       0       0       0       0        0    0\n##   0.25                   2      0       0       0       0       0       0        0    0\n##   0.333333333333333      6      0       0       0       0       0       0        0    0\n##   0.416666666666667      1      0       0       0       0       0       0        0    0\n##   0.5                    6      0       0       0       0       0       0        0    0\n##   0.583333333333333      3      0       0       0       0       0       0        0    0\n##   0.666666666666667      3      0       0       0       0       0       0        0    0\n##   0.75                   3      0       0       0       0       0       0        0    0\n##   0.833333333333333      1      0       0       0       0       0       0        0    0\n##   0.916666666666667      1      0       0       0       0       0       0        0    0\n##   1                    275      0       0       0       0       0       0        0    0\n##   1.5                    2      0       0       0       0       0       0        0    0\n##   2                    308      0       0       0       0       0       0        0    0\n##   3                    246      0       0       0       0       0       0        0    0\n##   4                    233      0       0       0       0       0       0        0    0\n##   5                    242      0       0       0       0       0       0        0    0\n##   6                      0    241       0       0       0       0       0        0    0\n##   7                      0    256       0       0       0       0       0        0    0\n##   8                      0    239       0       0       0       0       0        0    0\n##   9                      0    245       0       0       0       0       0        0    0\n##   10                     0    214       0       0       0       0       0        0    0\n##   11                     0      0     220       0       0       0       0        0    0\n##   12                     0      0     224       0       0       0       0        0    0\n##   13                     0      0     191       0       0       0       0        0    0\n##   14                     0      0     199       0       0       0       0        0    0\n##   15                     0      0     206       0       0       0       0        0    0\n##   16                     0      0       0     186       0       0       0        0    0\n##   17                     0      0       0     164       0       0       0        0    0\n##   18                     0      0       0     141       0       0       0        0    0\n##   19                     0      0       0     130       0       0       0        0    0\n##   20                     0      0       0     149       0       0       0        0    0\n##   21                     0      0       0       0     158       0       0        0    0\n##   22                     0      0       0       0     149       0       0        0    0\n##   23                     0      0       0       0     125       0       0        0    0\n##   24                     0      0       0       0     144       0       0        0    0\n##   25                     0      0       0       0     107       0       0        0    0\n##   26                     0      0       0       0     100       0       0        0    0\n##   27                     0      0       0       0     117       0       0        0    0\n##   28                     0      0       0       0      85       0       0        0    0\n##   29                     0      0       0       0      82       0       0        0    0\n##   30                     0      0       0       0      82       0       0        0    0\n##   31                     0      0       0       0       0      68       0        0    0\n##   32                     0      0       0       0       0      84       0        0    0\n##   33                     0      0       0       0       0      78       0        0    0\n##   34                     0      0       0       0       0      58       0        0    0\n##   35                     0      0       0       0       0      58       0        0    0\n##   36                     0      0       0       0       0      33       0        0    0\n##   37                     0      0       0       0       0      46       0        0    0\n##   38                     0      0       0       0       0      45       0        0    0\n##   39                     0      0       0       0       0      45       0        0    0\n##   40                     0      0       0       0       0      32       0        0    0\n##   41                     0      0       0       0       0      34       0        0    0\n##   42                     0      0       0       0       0      26       0        0    0\n##   43                     0      0       0       0       0      31       0        0    0\n##   44                     0      0       0       0       0      24       0        0    0\n##   45                     0      0       0       0       0      27       0        0    0\n##   46                     0      0       0       0       0      25       0        0    0\n##   47                     0      0       0       0       0      16       0        0    0\n##   48                     0      0       0       0       0      21       0        0    0\n##   49                     0      0       0       0       0      15       0        0    0\n##   50                     0      0       0       0       0      12       0        0    0\n##   51                     0      0       0       0       0       0      13        0    0\n##   52                     0      0       0       0       0       0       7        0    0\n##   53                     0      0       0       0       0       0       4        0    0\n##   54                     0      0       0       0       0       0       6        0    0\n##   55                     0      0       0       0       0       0       9        0    0\n##   56                     0      0       0       0       0       0       7        0    0\n##   57                     0      0       0       0       0       0       9        0    0\n##   58                     0      0       0       0       0       0       6        0    0\n##   59                     0      0       0       0       0       0       5        0    0\n##   60                     0      0       0       0       0       0       4        0    0\n##   61                     0      0       0       0       0       0       2        0    0\n##   62                     0      0       0       0       0       0       1        0    0\n##   63                     0      0       0       0       0       0       5        0    0\n##   64                     0      0       0       0       0       0       1        0    0\n##   65                     0      0       0       0       0       0       5        0    0\n##   66                     0      0       0       0       0       0       3        0    0\n##   67                     0      0       0       0       0       0       2        0    0\n##   68                     0      0       0       0       0       0       1        0    0\n##   69                     0      0       0       0       0       0       3        0    0\n##   70                     0      0       0       0       0       0       1        0    0\n##   72                     0      0       0       0       0       0       0        1    0\n##   73                     0      0       0       0       0       0       0        3    0\n##   76                     0      0       0       0       0       0       0        1    0\n##   84                     0      0       0       0       0       0       0        1    0\n##   <NA>                   0      0       0       0       0       0       0        0  107\n# N'oublier pas d'examiner les valeurs NA\nlinelist <- linelist %>% \n  \n  # cut() creates age_cat, automatically of class Factor      \n     # cut() crée  automatique une colonne dénommée age_cat avec des valeurs categorielles \n  mutate(age_cat = cut(\n    age_years,\n    breaks = c(0, 5, 10, 15, 20, 30, 50, 70, 100),          \n    right = FALSE,\n    include.lowest = TRUE,        \n    labels = c(\"0-4\", \"5-9\", \"10-14\", \"15-19\", \"20-29\", \"30-49\", \"50-69\", \"70-100\")),\n         \n   \n    # nommer explicitemment les valeurs manquantes\n    age_cat = fct_explicit_na(\n      age_cat,\n      na_level = \"Missing age\")  # you can specify the label\n    # on peut specifier les etiquettes\n  )    \n\n# tableau pour voir les effectifs\ntable(linelist$age_cat, useNA = \"always\")## \n##         0-4         5-9       10-14       15-19       20-29       30-49       50-69 \n##        1227        1223        1048         827        1216         848         105 \n##      70-100 Missing age        <NA> \n##           7         107           0\n# Make break points from 0 to 90 by 5\n# Crée un vecteur allant de 0 à 90 avec des pas de 5\nage_seq = seq(from = 0, to = 90, by = 5)\nage_seq\n\n# Make labels for the above categories, assuming default cut() settings\n# Créé des etiquettes pour les categories concues ci dessus avec les parametres de defaut de cut() \nage_labels = paste0(age_seq + 1, \"-\", age_seq + 5)\nage_labels\n\n# check that both vectors are the same length\n# Montrons que que les deux vecteurs sont de meme longueurs\nlength(age_seq) == length(age_labels)"},{"path":"cleaning_data.html","id":"seuil-de-rupture-par-le-quantile","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Seuil de rupture par le Quantile","text":"Dans le langage courant, les “quantiles” ou “percentiles” font généralement référence à une valeur en dessous de laquelle se situe une proportion de valeurs. Par exemple, le 95ème percentile des âges dans linelist serait l’âge en dessous duquel 95% de l’âge tombe.Cependant, dans le langage courant, les “quartiles” et les “déciles” peuvent également faire référence aux groupes de données divisés de manière égale en 4 ou 10 groupes (notez qu’il y aura un point de rupture de plus que le groupe).Pour obtenir les points de rupture des quantiles, vous pouvez utiliser quantile() du paquet stats de base R. Vous fournissez un vecteur numérique (par exemple une colonne dans un ensemble de données) et un vecteur de valeurs numériques de probabilité allant de 0 à 1,0. Les points de rupture sont renvoyés sous la forme d’un vecteur numérique. Explorez les détails des méthodologies statistiques en entrant ?quantile.Si votre tableau numérique d’entrée des valeurs manquantes, il est préférable de définir na.rm = TRUE.Définissez names = FALSE pour obtenir un tableau numérique sans nom.Vous pouvez utiliser les résultats de quantile() comme points de rupture dans age_categories() ou cut(). Ci-dessous, nous créons une nouvelle colonne déciles en utilisant cut() où les ruptures sont définies en utilisant quantiles() sur age_years. Ci-dessous, nous affichons les résultats en utilisant tabyl() de janitor pour que vous puissiez voir les pourcentages (voir la page Tableaux descriptifs). Notez comment ils ne sont pas exactement 10% dans chaque groupe.","code":"\nquantile(linelist$age_years,              #specifier le vecteur numerique sur lequel on travaille\n         \n  probs = c(0, .25, .50, .75, .90, .95),  #specifier les centiles qui vous interesse\n  na.rm = TRUE)                            # ignorer les valeurs manquantes ##  0% 25% 50% 75% 90% 95% \n##   0   6  13  23  33  41\nlinelist %>%                              #commencer avec la donnéé linelist\n  mutate(deciles = cut(age_years,           # creer un nouveau colonne decile qui represente des classes issues de l'application de cut() sur age_years \n    breaks = quantile(                      #definir les seuils  de la fonction cut en utilisant quantile()\n      age_years,                               # utiliser  la colonne age_years\n      probs = seq(0, 1, by = 0.1),             # 0.0 à 1.0 pas de  0.1\n      na.rm = TRUE),                           # ignorer les valeurs manquantes\n    include.lowest = TRUE)) %>%             #Pour cut() inclure age 0\n  janitor::tabyl(deciles)                   # piper pour obtenir un tableau à afficher##  deciles   n    percent valid_percent\n##    [0,2] 748 0.11319613    0.11505922\n##    (2,5] 721 0.10911017    0.11090601\n##    (5,7] 497 0.07521186    0.07644978\n##   (7,10] 698 0.10562954    0.10736810\n##  (10,13] 635 0.09609564    0.09767728\n##  (13,17] 755 0.11425545    0.11613598\n##  (17,21] 578 0.08746973    0.08890940\n##  (21,26] 625 0.09458232    0.09613906\n##  (26,33] 596 0.09019370    0.09167820\n##  (33,84] 648 0.09806295    0.09967697\n##     <NA> 107 0.01619249            NA"},{"path":"cleaning_data.html","id":"groupes-de-taille-égale","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Groupes de taille égale","text":"Un autre outil pour créer des groupes numériques est la fonction dplyr ntile(), qui tente de diviser vos données en n groupes de taille égale - mais sachez que contrairement à quantile(), la même valeur peut apparaître dans plus d’un groupe. Fournissez le tableau numérique et ensuite le nombre de groupes. Les valeurs dans la nouvelle colonne créée sont juste des “numéros” de groupe (par exemple 1 à 10), et non la plage de valeurs elle-même comme lors de l’utilisation de cut().","code":"\n# créer des classes avec ntile()\nntile_data <- linelist %>% \n  mutate(even_groups = ntile(age_years, 10))\n\n# créer un tableau avec les effectifs et les frequences des classes\nntile_table <- ntile_data %>% \n  janitor::tabyl(even_groups)\n  \n\n# ajouter les valeurs min/max pour voir l'etendu des classe\nntile_ranges <- ntile_data %>% \n  group_by(even_groups) %>% \n  summarise(\n    min = min(age_years, na.rm=T),\n    max = max(age_years, na.rm=T)\n  )## Warning: There were 2 warnings in `summarise()`.\n## The first warning was:\n## ℹ In argument: `min = min(age_years, na.rm = T)`.\n## ℹ In group 11: `even_groups = NA`.\n## Caused by warning in `min()`:\n## ! no non-missing arguments to min; returning Inf\n## ℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n# combine and print - note that values are present in multiple groups\n#\nleft_join(ntile_table, ntile_ranges, by = \"even_groups\")##  even_groups   n    percent valid_percent min  max\n##            1 651 0.09851695    0.10013844   0    2\n##            2 650 0.09836562    0.09998462   2    5\n##            3 650 0.09836562    0.09998462   5    7\n##            4 650 0.09836562    0.09998462   7   10\n##            5 650 0.09836562    0.09998462  10   13\n##            6 650 0.09836562    0.09998462  13   17\n##            7 650 0.09836562    0.09998462  17   21\n##            8 650 0.09836562    0.09998462  21   26\n##            9 650 0.09836562    0.09998462  26   33\n##           10 650 0.09836562    0.09998462  33   84\n##           NA 107 0.01619249            NA Inf -Inf"},{"path":"cleaning_data.html","id":"case_when","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"case_when()","text":"Il est possible d’utiliser la fonction dplyr case_when() pour créer des classes à partir d’une colonne numérique, mais il est plus facile d’utiliser age_categories() de epikit ou cut() car ceux-ci créeront un facteur ordonné automatiquement.Si vous utilisez case_when(), veuillez revoir l’utilisation correcte comme décrit précédemment dans la section Re-coder les valeurs de cette page. Sachez également que toutes les valeurs du côté droit doivent être de la même classe. Ainsi, si vous voulez que NA figure à droite, vous devez soit écrire “Missing”, soit utiliser la valeur spéciale NA, NA_character_.","code":""},{"path":"cleaning_data.html","id":"ajouter-à-la-chaine-de-commande-pipé-3","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Ajouter à la chaine de commande pipé","text":"Ci-dessous, le code pour créer deux colonnes d’âge catégorique est ajouté à la chaîne de nettoyage :","code":"\n# NETTOYAGE: enchainement de commandes  'PIPE'  (debute avec la donnée brute  et suivi de  pipe avec les commandes pour le nettoyage)\n##################################################################################\n\n# Debuter le nettoyage de la chaine de commande pipé\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardiser la syntaxe des noms de colonnes\n    janitor::clean_names() %>% \n    \n    # renommons manuellement les noms de colonnes\n           # Nouveau nom             # Ancien nom\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # supprimer colonne\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # supplimer les doublons\n    distinct() %>% \n\n    # ajouter colonnes\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %>%     \n\n    # convertir la classe des colonnes\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %>% \n    \n    # creer colonne: retard d'hospitalisation\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %>% \n    \n    # rendre propre les valeurs contenu dans la colonne hospitalisation\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %>% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %>% \n\n    # creons la colonne age_years column (à partir des colonnes age et age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age)) %>% \n  \n    # CI DESSUS LES ETAPES DU NETTOYAGE DEJA ABORDEES EN AMONT\n    ###################################################   \n    mutate(\n          # age classe: difinition\n          age_cat = epikit::age_categories(age_years, breakers = c(0, 5, 10, 15, 20, 30, 50, 70)),\n        \n          # age classe: 0 à 85 par pas de 5s\n          age_cat5 = epikit::age_categories(age_years, breakers = seq(0, 85, 5)))"},{"path":"cleaning_data.html","id":"ajouter-des-lignes","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"8.10 Ajouter des lignes","text":"","code":""},{"path":"cleaning_data.html","id":"une-à-une","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"une à une","text":"Ajouter des lignes une par une manuellement est fastidieux mais peut être fait avec add_row() de dplyr. Rappelez-vous que chaque colonne doit contenir des valeurs d’une seule classe (soit caractère, numérique, logique, etc.). Ainsi, l’ajout d’une ligne nécessite de la nuance pour maintenir cela.Utilisez .et .. pour spécifier le placement de la ligne que vous voulez ajouter. .= 3 placera la nouvelle ligne avant la 3ème ligne actuelle. Le comportement par défaut est d’ajouter la ligne à la fin. Les colonnes non spécifiées seront laissées vides (NA).Le nouveau numéro de ligne peut sembler étrange (“…23”) mais les numéros de ligne dans les lignes préexistantes ont changé. Donc, si vous utilisez la commande deux fois, examinez/testez soigneusement l’insertion.Si une classe que vous avez fournie est incorrecte, vous verrez une erreur comme celle-ci :(lorsque vous insérez une ligne avec une valeur de date, n’oubliez pas d’envelopper la date dans la fonction .Date() comme .Date(\"2020-10-10\").","code":"\nlinelist <- linelist %>% \n  add_row(row_num = 666,\n          case_id = \"abc\",\n          generation = 4,\n          `infection date` = as.Date(\"2020-10-10\"),\n          .before = 2)Error: Can't combine ..1$infection date <date> and ..2$infection date <character>."},{"path":"cleaning_data.html","id":"coller-des-lignes","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"coller des lignes","text":"Pour combiner des ensembles de données ensemble en liant les lignes d’un cadre de données au bas d’un autre cadre de données, vous pouvez utiliser bind_rows() de dplyr. Ceci est expliqué plus en détail dans la page Joindre des données.","code":""},{"path":"cleaning_data.html","id":"filtrer-les-lignes","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"8.11 Filtrer les lignes","text":"Une étape typique de nettoyage après avoir nettoyé les colonnes et recodé les valeurs est de filtrer le cadre de données pour des lignes spécifiques en utilisant le verbe dplyr filter().Dans filter(), spécifiez la logique qui doit être TRUE pour qu’une ligne de l’ensemble de données soit conservée. Nous montrons ci-dessous comment filtrer des lignes sur la base de conditions logiques simples et complexes.","code":""},{"path":"cleaning_data.html","id":"filtre-simple","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Filtre simple","text":"Cet exemple simple redéfinit le dataframe linelist comme lui-même, après avoir filtré les lignes pour répondre à une condition logique. **Seules les lignes où l’énoncé logique entre parenthèses est évalué à “VRAI” sont conservées.Dans cet exemple, l’instruction logique est gender == \"f\", qui demande si la valeur de la colonne gender est égale à “f” (sensible à la casse).Avant que le filtre ne soit appliqué, le nombre de lignes dans linelist est nrow(linelist).Une fois le filtre appliqué, le nombre de lignes dans linelist est linelist %>% filter(gender == \"f\") %>% nrow().","code":"\nlinelist <- linelist %>% \n  filter(gender == \"f\")   # garder unique les lignes ou le est egale à \"f\""},{"path":"cleaning_data.html","id":"filtrer-les-valeurs-manquantes","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Filtrer les valeurs manquantes","text":"Il est assez courant de vouloir filtrer les lignes qui ont des valeurs manquantes. Résistez à l’envie d’écrire filter(!.na(column) & !.na(column)) et utilisez plutôt la fonction tidyr qui est spécialement conçue à cet effet : drop_na(). Si elle est exécutée avec des parenthèses vides, elle supprime les lignes avec toutes les valeurs manquantes. Alternativement, vous pouvez fournir des noms de colonnes spécifiques à évaluer pour les valeurs manquantes, ou utiliser les fonctions d’aide “tidyselect” décrites ci-dessus.Voir la page sur les Données manquantes pour de nombreuses techniques d’analyse et de gestion des données manquantes dans vos données.","code":"\nlinelist %>% \n  drop_na(case_id, age_years)  # enlever les lignes avec des valeurs manquantes pour les colonnes case_id ou age_years"},{"path":"cleaning_data.html","id":"filtrer-par-numéro-de-ligne","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Filtrer par numéro de ligne","text":"Dans un cadre de données ou un tibble, chaque ligne aura généralement un “numéro de ligne” qui (vu dans R Viewer) apparaît à gauche de la première colonne. Ce n’est pas en soi une vraie colonne dans les données, mais il peut être utilisé dans une instruction filter().Pour filtrer sur la base du “numéro de ligne”, vous pouvez utiliser la fonction dplyr row_number() avec des parenthèses ouvertes dans le cadre d’une instruction de filtrage logique. Souvent, vous utiliserez l’opérateur %% et une plage de nombres dans le cadre de cette instruction logique, comme indiqué ci-dessous. Pour voir les premières N lignes, vous pouvez également utiliser la fonction spéciale dplyr head().Vous pouvez également convertir les numéros de ligne en une vraie colonne en passant votre cadre de données à la fonction tibble rownames_to_column() (ne mettez rien entre les parenthèses).","code":"\n# montrer les 100 premiere lignes\nlinelist %>% head(100)     # ou utiliser tail() pour voir les n derniers lignes \n\n# afficher uniquement la cinquieme ligne\nlinelist %>% filter(row_number() == 5)\n\n# voir la 2ème à la 20ème ligne et 3 colonnes specifiques\nlinelist %>% filter(row_number() %in% 2:20) %>% select(date_onset, outcome, age)"},{"path":"cleaning_data.html","id":"filtre-complexe","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Filtre complexe","text":"Des instructions logiques plus complexes peuvent être construites en utilisant les opérateurs parenthèses ( ), |, négation !, %%, et &. Un exemple est donné ci-dessous :Remarque : Vous pouvez utiliser l’opérateur ! devant un critère logique pour le nier. Par exemple, !.na(column) est évalué à true si la valeur de la colonne n’est pas manquante. De même, !column %% c(\"\", \"b\", \"c\") est évalué comme vrai si la valeur de la colonne n’est pas dans le vecteur.","code":""},{"path":"cleaning_data.html","id":"examiner-la-donnée","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Examiner la donnée","text":"Vous trouverez ci-dessous une commande simple en une ligne pour créer un histogramme des dates d’apparition. Notez qu’une deuxième épidémie plus petite, datant de 2012-2013, est également incluse dans cet ensemble de données brutes. **Pour nos analyses, nous voulons supprimer les entrées de cette épidémie antérieure.","code":"\nhist(linelist$date_onset, breaks = 50)"},{"path":"cleaning_data.html","id":"comment-les-filtres-traitent-les-valeurs-numériques-et-les-dates-manquantes","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Comment les filtres traitent les valeurs numériques et les dates manquantes","text":"Peut-simplement filtrer par date_onset les lignes après Juin 2013 ? Attention ! L’application du code filter(date_onset > .Date(\"2013-06-01\"))) supprimerait toutes les lignes de la dernière épidémie avec une date d’apparition manquante!.DANGERS: Le fait de filtrer sur une date ou un nombre supérieur (>) ou inférieur (<) peut supprimer toutes les lignes contenant des valeurs manquantes (NA) ! En effet, NA est considéré comme infiniment grand et petit.(Voir la page Manipuler les dates pour plus d’informations sur le travail avec des dates et le paquet lubridate).","code":""},{"path":"cleaning_data.html","id":"concevoir-le-filtre","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Concevoir le filtre","text":"Examinez un tableau croisé pour vous assurer que nous excluons uniquement les bonnes lignes :Quels autres critères pouvons-nous filtrer pour éliminer la première épidémie (en 2012 et 2013) de l’ensemble de données ? Nous constatons que :La première épidémie en 2012 & 2013 eu lieu à l’hôpital , à l’hôpital B, et qu’il y avait aussi 10 cas à l’hôpital du Port.Les hôpitaux et B n’ont pas eu de cas lors de la deuxième épidémie, mais l’hôpital du Port en eu.Nous voulons exclure :Les nrow(linelist %>% filter(hospital %% c(\"Hospital \", \"Hospital B\") | date_onset < .Date(\"2013-06-01\"))) lignes avec une apparition en 2012 et 2013 à l’hôpital , B ou Port :\nExclure nrow(linelist %>% filter(date_onset < .Date(\"2013-06-01\"))) les lignes dont l’apparition s’est produite en 2012 et 2013.\nExclure nrow(linelist %>% filter(hospital %% c('Hospital ', 'Hospital B') & .na(date_onset))) les lignes des hôpitaux et B avec des dates de début manquantes.\nNe pas exclure nrow(linelist %>% filter(!hospital %% c('Hospital ', 'Hospital B') & .na(date_onset))) d’autres lignes avec des dates de début manquantes.\nExclure nrow(linelist %>% filter(date_onset < .Date(\"2013-06-01\"))) les lignes dont l’apparition s’est produite en 2012 et 2013.Exclure nrow(linelist %>% filter(hospital %% c('Hospital ', 'Hospital B') & .na(date_onset))) les lignes des hôpitaux et B avec des dates de début manquantes.Ne pas exclure nrow(linelist %>% filter(!hospital %% c('Hospital ', 'Hospital B') & .na(date_onset))) d’autres lignes avec des dates de début manquantes.Nous commençons avec une linelist de `nrow(linelist). Voici notre déclaration de filtre :Lorsque nous refaisons le tableau croisé, nous constatons que les hôpitaux et B sont complètement retirés, ainsi que les 10 cas de l’hôpital du Port de 2012 et 2013, et que toutes les autres valeurs sont les mêmes - exactement comme nous le voulions.Plusieurs déclarations peuvent être incluses dans une commande de filtre (séparées par des virgules), ou vous pouvez toujours utiliser une commande filter() séparée pour plus de clarté.Note : certains lecteurs peuvent remarquer qu’il serait plus facile de filtrer simplement par date_hospitalisation parce qu’il est 100% complet, sans valeurs manquantes. Ceci est vrai. Mais date_onset est utilisé dans le de démontrer un filtre complexe.","code":"\ntable(Hospital  = linelist$hospital,                     # nom d'hopital\n      YearOnset = lubridate::year(linelist$date_onset),  # annee des dates d'apparition \n      useNA     = \"always\")                              # montrer les valeurs manquantes##                                       YearOnset\n## Hospital                               2012 2013 2014 2015 <NA>\n##   Central Hospital                        0    0  351   99   18\n##   Hospital A                            229   46    0    0   15\n##   Hospital B                            227   47    0    0   15\n##   Military Hospital                       0    0  676  200   34\n##   Missing                                 0    0 1117  318   77\n##   Other                                   0    0  684  177   46\n##   Port Hospital                           9    1 1372  347   75\n##   St. Mark's Maternity Hospital (SMMH)    0    0  322   93   13\n##   <NA>                                    0    0    0    0    0\nlinelist <- linelist %>% \n  \n # conserver les lignes où le début de la maladie est postérieur 1 June 2013 OU où le début de la maladie n'a pas de valeur renseignée et où il s'agissait d'un hôpital AUTRE que l'hôpital A ou B.\n  filter(date_onset > as.Date(\"2013-06-01\") | (is.na(date_onset) & !hospital %in% c(\"Hospital A\", \"Hospital B\")))\n\nnrow(linelist)## [1] 6019\ntable(Hospital  = linelist$hospital,                     # nom de l'hopital\n      YearOnset = lubridate::year(linelist$date_onset),   # année d'apparition de la maladie\n      useNA     = \"always\")                              # montrer les valeurs manquantes##                                       YearOnset\n## Hospital                               2014 2015 <NA>\n##   Central Hospital                      351   99   18\n##   Military Hospital                     676  200   34\n##   Missing                              1117  318   77\n##   Other                                 684  177   46\n##   Port Hospital                        1372  347   75\n##   St. Mark's Maternity Hospital (SMMH)  322   93   13\n##   <NA>                                    0    0    0"},{"path":"cleaning_data.html","id":"autres-complements","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Autres complements","text":"Le filtrage peut également être effectué comme une commande autonome (ne faisant pas partie d’une chaîne de tuyaux). Comme les autres verbes dplyr, dans ce cas, le premier argument doit être le jeu de données lui-même.Vous pouvez également utiliser base R pour effectuer un sous-ensemble en utilisant des crochets qui reflètent les [lignes, colonnes] que vous souhaitez conserver.","code":"\n# dataframe <- filter(dataframe, condition(s)pour les lignes à garder)\n\nlinelist <- filter(linelist, !is.na(case_id))\n# dataframe <- dataframe[lignes conditions, colonnes conditions] (vide signifie garder tous les colonnes ou lignes)\n\nlinelist <- linelist[!is.na(case_id), ]"},{"path":"cleaning_data.html","id":"examiner-rapidement-la-donnée","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Examiner rapidement la donnée","text":"Souvent, vous voulez examiner rapidement quelques enregistrements, pour seulement quelques colonnes. La fonction R base View() imprimera un cadre de données pour le visualiser dans votre RStudio.Visualisez la liste des lignes dans RStudio :Voici deux exemples d’affichage de cellules spécifiques (lignes spécifiques et colonnes spécifiques) :Avec les fonctions dplyr filter() et select():Dans View(), passez le jeu de données dans filter() pour conserver certaines lignes, puis dans select() pour conserver certaines colonnes. Par exemple, pour examiner les dates de début et d’hospitalisation de 3 cas spécifiques :Vous pouvez faire la même chose avec la syntaxe base de R, en utilisant les crochets `[ ]`` pour le sous-ensemble que vous voulez voir.","code":"\nView(linelist)\nView(linelist %>%\n       filter(case_id %in% c(\"11f8ea\", \"76b97a\", \"47a5f5\")) %>%\n       select(date_onset, date_hospitalisation))\nView(linelist[linelist$case_id %in% c(\"11f8ea\", \"76b97a\", \"47a5f5\"), c(\"date_onset\", \"date_hospitalisation\")])"},{"path":"cleaning_data.html","id":"ajouter-à-la-chaine-de-commande-pipé-to-pipé","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"Ajouter à la chaine de commande pipé to pipé","text":"","code":"\n# NETTOYAGE: enchainement de commandes  'PIPE'  (debute avec la donnée brute  et le  pipes avec les commandes pour le nettoyage)\n##################################################################################\n\n# Debuter la chaine de commande pipé pour le nettoyage \n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardiser la syntaxe des noms de colonnes\n    janitor::clean_names() %>% \n    \n    # manuallement renommer le noms des colonnes\n           # Nouveau nom             # Ancienne nom\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # supprimer les colonnes\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # supprimer les doublons\n    distinct() %>% \n\n    # ajouter colonne\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %>%     \n\n    # convertir la classe des colonnes\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %>% \n    \n    # ajout de colonne: retard d'hospitalisation\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %>% \n    \n    # Nettoyer les valeurs de la colonne hospitalisation\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %>% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %>% \n\n    # creer la colonne age_years (à partir de age et age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age)) %>% \n  \n    mutate(\n          # age classe: definition\n          age_cat = epikit::age_categories(age_years, breakers = c(0, 5, 10, 15, 20, 30, 50, 70)),\n        \n          # age classes: 0 à 85 par pas de 5s\n          age_cat5 = epikit::age_categories(age_years, breakers = seq(0, 85, 5))) %>% \n    \n     # CI DESSUS LES ETAPES DU NETTOYAGE DEJA ABORDEES EN AMONT\n    ###################################################\n    filter(\n          # conserver uniquement les lignes ou les valeurs  case_id ne sont pas  manquantes\n          !is.na(case_id),  \n          \n          # egalement filtrons pour garder uniquement la deuxieme pandemie\n          date_onset > as.Date(\"2013-06-01\") | (is.na(date_onset) & !hospital %in% c(\"Hospital A\", \"Hospital B\")))"},{"path":"cleaning_data.html","id":"calculs-par-rangée","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"8.12 Calculs par rangée","text":"Si vous voulez effectuer un calcul dans une ligne, vous pouvez utiliser rowwise() de dplyr. Voir cette vignette en ligne sur calculs par ligne.\nPar exemple, ce code applique rowwise() et crée une nouvelle colonne qui additionne le nombre de colonnes de symptômes spécifiées qui ont la valeur “yes”, pour chaque ligne de la linelist. Les colonnes sont spécifiées dans sum() par leur nom dans un vecteur c(). rowwise() est essentiellement un type spécial de group_by(), il est donc préférable d’utiliser ungroup() lorsque vous avez terminé (page sur Travailler sur des données groupées).Lorsque vous spécifiez la colonne à évaluer, vous pouvez utiliser les fonctions d’aide “tidyselect” décrites dans la section select() de cette page. Vous devez juste faire un ajustement (parce que vous ne les utilisez pas dans une fonction dplyr comme select() ou summarise()).Placez les critères de spécification des colonnes dans la fonction dplyr c_across(). Ceci marche parce que c_across ( documentation) est conçue pour fonctionner avec rowwise() spécifiquement. Par exemple, le code suivant :Applique rowwise() pour que l’opération suivante (sum()) soit appliquée à chaque ligne (sans additionner des colonnes entières)Crée la nouvelle colonne num_NA_dates, définie pour chaque ligne comme le nombre de colonnes (dont le nom contient “date”) pour lesquelles .na() donné la valeur TRUE (ce sont des données manquantes).ungroup() pour supprimer les effets de rowwise() pour les étapes suivantes.Vous pouvez également fournir d’autres fonctions, telles que max() pour obtenir la dernière ou la plus récente date pour chaque ligne :","code":"\nlinelist %>%\n  rowwise() %>%\n  mutate(num_symptoms = sum(c(fever, chills, cough, aches, vomit) == \"yes\")) %>% \n  ungroup() %>% \n  select(fever, chills, cough, aches, vomit, num_symptoms) # pour affichage## # A tibble: 5,888 × 6\n##    fever chills cough aches vomit num_symptoms\n##    <chr> <chr>  <chr> <chr> <chr>        <int>\n##  1 no    no     yes   no    yes              2\n##  2 <NA>  <NA>   <NA>  <NA>  <NA>            NA\n##  3 <NA>  <NA>   <NA>  <NA>  <NA>            NA\n##  4 no    no     no    no    no               0\n##  5 no    no     yes   no    yes              2\n##  6 no    no     yes   no    yes              2\n##  7 <NA>  <NA>   <NA>  <NA>  <NA>            NA\n##  8 no    no     yes   no    yes              2\n##  9 no    no     yes   no    yes              2\n## 10 no    no     yes   no    no               1\n## # ℹ 5,878 more rows\nlinelist %>%\n  rowwise() %>%\n  mutate(num_NA_dates = sum(is.na(c_across(contains(\"date\"))))) %>% \n  ungroup() %>% \n  select(num_NA_dates, contains(\"date\")) # pour affichage## # A tibble: 5,888 × 5\n##    num_NA_dates date_infection date_onset date_hospitalisation date_outcome\n##           <int> <date>         <date>     <date>               <date>      \n##  1            1 2014-05-08     2014-05-13 2014-05-15           NA          \n##  2            1 NA             2014-05-13 2014-05-14           2014-05-18  \n##  3            1 NA             2014-05-16 2014-05-18           2014-05-30  \n##  4            1 2014-05-04     2014-05-18 2014-05-20           NA          \n##  5            0 2014-05-18     2014-05-21 2014-05-22           2014-05-29  \n##  6            0 2014-05-03     2014-05-22 2014-05-23           2014-05-24  \n##  7            0 2014-05-22     2014-05-27 2014-05-29           2014-06-01  \n##  8            0 2014-05-28     2014-06-02 2014-06-03           2014-06-07  \n##  9            1 NA             2014-06-05 2014-06-06           2014-06-18  \n## 10            1 NA             2014-06-05 2014-06-07           2014-06-09  \n## # ℹ 5,878 more rows\nlinelist %>%\n  rowwise() %>%\n  mutate(latest_date = max(c_across(contains(\"date\")), na.rm=T)) %>% \n  ungroup() %>% \n  select(latest_date, contains(\"date\"))  # pour affichage ## # A tibble: 5,888 × 5\n##    latest_date date_infection date_onset date_hospitalisation date_outcome\n##    <date>      <date>         <date>     <date>               <date>      \n##  1 2014-05-15  2014-05-08     2014-05-13 2014-05-15           NA          \n##  2 2014-05-18  NA             2014-05-13 2014-05-14           2014-05-18  \n##  3 2014-05-30  NA             2014-05-16 2014-05-18           2014-05-30  \n##  4 2014-05-20  2014-05-04     2014-05-18 2014-05-20           NA          \n##  5 2014-05-29  2014-05-18     2014-05-21 2014-05-22           2014-05-29  \n##  6 2014-05-24  2014-05-03     2014-05-22 2014-05-23           2014-05-24  \n##  7 2014-06-01  2014-05-22     2014-05-27 2014-05-29           2014-06-01  \n##  8 2014-06-07  2014-05-28     2014-06-02 2014-06-03           2014-06-07  \n##  9 2014-06-18  NA             2014-06-05 2014-06-06           2014-06-18  \n## 10 2014-06-09  NA             2014-06-05 2014-06-07           2014-06-09  \n## # ℹ 5,878 more rows"},{"path":"cleaning_data.html","id":"arranger-et-trier","chapter":"8 Nettoyage de données et fonctions essentielles","heading":"8.13 Arranger et trier","text":"Utilisez la fonction dplyr arrange() pour trier ou ordonner les lignes par les valeurs des colonnes.Listez simplement les colonnes dans l’ordre où elles doivent être triées. Spécifiez .by_group = TRUE si vous voulez que le tri se fasse d’abord par tout groupement appliqué aux données (voir la page sur Travailler sur des données groupées).Par défaut, les colonnes seront triées dans l’ordre “ascendant” (ce qui s’applique aux colonnes numériques et aussi aux colonnes de caractères). Vous pouvez trier une variable dans l’ordre “descendant” en l’entourant de desc().Le tri des données avec arrange() est particulièrement utile lorsque vous créez des Tableaux de présentation, lorsque vous utilisez slice() pour prendre les lignes “supérieures” par groupe, ou lorsque vous définissez l’ordre des niveaux de facteurs par ordre d’apparition.Par exemple, pour trier les lignes de notre linelist par hospital, puis par date_onset en ordre décroissant, nous utiliserons :","code":"\nlinelist %>% \n   arrange(hospital, desc(date_onset))"},{"path":"working_dates.html","id":"working_dates","chapter":"9 Manipuler les dates","heading":"9 Manipuler les dates","text":"Travailler avec des dates dans R demande plus d’attention que de travailler avec d’autres classes d’objets. Nous vous proposons ci-dessous quelques outils et exemples pour rendre ce processus moins pénible. Heureusement, les dates peuvent étre facilement manipulées avec de la pratique et avec un ensemble de paquets utiles tels que lubridate.Lors de l’importation de données brutes, R interpréte souvent les dates comme des objets de type caractère, ce qui signifie qu’elles ne peuvent pas être utilisêes pour des opérations générales sur les dates, comme la création de séries chronologiques et le calcul des intervalles de temps. Pour compliquer encore les choses, il existe de nombreuses façons de formater une date et vous devez aider R à savoir quelle partie d’une date représente quoi (mois, jour, heure, etc.).Les dates dans R sont leur propre classe d’objet - la classe Date. Il est à noter qu’il existe également une classe qui stocke les objets de date et d’heure. Les objets date-heure sont formellement appelés classes POSIXt, POSIXct, et/ou POSIXlt (la différence n’est pas importante). Ces objets sont appelés de maniére informelle des classes datetime.Il est important de s’assurer que R reconnaît lorsqu’une colonne contient des dates.Les dates sont une classe d’objet et peut être difficile de travailler avec.Nous présentons ici plusieurs façons de convertir les colonnes de dates en classe Date.","code":""},{"path":"working_dates.html","id":"étapes-préliminaires","chapter":"9 Manipuler les dates","heading":"9.1 étapes préliminaires","text":"","code":""},{"path":"working_dates.html","id":"importation-des-paquets","chapter":"9 Manipuler les dates","heading":"Importation des paquets","text":"Ces lignes de code chargent les paquets nécessaires aux analyses. Dans ce guide, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire puis l’importe pour l’utiliser. Vous pouvez également charger les paquets installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les paquets R.","code":"\n# Vérifie si le paquet est installé, l'installe si nécessaire, et charge le paquet pour la session en cours.\n\npacman::p_load(\n  lubridate,  # paquet général pour la manipulation et la conversion des dates \n  parsedate,   # a une fonction pour \"deviner\" les dates désordonnées\n  aweek,      # une autre option pour convertir les dates en semaines, et les semaines en dates\n  zoo,        # fonctions supplémentaires de date et d'heure\n  tidyverse,  # gestion et visualisation des données  \n  rio)        # import des fichiers"},{"path":"working_dates.html","id":"importation-des-données","chapter":"9 Manipuler les dates","heading":"Importation des données","text":"Nous importons le jeu de données des cas d’une épidémie d’Ebola simulée. Si vous souhaitez télécharger les données pour suivre le processus étape par étape, consultez les instructions de la page télécharger le manuel et les données. Pour ce script, nous supposons que le fichier se trouve dans le répertoire de travail de la session R. Aucun sous-dossier n’est donc spécifié dans ce chemin de fichier.","code":"\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"working_dates.html","id":"date-actuelle","chapter":"9 Manipuler les dates","heading":"9.2 Date actuelle","text":"Vous pouvez obtenir la date ou l’heure “système” actuelle de votre ordinateur en effectuant les opérations suivantes avec base R.Avec le paquet lubridate, la date et l’heure du système peuvent aussi être retournées avec today() et now(), respectivement. date() renvoie la date et l’heure actuelles avec les noms des jours de la semaine et du mois.","code":"\n# obtenir la date du système - il s'agit d'une classe DATE\nSys.Date()## [1] \"2023-05-21\"\n# obtenir l'heure du système - il s'agit d'une classe DATETIME\nSys.time()## [1] \"2023-05-21 16:49:10 CEST\""},{"path":"working_dates.html","id":"convertir-en-date","chapter":"9 Manipuler les dates","heading":"9.3 Convertir en Date","text":"Après avoir importé un ensemble de données dans R, les valeurs des colonnes de date peuvent ressembler à “1989/12/30”, “05/06/2014” ou “13 Jan 2020”. Dans ces cas, R traite probablement encore ces valeurs comme des valeurs de caractères. Il faut dire à R que ces valeurs sont des dates… et quel est le format de la date (quelle partie est le jour, le mois, l’année, etc.).Une fois informé, R convertit ces valeurs en classe Date. En arriére-plan de l’interface, R stockera les dates sous forme de nombres (le nombre de jours depuis sa date “d’origine”, le 1er janvier 1970). Vous n’utiliserez pas souvent le nombre de dates, mais cela permet à R de traiter les dates comme des variables continues. Cela permet également à R d’autoriser des opérations spéciales pour les objets Date, comme le calcul de la distance entre les dates.Par défaut, les valeurs de la classe Date dans R sont affichées sous la forme YYYY-MM-DD. Plus tard dans cette section, nous verrons comment modifier l’affichage des valeurs de date.Nous présentons ci-dessous deux approches pour convertir une colonne de valeurs de caractères en classe Date.**__CONSEIL:_** Vous pouvez vérifier la classe actuelle d’une colonne avec la fonction R base class(), comme class(linelist$date_onset).","code":""},{"path":"working_dates.html","id":"base-r","chapter":"9 Manipuler les dates","heading":"base R","text":".Date() est la fonction standard de base R pour convertir un objet ou une colonne en classe Date (notez la majuscule de “D”).L’utilisation de .Date() nécessite que :Vous spécifiez le format existant de la date brute en caractères ou la date d’origine si vous fournissez des dates en forme de nombres (voir la section sur les dates Excel).Si vous l’utilisez sur une colonne de caractères, toutes les valeurs de date doivent avoir le même format exact (si ce n’est pas le cas, essayez parse_date() du paquet parsedate)Processus d’utilisation de .Date() :Premiérement, vérifiez la classe de votre colonne avec class() de base R. Si vous n’étiez pas sûr de la classe ou sommes confus au sujet de la classe de vos données (par exemple, vous voyez “POSIXct”, etc.), il peut être plus facile de convertir d’abord la colonne en classe Character avec .character(), et ensuite de la convertir en classe Date.Deuxiémement, dans la fonction .Date(), utilisez l’argument format = pour indiquer à R le format actuel de la chaîne de caractères de la date - quels caractères font référence au mois, au jour et à l’année, et comment ils sont séparés. Si vos valeurs sont déjà dans un des formats de date standard de R (“YYYY-MM-DD” ou “YYYY/MM/DD”) l’argument format = n’est pas nécessaire.Pour format =, fournissez une chaîne de caractères (entre guillemets) qui représente le format de date actuel en utilisant les abréviations spéciales “strptime” ci-dessous. Par exemple, si les dates de vos caractères sont actuellement au format “DD/MM/YYYY”, comme “24/04/1968”, vous utiliserez format = \"%d/%m/%Y\" pour convertir les valeurs en dates. Il est nécessaire de mettre le format entre guillemets. Et n’oubliez pas les barres obliques ou les tirets!La plupart des abréviations de strptime sont listées ci-dessous. Vous pouvez voir la liste compléte en exécutant ?strptime.%d = numéro du jour du mois (5, 17, 28, etc.)\n%j = numéro du jour de l’année (Jour 001-366)\n%= Jour de la semaine abrégé (Lun, Mar, Mer, etc.)\n%= Jour de la semaine (Lundi, Mardi, etc.)\n%w = numéro du jour de la semaine (0-6, le dimanche est 0)\n%u = numéro du jour de la semaine (1-7, le lundi est 1)\n%W = numéro de semaine(00-53, le lundi est le début de la semaine)\n%U = numéro de semaine (01-53, le dimanche est le début de la semaine)\n%m = numéro du mois (e.g. 01, 02, 03, 04)\n%b = Mois abrégé (jan, févr, etc.)\n%B = Mois complet (janvier, février, etc.)\n%y = année à 2 chiffres (par example 89)\n%Y = année à 4 chiffres (par example 1989)\n%h = heures (horloge de 24 heures)\n%m = minutes\n%s = secondes\n%z = décalage par rapport à GMT\n%Z = Fuseau horaire (caractère)CONSEIL: L’argument format = de la fonction .Date() n’indique pas à R le format que vous voulez donner aux dates, mais plutôt comment identifier les parties de la date telles qu’elles sont avant que vous lanciez la commande.CONSEIL: Assurez-vous que dans l’argument format = vous utilisez le séparateur de partie de date (par exemple /, -, ou espace) qui est présent dans vos dates.Une fois que les valeurs sont dans la classe Date, R les affichera par défaut dans le format standard, qui est AAAA-MM-JJ.","code":"\n# Convertir en classe de date\nlinelist <- linelist %>% \n  mutate(date_onset = as.Date(date_of_onset, format = \"%d/%m/%Y\"))"},{"path":"working_dates.html","id":"lubridate","chapter":"9 Manipuler les dates","heading":"lubridate","text":"La conversion d’objets caractères en dates peut être plus facile en utilisant le paquet lubridate. lubridate est un paquet tidyverse créé pour rendre le travail avec les dates et les heures plus simple et plus cohérent que dans base R. Pour ces raisons, lubridate est souvent considéré comme le paquet de référence pour les dates et les heures, et il est recommandé de travailler avec des variables de date ou d’heure.Le paquet lubridate fournit plusieurs fonctions d’aide différentes créées pour convertir les objets caractères en dates de maniére intuitive, et plus facile que de spécifier le format dans .Date(). Ces fonctions sont spécifiques au format de date brut, mais permettent une variété de séparateurs et de synonymes pour les dates (par exemple 01 vs Jan vs Janvier) - les synonymes sont nommés d’après les abréviations des formats de date.La fonction ymd() convertit de maniére flexible les valeurs de date fournies sous la forme année, mois, jour. Cette fonction fonctionne avec n’importe quel séparateur utilisé dans les variables.La fonction mdy() convertit de maniére flexible les valeurs de date fournies sous la forme mois, jour, année.La fonction dmy() convertit de maniére flexible les valeurs de date fournies sous la forme jour, mois, année.Si vous utilisez le piping, la conversion d’une colonne de caractères en dates avec lubridate pourrait ressembler à ceci :Une fois terminé, vous pouvez exécuter class() pour vérifier la classe de la colonneUne fois que les valeurs sont dans la classe Date, R les affichera par défaut dans le format standard, qui est AAAA-MM-JJ.Notez que les fonctions ci-dessus fonctionnent mieux avec des années à 4 chiffres. Les années à 2 chiffres peuvent produire des résultats inattendus, car lubridate va deviner le siècle.Pour convertir une année à 2 chiffres en une année à 4 chiffres (toutes dans le même siècle), vous pouvez convertir en caractères de classe, puis combiner les chiffres existants avec un préfixe en utilisant str_glue() du paquet stringr (voir la page Caractères et chaînes de caractères). Vous pouvez ensuite convertir la colonne en date.","code":"\n# installez/chargez lubridate\npacman::p_load(lubridate)\n# lire la date au format année-mois-jour\nymd(\"2020-10-11\")## [1] \"2020-10-11\"\nymd(\"20201011\")## [1] \"2020-10-11\"\n# lire la date au format mois-jour-année\nmdy(\"10/11/2020\")## [1] \"2020-10-11\"\nmdy(\"Oct 11 20\")## [1] \"2020-10-11\"\n# lire la date au format jour-mois-année\ndmy(\"11 10 2020\")## [1] \"2020-10-11\"\ndmy(\"11 October 2020\")## [1] \"2020-10-11\"\nlinelist <- linelist %>%\n  mutate(date_onset = lubridate::dmy(date_onset))\n#Vérifiez la classe de la colonne\nclass(linelist$date_onset)  \ntwo_digit_years <- c(\"15\", \"15\", \"16\", \"17\")\nstr_glue(\"20{two_digit_years}\")## 2015\n## 2015\n## 2016\n## 2017"},{"path":"working_dates.html","id":"combine-columns","chapter":"9 Manipuler les dates","heading":"Combine columns","text":"Vous pouvez utiliser les fonctions lubridate make_date() et make_datetime() pour combiner plusieurs colonnes numériques en une seule colonne de date. Par exemple, si vous avez les colonnes numériques onset_day, onset_month, et onset_year dans le cadre de données linelist :","code":"\nlinelist <- linelist %>% \n  mutate(onset_date = make_date(year = onset_year, month = onset_month, day = onset_day))"},{"path":"working_dates.html","id":"dates-en-excel","chapter":"9 Manipuler les dates","heading":"9.4 Dates en Excel","text":"En arriére-plan, la plupart des logiciels stockent les dates sous forme de nombres. R stocke les dates à partir du 1er janvier 1970. Ainsi, si vous exécutez .numeric(.Date(\"1970-01-01)) vous obtiendrez 0.Microsoft Excel enregistre les dates à partir du 30 décembre 1899 (Windows) ou du 1er janvier 1904 (Mac), selon votre système d’exploitation. Consultez ce guide Microsoft pour plus d’informations.Les dates d’Excel sont souvent importées dans R sous la forme de ces valeurs numériques plutôt que sous la forme de caractères. Si le jeu de données que vous avez importé d’Excel montre des dates sous forme de nombres ou de caractères comme “41369”… utilisez la fonction .Date() (ou la fonction as_date() de lubridate) pour convertir, mais au lieu de fournir un “format” comme ci-dessus, fournissez la date d’origine Excel à l’argument origin = dans la fonction.Cela ne fonctionnera pas si la date Excel est stockée dans R comme un type de caractère, donc assurez-vous que le nombre est de classe Numérique!NOTE: Vous devez fournir la date d’origine dans le format de date par défaut de R (“YYYY-MM-DD”).","code":"\n# Un exemple de fourniture de la \"date d'origine\" d'Excel lors de la conversion de dates numériques d'Excel.\ndata_cleaned <- data %>% \n  mutate(date_onset = as.numeric(date_onset)) %>%   # ensure class is numeric\n  mutate(date_onset = as.Date(date_onset, origin = \"1899-12-30\")) # convert to date using Excel origin"},{"path":"working_dates.html","id":"dates-désordonnées","chapter":"9 Manipuler les dates","heading":"9.5 Dates désordonnées","text":"Vous pouvez utiliser la fonction parse_date() du paquet parsedate pour lire une colonne de date “désordonnée” qui contient des dates dans de nombreux formats différents et convertir les dates dans un format standard. Vous pouvez en savoir plus en ligne sur parse_date().Par exemple, parse_date lira un vecteur des dates en caractères suivantes : “03 Jan 2018”, “07/03/1982”, et “08/20/85” et les convertira en classe Date sous la forme de : 2018-01-03, 1982-03-07, et 1985-08-20.","code":"\nparsedate::parse_date(c(\"03 January 2018\",\n                        \"07/03/1982\",\n                        \"08/20/85\"))## [1] \"2018-01-03 UTC\" \"1982-07-03 UTC\" \"1985-08-20 UTC\"\n# Un exemple d'utilisation de parse_date() sur la colonne date_onset\nlinelist <- linelist %>%                 # le dataframe s'appelle linelist, à ne pas confondre avec le paquet \"linelist\"\n  mutate(\n    date_onset = parse_date(date_onset))"},{"path":"working_dates.html","id":"travailler-avec-la-classe-date-heure","chapter":"9 Manipuler les dates","heading":"9.6 Travailler avec la classe date-heure","text":"Comme nous l’avons déjà mentionné, R supporte également une classe datetime - une colonne qui contient des informations de date et d’heure. Comme pour la classe Date, il faut souvent convertir les objets caracter en objets datetime.","code":""},{"path":"working_dates.html","id":"convertir-des-dates-avec-des-heures","chapter":"9 Manipuler les dates","heading":"Convertir des dates avec des heures","text":"Un objet datetime standard est formaté avec la date en premier, qui est suivie par une entrée de temps - par exemple 01 Jan 2020, 16:30. Comme pour les dates, il existe de nombreuses façons de formater cet objet. Il existe de nombreux niveaux de précision (heures, minutes, secondes) qui peuvent être fournis à un objet “datetime”.Il existe des fonctions du paquet lubridate pour aider à convertir ces chaînes en objets datetime. Ces fonctions sont des extensions des fonctions d’aide de date, avec _h (seulement les heures fournies), _hm (heures et minutes fournies), ou _hms (heures, minutes et secondes fournies) ajoutées à la fin (par exemple, dmy_hms()). Ils peuvent être utilisês comme indiqué :Convertir une date avec seulement des heures en objet datetimeConverter une date avec des heures et des minutes en objet datetime.Converrtir une date avec des heures, des minutes et des secondes en un objet de type datetime.Vous pouvez fournir le fuseau horaire mais il est ignoré par la fonction. Allez à la section plus bas dans le chapitre pour en savoir plus sur les fuseaux horaires dans R.Avec un dataframe chargé dans R, les colonnes d’heure et de date peuvent être combinées pour créer une colonne de date en utilisant la fonction str_glue() du paquet stringr et la fonction appropriée du paquet lubridate, selon le format de date et d’heure dans le dataframe. Voir la page caractères et chaînes de caractères pour plus de détails sur stringr.Dans cet exemple, le dataframe linelist une colonne au format “heures:minutes”. Pour la convertir en date, nous suivons quelques étapes :Vous créez une colonne de temps d’admission “propre” avec les valeurs manquantes remplies avec la médiane de la colonne. Nous faisons cela parce que lubridate ne fonctionne pas sur les valeurs manquantes. Combinez la nouvelle colonne avec la colonne date_hospitalisation, puis utilisez la fonction ymd_hm() pour convertir en objet datetime.","code":"\nymd_h(\"2020-01-01 16hrs\")## [1] \"2020-01-01 16:00:00 UTC\"\nymd_h(\"2020-01-01 4PM\")## [1] \"2020-01-01 16:00:00 UTC\"\ndmy_hm(\"01 Janvier 2020 16:20\")## Warning: All formats failed to parse. No formats found.## [1] NA\nmdy_hms(\"01 Janvier 2020, 16:20:40\")## [1] \"2020-01-20 16:20:40 UTC\"\nmdy_hms(\"01 Janvier 2020, 16:20:40 PST\")## [1] \"2020-01-20 16:20:40 UTC\"# packages\npacman::p_load(tidyverse, lubridate, stringr)\n\n# time_admission est une colonne en heures:minutes\nlinelist <- linelist %>%\n  \n#si l'heure d'admission n'est pas donnée, attribuez l'heure d'admission médiane.\n\n  mutate(\n    time_admission_clean = ifelse(\n      is.na(time_admission),         # si l'heure est manquante\n      median(time_admission),          # assigner la médiane\n      time_admission                   # si elle n'est pas manquante, la garder telle quelle\n  ) %>%\n  \n    # Utilisez str_glue() pour combiner les colonnes de date et d'heure afin de créer une colonne de caractères.\n    # puis utiliser ymd_hm() pour la convertir en classe datetime\n  mutate(\n    date_time_of_admission = str_glue(\"{date_hospitalisation} {time_admission_clean}\") %>% \n      ymd_hm()\n  )"},{"path":"working_dates.html","id":"convertir-uniquement-les-temps","chapter":"9 Manipuler les dates","heading":"Convertir uniquement les temps","text":"Si vos données ne contiennent qu’un caractère temps (heures et minutes), vous pouvez les convertir et les manipuler comme des temps en utilisant la fonction strptime() de base R. Par exemple, pour obtenir la différence entre deux temps :Notez cependant que si aucune valeur de date n’est fournie, la fonction suppose que la date est aujourd’hui. Pour combiner une chaîne de date et une chaîne d’heure, voyez comment utiliser stringr dans la section juste au-dessus. Pour en savoir plus sur strptime() ici.Pour convertir des nombres à un chiffre en nombres à deux chiffres (par exemple, pour ajouter des zéros aux heures ou aux minutes afin d’obtenir deux chiffres), consultez la section “Longueur des caractères” de la page caractères et chaînes de caractères.","code":"\n# temps comme objets de caractère\ntime1 <- \"13:45\" \ntime2 <- \"15:20\"\n\n# temps converties en une classe de datetime\ntime1_clean <- strptime(time1, format = \"%H:%M\")\ntime2_clean <- strptime(time2, format = \"%H:%M\")\n\n# La différence est de classe \"difftime\" par défaut, ici convertie en heures numériques. \nas.numeric(time2_clean - time1_clean)   # différence en heures## [1] 1.583333"},{"path":"working_dates.html","id":"extraction-déléments-du-temps","chapter":"9 Manipuler les dates","heading":"Extraction d’éléments du temps","text":"Vous pouvez extraire des éléments du temps avec hour(), minute(), ou second() du paquet lubridate.Voici un exemple d’extraction de l’heure, puis de classement par partie de la journée. Nous commençons par la colonne time_admission, qui est dans la classe Character au format “HH:MM”. D’abord, la fonction strptime() est utilisêe comme décrit ci-dessus pour convertir les caractères en classe datetime. Ensuite, l’heure est extraite avec hour(), retournant un nombre de 0-24. Enfin, une colonne time_period est crée en utilisant la logique de case_when() pour classer les lignes en Matin/Après-midi/Soir/Nuit en fonction de leur heure d’admission.Pour en savoir plus sur la fonction case_when(), consultez la page Nettoyage des données et des fonctions de base.","code":"\nlinelist <- linelist %>%\n  mutate(hour_admit = hour(strptime(time_admission, format = \"%H:%M\"))) %>%\n  mutate(time_period = case_when(\n    hour_admit > 06 & hour_admit < 12 ~ \"Matin\",\n    hour_admit >= 12 & hour_admit < 17 ~ \"Après-midi\",\n    hour_admit >= 17 & hour_admit < 21 ~ \"Soir\",\n    hour_admit >=21 | hour_admit <= 6 ~ \"Nuit\"))"},{"path":"working_dates.html","id":"travailler-avec-des-dates","chapter":"9 Manipuler les dates","heading":"9.7 Travailler avec des dates","text":"Le paquet lubridate peut également être utilisê pour une variété d’autres fonctions, telles que l’extraction d’aspects d’une date/heure, l’exécution d’arithmétique pour les dates, ou le calcul d’intervalles de dates.Nous définissons ici une date à utiliser dans les exemples :","code":"\n# créer un objet de la classe Date\nexample_date <- ymd(\"2020-03-01\")"},{"path":"working_dates.html","id":"extraire-les-composants-de-la-date","chapter":"9 Manipuler les dates","heading":"Extraire les composants de la date","text":"Vous pouvez extraire des aspects communs commes le mois, le jour, le jour de la semaine :Vous pouvez également extraire les composants temporels d’un objet ou d’une colonne en classe datetime. Cela peut être utile si vous voulez visualiser la distribution des temps d’admission.Il existe plusieurs options pour récupérer les semaines. Lisez la section sur les semaines épidémiologiques ci-dessous pour en savoir plus.Notez que si vous cherchez à afficher une date d’une certaine maniére (par exemple “Jan 2020” ou “Jeudi 20 mars” ou “Semaine 20, 1977”), vous pouvez le faire assez facilement en utilisant les méthodes décrites dans la section sur l’affichage des dates.","code":"\nmonth(example_date) # numéro du mois## [1] 3\nday(example_date) # jour (numéro) du mois## [1] 1\nwday(example_date) # numéro du jour de la semaine (1-7)## [1] 1\nexample_datetime <- ymd_hm(\"2020-03-01 14:45\")\n\nhour(example_datetime) # extraire l'heure\nminute(example_datetime) # extrait la minute\nsecond(example_datetime) # extrait les secondes"},{"path":"working_dates.html","id":"mathématiques-de-dates","chapter":"9 Manipuler les dates","heading":"Mathématiques de dates","text":"Vous pouvez ajouter certains nombres de jours ou de semaines en utilisant leur fonction respective du paquet lubridate.","code":"\n# ajouter 3 jours à cette date\nexample_date + days(3)## [1] \"2020-03-04\"\n# ajoute 7 semaines et soustrait deux jours à cette date\nexample_date + weeks(7) - days(2)## [1] \"2020-04-17\""},{"path":"working_dates.html","id":"intervalles-entre-les-dates","chapter":"9 Manipuler les dates","heading":"Intervalles entre les dates","text":"La différence entre les dates peut être calculée par :Assurez-vous que les deux dates sont de la classe DateUtilisez la soustraction pour obtenir la différence “difftime” entre les deux dates.Si nécessaire, convertissez le résultat en classe numérique pour effectuer les calculs mathématiques suivants.Ci-dessous, l’intervalle entre deux dates est calculé et affiché. Vous pouvez trouver des intervalles en utilisant le symbole “moins” de la soustraction sur des valeurs de la classe Date. Notez que la classe de la valeur retournée est “difftime” comme affiché ci-dessous, et doit être convertie en classe numérique.Pour effectuer d’autres opérations sur un objet de classe “difftime”, convertissez-le en numérique avec la fonction .numeric().Tout ceci peut être rassemblé pour travailler avec des données - par exemple :Dans le dataframe, si l’une des dates ci-dessus est manquante, l’opération échouera pour cette ligne. Il en résultera un NA au lieu d’une valeur numérique. Lorsque vous utilisez cette colonne pour des calculs, assurez-vous de mettre l’argument na.rm = à TRUE (vrai). Par exemple :","code":"\n# trouver l'intervalle entre example_date et le 20 février 2020 \noutput <- example_date - ymd(\"2020-02-20\")\noutput    # imprimer## Time difference of 10 days\nclass(output)## [1] \"difftime\"\npacman::p_load(lubridate, tidyverse) # charger les paquets\n\nlinelist <- linelist %>% # conversion de la date d'apparition en caractères\n  \n  # convertir la date d'apparition de objets caractères en objets date en spécifiant le format dmy\n  mutate(date_onset = dmy(date_onset),\n         date_hospitalisation = dmy(date_hospitalisation)) %>%\n  \n  # filtre tous les cas dont la date d'apparition n'est pas en mars\n  filter(month(date_onset) == 3) %>% # filtrer tous les cas sans apparition en mars\n    \n  # trouver la différence en jours entre l'apparition et l'hospitalisation pour tous les cas\n  mutate(days_onset_to_hosp = date_hospitalisation - date_of_onset)\n# Calculez le nombre médian de jours d'hospitalisation pour tous les cas pour lesquels des données sont disponibles.\nmedian(linelist_delay$days_onset_to_hosp, na.rm = T)"},{"path":"working_dates.html","id":"affichage-des-dates","chapter":"9 Manipuler les dates","heading":"9.8 Affichage des dates","text":"Une fois que les dates ont la bonne classe, vous voudrez peut-être qu’elles s’affichent différemment, par exemple qu’elles s’affichent comme “Lundi 05 Janvier” au lieu de “2018-01-05”. Vous pouvez aussi vouloir ajuster l’affichage afin de regrouper ensuite les lignes en fonction des éléments de date affichés - par exemple pour regrouper par mois-année.","code":""},{"path":"working_dates.html","id":"format","chapter":"9 Manipuler les dates","heading":"format()","text":"Ajustez l’affichage de la date avec la fonction format() de base R. Cette fonction accepte une chaîne de caractères (entre guillemets) spécifiant le format final souhaité dans les abréviations “%” strptime (la même syntaxe que celle utilisêe dans la fonction .Date()). Vous trouverez ci-dessous la plupart des abréviations courantes.NOTE: l’’utilisation de format() convertira les valeurs dans la classe Character, donc cette fonction est généralement utilisêe vers la fin d’une analyse ou uniquement pour l’affichage ! Vous pouvez voir la liste complète en exécutant ?strptime.%d = numéro du jour du mois (5, 17, 28, etc.)\n%j = numéro du jour de l’année (Jday 001-366)\n%= Jour de la semaine abrégé (lun, mar, mer, etc.)\n%= Jour de la semaine complet (lundi, mardi, etc.)\n%w = numéro du jour de la semaine (0-6, le dimanche est 0)\n%u = numéro du jour de la semaine (1-7, le lundi est 1)\n%W = numéro de la semaine (00-53, le lundi est le début de la semaine)\n%U = numéro de la semaine (01-53, le dimanche est le début de la semaine)\n%m = numéro du mois (par exemple 01, 02, 03, 04)\n%b = Mois abrégé (Jan, Feb, etc.)\n%B = Mois complet (janvier, février, etc.)\n%y = année à 2 chiffres (ex. 89)\n%Y = année à 4 chiffres (ex. 1989)\n%h = heures (horloge de 24 heures)\n%m = minutes\n%s = secondes\n%z = décalage par rapport à GMT\n%Z = Fuseau horaire (caractère)Un exemple de formatage de la date du jour:Notez que si vous utilisez la fonction str_glue(), sachez qu’à l’intérieur des guillemets doubles ” vous ne devez utiliser que des guillemets simples (comme ci-dessus).","code":"\n# date du jour, avec formatage\nformat(Sys.Date(), format = \"%d %B %Y\")## [1] \"21 May 2023\"\n# moyen simple d'obtenir la date et l'heure complètes (formatage par défaut)\ndate()## [1] \"Sun May 21 16:49:11 2023\"\n# formatage de la date, de l'heure et du fuseau horaire combinés ensemble avec la fonction str_glue()\nstr_glue(\"{format(Sys.Date(), format = '%A, %B %d %Y, %z %Z, ')}{format(Sys.time(), format = '%H:%M:%S')}\")## Sunday, May 21 2023, +0000 UTC, 16:49:11\n#Utilisation du formatage pour afficher les semaines\nformat(Sys.Date(), \"%Y Week %W\")## [1] \"2023 Week 20\""},{"path":"working_dates.html","id":"mois-année","chapter":"9 Manipuler les dates","heading":"Mois-année","text":"Pour convertir une colonne de date au format mois-année, nous vous suggérons d’utiliser la fonction .yearmon() du paquet zoo. Cette fonction convertit la date en classe “yearmon” et conserve l’ordre correct. En revanche, l’utilisation de la fonction format(colonne, \"%Y %B\") convertira la date en classe caractère et classera les valeurs par ordre alphabétique (de maniére incorrecte).Ci-dessous, une nouvelle colonne yearmonth est créée à partir de la colonne date_onset, en utilisant la fonction .yearmon(). L’ordre par défaut (correct) des valeurs résultantes est indiqué dans le tableau.En revanche, vous pouvez voir comment la seule utilisation de format() permet d’obtenir le format d’affichage souhaité, mais pas l’ordre correct.Note : si vous travaillez dans un ggplot() et vous voulez ajuster la façon dont les dates sont affichées uniquement, il peut être suffisant de fournir un format strptime à l’argument date_labels = dans scale_x_date() - vous pouvez utiliser \"%b %Y\" ou \"%Y %b\". Consultez la page Astuces de ggplot pour une explication plus approfondie.Alternativement, le paquet zoo posséde la fonction .yearqtr(), et vous pouvez utiliser scale_x_yearmon() lorsque vous utilisez ggplot() pour ajuster la façon dont les dates sont affichées sur le graphique.","code":"\n# créer une nouvelle colonne \ntest_zoo <- linelist %>% \n     mutate(yearmonth = zoo::as.yearmon(date_onset))\n\n# imprimer le tableau\ntable(test_zoo$yearmon)## \n## Apr 2014 May 2014 Jun 2014 Jul 2014 Aug 2014 Sep 2014 Oct 2014 Nov 2014 Dec 2014 \n##        7       64      100      226      528     1070     1112      763      562 \n## Jan 2015 Feb 2015 Mar 2015 Apr 2015 \n##      431      306      277      186\n# créer une nouvelle colonne\ntest_format <- linelist %>% \n     mutate(yearmonth = format(date_onset, \"%b %Y\"))\n\n# imprimer le tableau\ntable(test_format$yearmon)## \n## Apr 2014 Apr 2015 Aug 2014 Dec 2014 Feb 2015 Jan 2015 Jul 2014 Jun 2014 Mar 2015 \n##        7      186      528      562      306      431      226      100      277 \n## May 2014 Nov 2014 Oct 2014 Sep 2014 \n##       64      763     1112     1070"},{"path":"working_dates.html","id":"dates_epi_wks","chapter":"9 Manipuler les dates","heading":"9.9 Semaines épidémiologiques","text":"","code":""},{"path":"working_dates.html","id":"lubridate-1","chapter":"9 Manipuler les dates","heading":"lubridate","text":"Consultez la page Regroupement de données pour des exemples plus complets de regroupement de données par date. Ci-dessous, nous décrivons briévement le regroupement des données par semaine.Nous recommandons généralement d’utiliser la fonction floor_date() du package lubridate, avec l’argument unit = \"week\". Cela arrondit la date au “début” de la semaine, comme défini par l’argument week_start =. Le début de semaine par défaut est 1 (pour les lundis) mais vous pouvez spécifier n’importe quel jour de la semaine comme début (par exemple 7 pour les dimanches). floor_date() est polyvalent et peut être utilisê pour arrondir à d’autres unités de temps en définissant unit = à “seconde”, “minute”, “heure”, “jour”, “mois” ou “année”.La valeur retournée est la date de début de la semaine, dans la classe Date. La classe Date est utile pour tracer les données, car elle est ordonnée correctement et elle sera facilement reconnue par ggplot().Si vous êtes seulement intéressé par l’ajustement des dates pour afficher par semaine dans un graphique, voyez la section de ce chapitre sur l’affichage des dates. Par exemple, lorsque vous tracez une épicurve, vous pouvez formater l’affichage de la date en fournissant la nomenclature strptime “%” désirée. Par exemple, utilisez “%Y-%W” ou “%Y-%U” pour spécifier l’année et le numéro de semaine (respectivement le lundi ou le dimanche en début de semaine).","code":""},{"path":"working_dates.html","id":"comptages-hebdomadaires","chapter":"9 Manipuler les dates","heading":"Comptages hebdomadaires","text":"Allez à la page Regroupement des données pour une explication détaillée du regroupement des données avec count(), group_by(), et summarise(). Voici un bref exemple.créez une nouvelle colonne ‘semaine’ avec mutate(), en utilisant floor_date() avec unit = \"week\".Obtenez le nombre de lignes (cas) par semaine avec count() ; filtrez les cas dont la date est manquante.Terminez avec complete() du paquet tidyr pour vous assurer que toutes les semaines apparaissent dans les données - même celles qui n’ont pas de lignes/cas. Par défaut, les valeurs de comptage pour toutes les “nouvelles” lignes sont NA, mais vous pouvez les rendre 0 avec l’argument fill =, qui attend une liste nommée (ci-dessous, n est le nom de la colonne de comptage).Voici les premiéres lignes du jeu de données résultant :","code":"\n# créez un jeu de données agrégé des comptes hebdomadaires de cas.\nweekly_counts <- linelist %>% \n  drop_na(date_onset) %>%             # Suppression des cas pour lesquels il manque la date de début de la maladie\n  mutate(weekly_cases = floor_date(   # créer une nouvelle colonne, semaine d'apparition du cas\n    date_onset,\n    unit = \"week\")) %>%            \n  count(weekly_cases) %>%           # grouper les données par semaine et compter les lignes par groupe (crée la colonne 'n')\n  tidyr::complete(                  # Assurez-vous que toutes les semaines sont présentes, même celles où aucun cas n'a été observé.\n    weekly_cases = seq.Date(          # definir la colonne \"weekly_cases\" comme une séquence complète\n      from = min(weekly_cases),       # à partir de la date minimum\n      to = max(weekly_cases),         # jusqu'à la date maximale\n      by = \"week\"),                   # agrégé par semaines\n    fill = list(n = 0))             # Remplir les NA dans la colonne des comptes n avec 0"},{"path":"working_dates.html","id":"différentes-méthodes-pour-les-epiweeks","chapter":"9 Manipuler les dates","heading":"différentes méthodes pour les epiweeks","text":"Notez que le paquet lubridate posséde des fonctions alternatives week(), epiweek(), et isoweek(), dont chacune des dates de début légérement différentes et d’autres nuances. De maniére générale, floor_date() devrait suffire à vos besoins. Pour en savoir plus sur ces fonctions, entrez ?week dans la console ou lisez la documentation ici.Vous pouvez également utiliser le paquet aweek pour définir les semaines épidémiologiques. Vous pouvez en savoir plus sur le paquet aweek sur le site de RECON. aweek contient les fonctions date2week() et week2date() dans lesquelles vous pouvez définir le jour de début de semaine avec week_start = \"Monday\". aweek est le plus simple si vous voulez spécifier vos dates sous forme de numéro de semaine (par exemple “2020-W12”). Un autre avantage du package aweek est que lorsque date2week() est appliqué à une colonne de date, la colonne retournée (format de semaine) est automatiquement de la classe Factor et inclut les niveaux de toutes les semaines de l’intervalle de temps (cela évite l’étape supplémentaire de complete() décrite ci-dessus). Cependant, aweek n’pas la fonctionnalité d’arrondir les dates à d’autres unités de temps comme les mois, les années, etc.Une autre alternative pour les séries temporelles qui fonctionne également bien pour afficher un format “semaine” (“2020 W12”) est yearweek() du paquet tsibble, comme démontré dans la page sur Série temporelle et détection des épidémies.","code":""},{"path":"working_dates.html","id":"conversion-des-datesfuseaux-horaires","chapter":"9 Manipuler les dates","heading":"9.10 Conversion des dates/fuseaux horaires","text":"Lorsque des données sont présentes dans différents fuseaux horaires, il peut souvent être important de standardiser ces données dans un fuseau horaire unifié. Cela peut présenter un défi supplémentaire, car la l’élément fuseau horaire des données doit être codée manuellement dans la plupart des cas.Dans R, chaque objet datetime posséde un élément fuseau horaire. Par défaut, tous les objets datetime portent le fuseau horaire local de l’ordinateur utilisê - ce fuseau est généralement spécifique à une localisation plutôt qu’à un fuseau horaire nommé, car les fuseaux horaires changent souvent en fonction de l’heure d’été. Il n’est pas possible de compenser avec précision les fuseaux horaires sans la composante temporelle d’une date, car l’événement que représente une colonne de date ne peut être attribué à une heure spécifique, et les décalages horaires mesurés en heures ne peuvent donc pas être raisonnablement pris en compte.Pour définir des fuseaux horaires différents, il existe un certain nombre de fonctions dans le paquet lubridate qui peuvent être utilisêes pour changer le fuseau horaire d’un objet datetime du fuseau horaire local à un fuseau horaire différent. Les fuseaux horaires sont définis en attribuant un fuseau horaire valide de la base de données tz à l’objet datetime. Une liste de ces fuseaux est disponible ici - si le lieu dont vous utilisez les données ne figure pas sur cette liste, les grandes villes voisines dans le fuseau horaire sont disponibles et servent le même objectif.https://en.wikipedia.org/wiki/List_of_tz_database_time_zonesCela peut sembler largement abstrait, et n’est souvent pas nécessaire si l’utilisateur ne travaille pas sur plusieurs fuseaux horaires.","code":"\n# Assignez l'heure actuelle à une colonne \ntime_now <- Sys.time()\ntime_now## [1] \"2023-05-21 16:49:12 CEST\"\n# utilisez with_tz() pour affecter un nouveau fuseau horaire à la colonne, tout en CHANGEANT l'heure de l'horloge\ntime_london_real <- with_tz(time_now, \"Europe/London\")\n\n# Utilisez force_tz() pour assigner un nouveau fuseau horaire à la colonne, tout en conservant l'heure de l'horloge.\ntime_london_local <- force_tz(time_now, \"Europe/London\")\n\n\n# notez que tant que l'ordinateur qui a été utilisê pour exécuter ce code n'est PAS réglé sur l'heure de Londres,\n# il y aura une différence dans les heures \n# (le nombre d'heures de différence entre le fuseau horaire de l'ordinateur et l'heure de Londres)\ntime_london_real - time_london_local## Time difference of -1 hours"},{"path":"working_dates.html","id":"calculs-de-décalage-et-davance","chapter":"9 Manipuler les dates","heading":"9.11 Calculs de décalage et d’avance","text":"lead() et lag() sont des fonctions du paquet dplyr qui aident à trouver les valeurs précédentes (décalées) ou suivantes (en avance) dans un vecteur - généralement pour un vecteur numérique ou de date. Ces fonctions sont utiles pour calculer les changements/différences entre les unités de temps.Supposons que vous vouliez calculer la différence de cas entre la semaine en cours et la semaine précédente. Les données sont initialement fournies en nombre de cas hebdomadaires, comme indiqué ci-dessous.Lorsque vous utilisez lag() ou lead(), l’ordre des lignes dans le dataframe est très important ! - Faites attention à ce que vos dates/chiffres soient ascendants ou descendants.La premiére étape consiste à créer une nouvelle colonne contenant la valeur de la semaine précédente (décalée).Contrôlez le nombre d’unités en arriére/en avant avec n = (doit être un integer non-négatif)Utilisez default = pour définir la valeur placée dans les lignes inexistantes (par exemple, la premiére ligne pour laquelle il n’y pas de valeur décalée). Par défaut, c’est NA.Utilisez order_by = TRUE si vos lignes ne sont pas ordonnées par votre colonne de référence.L’étape suivante consiste à créer une nouvelle colonne qui est la différence entre les deux colonnes de cas :Vous pouvez en savoir plus sur lead() et lag() dans la documentation ici ou en entrant ?lag dans votre console.","code":"\ncounts <- counts %>% \n  mutate(cases_prev_wk = lag(cases_wk, n = 1))\ncounts <- counts %>% \n  mutate(cases_prev_wk = lag(cases_wk, n = 1),\n         case_diff = cases_wk - cases_prev_wk)"},{"path":"working_dates.html","id":"ressources-2","chapter":"9 Manipuler les dates","heading":"9.12 Ressources","text":"lubridate tidyverse pagelubridate RStudio cheatsheet\nR Data Science page dates timesOnline tutorial\nDate formats","code":""},{"path":"character_strings.html","id":"character_strings","chapter":"10 Caractères et chaînes de caractères","heading":"10 Caractères et chaînes de caractères","text":"Cette page démontre l’utilisation du paquet stringr pour évaluer et manipuler des valeurs de caractères (ou chaînes de caractères, ce que nous appelons “strings” en anglais).Combiner, ordonner, séparer, arranger - str_c(), str_glue(), str_order(), str_split()Nettoyer et standardiser\nAjuster la longueur - str_pad(), str_trunc(), str_wrap().\nChangez la casse - str_to_upper(), str_to_title(), str_to_lower(), str_to_sentence()\nAjuster la longueur - str_pad(), str_trunc(), str_wrap().Changez la casse - str_to_upper(), str_to_title(), str_to_lower(), str_to_sentence()Évaluer et extraire par position - str_length(), str_sub(), word().Modèles\ndétecter et localiser - str_detect(), str_subset(), str_match(), str_extract()\nModifier et remplacer - str_sub(), str_replace_all()\ndétecter et localiser - str_detect(), str_subset(), str_match(), str_extract()Modifier et remplacer - str_sub(), str_replace_all()Expressions régulières (“regex”)Afin d’expliquer facilement l’utilisation des chaînes de caractères dans le présent chapitre, la plupart des exemples utilisent un vecteur de caractères court et défini, mais ils peuvent facilement être adaptés à une colonne dans un dataframe.Une grande partie de l’inspiration pour ce chapitre est basée sur cette example de le paquet stringr.","code":""},{"path":"character_strings.html","id":"preparation","chapter":"10 Caractères et chaînes de caractères","heading":"10.1 Preparation","text":"","code":""},{"path":"character_strings.html","id":"charger-les-paquets","chapter":"10 Caractères et chaînes de caractères","heading":"Charger les paquets","text":"Installez ou chargez le paquet stringr et d’autres paquets de tidyverse.","code":"\n# installer/charger les paquets\npacman::p_load(\n  stringr,    # de nombreuses fonctions pour la manipulation des chaînes de caractères\n  tidyverse,  # pour diverses options de manipulation des données \n  tools)      # alternative pour la conversion en majuscules"},{"path":"character_strings.html","id":"importation-de-données","chapter":"10 Caractères et chaînes de caractères","heading":"Importation de données","text":"Dans cette page, il y aura parfois des références à la linelist (liste de cas ou liste linéaire) nettoyée des cas d’une épidémie d’Ebola simulée. Si vous voulez suivre les exemples dans votre propre script, cliquez ici pour télécharger la “linelist” nettoyée (.rds file). Importez les données avec la fonction import() du paquet rio (la fonction import() peut être utilisée pour importer plusieurs types de fichiers comme .xlsx, .csv, .rds - voir la page Importation et exportation pour plus de détails).Les 50 premiéres lignes de la linelist (liste linéaire ou liste de cas) sont affichées ci-dessous.","code":"\n# importez la linelist de cas\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"character_strings.html","id":"unir-séparer-et-arranger","chapter":"10 Caractères et chaînes de caractères","heading":"10.2 Unir, séparer et arranger","text":"Cette section couvre :Utilisation de str_c(), str_glue() et unite() pour combiner des chaînes de caractères.Utiliser str_order() pour organiser des chaînes de caractères.Utiliser str_split() et separate() pour séparer des chaînes de caractères.","code":""},{"path":"character_strings.html","id":"combiner-des-chaînes-de-caractères","chapter":"10 Caractères et chaînes de caractères","heading":"Combiner des chaînes de caractères","text":"Pour combiner ou concaténer plusieurs chaînes de caractères en une seule chaîne, nous suggérons d’utiliser la fonction str_c() du paquet stringr. Si vous avez des valeurs de caractères distinctes à combiner, fournissez-les simplement comme arguments uniques, séparés par des virgules.L’argument sep = insére une valeur de caractère entre chacun des arguments que vous avez fournis (par exemple, fournir une virgule, un espace ou une nouvelle ligne insérerait ce caractère entre chaque argument \"\\n\")L’argument collapse = est pertinent si vous mettez plusieurs vecteurs comme arguments à str_c(). L’argument collapse = est utilisé pour séparer les éléments inclus dans le vecteur produit par str_c(), où le vecteur produit est un long vecteur de type caractère.L’exemple ci-dessous montre la combinaison de deux vecteurs en un seul vecteur (prénoms et noms de famille). Un autre exemple similaire pourrait être montré avec des régions et le nombre de cas dans chaque région. Dans cet exemple :La valeur sep = apparaît entre chaque prénom et chaque nom.La valeur collapse = apparaît entre chaque personne.Remarque: Selon le contexte d’affichage souhaité, lorsque vous imprimez une telle chaîne combinée avec des nouvelles lignes, vous devrez peut-être envelopper la phrase entière dans cat() pour que les nouvelles lignes s’impriment correctement:","code":"\nstr_c(\"String1\", \"String2\", \"String3\")## [1] \"String1String2String3\"\nstr_c(\"String1\", \"String2\", \"String3\", sep = \", \")## [1] \"String1, String2, String3\"\nfirst_names <- c(\"abdul\", \"fahruk\", \"janice\") \nlast_names  <- c(\"hussein\", \"akinleye\", \"okeke\")\n\n# sep s'affiche entre les chaînes de caractères d'entrée respectives, tandis que collapse s'affiche entre les éléments produits\nstr_c(first_names, last_names, sep = \" \", collapse = \";  \")## [1] \"abdul hussein;  fahruk akinleye;  janice okeke\"\n# Pour que les nouvelles lignes s'impriment correctement, il peut être nécessaire d'envelopper la phrase dans cat()\ncat(str_c(first_names, last_names, sep = \" \", collapse = \";\\n\"))## abdul hussein;\n## fahruk akinleye;\n## janice okeke"},{"path":"character_strings.html","id":"chaînes-de-caractères-dynamiques","chapter":"10 Caractères et chaînes de caractères","heading":"Chaînes de caractères dynamiques","text":"Utilisez la fonction str_glue() pour insérer du code R dynamique dans une chaîne de caractères. C’est une fonction trés utile pour créer des légendes de graphiques dynamiques, comme démontré ci-dessous.Tout le contenu est placé entre guillemets doubles comme ceci str_glue(\"\").Tout code dynamique ou référence à des valeurs prédéfinies est placé entre des accolades {} à l’intérieur des guillemets doubles. Il peut y avoir plusieurs accolades dans la même commande de str_glue().Pour afficher les guillemets de caractères ’’, utilisez des guillemets simples entre les guillemets doubles (par exemple, pour le format de date - voir l’exemple ci-dessous).Conseil : Vous pouvez utiliser \\n pour forcer une nouvelle ligne.Conseil : Vous pouvez utiliser format() pour ajuster l’affichage de la date, et utiliser Sys.Date() pour afficher la date actuelle.Un exemple simple, d’une légende d’un graphique dynamique :Un format alternatif consiste à utiliser des caractères de remplacement à l’intérieur des parenthèses et à définir le code dans des arguments séparés à la fin de la fonction str_glue(), comme ci-dessous. Cela peut améliorer la lisibilité du code si le texte est long.Extraction d’un dataframeIl est parfois utile d’extraire des données d’un dataframe et de les coller ensemble en séquence.Vous trouverez ci-dessous un exemple de dataframe comprenant la juridiction (zone), les nouvelles affaires et les affaires totales. Nous allons l’utiliser pour faire une description résumée du nombre de nouveaux cas et du nombre total de cas par juridiction.Utilisez la fonction str_glue_data(), qui est spécifiquement utilisée pour prendre des données à partir des lignes du dataframe:Combinaison des chaînes de caractères entre les lignesSi vous essayez “d’enrouler” des valeurs dans une colonne d’un dataframe, c’est-à-dire de combiner des valeurs de plusieurs lignes en une seule ligne en les collant ensemble avec un séparateur. Consultez la section de la page Deduplication sur les valeurs “enroulées”.Dataframe combiné en une seule ligneVous pouvez faire apparaêtre la description résumée sur une seule ligne en utilisant str_c() (en spécifiant le dataframe et les noms des colonnes), et en fournissant les arguments sep = et collapse =.Vous pouvez ajouter le pré-fixe “New Cases :” (nouveaux cas en français) au début de la description en l’entourant d’une str_c() distincte (si “New Cases :” se trouvait dans la `str_c()``, il apparaîtrait plusieurs fois).","code":"\nstr_glue(\"Les données incluent {nrow(linelist)} cas et sont actuelles à {format(Sys.Date(), '%d %b %Y')}.\")## Les données incluent 5888 cas et sont actuelles à 21 May 2023.\nstr_glue(\"Linelist à la {current_date}.\\nDernier cas hospitalisé à l'hôpital {last_hospital}.\\n{n_missing_onset} cas n'ont pas de date d'apparition et ne sont pas représentés.\",\n         current_date = format(Sys.Date(), '%d %b %Y'),\n         last_hospital = format(as.Date(max(linelist$date_hospitalisation, na.rm=T)), '%d %b %Y'),\n         n_missing_onset = nrow(linelist %>% filter(is.na(date_onset)))\n         )## Linelist à la 21 May 2023.\n## Dernier cas hospitalisé à l'hôpital 30 Apr 2015.\n## 256 cas n'ont pas de date d'apparition et ne sont pas représentés.\n# créer un dataframe de cas\ncase_table <- data.frame(\n  zone        = c(\"Zone 1\", \"Zone 2\", \"Zone 3\", \"Zone 4\", \"Zone 5\"),\n  new_cases   = c(3, 0, 7, 0, 15),\n  total_cases = c(40, 4, 25, 10, 103)\n  )\ncase_table %>% \n  str_glue_data(\"{zone}: {new_cases} ({total_cases} total cases)\")## Zone 1: 3 (40 total cases)\n## Zone 2: 0 (4 total cases)\n## Zone 3: 7 (25 total cases)\n## Zone 4: 0 (10 total cases)\n## Zone 5: 15 (103 total cases)\nstr_c(case_table$zone, case_table$new_cases, sep = \" = \", collapse = \";  \")## [1] \"Zone 1 = 3;  Zone 2 = 0;  Zone 3 = 7;  Zone 4 = 0;  Zone 5 = 15\"\nstr_c(\"New Cases: \", str_c(case_table$zone, case_table$new_cases, sep = \" = \", collapse = \";  \"))## [1] \"New Cases: Zone 1 = 3;  Zone 2 = 0;  Zone 3 = 7;  Zone 4 = 0;  Zone 5 = 15\""},{"path":"character_strings.html","id":"str_unite","chapter":"10 Caractères et chaînes de caractères","heading":"Unir les colonnes","text":"Dans un cadre de données, le regroupement des valeurs de caractères de plusieurs colonnes peut être réalisé avec la fonction unite() du paquet tidyr. C’est l’inverse de la fonction separate().Vous devez fournir le nom de la nouvelle colonne unie et ensuite fournir les noms des colonnes que vous souhaitez unir.Par défaut, le séparateur utilisé dans la colonne unie est le caractère de soulignement _, mais cela peut être changé avec l’argument sep =.L’argument remove = supprime les colonnes qui seront unies du dataframe (VRAI par défaut).L’argument na.rm = supprime les valeurs manquantes lors de l’unification (FAUX par défaut)Ci-dessous, nous définissons un mini dataframe pour la démonstration:Voici l’exemple avec le dataframe dessus:Ci-dessous, nous réunissons les trois colonnes de symptômes:","code":"\ndf <- data.frame(\n  case_ID = c(1:6),\n  symptoms  = c(\"jaundice, fever, chills\",     # patient 1\n                \"chills, aches, pains\",        # patient 2 \n                \"fever\",                       # patient 3\n                \"vomiting, diarrhoea\",         # patient 4\n                \"bleeding from gums, fever\",   # patient 5\n                \"rapid pulse, headache\"),      # patient 6\n  outcome = c(\"Recover\", \"Death\", \"Death\", \"Recover\", \"Recover\", \"Recover\"))\ndf_split <- separate(df, symptoms, into = c(\"sym_1\", \"sym_2\", \"sym_3\"), extra = \"merge\")## Warning: Expected 3 pieces. Missing pieces filled with `NA` in 2 rows [3, 4].\ndf_split %>% \n  unite(\n    col = \"all_symptoms\", # nom de la nouvelle colonne unie\n    c(\"sym_1\", \"sym_2\", \"sym_3\"), # colonnes à unir\n    sep = \", \", # séparateur à utiliser dans la colonne unie\n    remove = TRUE, # si TRUE (VRAI), supprime les colonnes d'entrée du dataframe\n    na.rm = TRUE # Si TRUE (VRAI), les valeurs manquantes sont supprimées avant l'unification.\n  )##   case_ID                all_symptoms outcome\n## 1       1     jaundice, fever, chills Recover\n## 2       2        chills, aches, pains   Death\n## 3       3                       fever   Death\n## 4       4         vomiting, diarrhoea Recover\n## 5       5 bleeding, from, gums, fever Recover\n## 6       6      rapid, pulse, headache Recover"},{"path":"character_strings.html","id":"séparer","chapter":"10 Caractères et chaînes de caractères","heading":"séparer","text":"Pour diviser une chaîne de caractères en fonction d’un motif, utilisez la fonction str_split(). Cette fonction évalue la (ou les) chaîne(s) de caractères et renvoie une liste de vecteurs de caractères constituée des valeurs nouvellement séparées.L’exemple simple ci-dessous évalue une chaîne de caractères et la divise en trois. Par défaut, il retourne un objet de la classe list avec un élément (un vecteur de caractères) pour chaque chaîne initialement fournie. Si simplify = TRUE, (en français VRAI), il retourne une matrice de caractères.Dans cet exemple, une chaîne de caractères est fournie, et la fonction renvoie une liste avec un élément - un vecteur de caractères avec trois valeurs.Si les valeurs séparées sont enregistrées dans un objet, vous pouvez alors accéder à la n-iéme valeur séparée avec la syntaxe des crochets. Pour accéder à une valeur spécifique, vous pouvez utiliser une syntaxe comme celle-ci : nouveau_objet[[1]][2], qui accéderait à la deuxiéme valeur de la premiére chaîne évaluée (“fever”, ou fiévre en français, dans le dataframe de l’exemple). Consultez la page Bases de R pour plus de détails sur l’accés aux éléments.Si plusieurs chaînes de caractères sont fournies par str_split(), il y aura plus d’un élément dans la liste retournée.Pour retourner une “matrice de caractères” à la place, ce qui peut être utile pour créer des colonnes dans votre dataframe, définissez l’argument simplify = TRUE comme indiqué ci-dessous :Vous pouvez également ajuster le nombre de séparations à créer avec l’argument n =. Par exemple, l’exemple ci-dessous limite le nombre de séparations à deux. Toutes les autres virgules restent dans les deuxiémes valeurs.Note - les mêmes résultats peuvent être obtenus avec str_split_fixed(), dans lequel vous ne donnez pas l’argument simplify, mais devez à la place désigner le nombre de colonnes (n).","code":"\nstr_split(string = \"jaundice, fever, chills\",\n          pattern = \",\")## [[1]]\n## [1] \"jaundice\" \" fever\"   \" chills\"\npt1_symptoms <- str_split(\"jaundice, fever, chills\", \",\")\n\npt1_symptoms[[1]][2]  # extrait la 2éme valeur du 1er (et dans ce cas unique) élément de la liste## [1] \" fever\"\nsymptoms <- c(\"jaundice, fever, chills\",     # patient 1\n              \"chills, aches, pains\",        # patient 2 \n              \"fever\",                       # patient 3\n              \"vomiting, diarrhoea\",         # patient 4\n              \"bleeding from gums, fever\",   # patient 5\n              \"rapid pulse, headache\")       # patient 6\n\nstr_split(symptoms, \",\")                     # split each patient's symptoms## [[1]]\n## [1] \"jaundice\" \" fever\"   \" chills\" \n## \n## [[2]]\n## [1] \"chills\" \" aches\" \" pains\"\n## \n## [[3]]\n## [1] \"fever\"\n## \n## [[4]]\n## [1] \"vomiting\"   \" diarrhoea\"\n## \n## [[5]]\n## [1] \"bleeding from gums\" \" fever\"            \n## \n## [[6]]\n## [1] \"rapid pulse\" \" headache\"\nstr_split(symptoms, \",\", simplify = TRUE) #simplify = VRAI##      [,1]                 [,2]         [,3]     \n## [1,] \"jaundice\"           \" fever\"     \" chills\"\n## [2,] \"chills\"             \" aches\"     \" pains\" \n## [3,] \"fever\"              \"\"           \"\"       \n## [4,] \"vomiting\"           \" diarrhoea\" \"\"       \n## [5,] \"bleeding from gums\" \" fever\"     \"\"       \n## [6,] \"rapid pulse\"        \" headache\"  \"\"\nstr_split(symptoms, \",\", simplify = TRUE, n = 2)##      [,1]                 [,2]            \n## [1,] \"jaundice\"           \" fever, chills\"\n## [2,] \"chills\"             \" aches, pains\" \n## [3,] \"fever\"              \"\"              \n## [4,] \"vomiting\"           \" diarrhoea\"    \n## [5,] \"bleeding from gums\" \" fever\"        \n## [6,] \"rapid pulse\"        \" headache\"\nstr_split_fixed(symptoms, \",\", n = 2)"},{"path":"character_strings.html","id":"séparer-les-colonnes","chapter":"10 Caractères et chaînes de caractères","heading":"Séparer les colonnes","text":"Si vous essayez de séparer une colonne dans un dataframe, il est préférable d’utiliser la fonction separate() de dplyr. Cette fonction est utilisée pour séparer une colonne de caractères en d’autres colonnes.Disons que nous avons un simple dataframe df (défini et uni dans la section unite) contenant une colonne case_ID, une colonne de caractères avec plusieurs symptômes, et une colonne de résultats. Notre objectif est de séparer la colonne symptoms en plusieurs colonnes, chacune contenant un symptôme.En supposant que les données sont passées (‘pipe’, en utilisant %>%) dans separate(), vous devez d’abord fournir la colonne à séparer dans la fonction seperate(). Ensuite, fournissez = comme un vecteur c( ) contenant les noms des nouvelles colonnes, comme indiqué ci-dessous.sep = le séparateur, peut être un caractère, ou un nombre (interprété comme la position du caractère à séparer)remove = FAUX par défaut, supprime la colonne sélectionnée du dataframe une fois séparée.convert = FALSE par défaut, si TRUE, les “NA” de la chaîne deviendront des NA.extra = ce contréle ce qui se passe s’il y plus de valeurs créées par la séparation de la colonne que de nouveaux noms de colonnes fournis.\nextra = \"warn\" signifie que vous verrez un avertissement mais que les valeurs excédentaires seront supprimées (par défaut).\nextra = \"drop\", signifie que les valeurs excédentaires seront abandonnées sans avertissement.\n**extra = \"merge\" ne fractionnera que le nombre de nouvelles colonnes listées dans - *cette configuration préservera toutes vos données**.\nextra = \"warn\" signifie que vous verrez un avertissement mais que les valeurs excédentaires seront supprimées (par défaut).extra = \"drop\", signifie que les valeurs excédentaires seront abandonnées sans avertissement.\n**extra = \"merge\" ne fractionnera que le nombre de nouvelles colonnes listées dans - *cette configuration préservera toutes vos données**.Voici un exemple avec extra = \"merge\" - Deux nouvelles colonnes sont définies mais tous les troisiémes symptômes ou plus sont combinés dans la deuxiéme colonne:Lorsque l’option par défaut est utilisée ci-dessous, R retourne un avertissement mais les troisiémes symptômes sont perdus:CAUTION: Si vous ne fournissez pas suffisamment de valeurs pour les nouvelles colonnes, vos données peuvent être tronquées.","code":"\n# troisiémes symptômes combinés dans la deuxiéme nouvelle colonne\ndf %>% \n  separate(symptoms, into = c(\"sym_1\", \"sym_2\"), sep=\",\", extra = \"merge\")## Warning: Expected 2 pieces. Missing pieces filled with `NA` in 1 rows [3].##   case_ID              sym_1          sym_2 outcome\n## 1       1           jaundice  fever, chills Recover\n## 2       2             chills   aches, pains   Death\n## 3       3              fever           <NA>   Death\n## 4       4           vomiting      diarrhoea Recover\n## 5       5 bleeding from gums          fever Recover\n## 6       6        rapid pulse       headache Recover\n# les troisiémes symptômes sont perdus\ndf %>% \n  separate(symptoms, into = c(\"sym_1\", \"sym_2\"), sep=\",\")## Warning: Expected 2 pieces. Additional pieces discarded in 2 rows [1, 2].## Warning: Expected 2 pieces. Missing pieces filled with `NA` in 1 rows [3].##   case_ID              sym_1      sym_2 outcome\n## 1       1           jaundice      fever Recover\n## 2       2             chills      aches   Death\n## 3       3              fever       <NA>   Death\n## 4       4           vomiting  diarrhoea Recover\n## 5       5 bleeding from gums      fever Recover\n## 6       6        rapid pulse   headache Recover"},{"path":"character_strings.html","id":"classer-par-ordre-alphabétique","chapter":"10 Caractères et chaînes de caractères","heading":"Classer par ordre alphabétique","text":"Vous pouvez trier plusieurs chaînes de caractères par ordre alphabétique. str_order() renvoie l’ordre (numérique), tandis que str_sort() renvoie les chaînes de caractères dans l’ordre alphabétique.Pour utiliser un alphabet différent, ajoutez l’argument locale =. Voir la liste complète des locales en entrant stringi::stri_locale_list() dans la console R.","code":"\n# chaînes de caractères\nhealth_zones <- c(\"Alba\", \"Takota\", \"Delta\")\n\n# renvoie l'ordre alphabétique\nstr_order(health_zones)## [1] 1 3 2\n# retourne les chaînes de caractères par ordre alphabétique\nstr_sort(health_zones)## [1] \"Alba\"   \"Delta\"  \"Takota\""},{"path":"character_strings.html","id":"fonctions-de-la-base-r","chapter":"10 Caractères et chaînes de caractères","heading":"Fonctions de la base R","text":"Il est courant de voir les fonctions base R paste() et paste0(), qui concaténent des vecteurs aprés avoir converti toutes les parties en caractères. Ces fonctions agissent de manière similaire à str_c() mais la syntaxe est sans doute plus compliquée - dans les parenthèses, chaque partie est séparée par une virgule. Les parties sont soit du texte en caractères (entre guillemets), soit des objets de code prédéfinis (sans guillemets). Par exemple:Les arguments sep = et collapse = peuvent être spécifiés. paste() est simplement paste0() avec un sep = \" \" (un espace) par défaut.","code":"\nn_beds <- 10\nn_masks <- 20\n\npaste0(\"Regional hospital needs \", n_beds, \" beds and \", n_masks, \" masks.\")## [1] \"Regional hospital needs 10 beds and 20 masks.\""},{"path":"character_strings.html","id":"nettoyer-et-standardiser","chapter":"10 Caractères et chaînes de caractères","heading":"10.3 Nettoyer et standardiser","text":"","code":""},{"path":"character_strings.html","id":"changer-la-casse","chapter":"10 Caractères et chaînes de caractères","heading":"Changer la casse","text":"Souvent, doit modifier la casse/capitalisation d’une valeur de chaîne de caractères, par exemple les noms des jursidictions. Utilisez str_to_upper(), str_to_lower(), et str_to_title(), de stringr, comme indiqué ci-dessous :En utilisant *base** R, l’exemple ci-dessus peut également être réalisé avec toupper() ou tolower().Mots en majusculesLa transformation de la chaîne pour que chaque mot soit en majuscule peut être réalisée avec str_to_title():Utilisez la fonction toTitleCase() du paquet tools pour ne mettre en majuscules que certains mots (les mots comme “”, “” et “” ne sont pas mis en majuscules).Vous pouvez également utiliser la fonction str_to_sentence(), qui ne met en majuscule que la premiére lettre de la chaîne.","code":"\nstr_to_upper(\"California\")## [1] \"CALIFORNIA\"\nstr_to_lower(\"California\")## [1] \"california\"\nstr_to_title(\"go to the US state of california \")## [1] \"Go To The Us State Of California \"\ntools::toTitleCase(\"This is the US state of california\")## [1] \"This is the US State of California\"\nstr_to_sentence(\"the patient must be transported\")## [1] \"The patient must be transported\""},{"path":"character_strings.html","id":"str_pad","chapter":"10 Caractères et chaînes de caractères","heading":"Longueur du bloc","text":"Utilisez la fonction str_pad() pour ajouter des caractères à une chaîne, jusqu’à une longueur minimale. Par défaut, des espaces sont ajoutés, mais vous pouvez également ajouter d’autres caractères en utilisant l’argument pad =.Par exemple, pour complèter des nombres avec des zéros en tête (comme pour les heures ou les minutes), vous pouvez complèter le nombre à une longueur minimale de 2 avec pad = \"0\".","code":"\n# Codes ICD de longueur différente\nICD_codes <- c(\"R10.13\",\n               \"R10.819\",\n               \"R17\")\n\n# Les codes ICD sont complétés à 7 caractères sur la droite\nstr_pad(ICD_codes, 7, \"right\")## [1] \"R10.13 \" \"R10.819\" \"R17    \"\n# Remplir avec des points au lieu d'espaces\nstr_pad(ICD_codes, 7, \"right\", pad = \".\")## [1] \"R10.13.\" \"R10.819\" \"R17....\"\n# Ajoutez des zéros à deux chiffres (par exemple, pour les minutes/heures)\nstr_pad(\"4\", 2, pad = \"0\") ## [1] \"04\"\n# Exemple utilisant une colonne numérique nommée \"heures\" (hours en Anglais)\n# hours <- str_pad(hours, 2, pad = \"0\")"},{"path":"character_strings.html","id":"tronquer","chapter":"10 Caractères et chaînes de caractères","heading":"Tronquer","text":"La fonction str_trunc() définit une longueur maximale pour chaque chaîne. Si une chaîne dépasse cette longueur, elle est tronquée (raccourcie) et une ellipse (…) est incluse pour indiquer que la chaîne était auparavant plus longue. Notez que l’ellipse est comptée dans la longueur. Les caractères d’ellipses peuvent être changés avec l’argument ellipsis =. L’argument optionnel side = spécifie où l’ellipse apparaîtra dans la chaîne tronquée (“gauche”, “droite”, ou “centre”).","code":"\noriginal <- \"Symptom onset on 4/3/2020 with vomiting\"\nstr_trunc(original, 10, \"center\")## [1] \"Symp...ing\""},{"path":"character_strings.html","id":"normaliser-la-longueur","chapter":"10 Caractères et chaînes de caractères","heading":"Normaliser la longueur","text":"Utilisez la fonction str_trunc() pour définir une longueur maximale, puis utilisez str_pad() pour étendre les chaînes trés courtes à cette longueur tronquée. Dans l’exemple ci-dessous, 6 est défini comme longueur maximale (une valeur est tronquée), puis une valeur trés courte est ajoutée pour atteindre la longueur de 6.","code":"\n# Codes CIM de longueur différente\nICD_codes   <- c(\"R10.13\",\n                 \"R10.819\",\n                 \"R17\")\n\n# tronquer à la longueur maximale de 6\nICD_codes_2 <- str_trunc(ICD_codes, 6)\nICD_codes_2## [1] \"R10.13\" \"R10...\" \"R17\"\n# étendre à une longueur minimale de 6\nICD_codes_3 <- str_pad(ICD_codes_2, 6, \"right\")\nICD_codes_3## [1] \"R10.13\" \"R10...\" \"R17   \""},{"path":"character_strings.html","id":"supprimer-les-espaces-avantaprés-les-chaînes-de-caractères","chapter":"10 Caractères et chaînes de caractères","heading":"Supprimer les espaces avant/aprés les chaînes de caractères","text":"Utilisez la fonction str_trim() pour supprimer les espaces, les nouvelles lignes (\\n) ou les tabulations (\\t) sur les côtés d’une entrée de chaîne de caractères. Ajoutez \"right\" (en français droite), \"left\" (en français gauche) ou \"\" (en français les deux) à la commande pour spécifier le côté à découper (par exemple, str_trim(x, \"right\").","code":"\n# Numéros d'identification avec espaces excédentaires à droite\nIDs <- c(\"provA_1852  \", # deux espaces excédentaires\n         \"provA_2345\",   # zero espace excédentaire\n         \"provA_9460 \")  # un espace excédentaire\n\n#  les identifiants sont coupés pour supprimer les espaces excédentaires du côté droit uniquement\nstr_trim(IDs)## [1] \"provA_1852\" \"provA_2345\" \"provA_9460\""},{"path":"character_strings.html","id":"supprimer-les-espaces-répétés-dans-les-chaînes-de-caractères","chapter":"10 Caractères et chaînes de caractères","heading":"Supprimer les espaces répétés dans les chaînes de caractères","text":"Utilisez la fonction str_squish() pour supprimer les espaces répétés qui apparaissent à l’intérieur d’une chaîne. Par exemple, pour convertir les espaces doubles en espaces simples. Elle supprime également les espaces, les retours à la ligne ou les tabulations à l’extérieur de la chaîne, comme str_trim().Entrez ?str_trim, ?str_pad dans votre console R pour voir plus de détails.","code":"\n# L'original contient des espaces supplémentaires dans la chaîne\nstr_squish(\"  Pt requires   IV saline\\n\") ## [1] \"Pt requires IV saline\""},{"path":"character_strings.html","id":"transformer-en-paragraphes","chapter":"10 Caractères et chaînes de caractères","heading":"Transformer en paragraphes","text":"Utilisez str_wrap() pour transformer un long texte non structuré en un paragraphe structuré avec une longueur de ligne fixe. Fournissez la longueur idéale de caractères pour chaque ligne, et la fonction applique un algorithme pour insérer des nouvelles lignes (\\n) dans le paragraphe, comme dans l’exemple ci-dessous.La fonction de base R cat()` peut être enroulée autour de la commande ci-dessus afin d’imprimer le résultat dans la console R.","code":"\npt_course <- \"Début des symptômes 1/4/2020 : vomissements, frissons, fièvre. Le patient a vu un guérisseur traditionnel dans son village natal le 2/4/2020. Le 5/4/2020, les symptômes du patient se sont aggravés et il a été admis à la clinique Lumta. Un échantillon a été prélevé et le patient a été transporté à l'hôpital régional le 6/4/2020. Le patient est décédé à l'hôpital régional le 7/4/2020.\"\n\nstr_wrap(pt_course, 40)## [1] \"Début des symptômes 1/4/2020 :\\nvomissements, frissons, fièvre. Le\\npatient a vu un guérisseur traditionnel\\ndans son village natal le 2/4/2020. Le\\n5/4/2020, les symptômes du patient se\\nsont aggravés et il a été admis à la\\nclinique Lumta. Un échantillon a été\\nprélevé et le patient a été transporté\\nà l'hôpital régional le 6/4/2020. Le\\npatient est décédé à l'hôpital régional\\nle 7/4/2020.\"\ncat(str_wrap(pt_course, 40))## Début des symptômes 1/4/2020 :\n## vomissements, frissons, fièvre. Le\n## patient a vu un guérisseur traditionnel\n## dans son village natal le 2/4/2020. Le\n## 5/4/2020, les symptômes du patient se\n## sont aggravés et il a été admis à la\n## clinique Lumta. Un échantillon a été\n## prélevé et le patient a été transporté\n## à l'hôpital régional le 6/4/2020. Le\n## patient est décédé à l'hôpital régional\n## le 7/4/2020."},{"path":"character_strings.html","id":"gérer-par-position","chapter":"10 Caractères et chaînes de caractères","heading":"10.4 Gérer par position","text":"","code":""},{"path":"character_strings.html","id":"extraire-par-position-de-caractère","chapter":"10 Caractères et chaînes de caractères","heading":"Extraire par position de caractère","text":"Utilisez la fonction str_sub() pour retourner seulement une partie d’une chaîne de caractères. La fonction prend trois arguments principaux :le(s) vecteur(s) de caractèresla position de départ dans le vecteurla position finale dans le vecteurQuelques remarques sur les numéros de position :Si le numéro de position est positif, la position est comptée à partir de l’extrémité gauche de la chaîne.Si le numéro de position est négatif, il est compté à partir de l’extrémité droite de la chaîne.Les numéros de position sont inclusifs.Les positions qui dépassent la chaîne de caractères seront tronquées (supprimées).Voici quelques exemples appliqués à la chaîne “pneumonie” :","code":"\n# position de départ et position finale troisiéme en partant de la gauche (3éme lettre en partant de la gauche)\nstr_sub(\"pneumonia\", 3, 3)## [1] \"e\"\n# 0 n'est pas présent, donc cela renvoie \"\"\nstr_sub(\"pneumonia\", 0, 0)## [1] \"\"\n# # 6éme en partant de la gauche, jusqu'à  la 1ére en partant de la droite\nstr_sub(\"pneumonia\", 6, -1)## [1] \"onia\"\n# 5éme de la droite, vers le 2éme de la droite\nstr_sub(\"pneumonia\", -5, -2)## [1] \"moni\"\n# 4éme en partant de la gauche, jusqu'à  une position en dehors de la chaîne de caractères\nstr_sub(\"pneumonia\", 4, 15)## [1] \"umonia\""},{"path":"character_strings.html","id":"extraire-par-position-de-mot","chapter":"10 Caractères et chaînes de caractères","heading":"Extraire par position de mot","text":"Pour extraire le niéme “mot”, utilisez la fonction word(), du paquet stringr. Fournissez la ou les chaînes de caractères, puis la premiére position du mot à extraire, et la dernière position du mot à extraire.Par défaut, le séparateur entre les mots est supposé être un espace, sauf indication contraire avec sep = (par exemple, sep = \"_\" où les mots sont séparés par des caractères de soulignement).","code":"\n# chaînes de caractères à évaluer\nchief_complaints <- c(\"I just got out of the hospital 2 days ago, but still can barely breathe.\",\n                      \"My stomach hurts\",\n                      \"Severe ear pain\")\n\n# extract 1st to 3rd words of each string\nword(chief_complaints, start = 1, end = 3, sep = \" \")## [1] \"I just got\"       \"My stomach hurts\" \"Severe ear pain\""},{"path":"character_strings.html","id":"remplacer-par-la-position-du-caractère","chapter":"10 Caractères et chaînes de caractères","heading":"Remplacer par la position du caractère","text":"str_sub() apparié avec l’opérateur d’affectation (<-) peut être utilisé pour modifier une partie d’une chaîne :Voici ci-dessus Un exemple appliqué à plusieurs chaînes de caractères (par exemple, un vecteur de mots ou une colonne). Notez l’expansion en longueur de “HIV”.","code":"\nword <- \"pneumonia\"\n\n# convertissez les troisiéme et quatriéme caractères en X \nstr_sub(word, 3, 4) <- \"XX\"\n\n# imprimer\nword## [1] \"pnXXmonia\"\nwords <- c(\"pneumonia\", \"tubercolosis\", \"HIV\")\n\n# convertissez les troisiéme et quatriéme caractères en X \nstr_sub(words, 3, 4) <- \"XX\"\n\nwords## [1] \"pnXXmonia\"    \"tuXXrcolosis\" \"HIXX\""},{"path":"character_strings.html","id":"evaluer-la-longueur","chapter":"10 Caractères et chaînes de caractères","heading":"Evaluer la longueur","text":"Alternativement, utilisez la fonction nchar() de base R.","code":"\nstr_length(\"abc\")## [1] 3"},{"path":"character_strings.html","id":"motifs","chapter":"10 Caractères et chaînes de caractères","heading":"10.5 Motifs","text":"De nombreuses fonctions du paquet stringr fonctionnent pour détecter, localiser, extraire, correspondre, remplacer et séparer en fonction d’un motif spécifié.","code":""},{"path":"character_strings.html","id":"détecter-un-motif","chapter":"10 Caractères et chaînes de caractères","heading":"détecter un motif","text":"Utilisez la fonction str_detect() comme ci-dessous pour détecter la présence/absence d’un motif dans une chaîne de caractères. Fournissez d’abord la chaîne ou le vecteur à rechercher (string =), puis le motif à rechercher (pattern =). Notez que par défaut, la recherche est sensible à la casse!L’argument negate = peut être inclus et mis à TRUE (en français VRAI) si vous voulez savoir si le motif n’est PAS présent.Pour ignorer les majuscules et les minuscules, intégrez le motif dans regex(), et dans regex() ajoutez l’argument ignore_case = TRUE (ou T en raccourci).Lorsque str_detect() est appliqué à un vecteur de caractères ou à une colonne de dataframe, il renvoie TRUE (en français VRAI) ou FALSE (en français FAUX) pour chacune des valeurs.Si vous avez besoin de compter les TRUEs, utilisez la fonction sum() sur les valeurs ou le vecteur retourné(es). Ceci compte le nombre de TRUE (VRAI) dans les valeurs ou le vecteur retourné(es).Pour effectuer une recherche incluant plusieurs termes, incluez-les séparés par des barres (|) dans l’argument pattern =, comme indiqué ci-dessous:Si vous avez besoin de construire une longue liste de termes de recherche, vous pouvez les combiner en utilisant str_c() et sep = |, et assigner ceci à un objet. Vous pouvez ensuite référencer le vecteur par le nom de l’objet. L’exemple ci-dessous combine les termes de recherche d’une occupation possible en un seul objet.Cette commande renvoie le nombre de professions qui contiennent l’un des termes de recherche pour les praticiens médicaux (occupation_med_frontline):Fonctions de recherche de chaînes de caractères de base RLa fonction de R base grepl() fonctionne de manière similaire à str_detect(), dans le sens qu’elle recherche les correspondances avec un motif et retourne un vecteur logique. La syntaxe de base est grepl(pattern, strings_to_search, ignore.case = FALSE, ...). Un avantage est que l’argument ignore.case est plus facile à écrire (il n’y pas besoin d’impliquer la fonction regex()).Les fonctions sub() et gsub() de base R agissent de manière similaire à str_replace(). Leur syntaxe générale suit ce format : gsub(motif, remplacement, chaînes_a_rechercher, ignore.case = FALSE). sub() remplacera seulement la premiére instance du motif, alors que gsub() remplacera toutes les instances du motif.","code":"\nstr_detect(string = \"primary school teacher\", pattern = \"teach\")## [1] TRUE\nstr_detect(string = \"primary school teacher\", pattern = \"teach\", negate = TRUE)## [1] FALSE\nstr_detect(string = \"Teacher\", pattern = regex(\"teach\", ignore_case = T))## [1] TRUE\n# un vecteur/colonne de professions \noccupations <- c(\"field laborer\",\n                 \"university professor\",\n                 \"primary school teacher & tutor\",\n                 \"tutor\",\n                 \"nurse at regional hospital\",\n                 \"lineworker at Amberdeen Fish Factory\",\n                 \"physican\",\n                 \"cardiologist\",\n                 \"office worker\",\n                 \"food service\")\n\n# détecter la présence du motif \"teach\" dans chaque chaîne - la valeur retournée est un vecteur de VRAI/FAUX\nstr_detect(occupations, \"teach\")##  [1] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\nsum(str_detect(occupations, \"teach\"))## [1] 1\nsum(str_detect(string = occupations, pattern = \"teach|professor|tutor\"))## [1] 3\n# termes de recherche\noccupation_med_frontline <- str_c(\"medical\", \"medicine\", \"hcw\", \"healthcare\", \"home care\", \"home health\",\n                                \"surgeon\", \"doctor\", \"doc\", \"physician\", \"surgery\", \"peds\", \"pediatrician\",\n                               \"intensivist\", \"cardiologist\", \"coroner\", \"nurse\", \"nursing\", \"rn\", \"lpn\",\n                               \"cna\", \"pa\", \"physician assistant\", \"mental health\",\n                               \"emergency department technician\", \"resp therapist\", \"respiratory\",\n                                \"phlebotomist\", \"pharmacy\", \"pharmacist\", \"hospital\", \"snf\", \"rehabilitation\",\n                               \"rehab\", \"activity\", \"elderly\", \"subacute\", \"sub acute\",\n                                \"clinic\", \"post acute\", \"therapist\", \"extended care\",\n                                \"dental\", \"dential\", \"dentist\", sep = \"|\")\n\noccupation_med_frontline## [1] \"medical|medicine|hcw|healthcare|home care|home health|surgeon|doctor|doc|physician|surgery|peds|pediatrician|intensivist|cardiologist|coroner|nurse|nursing|rn|lpn|cna|pa|physician assistant|mental health|emergency department technician|resp therapist|respiratory|phlebotomist|pharmacy|pharmacist|hospital|snf|rehabilitation|rehab|activity|elderly|subacute|sub acute|clinic|post acute|therapist|extended care|dental|dential|dentist\"\nsum(str_detect(string = occupations, pattern = occupation_med_frontline))## [1] 2"},{"path":"character_strings.html","id":"convertir-les-virgules-en-points","chapter":"10 Caractères et chaînes de caractères","heading":"Convertir les virgules en points","text":"Voici un exemple d’utilisation de gsub() pour convertir des virgules en points dans un vecteur de nombres. Cela peut être utile si vos données proviennent de différents endroits dans le monde avec une syntaxe de langue différente.L’exemple ci-dessous utilise deux applications de gsub. L’application interne gsub(), qui agit en premier sur l’objet lengths, convertit tous les points en “” sans espace. Le caractère point “.” doit être “spécifié” avec deux slashs pour signifier réellement un point, parce que “.” en regex sans deux slashs signifie ” n’importe quel caractère”. Ensuite, le résultat (avec seulement des virgules) est passé à la fonction externe gsub() dans laquelle les virgules sont remplacées par des points.","code":"\nlengths <- c(\"2.454,56\", \"1,2\", \"6.096,5\")\n\nas.numeric(gsub(pattern = \",\",                # trouver les virgules    \n                replacement = \".\",            # remplacer par des points\n                x = gsub(\"\\\\.\", \"\", lengths)  # vecteur avec d'autres points supprimés \n                )\n           )                                  # convertir le résultat en numérique"},{"path":"character_strings.html","id":"remplacer-tous-les-éléments","chapter":"10 Caractères et chaînes de caractères","heading":"Remplacer tous les éléments","text":"Utilisez la fonction str_replace_all() comme un outil de “recherche et remplacement”. Vous fournissez d’abord les chaînes à évaluer à string =, puis le motif à remplacer à pattern =, et enfin la valeur de remplacement à replacement =. L’exemple ci-dessous remplace toutes les occurrences de “dead” (en français mort) par “deceased” (en français décédés). Notez que cette opération est sensible à la casse.Remarques :Pour remplacer un motif par NA, utilisez str_replace_na().La fonction str_replace() remplace uniquement la premiére instance du motif dans chaque chaîne évaluée.","code":"\noutcome <- c(\"Karl: dead\",\n            \"Samantha: dead\",\n            \"Marco: not dead\")\n\nstr_replace_all(string = outcome, pattern = \"dead\", replacement = \"deceased\")## [1] \"Karl: deceased\"      \"Samantha: deceased\"  \"Marco: not deceased\""},{"path":"character_strings.html","id":"détecter-en-utilisant-des-instructions-logiques","chapter":"10 Caractères et chaînes de caractères","heading":"détecter en utilisant des instructions logiques","text":"l’intérieur de case_when()str_detect() est souvent utilisé dans case_when() (du paquet dplyr). Disons que occupations est une colonne de la linelist (liste linéaire ou liste de cas). La fonction mutate() ci-dessous crée une nouvelle colonne appelée is_educator en utilisant la logique conditionnelle via case_when(). Consultez la page sur le nettoyage des données pour en savoir plus sur la méthode case_when().Par ailleurs, il peut être important d’ajouter des critéres d’exclusion à la logique conditionnelle (negate = F) :","code":"\ndf <- df %>% \n  mutate(is_educator = case_when(\n    #  recherche de termes dans la profession, non sensible à la casse\n    str_detect(occupations,\n               regex(\"teach|prof|tutor|university\",\n                     ignore_case = TRUE))              ~ \"Educator\",\n    # all others\n    TRUE                                               ~ \"Not an educator\"))df <- df %>% \n  # la valeur de la nouvelle colonne is_educator est basée sur la logique conditionnelle\n  mutate(is_educator = case_when(\n    \n    # la colonne occupation doit répondre à 2 critéres pour se voir attribuer \"Educateur\" :\n    # elle doit avoir un terme de recherche ET PAS de terme d'exclusion\n    \n    #  Doit avoir un terme de recherche\n    str_detect(occupations,\n               regex(\"teach|prof|tutor|university\", ignore_case = T)) &              \n    \n    # AND ne doit PAS avoir de terme d'exclusion\n    str_detect(occupations,\n               regex(\"admin\", ignore_case = T),\n               negate = TRUE                        ~ \"Educator\"\n    \n    # Toutes les lignes ne répondant pas aux critéres ci-dessus\n    TRUE                                            ~ \"Not an educator\"))"},{"path":"character_strings.html","id":"localiser-la-position-du-motif","chapter":"10 Caractères et chaînes de caractères","heading":"Localiser la position du motif","text":"Pour localiser la premiére position d’un motif, utilisez la fonction str_locate(). Elle produit une position de début et de fin.Comme les autres fonctions de la famille str, il existe une version “_all” (str_locate_all()) qui renvoie les positions de toutes les instances du motif dans chaque chaîne. Cette fonction renvoie les valeurs sous forme de liste.","code":"\nstr_locate(\"I wish\", \"sh\")##      start end\n## [1,]     5   6\nphrases <- c(\"I wish\", \"I hope\", \"he hopes\", \"He hopes\")\n\nstr_locate(phrases, \"h\" ) # position de la *premiére* instance du motif##      start end\n## [1,]     6   6\n## [2,]     3   3\n## [3,]     1   1\n## [4,]     4   4\nstr_locate_all(phrases, \"h\" ) # position de *chaque* instance du motif## [[1]]\n##      start end\n## [1,]     6   6\n## \n## [[2]]\n##      start end\n## [1,]     3   3\n## \n## [[3]]\n##      start end\n## [1,]     1   1\n## [2,]     4   4\n## \n## [[4]]\n##      start end\n## [1,]     4   4"},{"path":"character_strings.html","id":"extraire-une-correspondance","chapter":"10 Caractères et chaînes de caractères","heading":"Extraire une correspondance","text":"str_extract_all() retourne les motifs de correspondance eux-mêmes, ce qui est trés utile lorsque vous avez proposé plusieurs motifs via des conditions “” (en français OU). Par exemple, si vous cherchez dans le vecteur de chaînes de professions (voir l’exemple précédent) soit “teach”, “prof”, ou “tutor”.str_extract_all() renvoie une liste qui contient toutes les correspondances pour chaque chaîne évaluée. Voyez ci-dessous comment l’occupation 3 contient deux correspondances de motifs.str_extract() extrait seulement la premiére correspondance dans chaque chaîne évaluée, produisant un vecteur de caractères avec un élément pour chaque chaîne évaluée. Elle retourne NA lorsqu’il n’y pas de correspondance. Les NAs peuvent être supprimés en enveloppant le vecteur retourné avec na.exclude(). Notez que la deuxiéme correspondance de l’occupation 3 n’est pas affichée.","code":"\nstr_extract_all(occupations, \"teach|prof|tutor\")## [[1]]\n## character(0)\n## \n## [[2]]\n## [1] \"prof\"\n## \n## [[3]]\n## [1] \"teach\" \"tutor\"\n## \n## [[4]]\n## [1] \"tutor\"\n## \n## [[5]]\n## character(0)\n## \n## [[6]]\n## character(0)\n## \n## [[7]]\n## character(0)\n## \n## [[8]]\n## character(0)\n## \n## [[9]]\n## character(0)\n## \n## [[10]]\n## character(0)\nstr_extract(occupations, \"teach|prof|tutor\")##  [1] NA      \"prof\"  \"teach\" \"tutor\" NA      NA      NA      NA      NA      NA"},{"path":"character_strings.html","id":"sous-ensemble-et-comptage","chapter":"10 Caractères et chaînes de caractères","heading":"Sous-ensemble et comptage","text":"Les fonctions alignées comprennent str_subset() et str_count().str_subset() renvoie les valeurs réelles qui contiennent le motif :str_count() renvoie un vecteur de nombres : le nombre de fois qu’un terme de recherche apparaît dans chaque valeur évaluée.","code":"\nstr_subset(occupations, \"teach|prof|tutor\")## [1] \"university professor\"           \"primary school teacher & tutor\"\n## [3] \"tutor\"\nstr_count(occupations, regex(\"teach|prof|tutor\", ignore_case = TRUE))##  [1] 0 1 2 1 0 0 0 0 0 0"},{"path":"character_strings.html","id":"groupes-de-regex","chapter":"10 Caractères et chaînes de caractères","heading":"Groupes de regex","text":"EN CONSTRUCTION","code":""},{"path":"character_strings.html","id":"caractères-spéciaux","chapter":"10 Caractères et chaînes de caractères","heading":"10.6 caractères spéciaux","text":"Slash arriére \\ comme échappementLa barre oblique inverse \\ est utilisée pour “échapper” à la signification du caractère suivant. Ainsi, une barre oblique inversée peut être utilisée pour afficher un guillemet dans d’autres guillemets (\\\") - le guillemet central ne “cassera” pas les guillemets environnants.Note - Si vous voulez afficher une barre oblique inverse, vous devez échapper à sa signification avec une autre barre oblique inverse. Ainsi, vous devez écrire deux barres obliques inversées \\\\ pour en afficher une.**caractères spéciaux ”Exécutez ?\"'\" dans la console R pour afficher la liste complète de ces caractères spéciaux (elle apparaîtra dans le volet d’aide de RStudio).","code":""},{"path":"character_strings.html","id":"expressions-régulières-regex","chapter":"10 Caractères et chaînes de caractères","heading":"10.7 Expressions régulières (regex)","text":"","code":""},{"path":"character_strings.html","id":"regex-et-caractères-spéciaux","chapter":"10 Caractères et chaînes de caractères","heading":"10.8 Regex et caractères spéciaux","text":"Les expressions régulières, ou “regex”, sont un langage concis pour décrire des motifs dans des chaînes de caractères. Si vous n’étes pas familier avec ce langage, une expression régulière peut ressembler à une langue étrangére. Nous allons essayer de démystifier un peu ce langage.Une grande partie de cette section est adaptée de ce tutoriel et de cette cheatsheet. Nous adaptons ici de manière sélective, sachant que ce manuel pourrait être consulté par des personnes n’ayant pas d’accés à l’Internet pour consulter les autres tutoriels.Une expression régulière est souvent utilisée pour extraire des motifs spécifiques d’un texte “non structuré”, par exemple des notes médicales, des plaintes principales, des antécédents du patient ou d’autres colonnes de texte libre dans un dataframe.Il existe quatre outils de base que l’peut utiliser pour créer une expression régulière de base :Jeux de caractèresMéta-caractèresQuantificateursGroupesJeux de caractèresLes jeux de caractères sont une façon d’exprimer les options de liste pour une correspondance de caractères, entre parenthèses. Ainsi, une correspondance sera déclenchée si l’un des caractères entre parenthèses est trouvé dans la chaîne. Par exemple, pour rechercher des voyelles, peut utiliser ce jeu de caractères: “[aeiou]”. Voici d’autres jeux de caractères courants:Les jeux de caractères peuvent être combinés à l’intérieur d’une même parenthèse (sans espace !), par exemple \"[-Za-z]\" (toute lettre majuscule OU minuscule), ou un autre exemple \"[t-z0-5]\" (minuscules de t à z OU nombre de 0 à 5).Meta charactersLes métacaractères sont des raccourcis pour les jeux de caractères. Certains des plus importants sont énumérés ci-dessous :QuantificateursEn général, vous ne souhaitez pas rechercher une correspondance sur un seul caractère. Les quantificateurs vous permettent de désigner la longueur des lettres/chiffres pour permettre une correspondance plus spécifique.Les quantificateurs sont des nombres écrits entre accolades { } aprés le caractère qu’ils quantifient, par exemple:\"{2}\" renverra les instances de deux lettres majuscules .\"{2,4}\" renverra les instances de deux à quatre lettres majuscules (ne mettez pas d’espace !).\"{2,}\" renverra les instances de deux lettres majuscules ou plus.\"+\" renverra les instances de une ou plusieurs lettres majuscules (groupe étendu jusqu’à ce qu’un caractère différent soit rencontré).Faites précéder d’un astérisque * pour obtenir zéro ou plus de correspondances (utile si vous n’étes pas sûr que le motif soit présent).En utilisant le symbole plus + comme quantificateur, la correspondance se fera jusqu’à ce qu’un caractère différent soit rencontré. Par exemple, cette expression retournera tous les mots (caractères alpha : \"[-Za-z]+\").Lorsqu’un quantificateur de {2} est utilisé, seules les paires de consécutifs sont renvoyées. Deux paires sont identifiées dans AAAA.Lorsqu’un quantificateur de {2,4} est utilisé, les groupes de consécutifs d’une longueur de deux à quatre sont renvoyés.Avec le quantificateur +, les groupes de un ou plus sont renvoyés :Relative positionIl existe des exigences spécifiques pour ce qui précéde ou suit un motif. Par exemple, pour extraire des phrases, “deux chiffres qui sont suivis d’un point” (\"\"). (?<=\\.)\\s(?=[-Z])GroupesLa capture de groupes dans votre expression régulière est un moyen d’obtenir des valeurs plus organisées lors de l’extraction.Exemples de regexVous trouverez ci-dessous un texte libre pour les exemples. Nous allons essayer d’en extraire des informations utiles en utilisant un terme de recherche par expression régulière.Cette expression correspond à tous les mots (tout caractère jusqu’à la frappe d’un non-caractère tel qu’un espace):L’expression \"[0-9]{1,2}\" correspond à des nombres consécutifs de 1 ou 2 chiffres. pourrait aussi l’écrire \"\\d{1,2}\", ou \"[:digit:]{1,2}\".”\n“.Vous pouvez consulter une liste utile d’expressions regex et de conseils à la page 2 de cette cheatsheet.Voir également ce tutoriel.","code":"\n# chaîne de caractères pour tester les quantificateurs\ntest <- \"A-AA-AAA-AAAA\"\nstr_extract_all(test, \"A{2}\")## [[1]]\n## [1] \"AA\" \"AA\" \"AA\" \"AA\"\nstr_extract_all(test, \"A{2,4}\")## [[1]]\n## [1] \"AA\"   \"AAA\"  \"AAAA\"\nstr_extract_all(test, \"A+\")## [[1]]\n## [1] \"A\"    \"AA\"   \"AAA\"  \"AAAA\"\nstr_extract_all(test, \"\")## [[1]]\n##  [1] \"A\" \"-\" \"A\" \"A\" \"-\" \"A\" \"A\" \"A\" \"-\" \"A\" \"A\" \"A\" \"A\"\npt_note <- \"Le patient est arrivé aux urgences de l'hôpital Broward à 18h00 le 6/12/2005. Le patient s'est présenté avec une douleur abdominale irradiant du quadrant LR. La peau du patient était pâle, fraîche et moite. Sa température était de 99,8 degrés Farinheit. Le pouls du patient était de 100 bpm et filant. La fréquence respiratoire était de 29 par minute.\"\nstr_extract_all(pt_note, \"[A-Za-z]+\")## [[1]]\n##  [1] \"Le\"           \"patient\"      \"est\"          \"arriv\"        \"aux\"         \n##  [6] \"urgences\"     \"de\"           \"l\"            \"h\"            \"pital\"       \n## [11] \"Broward\"      \"h\"            \"le\"           \"Le\"           \"patient\"     \n## [16] \"s\"            \"est\"          \"pr\"           \"sent\"         \"avec\"        \n## [21] \"une\"          \"douleur\"      \"abdominale\"   \"irradiant\"    \"du\"          \n## [26] \"quadrant\"     \"LR\"           \"La\"           \"peau\"         \"du\"          \n## [31] \"patient\"      \"tait\"         \"p\"            \"le\"           \"fra\"         \n## [36] \"che\"          \"et\"           \"moite\"        \"Sa\"           \"temp\"        \n## [41] \"rature\"       \"tait\"         \"de\"           \"degr\"         \"s\"           \n## [46] \"Farinheit\"    \"Le\"           \"pouls\"        \"du\"           \"patient\"     \n## [51] \"tait\"         \"de\"           \"bpm\"          \"et\"           \"filant\"      \n## [56] \"La\"           \"fr\"           \"quence\"       \"respiratoire\" \"tait\"        \n## [61] \"de\"           \"par\"          \"minute\"\nstr_extract_all(pt_note, \"[0-9]{1,2}\")## [[1]]\n##  [1] \"18\" \"00\" \"6\"  \"12\" \"20\" \"05\" \"99\" \"8\"  \"10\" \"0\"  \"29\""},{"path":"character_strings.html","id":"resources","chapter":"10 Caractères et chaînes de caractères","heading":"10.9 Resources","text":"Une fiche de référence pour les fonctions du paquet stringr peut être trouvée iciUne vignette sur stringr peut être trouvée ici.","code":""},{"path":"factors.html","id":"factors","chapter":"11 Facteurs","heading":"11 Facteurs","text":"En R, les facteurs sont une classe de données qui permettent de créer des catégories ordonnées avec un ensemble fixe de valeurs acceptables.En règle générale, vous convertissez une colonne de la classe caractères ou numérique en un facteur si vous souhaitez définir un ordre intrinsèque aux valeurs (“niveaux”) afin qu’elles puissent être affichées de manière non alphabétique dans les graphiques et les tableaux. Une autre utilisation courante des facteurs consiste à normaliser les légendes des graphiques afin qu’elles ne fluctuent pas si certaines valeurs sont temporairement absentes des données.Cette page présente l’utilisation des fonctions du package forcats (un nom court pour “categorical variables”) et de certaines fonctions R base. Nous abordons également l’utilisation de lubridate et aweek pour les cas de facteurs spéciaux liés aux semaines épidémiologiques.Une liste complète des fonctions du pacakge forcats est disponible en ligne ici. Nous présentons ci-dessous quelques-unes des fonctions les plus courantes.","code":""},{"path":"factors.html","id":"preparation-1","chapter":"11 Facteurs","heading":"11.1 Preparation","text":"","code":""},{"path":"factors.html","id":"chargement-des-paquets","chapter":"11 Facteurs","heading":"Chargement des paquets","text":"Ce morceau de code montre le chargement des packages nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le package si nécessaire et le charge pour l’utiliser. Vous pouvez également charger les packages installés avec library() de base R. Voir la page sur R basics pour plus d’informations sur les packages R.","code":"\npacman::p_load(\n  rio,           # importer/exporter\n  here,          # chemin des fichiers\n  lubridate,     # travailler avec les dates\n  forcats,       # facteurs\n  aweek,         # creer epiweeks avec les niveaux des facteurs\n  janitor,       # tableau\n  tidyverse      # données management et visualisation\n  )"},{"path":"factors.html","id":"importer-données","chapter":"11 Facteurs","heading":"Importer données","text":"Nous importons le jeu de données des cas d’une épidémie d’Ebola simulée. Si vous voulez suivre, , cliquer pour telecharger le jeu de données “nettoyé” linelist (.rds file). Importez vos données avec la fonction import() du package rio (elle accepte de nombreux types de fichiers comme .xlsx, .rds, .csv - voir la page Importation et exportation pour plus de détails).","code":"\n# importer ton jeu de donnée\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"factors.html","id":"fct_newcat","chapter":"11 Facteurs","heading":"Nouveau variable qualitative","text":"Pour la démonstration dans cette page, nous utiliserons un scénario commun - la création d’une nouvelle variable catégorielle.Notez que si vous convertissez une colonne numérique en facteur de classe, vous ne serez pas en mesure de calculer des statistiques numériques sur celle-ci.","code":""},{"path":"factors.html","id":"creation-de-colonnes","chapter":"11 Facteurs","heading":"Creation de colonnes","text":"Nous utilisons la colonne existante days_onset_hosp (jours entre l’apparition des symptômes et l’admission à l’hôpital) et créons une nouvelle colonne delay_cat en classant chaque ligne dans l’une de plusieurs catégories. Nous faisons cela avec la fonction dplyr case_when(), qui applique séquentiellement des critères logiques (côté droit) à chaque ligne et renvoie la valeur correspondante côté gauche pour la nouvelle colonne delay_cat. Vous trouverez plus d’informations sur la fonction case_when() dans Nettoyage des données et des fonctions de base.","code":"\nlinelist <- linelist %>% \n  mutate(delay_cat = case_when(\n    # critere                                 # nouveau valeur si vrai\n    days_onset_hosp < 2                        ~ \"<2 days\",\n    days_onset_hosp >= 2 & days_onset_hosp < 5 ~ \"2-5 days\",\n    days_onset_hosp >= 5                       ~ \">5 days\",\n    is.na(days_onset_hosp)                     ~ NA_character_,\n    TRUE                                       ~ \"Check me\"))  "},{"path":"factors.html","id":"ordre-des-valeurs-par-defaut","chapter":"11 Facteurs","heading":"Ordre des valeurs par defaut","text":"Telle que créée avec case_when(), la nouvelle colonne delay_cat est une colonne catégorielle de la classe Character - pas encore un facteur. Ainsi, dans un tableau de fréquence, nous voyons que les valeurs uniques apparaissent dans un ordre alphanumérique par défaut - un ordre qui n’pas beaucoup de sens intuitif :De même, si nous réalisons un diagramme à barres, les valeurs apparaissent également dans cet ordre sur l’axe des x (voir la page sur les bases de ggplot pour en savoir plus sur ggplot2 - le package de visualisation le plus courant dans R).","code":"\ntable(linelist$delay_cat, useNA = \"always\")## \n##  <2 days  >5 days 2-5 days     <NA> \n##     2990      602     2040      256\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = delay_cat))"},{"path":"factors.html","id":"convertir-en-facteur","chapter":"11 Facteurs","heading":"11.2 Convertir en facteur","text":"Pour convertir une colonne de caractères ou de chiffres en facteur de classe, vous pouvez utiliser n’importe quelle fonction du package forcats (plusieurs sont détaillées ci-dessous). Elles convertiront en facteur de classe et effectueront ou permettront un certain ordre des niveaux - par exemple, l’utilisation de fct_relevel() vous permet de spécifier manuellement l’ordre des niveaux. La fonction as_factor() convertit simplement la classe sans autres capacités.La fonction R base factor() convertit une colonne en facteur et vous permet de spécifier manuellement l’ordre des niveaux, comme un vecteur de caractères à son argument levels =.Ci-dessous, nous utilisons mutate() et fct_relevel() pour convertir la colonne delay_cat de la classe caractère à la classe facteur. La colonne delay_cat est créée dans la section Préparation ci-dessus.Les “valeurs” uniques de cette colonne sont maintenant considérées comme des “niveaux” du facteur.\nLes niveaux ont un ordre, qui peut être affiché avec la fonction base R levels(), ou alternativement visualisé dans un tableau de comptage via table() de base R ou tabyl() de janitor. Par défaut, l’ordre des niveaux sera alpha-numérique, comme auparavant. Notez que NA n’est pas un niveau de facteur.La fonction fct_relevel() l’utilité supplémentaire de vous permettre de spécifier manuellement l’ordre des niveaux. Il suffit d’écrire les valeurs des niveaux dans l’ordre, entre guillemets, séparés par des virgules, comme indiqué ci-dessous. Notez que l’orthographe doit correspondre exactement aux valeurs. Si vous voulez créer des niveaux qui n’existent pas dans les données, utilisez plutôt fct_expand()).Nous pouvons maintenant voir que les niveaux sont ordonnés, comme spécifié dans la commande précédente, dans un ordre raisonnable.Maintenant, l’ordre de l’intrigue aussi un sens plus intuitif.","code":"\nlinelist <- linelist %>%\n  mutate(delay_cat = fct_relevel(delay_cat))\nlevels(linelist$delay_cat)## [1] \"<2 days\"  \">5 days\"  \"2-5 days\"\nlinelist <- linelist %>%\n  mutate(delay_cat = fct_relevel(delay_cat, \"<2 days\", \"2-5 days\", \">5 days\"))\nlevels(linelist$delay_cat)## [1] \"<2 days\"  \"2-5 days\" \">5 days\"\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = delay_cat))"},{"path":"factors.html","id":"ajouter-ou-enlever-des-niveaux","chapter":"11 Facteurs","heading":"11.3 Ajouter ou enlever des niveaux","text":"","code":""},{"path":"factors.html","id":"fct_add","chapter":"11 Facteurs","heading":"Ajouter","text":"Si vous devez ajouter des niveaux à un facteur, vous pouvez le faire avec fct_expand(). Il suffit d’écrire le nom de la colonne suivi des nouveaux niveaux (séparés par des virgules). En tabulant les valeurs, nous pouvons voir les nouveaux niveaux et le nombre de zéros. Vous pouvez utiliser table() de base R, ou tabyl() de janitor :Note : il existe une fonction spéciale forcats pour ajouter facilement les valeurs manquantes (NA) comme niveau. Voir la section sur les Valeurs manquantes ci-dessous.","code":"\nlinelist %>% \n  mutate(delay_cat = fct_expand(delay_cat, \"Not admitted to hospital\", \"Transfer to other jurisdiction\")) %>% \n  tabyl(delay_cat)   # afficher le tableau##                       delay_cat    n    percent valid_percent\n##                         <2 days 2990 0.50781250     0.5308949\n##                        2-5 days 2040 0.34646739     0.3622159\n##                         >5 days  602 0.10224185     0.1068892\n##        Not admitted to hospital    0 0.00000000     0.0000000\n##  Transfer to other jurisdiction    0 0.00000000     0.0000000\n##                            <NA>  256 0.04347826            NA"},{"path":"factors.html","id":"enlever","chapter":"11 Facteurs","heading":"Enlever","text":"Si vous utilisez fct_drop(), les niveaux “inutilisés” avec des comptes nuls seront supprimés de l’ensemble des niveaux. Les niveaux que nous avons ajoutés ci-dessus (“Non admis à l’hôpital”) existent en tant que niveau mais aucune ligne n’réellement ces valeurs. Ils seront donc supprimés en appliquant fct_drop() à notre colonne de facteurs :","code":"\nlinelist %>% \n  mutate(delay_cat = fct_drop(delay_cat)) %>% \n  tabyl(delay_cat)##  delay_cat    n    percent valid_percent\n##    <2 days 2990 0.50781250     0.5308949\n##   2-5 days 2040 0.34646739     0.3622159\n##    >5 days  602 0.10224185     0.1068892\n##       <NA>  256 0.04347826            NA"},{"path":"factors.html","id":"fct_adjust","chapter":"11 Facteurs","heading":"11.4 Ajuster l’ordre des niveaux","text":"Le package forcats offre des fonctions utiles pour ajuster facilement l’ordre des niveaux d’un facteur (après qu’une colonne ait été définie comme facteur de classe) :Ces fonctions peuvent être appliquées à une colonne de facteurs dans deux contextes :la colonne dans le dataframe, comme d’habitude, afin que la transformation soit disponible pour toute utilisation ultérieure des données.À l’intérieur d’un graphique, de sorte que la modification soit appliquée uniquement à l’intérieur du graphique.","code":""},{"path":"factors.html","id":"manuellement","chapter":"11 Facteurs","heading":"Manuellement","text":"Cette fonction est utilisée pour ordonner manuellement les niveaux des facteurs. Si elle est utilisée sur une colonne sans facteur, la colonne sera d’abord convertie en facteur de classe.Entre les parenthèses, fournissez d’abord le nom de la colonne de facteur, puis fournissez soit :Tous les niveaux dans l’ordre désiré (comme un vecteur de caractères c()), ou bienUn niveau et son placement corrigé en utilisant l’argument =.Voici un exemple de redéfinition de la colonne delay_cat (qui est déjà de la classe Factor) et de spécification de tous les niveaux dans l’ordre souhaité.Si vous voulez seulement déplacer un niveau, vous pouvez le spécifier à fct_relevel() seul et donner un nombre à l’argument = pour indiquer où dans l’ordre il doit être. Par exemple, la commande ci-dessous déplace “<2 jours” en deuxième position :","code":"\n# re-define level order\nlinelist <- linelist %>% \n  mutate(delay_cat = fct_relevel(delay_cat, c(\"<2 days\", \"2-5 days\", \">5 days\")))\n# re-define level order\nlinelist %>% \n  mutate(delay_cat = fct_relevel(delay_cat, \"<2 days\", after = 1)) %>% \n  tabyl(delay_cat)"},{"path":"factors.html","id":"dans-un-graphe","chapter":"11 Facteurs","heading":"Dans un graphe","text":"Les commandes forcats peuvent être utilisées pour définir l’ordre des niveaux dans le dataframe, ou seulement dans un graphique. En utilisant la commande pour “envelopper” le nom de la colonne dans la commande de traçage ggplot(), vous pouvez inverser/niveler/etc. la transformation ne s’appliquera que dans ce tracé.Ci-dessous, deux tracés sont créés avec ggplot() (voir la page les bases de ggplot). Dans le premier, la colonne delay_cat est mise en correspondance avec l’axe des x du graphique, avec son ordre de niveau par défaut comme dans les données linelist. Dans le second exemple, elle est enveloppée dans fct_relevel() et l’ordre est modifié dans le graphe.Notez que le titre par défaut de l’axe des x est maintenant assez compliqué - vous pouvez changer ce titre avec l’argument ggplot2 labs().","code":"\n# Ordre alphanumerique par defaut - pas d'ajustement dans ggplot\nggplot(data = linelist)+\n    geom_bar(mapping = aes(x = delay_cat))\n\n# Ordonner des niveaux de facteurs dans ggplot\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = fct_relevel(delay_cat, c(\"<2 days\", \"2-5 days\", \">5 days\"))))"},{"path":"factors.html","id":"inverser","chapter":"11 Facteurs","heading":"Inverser","text":"Il est assez fréquent que vous vouliez inverser l’ordre des niveaux. Enveloppez simplement le facteur avec fct_rev().Notez que si vous voulez inverser seulement la légende du graphique mais pas les niveaux réels du facteur, vous pouvez le faire avec guides() (voir la page Astuces avec ggplot)).","code":""},{"path":"factors.html","id":"par-fréquence","chapter":"11 Facteurs","heading":"Par fréquence","text":"Pour ordonner par fréquence que la valeur apparaît dans les données, utilisez fct_infreq(). Toute valeur manquante (NA) sera automatiquement incluse à la fin, à moins qu’elle ne soit convertie en un niveau explicite (voir cette section). Vous pouvez inverser l’ordre en enveloppant davantage avec fct_rev().Cette fonction peut être utilisée dans un ggplot(), comme indiqué ci-dessous.","code":"\n# ordered by frequency\nggplot(data = linelist, aes(x = fct_infreq(delay_cat)))+\n  geom_bar()+\n  labs(x = \"Delay onset to admission (days)\",\n       title = \"Ordered by frequency\")\n\n# fréquence inversée\nggplot(data = linelist, aes(x = fct_rev(fct_infreq(delay_cat))))+\n  geom_bar()+\n  labs(x = \"Delay onset to admission (days)\",\n       title = \"Reverse of order by frequency\")"},{"path":"factors.html","id":"par-apparence","chapter":"11 Facteurs","heading":"Par apparence","text":"Utilisez fct_inorder() pour définir l’ordre des niveaux afin de correspondre à l’ordre d’apparition dans les données, en commençant par la première ligne. Cela peut être utile si vous avez d’abord soigneusement arrange() les données dans le cadre de données, et ensuite l’utiliser pour définir l’ordre des facteurs.","code":""},{"path":"factors.html","id":"par-la-statistique-sommaire-dune-autre-colonne","chapter":"11 Facteurs","heading":"Par la statistique sommaire d’une autre colonne","text":"Vous pouvez utiliser fct_reorder() pour ordonner les niveaux d’une colonne par une statistique sommaire d’une autre colonne. Visuellement, cela peut donner des graphiques agréables où les barres/points montent ou descendent régulièrement sur le graphique.Dans les exemples ci-dessous, l’axe des x est delay_cat, et l’axe des y est la colonne numérique ct_blood (valeur du seuil de cycle). Les box plots montrent la distribution des valeurs CT par groupe delay_cat. Nous voulons ordonner les box plots dans l’ordre croissant de la valeur médiane du groupe.Dans le premier exemple ci-dessous, l’ordre par défaut alpha-numérique est utilisé. Vous pouvez voir que les hauteurs des box plots sont mélangées et ne sont pas dans un ordre particulier. Dans le deuxième exemple, la colonne delay_cat (mappée sur l’axe des x) été enveloppée dans fct_reorder(), la colonne ct_blood est donnée comme deuxième argument, et “median” est donné comme troisième argument (vous pourriez aussi utiliser “max”, “mean”, “min”, etc). Ainsi, l’ordre des niveaux de delay_cat reflètera maintenant les valeurs médianes croissantes de la valeur médiane de CT de chaque groupe delay_cat. Ceci est reflété dans le deuxième graphique - les box plots ont été réarrangés pour être ascendants. Notez comment NA (manquant) apparaîtra à la fin, à moins d’être converti en un niveau explicite.Notez que dans l’exemple ci-dessus, aucune étape n’est nécessaire avant l’appel à ggplot() - le regroupement et les calculs sont tous effectués en interne par la commande ggplot.","code":"\n# boxplots ordonnés par les niveaux des facteurs initiaux\nggplot(data = linelist)+\n  geom_boxplot(\n    aes(x = delay_cat,\n        y = ct_blood, \n        fill = delay_cat))+\n  labs(x = \"Délai d'apparition à l'admission (jours)\",\n       title = \"Classé par niveaux alphanumériques originaux\")+\n  theme_classic()+\n  theme(legend.position = \"none\")\n\n\n# boxplots ordonner par la mediane des valeurs de CT \nggplot(data = linelist)+\n  geom_boxplot(\n    aes(x = fct_reorder(delay_cat, ct_blood, \"median\"),\n        y = ct_blood,\n        fill = delay_cat))+\n  labs(x = \"Délai d'apparition à l'admission (jours)\",\n       title = \"Classé par valeur médiane de CT dans par groupe\" )+\n  theme_classic()+\n  theme(legend.position = \"none\")"},{"path":"factors.html","id":"par-la-valeur-end","chapter":"11 Facteurs","heading":"Par la valeur “end”","text":"Utilisez fct_reorder2() pour des tracés de lignes groupées. Il ordonne les niveaux (et donc le légende) pour s’aligner avec l’ordre vertical des lignes à la “fin” du tracé. Techniquement parlant, il “ordonne par les valeurs y associées aux plus grandes valeurs x”.Par exemple, si vous avez des lignes montrant le nombre de cas par hôpital au fil du temps, vous pouvez appliquer fct_reorder2() à l’argument color = dans aes(), de sorte que l’ordre vertical des hôpitaux apparaissant dans la légende s’aligne sur l’ordre des lignes à l’extrémité du tracé. Pour en savoir plus, consultez la documentation en ligne.","code":"\nepidemic_data <- linelist %>%         # commencer avec linelist  \n    filter(date_onset < as.Date(\"2014-09-21\")) %>%    # point de coupure  la date, pour une meilleur visualisation\n    count(                                            # obtenir le nombre de cas par semaine et par hôpital\n      epiweek = lubridate::floor_date(date_onset, \"week\"),  \n      hospital                                            \n    ) \n  \nggplot(data = epidemic_data)+                       # debut pour representaton graphique\n  geom_line(                                        # faire des lignes\n    aes(\n      x = epiweek,                                  # l'axe x est epiweek\n      y = n,                                        # l'axe y est le nombre de cas par semaine\n      color = fct_reorder2(hospital, epiweek, n)))+ # données regroupées et colorées par hôpital, avec un ordre des facteurs par hauteur à la fin du graphique\n  labs(title = \"Niveaux des facteurs (et affichage de la légende) par hauteur de ligne à la fin du grahpique\",\n       color = \"Hôpital\")                          # changer le titre de la legende"},{"path":"factors.html","id":"fct_missing","chapter":"11 Facteurs","heading":"11.5 Valeurs manquantes","text":"Si vous avez des valeurs NA dans votre colonne de facteurs, vous pouvez facilement les convertir en un niveau nommé tel que “Missing” avec fct_explicit_na(). Les valeurs NA sont converties en “(Missing)” à la fin de l’ordre des niveaux par défaut. Vous pouvez ajuster le nom du niveau avec l’argument na_level =.Ci-dessous, cette opération est effectuée sur la colonne delay_cat et un tableau est imprimé avec tabyl() avec NA converti en “Missing delay”.","code":"\nlinelist %>% \n  mutate(delay_cat = fct_explicit_na(delay_cat, na_level = \"Missing delay\")) %>% \n  tabyl(delay_cat)##      delay_cat    n    percent\n##       2-5 days 2040 0.34646739\n##        <2 days 2990 0.50781250\n##        >5 days  602 0.10224185\n##  Missing delay  256 0.04347826"},{"path":"factors.html","id":"combiner-les-niveaux","chapter":"11 Facteurs","heading":"11.5.1 Combiner les niveaux","text":"","code":""},{"path":"factors.html","id":"manuellement-1","chapter":"11 Facteurs","heading":"Manuellement","text":"Vous pouvez ajuster l’affichage des niveaux manuellement avec fct_recode(). C’est comme la fonction dplyr recode() (voir Nettoyage des données et fonctions de base), mais elle permet la création de nouveaux niveaux de facteurs. Si vous utilisez le simple recode() sur un facteur, les nouvelles valeurs recodées seront rejetées à moins qu’elles n’aient déjà été définies comme des niveaux admissibles.Cet outil peut aussi être utilisé pour “combiner” des niveaux, en assignant à plusieurs niveaux la même valeur re-codée. Veillez simplement à ne pas perdre d’informations ! Pensez à effectuer ces étapes de combinaison dans une nouvelle colonne (sans écraser la colonne existante).fct_recode() une syntaxe différente de celle de recode(). recode() utilise OLD = NEW, alors que fct_recode() utilise NEW = OLD.Les niveaux actuels de delay_cat sont :Les nouveaux niveaux sont créés à l’aide de la syntaxe fct_recode(colonne, \"nouveau\" = \"ancien\", \"nouveau\" = \"ancien\", \"nouveau\" = \"ancien\") et imprimés :Ici, ils sont combinés manuellement avec fct_recode(). Notez qu’aucune erreur n’est soulevée lors de la création d’un nouveau niveau “Moins de 5 jours”.","code":"\nlevels(linelist$delay_cat)## [1] \"<2 days\"  \"2-5 days\" \">5 days\"\nlinelist %>% \n  mutate(delay_cat = fct_recode(\n    delay_cat,\n    \"Less than 2 days\" = \"<2 days\",\n    \"2 to 5 days\"      = \"2-5 days\",\n    \"More than 5 days\" = \">5 days\")) %>% \n  tabyl(delay_cat)##         delay_cat    n    percent valid_percent\n##  Less than 2 days 2990 0.50781250     0.5308949\n##       2 to 5 days 2040 0.34646739     0.3622159\n##  More than 5 days  602 0.10224185     0.1068892\n##              <NA>  256 0.04347826            NA\nlinelist %>% \n  mutate(delay_cat = fct_recode(\n    delay_cat,\n    \"Less than 5 days\" = \"<2 days\",\n    \"Less than 5 days\" = \"2-5 days\",\n    \"More than 5 days\" = \">5 days\")) %>% \n  tabyl(delay_cat)##         delay_cat    n    percent valid_percent\n##  Less than 5 days 5030 0.85427989     0.8931108\n##  More than 5 days  602 0.10224185     0.1068892\n##              <NA>  256 0.04347826            NA"},{"path":"factors.html","id":"réduire-en-autre","chapter":"11 Facteurs","heading":"Réduire en “Autre”","text":"Vous pouvez utiliser fct_other() pour assigner manuellement des niveaux de facteurs à un niveau “Autre”. Ci-dessous, tous les niveaux de la colonne hospital, à part “Port Hospital” et “Central Hospital”, sont combinés dans “”. Vous pouvez fournir un vecteur pour soit maintenir =, soit drop =. Vous pouvez modifier l’affichage du niveau “Autre” avec other_level =.","code":"\nlinelist %>%    \n  mutate(hospital = fct_other(                      # ajuster niveaux\n    hospital,\n    keep = c(\"Port Hospital\", \"Central Hospital\"),  # garder  ceux ci separer\n    other_level = \"Other Hospital\")) %>%            # Considerer tout autre niveau comme  \"Other Hospital\"\n  tabyl(hospital)                                   # afficher tableau##          hospital    n    percent\n##  Central Hospital  454 0.07710598\n##     Port Hospital 1762 0.29925272\n##    Other Hospital 3672 0.62364130"},{"path":"factors.html","id":"réduire-par-fréquence","chapter":"11 Facteurs","heading":"Réduire par fréquence","text":"Vous pouvez combiner automatiquement les niveaux de facteurs les moins fréquents en utilisant fct_lump().Pour “regrouper” plusieurs niveaux à basse fréquence dans un groupe “Autre”, faites l’une des choses suivantes :Définissez n = comme le nombre de groupes que vous voulez garder. Les n niveaux les plus fréquents seront conservés, et tous les autres seront regroupés dans “Autres”.Définissez prop = comme étant la proportion de fréquence seuil pour les niveaux au-dessus desquels vous voulez garder. Toutes les autres valeurs seront regroupées dans “Autres”.Vous pouvez modifier l’affichage du niveau “Autre” avec other_level =. Ci-dessous, tous les hôpitaux sauf les deux les plus fréquents sont combinés dans “Autre hôpital”., avertir\n## Afficher tous les niveauxL’un des avantages de l’utilisation des facteurs est de standardiser l’apparence des légendes et des tableaux des graphiques, quelles que soient les valeurs réellement présentes dans un ensemble de données.Si vous préparez de nombreuses figures (par exemple, pour plusieurs juridictions), vous voudrez que les légendes et les tableaux apparaissent de manière identique, même si les niveaux de complétion ou de composition des données varient.","code":"\nlinelist %>%    \n  mutate(hospital = fct_lump(                      # ajuster niveaux\n    hospital,\n    n = 2,                                          # garder les  2 premiers  niveaux\n    other_level = \"Other Hospital\")) %>%            #  Considerer tout autre niveau comme  \"Other Hospital\"\n  tabyl(hospital)                                   # afficher tableau##        hospital    n   percent\n##         Missing 1469 0.2494905\n##   Port Hospital 1762 0.2992527\n##  Other Hospital 2657 0.4512568"},{"path":"factors.html","id":"dans-les-graphiques","chapter":"11 Facteurs","heading":"Dans les graphiques","text":"Dans une figure ggplot(), ajoutez simplement l’argument drop = FALSE dans la fonction scale_xxxx() concernée. Tous les niveaux de facteurs seront affichés, qu’ils soient présents ou non dans les données. Si les niveaux de vos colonnes de facteurs sont affichés en utilisant fill =, alors dans scale_fill_discrete() vous incluez drop = FALSE, comme indiqué ci-dessous. Si vos niveaux sont affichés avec x = (sur l’axe des x) color = ou size =, vous devez le fournir à scale_color_discrete() ou scale_size_discrete() en conséquence.Cet exemple est un diagramme à barres empilées de la catégorie d’âge, par hôpital. L’ajout de scale_fill_discrete(drop = FALSE) garantit que tous les groupes d’âge apparaissent dans la légende, même s’ils ne sont pas présents dans les données.","code":"\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = hospital, fill = age_cat)) +\n  scale_fill_discrete(drop = FALSE)+                        # montrer tous les groupes d'âge dans la légende, même ceux qui ne sont pas présents\n  labs(\n    title = \"Tous les groupes d'âge apparaissent dans la légende, même s'ils ne sont pas présents dans les données\")"},{"path":"factors.html","id":"dans-les-tableaux","chapter":"11 Facteurs","heading":"Dans les tableaux","text":"Tant le base R table() que tabyl() de janitor montreront tous les niveaux de facteurs (même les niveaux non utilisés).Si vous utilisez count() ou summarise() de dplyr pour faire une table, ajoutez l’argument .drop = FALSE pour inclure les comptes pour tous les niveaux de facteurs, même ceux qui ne sont pas utilisés.Pour en savoir plus, consultez la page Descriptive tables, ou la documentation scale_discrete, ou la documentation count(). Vous pouvez voir un autre exemple à la page Suivi des contacts.","code":""},{"path":"factors.html","id":"epiweeks","chapter":"11 Facteurs","heading":"11.6 Epiweeks","text":"Veuillez consulter la discussion approfondie sur la création de semaines épidémiologiques à la page Regroupement des données.\nVeuillez également consulter la page Travailler avec des dates pour obtenir des conseils sur la façon de créer et de formater des semaines épidémiologiques.","code":""},{"path":"factors.html","id":"semaines-épidémiologiques-dans-un-graphique","chapter":"11 Facteurs","heading":"Semaines épidémiologiques dans un graphique","text":"Si votre objectif est de créer des semaines épidémiologiques à afficher dans un graphique, vous pouvez le faire simplement avec la fonction floor_date() de lubridate, comme expliqué dans la page Regroupement de données. Les valeurs retournées seront de la classe Date avec le format AAAA-MM-JJ. Si vous utilisez cette colonne dans un graphique, les dates seront naturellement ordonnées correctement, et vous n’aurez pas à vous soucier des niveaux ou de la conversion en classe Facteur. Voir l’histogramme ggplot() des dates d’apparition ci-dessous.Dans cette approche, vous pouvez ajuster l’affichage des dates sur un axe avec scale_x_date(). Voir la page sur les Courbes épidémiques pour plus d’informations. Vous pouvez spécifier un format d’affichage “strptime” à l’argument date_labels = de scale_x_date(). Ces formats utilisent des caractères de remplacement “%” et sont traités dans la page Manipuler les dates. Utilisez “%Y” pour représenter une année à 4 chiffres, et “%W” ou “%U” pour représenter le numéro de la semaine (semaines du lundi ou du dimanche respectivement).","code":"\nlinelist %>% \n  mutate(epiweek_date = floor_date(date_onset, \"week\")) %>%  # créer une colonne semaine\n  ggplot()+                                                  # commencer ggplot\n  geom_histogram(mapping = aes(x = epiweek_date))+           # histogramme de la date d'apparition\n  scale_x_date(date_labels = \"%Y-W%W\")                       # ajuster la répartition des dates pour qu'elle soit YYYY-WWw"},{"path":"factors.html","id":"epiweeks-dans-les-données","chapter":"11 Facteurs","heading":"Epiweeks dans les données","text":"Cependant, si le de la factorisation n’est pas de tracer, vous pouvez l’aborder de deux façons :Pour un contrôle précis de l’affichage, convertissez la colonne lubridée des épihebdomadaires (AAAA-MM-JJ) au format d’affichage souhaité (AAAA-WWW) dans le cadre de données lui-même, puis convertissez-la en classe Factor.\nPour un contrôle précis de l’affichage, convertissez la colonne lubridée des épihebdomadaires (AAAA-MM-JJ) au format d’affichage souhaité (AAAA-WWW) dans le cadre de données lui-même, puis convertissez-la en classe Factor.Tout d’abord, utilisez format() de base R pour convertir l’affichage de la date de YYYY-MM-DD en YYYY-Www (voir la page Manipuler les dates). Dans ce processus, la classe sera convertie en caractère. Ensuite, convertissez le caractère en classe Factor avec factor().DANGERS: Si vous placez les semaines avant les années (“Www-YYYY”) (“%W-%Y”), l’ordre par défaut des niveaux alphanumériques sera incorrect (par exemple, 01-2015 sera avant 35-2014). Vous pourriez avoir besoin d’ajuster manuellement l’ordre, ce qui serait un processus long et difficile..Pour un affichage rapide par défaut, utilisez le package aweek et sa fonction date2week(). Vous pouvez définir le jour week_start =, et si vous définissez factor = TRUE alors la colonne de sortie est un facteur ordonné. En prime, le facteur inclut des niveaux pour toutes les semaines possibles dans l’intervalle - même s’il n’y pas de cas cette semaine-là.Voir la page Manipuler les dates pour plus d’informations sur aweek. Il propose également la fonction inverse week2date().","code":"\nlinelist <- linelist %>% \n  mutate(epiweek_date = floor_date(date_onset, \"week\"),       # creer epiweeks (YYYY-MM-DD)\n         epiweek_formatted = format(epiweek_date, \"%Y-W%W\"),  # Convertir pour afficher (YYYY-WWw)\n         epiweek_formatted = factor(epiweek_formatted))       # Convertir un facteur\n\n# Afficher les niveaux\nlevels(linelist$epiweek_formatted)##  [1] \"2014-W13\" \"2014-W14\" \"2014-W15\" \"2014-W16\" \"2014-W17\" \"2014-W18\" \"2014-W19\"\n##  [8] \"2014-W20\" \"2014-W21\" \"2014-W22\" \"2014-W23\" \"2014-W24\" \"2014-W25\" \"2014-W26\"\n## [15] \"2014-W27\" \"2014-W28\" \"2014-W29\" \"2014-W30\" \"2014-W31\" \"2014-W32\" \"2014-W33\"\n## [22] \"2014-W34\" \"2014-W35\" \"2014-W36\" \"2014-W37\" \"2014-W38\" \"2014-W39\" \"2014-W40\"\n## [29] \"2014-W41\" \"2014-W42\" \"2014-W43\" \"2014-W44\" \"2014-W45\" \"2014-W46\" \"2014-W47\"\n## [36] \"2014-W48\" \"2014-W49\" \"2014-W50\" \"2014-W51\" \"2015-W00\" \"2015-W01\" \"2015-W02\"\n## [43] \"2015-W03\" \"2015-W04\" \"2015-W05\" \"2015-W06\" \"2015-W07\" \"2015-W08\" \"2015-W09\"\n## [50] \"2015-W10\" \"2015-W11\" \"2015-W12\" \"2015-W13\" \"2015-W14\" \"2015-W15\" \"2015-W16\"\ndf <- linelist %>% \n  mutate(epiweek = date2week(date_onset, week_start = \"Monday\", factor = TRUE))\n\nlevels(df$epiweek)"},{"path":"factors.html","id":"ressources-3","chapter":"11 Facteurs","heading":"11.7 Ressources","text":"R Data Science page factorsaweek package vignette","code":""},{"path":"pivoting_data.html","id":"pivoting_data","chapter":"12 Restructurer les données","heading":"12 Restructurer les données","text":"Dans le contexte de la gestion des données, le pivot des données fait référence à l’un des deux processus suivants :La création de tableaux croisés, qui sont des tableaux de statistiques résumant les données d’un tableau plus étendu.La création de tableaux croisés, qui sont des tableaux de statistiques résumant les données d’un tableau plus étendu.La restructuration d’un tableau du format long au format large, ou vice versa.La restructuration d’un tableau du format long au format large, ou vice versa.Dans ce chapitre, nous allons nous focaliser sur le second processus. Résumer ses données dans des tableau est une étape cruciale de l’analyse des données et est traitée dans les chapitres sur le regroupement des données et les tableaux descriptifs.Ce chapitre traite des formats de données. Il est utile de connaître l’idée de “données bien rangées / ordonnées”, dans laquelle chaque variable sa propre colonne, chaque observation sa propre ligne et chaque valeur sa propre cellule. Vous trouverez plus d’informations sur ce sujet dans ce chapitre en ligne de R Data Science(en Anglais).","code":""},{"path":"pivoting_data.html","id":"pivot_prep_data","chapter":"12 Restructurer les données","heading":"12.1 Étapes préliminaires","text":"","code":""},{"path":"pivoting_data.html","id":"importation-des-paquets-1","chapter":"12 Restructurer les données","heading":"Importation des paquets","text":"Ces lignes de code chargent les paquets nécessaires aux analyses. Dans ce guide, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire puis l’importe pour l’utiliser. Vous pouvez également charger les paquets installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les paquets R.","code":"\npacman::p_load(\n  rio,          # import des fichiers\n  here,         # gestion des chemins d'accès\n  kableExtra,\n  tidyverse)    # gestion des données + graphiques (ggplot2)"},{"path":"pivoting_data.html","id":"importation-des-données-1","chapter":"12 Restructurer les données","heading":"Importation des données","text":"","code":""},{"path":"pivoting_data.html","id":"cas-de-malaria","chapter":"12 Restructurer les données","heading":"Cas de Malaria","text":"Dans ce chapitre, nous utiliserons un jeu de données fictif de cas quotidiens de paludisme, par établissement et par groupe d’âge. Pour reproduire les étapes, cliquez ici pour télécharger les données (en tant que fichier .rds). Ou importez des données avec la fonction import() du paquet rio (elle gère de nombreux types de fichiers comme .xlsx, .csv, .rds - voir la page Importation et exportation des données pour plus de détails).Les premières cinquantes lignes sont affichées ci-dessous.","code":"\n# Importation des données\ncount_data <- import(\"malaria_facility_count_data.rds\")"},{"path":"pivoting_data.html","id":"linelist-des-cas","chapter":"12 Restructurer les données","heading":"Linelist des cas","text":"la fin de ce chapitre, nous utiliserons également une liste des cas d’une épidémie d’Ebola simulée. Pour reproduire les étapes, cliquez pour télécharger la linelist “propre” (en tant que fichier .rds). Importez vos données avec la fonction import() du paquet rio (elle accepte de nombreux types de fichiers comme .xlsx, .rds, .csv - voir la page Importation et exportation des données pour plus de détails).","code":"\n# Importer la linelist\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"pivoting_data.html","id":"transformation-du-format-large-vers-long","chapter":"12 Restructurer les données","heading":"12.2 Transformation du format large vers long","text":"","code":""},{"path":"pivoting_data.html","id":"le-format-large","chapter":"12 Restructurer les données","heading":"Le format “large”","text":"Les données sont souvent saisies et stockées dans un format “large” (ou “étendu”), où les caractéristiques ou les réponses d’un sujet/d’un item sont entrées dans une même ligne. Cette structure de données est utile pour la saisie et la présentation des données, mais elle n’est pas appropriée pour de nombreuses analyses.Par exemple, dans le jeu de données count_data importé auparavant, chaque ligne représente un établissement à une date donnée. Les nombres de cas\nsont contenus dans les colonnes les plus à droites, avec une colonne par classe d’age, et une colonne pour le nombre total de cas ce jour là dans cet établissement. L’information “nombre de cas” est donc contenues sur plusieurs colonnes, au lieu d’une seule, d’où la structure dite “large”.Plus précisément, chaque ligne dans ce tableau contient le nombre de cas de paludisme dans l’un des 65 établissements à une date donnée, dans la période allant de count_data$data_date %>% min() à count_data$data_date %>% max(). Ces établissements sont situés dans une province (Nord) et quatre districts (Spring, Bolo, Dingo, et Barnard). Le dataframe contient les totaux des cas de paludisme, globaux et pour chaque classe d’age (<4 ans, 5-14 ans, et 15 ans et plus).Les données sous format “large” comme celle-ci ne respectent pas les normes de “données rangées”, car les en-têtes de colonne ne représentent pas réellement des “variables”: ils contiennent les valeurs d’une hypothétique variable “groupe d’âge”.Ce format est utile pour présenter les informations dans un tableau, ou pour saisir des données (dans Excel par exemple) à partir de formulaires de notification des cas. Cependant, au stade de l’analyse, ces données doivent généralement être restructurées et rangées en un format plus long. Le paquet de visualisations ggplot2, fonctionne également mieux lorsque les données sont dans un format “long”.La visualisation du nombre total de cas de paludisme dans le temps ne pose aucun problème avec les données dans leur format actuel :Cependant, les choses se compliquent si l’veut visualiser les contributions relatives de chaque groupe d’âge au total des cas ? Nous devons alors nous assurer que la variable d’intérêt (le groupe d’âge) ait sa propre colonne dans le dataframe, colonne qui peut être passée à l’argument “mapping aesthetics” aes() de ggplot2.","code":"\nggplot(count_data) +\n  geom_col(aes(x = data_date, y = malaria_tot), width = 1)"},{"path":"pivoting_data.html","id":"pivot_longer","chapter":"12 Restructurer les données","heading":"pivot_longer()","text":"La fonction pivot_longer() de tidyr transforme un jeu de données au format “large” en un jeu de données “plus long”. tidyr fait partie du méta-paquet tidyverse.Elle accepte une ou plusieurs colonnes à transformer (argument cols =), ce qui donne un contrôle fin sur les colonnes à restructurer. Par exemple, pour les données sur le paludisme, nous ne voulons faire pivoter que les colonnes contenant des nombre de cas.Suite à ce processus, nous obtenons deux “nouvelles” colonnes: l’une contenant les catégories (anciennement sotckées dans les noms de colonnes), et l’autre avec les valeurs correspondantes (ici, le nombre de cas). Nous pouvons accepter les noms par défaut pour ces nouvelles colonnes, ou spécifier de nouveaux noms dans names_to = et values_to = respectivement.Voyons comment utiliser pivot_longer()…","code":""},{"path":"pivoting_data.html","id":"transformation-simple","chapter":"12 Restructurer les données","heading":"Transformation simple","text":"Nous utilisons la fonction pivot_longer() de tidyr pour convertir les données d’un format “large” à un format “long”. Plus précisément, il s’agit de convertir les quatre colonnes numériques contenant des nombre de cas de paludisme en deux nouvelles colonnes : une qui contient les groupes d’âge et une qui contient les valeurs correspondantes.Notons que le dataframe nouvellement crée (df_long) plus de lignes (12 152 contre 3 038) : il est devenu plus long. Pour être précis, il est quatre fois plus long, car chaque ligne du tableau d’origine donné quatre lignes dans `df_long``, une pour chacun des colonnes restructurées (<4 ans, 5-14 ans, 15 ans et plus, et total).Le nouveau tableau également moins de colonnes (8 contre 10), car les données précédemment stockées dans quatre colonnes (celles qui commencent par le préfixe malaria_) sont maintenant stockées dans deux colonnes.Note : puisque les noms de quatre colonnes transformées commencent tous par le préfixe malaria_, nous aurions pu sélectionner les colonnes à transformer en utilisant la fonction starts_with() pour obtenir le même résultat (voir la page sur le nettoyage des données et les fonctions de base pour plus de ces fonctions d’aide de type “tidyselect”).ou par position :ou dans le cas de colonnes consécutives, avec la première et la dernière colonne :Les deux nouvelles colonnes crées lors de la restructuration reçoivent les noms par défaut de name et value, mais nous pouvons remplacer ces valeurs par défaut par des noms qui décrivent mieux le contenu des colonnes en utilisant les arguments names_to et values_to. Par exemple, si nous voulons renommer les colonnes age_group et counts :Nous pouvons maintenant passer ce nouveau jeu de données à ggplot2, et placer la nouvelle colonne count dans l’axe des y et colorer les barres en fonction des valeurs de la colonne age_group grâce à l’argument fill =. Nous obtenons alors un diagramme en bâtons des cas de paludisme par groupe d’âge :Examinez ce nouveau tracé et comparez-le avec le tracé que nous avons créé précédemment : qu’est-ce qui cloche ?Nous fait une erreur classique du traitement des données de surveillance et inclus le nombre de cas totaux de la colonne malaria_tot. La conséquence est que chaque barre du graphique est deux fois plus élevée qu’elle ne devrait l’être.Nous pouvons résoudre ce problème de plusieurs façons. Tout d’abord nous pouvons simplement filtrer les données avant de les passer à ggplot() :Autrement, nous aurions pu exclure cette variable lors du pivot_longer(), la conservant comme une variable séparée dans le tableau :Les valeurs sont alors répétées dans les lignes des groupes d’age.","code":"\ndf_long <- count_data %>% \n  pivot_longer(\n    cols = c(`malaria_rdt_0-4`, `malaria_rdt_5-14`, \n             `malaria_rdt_15`, `malaria_tot`)\n  )\n\ndf_long\n# choisir les colonnes avec l'aide d'une fonction \"tidyselect\"\ncount_data %>% \n  pivot_longer(\n    cols = starts_with(\"malaria_\")\n  )## # A tibble: 12,152 × 8\n##    location_name data_date  submitted_date Province District newid name            value\n##    <chr>         <date>     <date>         <chr>    <chr>    <int> <chr>           <int>\n##  1 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_0-4    11\n##  2 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_5-…    12\n##  3 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_15     23\n##  4 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_tot        46\n##  5 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_0-4    11\n##  6 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_5-…    10\n##  7 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_15      5\n##  8 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_tot        26\n##  9 Facility 3    2020-08-11 2020-08-12     North    Dingo        3 malaria_rdt_0-4     8\n## 10 Facility 3    2020-08-11 2020-08-12     North    Dingo        3 malaria_rdt_5-…     5\n## # ℹ 12,142 more rows\n# Choisir les colonnes à partir de leur position dans le tableau\ncount_data %>% \n  pivot_longer(\n    cols = 6:9\n  )\n# Choisir les colonnes avec un \"intervalle\"\ncount_data %>% \n  pivot_longer(\n    cols = `malaria_rdt_0-4`:malaria_tot\n  )\ndf_long <- count_data %>% \n  pivot_longer(\n    cols      = starts_with(\"malaria_\"),\n    names_to  = \"age_group\",\n    values_to = \"counts\"\n  )\n\ndf_long## # A tibble: 12,152 × 8\n##    location_name data_date  submitted_date Province District newid age_group      counts\n##    <chr>         <date>     <date>         <chr>    <chr>    <int> <chr>           <int>\n##  1 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_0…     11\n##  2 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_5…     12\n##  3 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_15     23\n##  4 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_tot        46\n##  5 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_0…     11\n##  6 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_5…     10\n##  7 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_15      5\n##  8 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_tot        26\n##  9 Facility 3    2020-08-11 2020-08-12     North    Dingo        3 malaria_rdt_0…      8\n## 10 Facility 3    2020-08-11 2020-08-12     North    Dingo        3 malaria_rdt_5…      5\n## # ℹ 12,142 more rows\nggplot(data = df_long) +\n  geom_col(\n    mapping = aes(x = data_date,\n                  y = counts, \n                  fill = age_group),\n    width = 1\n  )\ndf_long %>% \n  filter(age_group != \"malaria_tot\") %>% \n  ggplot() +\n  geom_col(\n    aes(x = data_date, \n        y = counts, \n        fill = age_group),\n    width = 1\n  )\ncount_data %>% \n  pivot_longer(\n    cols = `malaria_rdt_0-4`:malaria_rdt_15,   # does not include the totals column\n    names_to = \"age_group\",\n    values_to = \"counts\"\n  )## # A tibble: 9,114 × 9\n##    location_name data_date  submitted_date Province District malaria_tot newid age_group\n##    <chr>         <date>     <date>         <chr>    <chr>          <int> <int> <chr>    \n##  1 Facility 1    2020-08-11 2020-08-12     North    Spring            46     1 malaria_…\n##  2 Facility 1    2020-08-11 2020-08-12     North    Spring            46     1 malaria_…\n##  3 Facility 1    2020-08-11 2020-08-12     North    Spring            46     1 malaria_…\n##  4 Facility 2    2020-08-11 2020-08-12     North    Bolo              26     2 malaria_…\n##  5 Facility 2    2020-08-11 2020-08-12     North    Bolo              26     2 malaria_…\n##  6 Facility 2    2020-08-11 2020-08-12     North    Bolo              26     2 malaria_…\n##  7 Facility 3    2020-08-11 2020-08-12     North    Dingo             18     3 malaria_…\n##  8 Facility 3    2020-08-11 2020-08-12     North    Dingo             18     3 malaria_…\n##  9 Facility 3    2020-08-11 2020-08-12     North    Dingo             18     3 malaria_…\n## 10 Facility 4    2020-08-11 2020-08-12     North    Bolo              49     4 malaria_…\n## # ℹ 9,104 more rows\n## # ℹ 1 more variable: counts <int>"},{"path":"pivoting_data.html","id":"transformer-les-données-de-plusieurs-classes","chapter":"12 Restructurer les données","heading":"Transformer les données de plusieurs classes","text":"L’exemple ci-dessus fonctionne bien dans les situations où toutes les colonnes que l’veut faire pivoter sont de la même classe (chaîne de caractère, numérique, logique…).Cependant, en tant qu’épidémiologiste de terrain, vous serez amené à travailler avec des données qui ont été préparées par des non-spécialistes, appliquant leur propre logique. Cela aboutit parfois à des jeux de données non-standard, voire totalement désorganisés. Comme Hadley Wickham l’noté (en faisant référence à Tolstoï) dans son article séminal sur les principes des données rangées, organisées (tidy data) :Comme les familles, les tableaux de données rangés et organisés se ressemblent tous, mais chaque fichier de données désorganisé / mal rangé l’est à sa manière.Un problème particulièrement courant est la nécessité de restructurer des colonnes qui contiennent différentes types de données. Cette transformation aurait pour conséquence de stocker différents types de données dans une seule colonne, ce qui est déconseillé. Il y plusieurs manière de gérer les problèmes associés à ce type de données mais la restructuration avec pivot_longer() est une étape importante.Imaginons cette situation : une série d’observations été effectuée à différents pas de temps pour chacun des trois éléments , B et C. Il peut s’agir d’individus (par exemple, les contacts d’un cas d’Ebola sont suivis chaque jour pendant 21 jours) ou de postes de santé de villages éloignés qui sont contrôlés une fois par pour s’assurer qu’ils sont toujours fonctionnels. Reprenons l’exemple de la recherche des contacts. Imaginons que les données soient stockées comme suit :Le format de ces données est un peu plus compliqué que dans l’exemple précédent : chaque ligne stocke des informations sur un élément, et des paires de colonnes contiennent des séries d’observations à différentes dates. Le fichier s’allonge avec de nouvelles colonnes à droite au fur et à mesure des observations. Les classes de colonnes alternent entre dates et chaînes de caractères.Pour la petite histoire, un des pires exemples de ce type de données qu’il m’ait été donné de rencontrer concernait des données de surveillance du choléra, dans lesquelles 8 nouvelles colonnes d’observations étaient ajoutées chaque jour, pendant 4 ans. L’ouverture du fichier Excel sur mon ordinateur portable pris plus de dix minutes…Pour travailler avec ces données, nous devons les transformer en format “long” tout en gardant la séparation entre une colonne date et une colonne caractère (statut), pour chaque observation pour chaque élément. Ceci afin d’éviter de nous retrouver avec un mélange de types de variables dans une seule colonne, une situation que vous devrez chercher à éviter à tout prix dans votre gestion de données, en particulier avec des données ordonnées.C’est malheureusement ce qui se produit si l’effectue une transformation simple :Ci-dessus, notre restructuration fusionné dates et caractères en une seule colonne valeur. Face à deux colonnes de classes différentes, la fonction convertit par défaut la colonne entière en chaîne de caractères.Pour éviter cette situation, nous pouvons tirer parti de la structure des noms de colonnes dans le tableau original, qui respectent le même format : le numéro de l’observation, un “_” puis soit “statut” soit “date”.Pour cela, il nous faut :fournir un vecteur de chaîne de caractères un peu spécial à l’argument names_to =. Dans ce vecteur, le second élément est \".value\", ce terme spécial indiquant que les colonnes restructurées seront divisées sur la base d’un mot dans le nom des colonnes.fournir un vecteur de chaîne de caractères un peu spécial à l’argument names_to =. Dans ce vecteur, le second élément est \".value\", ce terme spécial indiquant que les colonnes restructurées seront divisées sur la base d’un mot dans le nom des colonnes.fournir le caractère utilisé comme séparateur à l’argument names_sep = . Dans le cas présent, il s’agit du tiret-bas “_“.fournir le caractère utilisé comme séparateur à l’argument names_sep = . Dans le cas présent, il s’agit du tiret-bas “_“.Ainsi, le nommage et la division des nouvelles colonnes sont basés sur le “_” dans les noms des variables existantes.Derniers détails :La colonne date est actuellement sous la forme d’une chaîne de caractères mais nous pouvons facilement la convertir en classe date en utilisant les fonctions mutate() et as_date() décrites dans la page travailler avec des dates.Nous pouvons aussi améliorer la colonne observation en supprimant le préfixe “obs” et en la convertissant en format numérique. Nous pouvons le faire avec str_remove_all() du paquet stringr (voir la page sur les chaînes de caractères).Nous pouvons maintenant travailler avec les données dans ce format allongé. par exemple, en créant une carte de chaleur :","code":"\ndf %>% \n  pivot_longer(\n    cols     = -id,\n    names_to = c(\"observation\")\n  )## # A tibble: 18 × 3\n##    id    observation value     \n##    <chr> <chr>       <chr>     \n##  1 A     obs1_date   2021-04-23\n##  2 A     obs1_status Healthy   \n##  3 A     obs2_date   2021-04-24\n##  4 A     obs2_status Healthy   \n##  5 A     obs3_date   2021-04-25\n##  6 A     obs3_status Unwell    \n##  7 B     obs1_date   2021-04-23\n##  8 B     obs1_status Healthy   \n##  9 B     obs2_date   2021-04-24\n## 10 B     obs2_status Healthy   \n## 11 B     obs3_date   2021-04-25\n## 12 B     obs3_status Healthy   \n## 13 C     obs1_date   2021-04-23\n## 14 C     obs1_status Missing   \n## 15 C     obs2_date   2021-04-24\n## 16 C     obs2_status Healthy   \n## 17 C     obs3_date   2021-04-25\n## 18 C     obs3_status Healthy\ndf_long <- \n  df %>% \n  pivot_longer(\n    cols      = -id,\n    names_to  = c(\"observation\", \".value\"),\n    names_sep = \"_\"\n  )\n\ndf_long## # A tibble: 9 × 4\n##   id    observation date       status \n##   <chr> <chr>       <chr>      <chr>  \n## 1 A     obs1        2021-04-23 Healthy\n## 2 A     obs2        2021-04-24 Healthy\n## 3 A     obs3        2021-04-25 Unwell \n## 4 B     obs1        2021-04-23 Healthy\n## 5 B     obs2        2021-04-24 Healthy\n## 6 B     obs3        2021-04-25 Healthy\n## 7 C     obs1        2021-04-23 Missing\n## 8 C     obs2        2021-04-24 Healthy\n## 9 C     obs3        2021-04-25 Healthy\ndf_long <- \n  df_long %>% \n  mutate(\n    date = date %>% lubridate::as_date(),\n    observation = \n      observation %>% \n      str_remove_all(\"obs\") %>% \n      as.numeric()\n  )\n\ndf_long## # A tibble: 9 × 4\n##   id    observation date       status \n##   <chr>       <dbl> <date>     <chr>  \n## 1 A               1 2021-04-23 Healthy\n## 2 A               2 2021-04-24 Healthy\n## 3 A               3 2021-04-25 Unwell \n## 4 B               1 2021-04-23 Healthy\n## 5 B               2 2021-04-24 Healthy\n## 6 B               3 2021-04-25 Healthy\n## 7 C               1 2021-04-23 Missing\n## 8 C               2 2021-04-24 Healthy\n## 9 C               3 2021-04-25 Healthy\nggplot(data = df_long, \n       mapping = aes(x = date, \n                     y = id, \n                     fill = status)) +\n  geom_tile(colour = \"black\") +\n  scale_fill_manual(\n    values = \n      c(\"Healthy\" = \"lightgreen\", \n        \"Unwell\"  = \"red\", \n        \"Missing\" = \"orange\")\n  )"},{"path":"pivoting_data.html","id":"transformation-du-format-long-en-large","chapter":"12 Restructurer les données","heading":"12.3 Transformation du format long en large","text":"Il peut être utile de transformer un jeu de données d’un format “long” en un format plus large à l’aide de la fonction pivot_wider().Un cas d’utilisation typique est lorsque qu’il faut transformer les résultats d’une analyse dans un format plus digeste pour le lecteur, tel qu’un tableau résumé. En général, il s’agit de transformer un dataframe dans lequel les informations relatives à un sujet sont réparties sur plusieurs lignes en un format dans lequel ces informations sont stockées sur une seule ligne.","code":""},{"path":"pivoting_data.html","id":"données-utilisées","chapter":"12 Restructurer les données","heading":"Données utilisées","text":"Pour cette section nous utiliserons la liste des cas (voir la section Etapes préliminaires), qui contient une ligne par cas.Voici les 50 premières lignes :Imaginons que nous voulions voir les nombres d’individus dans les différentes classes d’age, par genre :Cette commande renvoi un dataframe en format long, qui est très adapté à la création de graphiques avec ggplot2, mais moins idéal pour un tableau résumé dans un rapport :Nous pouvons utiliser la fonction pivot_wider() pour restructurer les données dans un format plus lisible par un lecteur humain.","code":"\ndf_wide <- \n  linelist %>% \n  count(age_cat, gender)\n\ndf_wide##    age_cat gender   n\n## 1      0-4      f 640\n## 2      0-4      m 416\n## 3      0-4   <NA>  39\n## 4      5-9      f 641\n## 5      5-9      m 412\n## 6      5-9   <NA>  42\n## 7    10-14      f 518\n## 8    10-14      m 383\n## 9    10-14   <NA>  40\n## 10   15-19      f 359\n## 11   15-19      m 364\n## 12   15-19   <NA>  20\n## 13   20-29      f 468\n## 14   20-29      m 575\n## 15   20-29   <NA>  30\n## 16   30-49      f 179\n## 17   30-49      m 557\n## 18   30-49   <NA>  18\n## 19   50-69      f   2\n## 20   50-69      m  91\n## 21   50-69   <NA>   2\n## 22     70+      m   5\n## 23     70+   <NA>   1\n## 24    <NA>   <NA>  86\nggplot(df_wide) +\n  geom_col(aes(x = age_cat, y = n, fill = gender))"},{"path":"pivoting_data.html","id":"pivot_wider","chapter":"12 Restructurer les données","heading":"pivot_wider()","text":"L’argument names_from spécifie la colonne depuis laquelle générer les nouveaux noms de colonne, tandis que l’argument values_from spécifie la colonne depuis laquelle prendre les valeurs pour remplir les cellules. L’argument id_cols = est facultatif, mais peut servir à fournir un vecteur de noms de colonnes qui ne doivent pas être pivotées, et qui serviront d’identifiant pour chaque ligne.Ce tableau est beaucoup plus facile à lire, et est une base pour créer des tableaux résumés dans des rapports et articles. Nous pouvons améliorer son apparence à l’aide de paquets tels que flextable et knitr (voir la page Tableaux pour la présentation.","code":"\ntable_wide <- \n  df_wide %>% \n  pivot_wider(\n    id_cols     = age_cat,\n    names_from  = gender,\n    values_from = n\n  )\n\ntable_wide## # A tibble: 9 × 4\n##   age_cat     f     m  `NA`\n##   <fct>   <int> <int> <int>\n## 1 0-4       640   416    39\n## 2 5-9       641   412    42\n## 3 10-14     518   383    40\n## 4 15-19     359   364    20\n## 5 20-29     468   575    30\n## 6 30-49     179   557    18\n## 7 50-69       2    91     2\n## 8 70+        NA     5     1\n## 9 <NA>       NA    NA    86\ntable_wide %>% \n  janitor::adorn_totals(c(\"row\", \"col\")) %>% # adds row and column totals\n  knitr::kable() %>% \n  kableExtra::row_spec(row = 10, bold = TRUE) %>% \n  kableExtra::column_spec(column = 5, bold = TRUE) "},{"path":"pivoting_data.html","id":"remplissage-des-colonnes","chapter":"12 Restructurer les données","heading":"12.4 Remplissage des colonnes","text":"Parfois, après un pivot, ou plus fréquemment après un bind, nous nous retrouvons avec des vides dans certaines cellules que nous aimerions remplir.","code":""},{"path":"pivoting_data.html","id":"données","chapter":"12 Restructurer les données","heading":"Données","text":"Par exemple, prenons deux jeux de données qui contiennent tout deux des observations pour le numéro de mesure, le nom de l’établissement et le nombre de cas à ce moment-là. En plus de cela, le deuxième jeu de données également une variable Year.Lorsque nous effectuons une liaison avec bind_rows() pour joindre les deux ensembles de données ensemble, la variable Year est remplie avec de NA pour les lignes où il n’y avait pas d’information préalable (c’est-à-dire le premier ensemble de données) :","code":"\ndf1 <- \n  tibble::tribble(\n       ~Measurement, ~Facility, ~Cases,\n                  1,  \"Hosp 1\",     66,\n                  2,  \"Hosp 1\",     26,\n                  3,  \"Hosp 1\",      8,\n                  1,  \"Hosp 2\",     71,\n                  2,  \"Hosp 2\",     62,\n                  3,  \"Hosp 2\",     70,\n                  1,  \"Hosp 3\",     47,\n                  2,  \"Hosp 3\",     70,\n                  3,  \"Hosp 3\",     38,\n       )\n\ndf1 ## # A tibble: 9 × 3\n##   Measurement Facility Cases\n##         <dbl> <chr>    <dbl>\n## 1           1 Hosp 1      66\n## 2           2 Hosp 1      26\n## 3           3 Hosp 1       8\n## 4           1 Hosp 2      71\n## 5           2 Hosp 2      62\n## 6           3 Hosp 2      70\n## 7           1 Hosp 3      47\n## 8           2 Hosp 3      70\n## 9           3 Hosp 3      38\ndf2 <- \n  tibble::tribble(\n    ~Year, ~Measurement, ~Facility, ~Cases,\n     2000,            1,  \"Hosp 4\",     82,\n     2001,            2,  \"Hosp 4\",     87,\n     2002,            3,  \"Hosp 4\",     46\n  )\n\ndf2## # A tibble: 3 × 4\n##    Year Measurement Facility Cases\n##   <dbl>       <dbl> <chr>    <dbl>\n## 1  2000           1 Hosp 4      82\n## 2  2001           2 Hosp 4      87\n## 3  2002           3 Hosp 4      46\ndf_combined <- \n  bind_rows(df1, df2) %>% \n  arrange(Measurement, Facility)\n\ndf_combined## # A tibble: 12 × 4\n##    Measurement Facility Cases  Year\n##          <dbl> <chr>    <dbl> <dbl>\n##  1           1 Hosp 1      66    NA\n##  2           1 Hosp 2      71    NA\n##  3           1 Hosp 3      47    NA\n##  4           1 Hosp 4      82  2000\n##  5           2 Hosp 1      26    NA\n##  6           2 Hosp 2      62    NA\n##  7           2 Hosp 3      70    NA\n##  8           2 Hosp 4      87  2001\n##  9           3 Hosp 1       8    NA\n## 10           3 Hosp 2      70    NA\n## 11           3 Hosp 3      38    NA\n## 12           3 Hosp 4      46  2002"},{"path":"pivoting_data.html","id":"fill","chapter":"12 Restructurer les données","heading":"fill()","text":"Dans ce cas, Year est une variable utile à inclure si nous souhaitons explorer les tendances temporelle. Nous pouvons utiliser fill() pour remplir les cellules vides, en spécifiant la colonne à remplir et la direction (dans ce cas ) :Alternativement, nous pouvons réordonner les données pour remplir vers le bas :Nous avons à présent un jeu de données facilement visualisable à l’aide de ggplot2 :Mais ce jeu de données est peu lisible si présenté tel quel dans un rapport. Nous pouvons appliquer pivot_larger() pour le transformer en un format plus large :Note : dans ce cas, nous avons dû spécifier de n’inclure que les trois variables Facility, Year, et Cases car la variable supplémentaire Measurement interférait avec la création de la table :","code":"\ndf_combined %>% \n  fill(Year, .direction = \"up\")## # A tibble: 12 × 4\n##    Measurement Facility Cases  Year\n##          <dbl> <chr>    <dbl> <dbl>\n##  1           1 Hosp 1      66  2000\n##  2           1 Hosp 2      71  2000\n##  3           1 Hosp 3      47  2000\n##  4           1 Hosp 4      82  2000\n##  5           2 Hosp 1      26  2001\n##  6           2 Hosp 2      62  2001\n##  7           2 Hosp 3      70  2001\n##  8           2 Hosp 4      87  2001\n##  9           3 Hosp 1       8  2002\n## 10           3 Hosp 2      70  2002\n## 11           3 Hosp 3      38  2002\n## 12           3 Hosp 4      46  2002\ndf_combined <- \n  df_combined %>% \n  arrange(Measurement, desc(Facility))\n\ndf_combined## # A tibble: 12 × 4\n##    Measurement Facility Cases  Year\n##          <dbl> <chr>    <dbl> <dbl>\n##  1           1 Hosp 4      82  2000\n##  2           1 Hosp 3      47    NA\n##  3           1 Hosp 2      71    NA\n##  4           1 Hosp 1      66    NA\n##  5           2 Hosp 4      87  2001\n##  6           2 Hosp 3      70    NA\n##  7           2 Hosp 2      62    NA\n##  8           2 Hosp 1      26    NA\n##  9           3 Hosp 4      46  2002\n## 10           3 Hosp 3      38    NA\n## 11           3 Hosp 2      70    NA\n## 12           3 Hosp 1       8    NA\ndf_combined <- \n  df_combined %>% \n  fill(Year, .direction = \"down\")\n\ndf_combined## # A tibble: 12 × 4\n##    Measurement Facility Cases  Year\n##          <dbl> <chr>    <dbl> <dbl>\n##  1           1 Hosp 4      82  2000\n##  2           1 Hosp 3      47  2000\n##  3           1 Hosp 2      71  2000\n##  4           1 Hosp 1      66  2000\n##  5           2 Hosp 4      87  2001\n##  6           2 Hosp 3      70  2001\n##  7           2 Hosp 2      62  2001\n##  8           2 Hosp 1      26  2001\n##  9           3 Hosp 4      46  2002\n## 10           3 Hosp 3      38  2002\n## 11           3 Hosp 2      70  2002\n## 12           3 Hosp 1       8  2002\nggplot(df_combined) +\n  aes(Year, Cases, fill = Facility) +\n  geom_col()\ndf_combined %>% \n  pivot_wider(\n    id_cols     = c(Measurement, Facility),\n    names_from  = \"Year\",\n    values_from = \"Cases\"\n  ) %>% \n  arrange(Facility) %>% \n  janitor::adorn_totals(c(\"row\", \"col\")) %>% \n  knitr::kable() %>% \n  kableExtra::row_spec(row = 5, bold = TRUE) %>% \n  kableExtra::column_spec(column = 5, bold = TRUE) \ndf_combined %>% \n  pivot_wider(\n    names_from = \"Year\",\n    values_from = \"Cases\"\n  ) %>% \n  knitr::kable()"},{"path":"pivoting_data.html","id":"resources-1","chapter":"12 Restructurer les données","heading":"12.5 Resources","text":"Voici un tutoriel utilel","code":""},{"path":"grouping_data.html","id":"grouping_data","chapter":"13 Travailler sur des données groupées","heading":"13 Travailler sur des données groupées","text":"Ce chapitre explique comment grouper et agréger des données lors une analyse descriptive. Il utilise les fonctions du méta-paquet tidyverse pour des fonctions communes et faciles à utiliser.Grouper les données est une étape essentielle de la gestion et de l’analyse de données. Par exemple, il est souvent nécessaire de créer des résumés statistiques ou des figures “par groupe”. Les fonctions du paquet dplyr (qui fait partie de tidyverse) permettent de grouper les données et d’effectuer de nombreuses\nactions “par groupes très facilement.Ce chapitre aborde les sujets suivants :Grouper les données avec la fonction group_by().Dé-grouper des donnéesRésumer les données groupées avec des statistiques (summarise())La différence entre count() et tally().Trier les données groupées avec la fonction arrange()Filtrer les données groupées avec la fonction filter()Créer de nouvelles colonnes avec la fonction mutate()Sélectionner les colonnes avec la fonction select()La commande base R aggregate(), qui est une alternative aux fonctions de dplyr.","code":""},{"path":"grouping_data.html","id":"étapes-préliminaires-1","chapter":"13 Travailler sur des données groupées","heading":"13.1 Étapes préliminaires","text":"","code":""},{"path":"grouping_data.html","id":"importation-des-paquets-2","chapter":"13 Travailler sur des données groupées","heading":"Importation des paquets","text":"Ces lignes de code chargent les paquets nécessaires aux analyses. Dans ce guide, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire puis l’importe pour l’utiliser. Vous pouvez également charger les paquets installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les paquets R.","code":"\npacman::p_load(\n  rio,       # import des fichiers\n  here,      # gestion des chemins d'accès\n  tidyverse, # gestion des données + graphiques (inclus dplyr)\n  janitor)   # ajout de totaux aux lignes et colonnes"},{"path":"grouping_data.html","id":"import-des-données","chapter":"13 Travailler sur des données groupées","heading":"Import des données","text":"Dans ce chapitre, nous utiliserons un jeu de données fictif pour une épidémie d’Ebola. Pour reproduire les étapes, cliquez pour télécharger la liste “nettoyée” (sous forme de fichier .rds). Le jeu de données est importé à l’aide de la fonction import() du paquet rio. voir la page Importation et exportation des données pour plus de détails).Les premières cinquante lignes de la linelist :","code":"\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"grouping_data.html","id":"grouper-des-données","chapter":"13 Travailler sur des données groupées","heading":"13.2 Grouper des données","text":"La fonction group_by() de dplyr permet de définir des groupes de lignes à partir des valeurs d’une ou de plusieurs colonnes. Chaque valeur unique (ou combinaison de valeurs unique, dans le cas où plusieurs colonnes sont spécifiées) constitue un groupe. Une fois les données groupées, de nombreuses fonctions utilisées pour le nettoyage ou des analyses descriptives seront appliquées à chaque groupe.Par exemple, le code ci-dessous groupe la linelist en fonction des valeurs uniques de la colonne outcome. La ou les colonnes selon lesquelles grouper les données sont placées entre parenthèses dans la fonction group_by(). La fonction génère un nouveau tableau de données, que nous nommons ll_by_outcome.Notez que les données elles mêmes n’ont pas été modifiées après avoir exécuté group_by(). Le fait que le dataframe soit “groupé” se verra lorsqu’une autre fonction du paquet dplyr tel que mutate(), summarise(), ou arrange() sera appliquée sur le dataframe “groupé”.Vous pouvez cependant savoir qu’un dataframe est groupé en l’imprimant dans la console. Vous verrez alors qu’il été transformé en un objet de classe tibble qui, lorsqu’il est affiché, indique les groupements présents et le nombre de groupes qu’il y juste au-dessus de la ligne d’en-tête.","code":"\nll_by_outcome <- linelist %>% \n  group_by(outcome)\n# Faire afficher pour voir le schéma de groupement\nll_by_outcome## # A tibble: 5,888 × 30\n## # Groups:   outcome [3]\n##    case_id generation date_infection date_onset date_hospitalisation date_outcome\n##    <chr>        <dbl> <date>         <date>     <date>               <date>      \n##  1 5fe599           4 2014-05-08     2014-05-13 2014-05-15           NA          \n##  2 8689b7           4 NA             2014-05-13 2014-05-14           2014-05-18  \n##  3 11f8ea           2 NA             2014-05-16 2014-05-18           2014-05-30  \n##  4 b8812a           3 2014-05-04     2014-05-18 2014-05-20           NA          \n##  5 893f25           3 2014-05-18     2014-05-21 2014-05-22           2014-05-29  \n##  6 be99c8           3 2014-05-03     2014-05-22 2014-05-23           2014-05-24  \n##  7 07e3e8           4 2014-05-22     2014-05-27 2014-05-29           2014-06-01  \n##  8 369449           4 2014-05-28     2014-06-02 2014-06-03           2014-06-07  \n##  9 f393b4           4 NA             2014-06-05 2014-06-06           2014-06-18  \n## 10 1389ca           4 NA             2014-06-05 2014-06-07           2014-06-09  \n## # ℹ 5,878 more rows\n## # ℹ 24 more variables: outcome <chr>, gender <chr>, age <dbl>, age_unit <chr>,\n## #   age_years <dbl>, age_cat <fct>, age_cat5 <fct>, hospital <chr>, lon <dbl>,\n## #   lat <dbl>, infector <chr>, source <chr>, wt_kg <dbl>, ht_cm <dbl>, ct_blood <dbl>,\n## #   fever <chr>, chills <chr>, cough <chr>, aches <chr>, vomit <chr>, temp <dbl>,\n## #   time_admission <chr>, bmi <dbl>, days_onset_hosp <dbl>"},{"path":"grouping_data.html","id":"groupes-distincts","chapter":"13 Travailler sur des données groupées","heading":"Groupes distincts","text":"Les groupes sont basés sur les combinaisons uniques de valeurs dans les colonnes de groupement.Pour afficher les groupes et le nombre de lignes de chaque groupe, passez les données groupées à la fonction tally(). Pour afficher les groupes présents mais pas le nombre de lignes, passez les données à la fonction group_keys().Dans l’exemple ci-dessous, il y trois valeurs uniques dans la colonne de groupement outcome : “Death”, “Recover”, et “NA”. Vous voyez qu’il y avait nrow(linelist %>% filter(outcome == \"Death\")) morts, nrow(linelist %>% filter(outcome == \"Recover\")) guéris, et nrow(linelist %>% filter(.na(outcome))) individus sans information renseignée.Vous pouvez regrouper par plus d’une colonne. Ci-dessous, nous groupons le dataframe par outcome et gender, puis comptons le nombre de lignes dans chaque groupe. Chaque combinaison unique de outcome et gender crée un groupe différent, y compris les valeurs manquantes pour chaque colonne.","code":"\nlinelist %>% \n  group_by(outcome) %>% \n  tally()## # A tibble: 3 × 2\n##   outcome     n\n##   <chr>   <int>\n## 1 Death    2582\n## 2 Recover  1983\n## 3 <NA>     1323\nlinelist %>% \n  group_by(outcome, gender) %>% \n  tally()## # A tibble: 9 × 3\n## # Groups:   outcome [3]\n##   outcome gender     n\n##   <chr>   <chr>  <int>\n## 1 Death   f       1227\n## 2 Death   m       1228\n## 3 Death   <NA>     127\n## 4 Recover f        953\n## 5 Recover m        950\n## 6 Recover <NA>      80\n## 7 <NA>    f        627\n## 8 <NA>    m        625\n## 9 <NA>    <NA>      71"},{"path":"grouping_data.html","id":"nouvelle-colonne","chapter":"13 Travailler sur des données groupées","heading":"Nouvelle colonne","text":"Vous pouvez également grouper selon une colonne crée directement dans la fonction group_by(). Cela revient à appeler mutate() avant le group_by(). Cela peut être intéressant pour créer de petites tables descriptives rapidement, mais dans d’autres cas, il sera plus lisible de créer la nouvelle colonne avec la fonction mutate() avant de passer le tableau à group_by().","code":"\n# grouper les données sur la base d'une colonne crée dans la commande group_by()\nlinelist %>% \n  group_by(\n    age_class = ifelse(age >= 18, \"adult\", \"child\")) %>% \n  tally(sort = TRUE)## # A tibble: 3 × 2\n##   age_class     n\n##   <chr>     <int>\n## 1 child      3618\n## 2 adult      2184\n## 3 <NA>         86"},{"path":"grouping_data.html","id":"grouper-selon-plus-ou-moins-de-colonnes","chapter":"13 Travailler sur des données groupées","heading":"Grouper selon plus ou moins de colonnes","text":"Par défaut, si vous exécutez group_by() sur des données déjà groupées, les anciens groupes seront supprimés et le ou les nouveaux groupes s’appliqueront. Si vous voulez ajouter de nouveaux groupes à ceux qui existent déjà, incluez l’argument .add = TRUE.","code":"\n# Grouper par  outcome\nby_outcome <- linelist %>% \n  group_by(outcome)\n\n# Ajouter gender aux définition de groupe (grouper par une combinaison\n# de gender et outcome)\nby_outcome_gender <- by_outcome %>% \n  group_by(gender, .add = TRUE)"},{"path":"grouping_data.html","id":"conserver-tous-les-groupes","chapter":"13 Travailler sur des données groupées","heading":"Conserver tous les groupes","text":"Si vous groupez les données sur la base d’une colonne de type “facteur”, il se peut que certains niveaux du facteur ne soient pas présents dans le jeu de données dans son état actuel. Dans ce cas, ces niveaux non représentés seront abandonnés par défaut et n’apparaîtront pas dans les groupes. Pour éviter ce comportement et prendre en compte tous les niveaux du facteur, y compris lorsqu’ils ne contiennent pas de données, utilisez l’argument .drop = FALSE dans votre commande group_by().","code":""},{"path":"grouping_data.html","id":"dégrouper-les-données","chapter":"13 Travailler sur des données groupées","heading":"13.3 Dégrouper les données","text":"Les dataframes qui ont été groupés le resteront jusqu’à ce qu’ils soient spécifiquement dégroupés grâce à la fonction ungroup().Attention à ne pas oublier de dégrouper les données avant de passer aux étapes qui nécessitent le jeu de données complet et non groupé.peut également dégrouper seulement certaines colonnes, en passant le nom de la colonne à ungroup().NOTE: Le verbe count() dégroupe automatiquement les données après avoir compté les lignes.","code":"\nlinelist %>% \n  group_by(outcome, gender) %>% \n  tally() %>% \n  ungroup()\nlinelist %>% \n  group_by(outcome, gender) %>% \n  tally() %>% \n  ungroup(gender) # dégroupe gender, mais garde le groupement par outcome"},{"path":"grouping_data.html","id":"group_summarise","chapter":"13 Travailler sur des données groupées","heading":"13.4 Résumer les données par groupe","text":"Voir la section dplyr du chapitre sur les Tableaux descriptifs pour une explication détaillée sur comment produire des tableaux récapitulatifs à l’aide de la fonction summarise(). Ici, nous décrivons le comportement de summarise() lorsque la fonction est appliquée à des données groupées.La fonction de dplyr summarise() (ou summarize()) prend un dataframe en entrée et le convertit en un nouveau dataframe contenant des statistiques de synthèse définies par l’utilisateur. Sur un tableau non groupé, le calcul de synthèse est effectuée sur toutes les lignes. Sur un tableau groupé, le calcul est effectué pour chaque groupe.Plus précisement, la syntaxe de la fonction summarise() est du type :\n“NOM_NOUVELLE_COLONNE = fonction résumé d’une ou plusieurs colonnes des données source”. Dans la fonction statistique, indiquez la colonne à traiter et tout argument pertinent (par exemple, na.rm = TRUE). Les fonctions régulièrement utilisées incluent par exemple mean(), min(), max(), median(), ou sd(), mais peut également utiliser sum() pour compter le nombre de lignes qui répondent à un critère logique (avec l’opérateur ==).Vous trouverez ci-dessous un premier où summarise() est appliquée sur des données non groupées : les statistiques retournées sont produites à partir de l’ensemble des données.Maintenant, la même commande est appliquée sur la linelist groupée, ce qui génère les résumés statistique pour chaque groupe. Notez que les colonnes utilisées pour définir les groupes sont gardées dans le tableau agrégé généré par summarise().Note: il est possible d’appeler la fonction en utilisant l’orthographe britannique et américaine : summarise() et summarize() sont équivalentes.","code":"\n# statistiques résumées appliquées sur le jeu de données complet\nlinelist %>% \n  summarise(\n    n_cases  = n(),\n    mean_age = mean(age_years, na.rm = T),\n    max_age  = max(age_years,  na.rm = T),\n    min_age  = min(age_years,  na.rm = T),\n    n_males  = sum(gender == \"m\", na.rm = T))##   n_cases mean_age max_age min_age n_males\n## 1    5888 16.01831      84       0    2803\n# statistiques résumées appliquées sur le jeu de données complet \n# mais groupé par outcome\nlinelist %>% \n  group_by(outcome) %>% \n  summarise(\n    n_cases  = n(),\n    mean_age = mean(age_years, na.rm = T),\n    max_age  = max(age_years,  na.rm = T),\n    min_age  = min(age_years,  na.rm = T),\n    n_males  = sum(gender == \"m\", na.rm = T))## # A tibble: 3 × 6\n##   outcome n_cases mean_age max_age min_age n_males\n##   <chr>     <int>    <dbl>   <dbl>   <dbl>   <int>\n## 1 Death      2582     15.9      76       0    1228\n## 2 Recover    1983     16.1      84       0     950\n## 3 <NA>       1323     16.2      69       0     625"},{"path":"grouping_data.html","id":"comptes-et-additions","chapter":"13 Travailler sur des données groupées","heading":"13.5 Comptes et additions","text":"Les fonctions count() et tally() fournissent des fonctionnalités similaires mais légèrement différentes. Pour plus de détails sur la distinction entre les deux, voir ici.","code":""},{"path":"grouping_data.html","id":"tally","chapter":"13 Travailler sur des données groupées","heading":"tally()","text":"tally() est un raccourci pour summarise(n = n()), et ne groupe pas les données d’elle même. Ainsi, pour obtenir des totaux groupés, il faut d’abord exécuter la commande group_by() avant la commande tally(). peut ajouter sort = TRUE pour voir les plus grands groupes en premier.Exemple sans grouper les données :En groupant les données avant d’applique la fonction tally() :","code":"\nlinelist %>% \n  tally()##      n\n## 1 5888\nlinelist %>% \n  group_by(outcome) %>% \n  tally(sort = TRUE)## # A tibble: 3 × 2\n##   outcome     n\n##   <chr>   <int>\n## 1 Death    2582\n## 2 Recover  1983\n## 3 <NA>     1323"},{"path":"grouping_data.html","id":"count","chapter":"13 Travailler sur des données groupées","heading":"count()","text":"En revanche, la fonction count() effectue les actions suivantes :applique group_by() sur la ou les colonnes spécifiéesapplique summarise() et retourne la colonne n avec le nombre de lignes par groupepuis applique la fonction ungroup().Tout comme avec group_by() il est possible de créer une nouvelle colonne directement dans la commande count() :count() peut être utilisée plusieurs fois à la suite pour résumer des données de manière plus en plus compacte. Par exemple, pour résumer le nombre d’hôpitaux présents pour chaque sexe, exécutez ce qui suit. Notez que le nom de la dernière colonne est changé de la valeur par défaut “n” pour plus de clarté (avec name =).","code":"\nlinelist %>% \n  count(outcome)##   outcome    n\n## 1   Death 2582\n## 2 Recover 1983\n## 3    <NA> 1323\nlinelist %>% \n  count(age_class = ifelse(age >= 18, \"adult\", \"child\"), \n        sort = T)##   age_class    n\n## 1     child 3618\n## 2     adult 2184\n## 3      <NA>   86\nlinelist %>% \n  # compte le nombre de lignes pour chaque combinaison gender x hospital\n  count(gender, hospital) %>% \n  # en utilisant le jeu de données agrégées, compte le nombre d’hôpitaux pour chaque genre.\n  count(gender, name = \"hospitals per gender\" ) ##   gender hospitals per gender\n## 1      f                    6\n## 2      m                    6\n## 3   <NA>                    6"},{"path":"grouping_data.html","id":"ajouter-des-colonnes-contenant-les-décomptes","chapter":"13 Travailler sur des données groupées","heading":"Ajouter des colonnes contenant les décomptes","text":"Construites sur des principes similaires à count() et tally(), vous pouvez utiliser les fonctions add_count() et add_tally() pour ajouter une nouvelle colonne n avec le nombre de lignes par groupe tout en conservant toutes les autres colonnes du dataframe. Cela signifie que le nombre de lignes total d’un groupe est ajouté pour chaque ligne du groupe dans une nouvelle colonne n.Dans l’exemple suivant, nous ajoutons cette colonne et ré-arrangeons ensuite les colonnes pour une lecture plus aisée du tableau. Pour un autre exemple, voir la section plus bas sur comment filtrer sur la taille du groupe.","code":"\nlinelist %>% \n  as_tibble() %>%  # conversion en tibble pour un meilleur affichage\n  add_count(hospital) %>%  # ajoute la colonne n avec les totaux par hôpitaux\n  select(hospital, n, everything()) # trie les colonnes## # A tibble: 5,888 × 31\n##    hospital          n case_id generation date_infection date_onset date_hospitalisation\n##    <chr>         <int> <chr>        <dbl> <date>         <date>     <date>              \n##  1 Other           885 5fe599           4 2014-05-08     2014-05-13 2014-05-15          \n##  2 Missing        1469 8689b7           4 NA             2014-05-13 2014-05-14          \n##  3 St. Mark's M…   422 11f8ea           2 NA             2014-05-16 2014-05-18          \n##  4 Port Hospital  1762 b8812a           3 2014-05-04     2014-05-18 2014-05-20          \n##  5 Military Hos…   896 893f25           3 2014-05-18     2014-05-21 2014-05-22          \n##  6 Port Hospital  1762 be99c8           3 2014-05-03     2014-05-22 2014-05-23          \n##  7 Missing        1469 07e3e8           4 2014-05-22     2014-05-27 2014-05-29          \n##  8 Missing        1469 369449           4 2014-05-28     2014-06-02 2014-06-03          \n##  9 Missing        1469 f393b4           4 NA             2014-06-05 2014-06-06          \n## 10 Missing        1469 1389ca           4 NA             2014-06-05 2014-06-07          \n## # ℹ 5,878 more rows\n## # ℹ 24 more variables: date_outcome <date>, outcome <chr>, gender <chr>, age <dbl>,\n## #   age_unit <chr>, age_years <dbl>, age_cat <fct>, age_cat5 <fct>, lon <dbl>,\n## #   lat <dbl>, infector <chr>, source <chr>, wt_kg <dbl>, ht_cm <dbl>, ct_blood <dbl>,\n## #   fever <chr>, chills <chr>, cough <chr>, aches <chr>, vomit <chr>, temp <dbl>,\n## #   time_admission <chr>, bmi <dbl>, days_onset_hosp <dbl>"},{"path":"grouping_data.html","id":"ajouter-les-totaux","chapter":"13 Travailler sur des données groupées","heading":"Ajouter les totaux","text":"Pour facilement ajouter les totaux par lignes ou colonnes d’un tableau après avoir utilisé tally() ou count(), consultez la section janitor de la page sur les tables descriptives. Ce paquet offre des fonctions telles que adorn_totals() et adorn_percentages() pour ajouter des totaux et pourcentages. Par exemple :Pour ajouter des lignes de totaux plus complexes qui impliquent des statistiques récapitulatives autres que des sommes, voir cette section de la page Tables descriptives.","code":"\nlinelist %>%                                  \n  tabyl(age_cat, gender) %>%                  # décomptes croisés de deux colonnes\n  adorn_totals(where = \"row\") %>%             # ajoute ligne de totaux\n  adorn_percentages(denominator = \"col\") %>%  # ajoute proportions (dénominateur colonne)\n  adorn_pct_formatting() %>%                  # formate en %\n  adorn_ns(position = \"front\") %>%            # formate en : \"N (%)\"\n  adorn_title(                                # ajuste les titres\n    row_name = \"Catégorie d'âge\",\n    col_name = \"Sexe\")##                            Sexe                            \n##  Catégorie d'âge              f              m          NA_\n##              0-4   640  (22.8%)   416  (14.8%)  39  (14.0%)\n##              5-9   641  (22.8%)   412  (14.7%)  42  (15.1%)\n##            10-14   518  (18.5%)   383  (13.7%)  40  (14.4%)\n##            15-19   359  (12.8%)   364  (13.0%)  20   (7.2%)\n##            20-29   468  (16.7%)   575  (20.5%)  30  (10.8%)\n##            30-49   179   (6.4%)   557  (19.9%)  18   (6.5%)\n##            50-69     2   (0.1%)    91   (3.2%)   2   (0.7%)\n##              70+     0   (0.0%)     5   (0.2%)   1   (0.4%)\n##             <NA>     0   (0.0%)     0   (0.0%)  86  (30.9%)\n##            Total 2,807 (100.0%) 2,803 (100.0%) 278 (100.0%)"},{"path":"grouping_data.html","id":"grouper-par-date","chapter":"13 Travailler sur des données groupées","heading":"13.6 Grouper par date","text":"Pour grouper des données par date, il faut avoir, ou créer une colonne contenant l’unité de temps qui vous intéresse (par exemple : “jour”, “semaine épidémiologique”, “mois”, etc). Vous pouvez créer cette colonne en utilisant floor_date() du paquet lubridate, tel qu’expliqué dans la section sur les Semaines épidémiologiques du chapitre sur les dates. Cette colonne peut être simplement passée à group_by() ou count() de dplyr pour grouper les lignes par les valeurs uniques de date ou obtenir le nombre de lignes par date.Un besoin spécifique à la gestion et l’analyse de données par date consiste à compléter les dates de la séquence qui ne sont pas présentes dans les données. Pour cela, peut utiliser complete() du paquet tidyr pour que la série de dates agrégées comprenne toutes les unités de dates possibles dans la plage. Sans cette étape, une semaine où aucun cas n’été signalé n’apparaîtrait pas dans les données…La fonction complete(), redéfinit la colonne contenant les dates comme une séquence de dates (en passant seq.Date() du minimum au maximum comme argument). Par défaut, les valeurs du nombre de cas (et autres colonnes) dans les nouvelles lignes “développées” contient des “NA”, mais l’peut modifier ce comportement. Par exemple, peut mettre le nombre de cas à 0 en utilisant l’argument fill = de complete(), qui prend en entrée une liste nommée (si votre colonne de nombre de cas est nommée n, fournissez fill = list(n = 0). Voir ?complete pour plus de détails et la page Manipuler les dates pour un exemple.","code":""},{"path":"grouping_data.html","id":"grouper-par-jours-linelist","chapter":"13 Travailler sur des données groupées","heading":"Grouper par jours (linelist)","text":"Voici un exemple où l’va grouper le nombre de cas de la linelist par jour, sans utiliser la fonction complete(). Note : la première ligne permet d’ignorer les cas où il n’y pas eu de date de rentrée.Maintenant, le même exemple en utilisant la commande complete() pour s’assurer que tous les jours dans la fourchette temporelle seront représentés dans les données.","code":"\ndaily_counts <- linelist %>% \n  drop_na(date_onset) %>%        # Exclut les cas où date_onset est vide\n  count(date_onset)              # Compte le nombre de lignes par date\ndaily_counts <- linelist %>% \n  drop_na(date_onset) %>%     # Exclut les cas où date_onset est vide\n  count(date_onset) %>%       # Compte le nombre de lignes par jour\n  complete(                   # Ajoute les jours manquants (sans cas)\n    date_onset = seq.Date(    # redéfinit la colonne comme une séquence de dates\n      from = min(date_onset, na.rm=T), \n      to   = max(date_onset, na.rm=T),\n      by   = \"day\"),\n    fill   = list(n = 0))     # remplit les nouvelles dates ajoutées de 0 (aurait été des NA par défaut) "},{"path":"grouping_data.html","id":"grouper-par-semaines-linelist","chapter":"13 Travailler sur des données groupées","heading":"Grouper par semaines (linelist)","text":"Le même principe peut être appliqué au groupement par semaine. Dans cet exemple, va d’abord créer une nouvelle colonne contenant la semaine à l’aide de la fonction floor_date() du package lubridate (avec unit = \"week\"). Cela arrondit chaque date au premier jour de la semaine correspondante. Ensuite, utilise la fonction count() pour obtenir le nombre de cas hebdomadaires. termine enfin avec un complete() pour compléter toutes les semaines dans le jeu de données agrégées, même il n’y pas eu de cas cette semaine là.Voici les 50 premières lignes du jeu de données créé :","code":"\nweekly_counts <- linelist %>% \n  drop_na(date_onset) %>%        # Exclut les cas où date_onset est vide\n  mutate(week = lubridate::floor_date(date_onset, \n                                      unit = \"week\")) %>%  # Crée colonne avec la date de début des symptomes\n  count(week) %>%                # Compte le nombre de lignes par semaine\n  complete(                      # Ajoute les semaines non représentées (sans cas)\n    week = seq.Date(             # redéfinit la colonne comme une séquence de dates\n      from = min(week, na.rm=T), \n      to = max(week, na.rm=T),\n      by = \"week\"),\n    fill = list(n = 0))          # remplit les nouvelles dates ajoutées de 0 (aurait été des NA par "},{"path":"grouping_data.html","id":"grouper-par-mois-linelist","chapter":"13 Travailler sur des données groupées","heading":"Grouper par mois (linelist)","text":"Pour agréger les cas par mois, nous utiliserons à nouveau floor_date(), avec l’argument unit = \"months\". Cette commande arrondit chaque date au 1er de son mois. La sortie sera donc de la classe Date. Notez que dans l’étape complete(), nous utilisons également = \"months\".","code":"\nmonthly_counts <- linelist %>% \n  drop_na(date_onset) %>% \n  mutate(month = lubridate::floor_date(date_onset, \n                                       unit = \"months\")) %>%  # nouvelle colonne, 1st du mois de début des symptomes\n  count(month) %>%             # Compte le nombre de cas par mois\n  complete(\n    month = seq.Date(\n      min(month, na.rm=T),     # Ajoute les mois non représentées (sans cas)\n      max(month, na.rm=T),\n      by=\"month\"),\n    fill = list(n = 0))"},{"path":"grouping_data.html","id":"comptes-journaliers-en-semaines-données-agrégées","chapter":"13 Travailler sur des données groupées","heading":"Comptes journaliers en semaines (données agrégées)","text":"Pour agréger les nombres de cas quotidiens (données déjà agrégées par jour, donc) en nombre de cas hebdomadaires, utilisez floor_date() de la même manière que dans les exemples précédents. Cependant, il faut ensuite utiliser les fonctions group_by() et summarize() au lieu de count() car il faut faire la somme des nombres de cas quotidiens au lieu de simplement compter le nombre de lignes par semaine.","code":""},{"path":"grouping_data.html","id":"comptes-journaliers-en-mois-données-agrégées","chapter":"13 Travailler sur des données groupées","heading":"Comptes journaliers en mois (données agrégées)","text":"Pour agréger les nombres de cas journaliers par mois, utilisez floor_date() de la même manière que dans les exemples précédents (avec unit = \"month\"). Cependant, il faut ensuite utiliser les fonctions group_by() et summarize() au lieu de count() car il faut additionner le nombre de cas quotidiens au lieu de simplement compter le nombre de lignes par mois.","code":""},{"path":"grouping_data.html","id":"trier-les-données-groupées","chapter":"13 Travailler sur des données groupées","heading":"13.7 Trier les données groupées","text":"La fonction arrange() de dplyr qui permet d’ordonner les lignes d’un dataframe se comporte de la même manière lorsque les données sont groupées, sauf si vous définissez l’argument .by_group = TRUE. Dans ce cas, les lignes sont d’abord ordonnées par les colonnes de regroupement, puis par toutes les autres colonnes que vous spécifiez à arrange().","code":""},{"path":"grouping_data.html","id":"filtrer-les-données-groupées","chapter":"13 Travailler sur des données groupées","heading":"13.8 Filtrer les données groupées","text":"","code":""},{"path":"grouping_data.html","id":"filter","chapter":"13 Travailler sur des données groupées","heading":"filter()","text":"Lorsque l’utilise la fonction filter en conjonction avec des fonctions qui évaluent le dataframe (max(), min() ou mean() par exemple), la commande est désormais appliquée à chaque groupe indépendamment. Par exemple, pour filtrer et conserver les lignes où les patients ont un âge supérieur à l’âge médian, le filtre s’appliquera désormais à l’intérieur de chaque groupe, pour pour conserver les lignes où l’age des patients est supérieur à l’âge médian du groupe.","code":""},{"path":"grouping_data.html","id":"slice","chapter":"13 Travailler sur des données groupées","heading":"slice()","text":"La fonction dplyr slice(), qui filtre les lignes en fonction de leur position dans les données, peut également être appliquée par groupe. N’oubliez pas de trier les données au sein de chaque groupe pour obtenir la “tranche” souhaitée.Par exemple, pour extraire uniquement les 5 dernières admissions de chaque hôpital :Groupez les données de la linelist par la colonne hospital.Triez les enregistrements du plus récent au plus ancien grâce à la colonne date_hospitalisation dans chaque groupe d’hôpitaux.Tranchez pour récupérer les 5 premières lignes de chaque hôpitalslice_head() : sélectionne les n premières lignes (“par le haut”)slice_tail() : sélectionne les n dernières lignes (“par le bas”)slice_sample() : sélectionne n lignes aléatoirement. Utiliser replace = TRUE pour un échantillonnage avec remplacementslice_min() : sélectionne les n lignes avec les plus petites valeurs dans une colonne donnée (argument order_by =). Utiliser with_ties = TRUE pour garder les ex-æquoslice_max() : sélectionne les n lignes avec les plus grandes valeurs dans une colonne donnée (argument order_by =)Voir le chapitre sur la dé-duplication pour plus d’exemples et de détails sur la fonction slice().","code":"\nlinelist %>%\n  group_by(hospital) %>%\n  arrange(hospital, date_hospitalisation) %>%\n  slice_head(n = 5) %>% \n  arrange(hospital) %>%                            # (pour l'affichage)\n  select(case_id, hospital, date_hospitalisation)  # (pour l'affichage)## # A tibble: 30 × 3\n## # Groups:   hospital [6]\n##    case_id hospital          date_hospitalisation\n##    <chr>   <chr>             <date>              \n##  1 20b688  Central Hospital  2014-05-06          \n##  2 d58402  Central Hospital  2014-05-10          \n##  3 b8f2fd  Central Hospital  2014-05-13          \n##  4 acf422  Central Hospital  2014-05-28          \n##  5 275cc7  Central Hospital  2014-05-28          \n##  6 d1fafd  Military Hospital 2014-04-17          \n##  7 974bc1  Military Hospital 2014-05-13          \n##  8 6a9004  Military Hospital 2014-05-13          \n##  9 09e386  Military Hospital 2014-05-14          \n## 10 865581  Military Hospital 2014-05-15          \n## # ℹ 20 more rows"},{"path":"grouping_data.html","id":"group_filter_grp_size","chapter":"13 Travailler sur des données groupées","heading":"Filtrer sur la taille des groupes","text":"La fonction add_count() ajoute une colonne n aux données originales, ajoutant ainsi, pour chaque ligne, le nombre de lignes du groupe auquel cette ligne appartient.Dans l’exemple ci-dessous, add_count() est appliqué à la colonne hospital, de sorte que les valeurs de la nouvelle colonne n reflètent le nombre de lignes dans le groupe hospitalier de cette ligne. Bien sûr, cela veut dire que la valeur de la colonne “n” est répétée pour chaque ligne du groupe.Dans l’exemple ci-dessous, le nom de la colonne n pourrait être modifié en utilisant name = dans add_count().Il est alors facile de filtrer les lignes de cas qui ont été hospitalisés dans un “petit” hôpital. Par exemple un hôpital qui admis moins de 500 patients :","code":"\nlinelist %>% \n  as_tibble() %>% \n  add_count(hospital) %>%          # ajoute le nombre de patients admis dans cette hôpital, pour chaque groupe\n  select(hospital, n, everything()) # Pour un meilleur affichage## # A tibble: 5,888 × 31\n##    hospital          n case_id generation date_infection date_onset date_hospitalisation\n##    <chr>         <int> <chr>        <dbl> <date>         <date>     <date>              \n##  1 Other           885 5fe599           4 2014-05-08     2014-05-13 2014-05-15          \n##  2 Missing        1469 8689b7           4 NA             2014-05-13 2014-05-14          \n##  3 St. Mark's M…   422 11f8ea           2 NA             2014-05-16 2014-05-18          \n##  4 Port Hospital  1762 b8812a           3 2014-05-04     2014-05-18 2014-05-20          \n##  5 Military Hos…   896 893f25           3 2014-05-18     2014-05-21 2014-05-22          \n##  6 Port Hospital  1762 be99c8           3 2014-05-03     2014-05-22 2014-05-23          \n##  7 Missing        1469 07e3e8           4 2014-05-22     2014-05-27 2014-05-29          \n##  8 Missing        1469 369449           4 2014-05-28     2014-06-02 2014-06-03          \n##  9 Missing        1469 f393b4           4 NA             2014-06-05 2014-06-06          \n## 10 Missing        1469 1389ca           4 NA             2014-06-05 2014-06-07          \n## # ℹ 5,878 more rows\n## # ℹ 24 more variables: date_outcome <date>, outcome <chr>, gender <chr>, age <dbl>,\n## #   age_unit <chr>, age_years <dbl>, age_cat <fct>, age_cat5 <fct>, lon <dbl>,\n## #   lat <dbl>, infector <chr>, source <chr>, wt_kg <dbl>, ht_cm <dbl>, ct_blood <dbl>,\n## #   fever <chr>, chills <chr>, cough <chr>, aches <chr>, vomit <chr>, temp <dbl>,\n## #   time_admission <chr>, bmi <dbl>, days_onset_hosp <dbl>\nlinelist %>% \n  add_count(hospital) %>% \n  filter(n < 500)"},{"path":"grouping_data.html","id":"mutate","chapter":"13 Travailler sur des données groupées","heading":"13.9 mutate()","text":"Pour conserver toutes les colonnes et lignes (sans les résumer) et ajouter une nouvelle colonne contenant des statistiques de groupe, utilisez mutate() après group_by() au lieu de summarise().Ceci est utile si vous voulez les statistiques de groupe dans le jeu de données original avec toutes les autres colonnes présentes - par exemple pour les calculs qui comparent une ligne à son groupe.Par exemple, le code ci-dessous calcule la différence entre le délai d’admission d’une ligne et le délai d’admission médian pour son hôpital. Les étapes sont les suivantes :Groupez les données par hôpitalUtilisez la colonne days_onset_hosp (délai à l’hospitalisation) pour créer une nouvelle colonne contenant le délai moyen de l’hôpital pour chaque patient de cet hôpitalCalculez la différence entre les deux colonnes","code":"\nlinelist %>% \n  # grouper les données par hôpital\n  group_by(hospital) %>% \n  \n  # Ajoute de nouvelles colonnes (conserve toutes lies lignes)\n  mutate(\n    # Délai moyen d'admission pour chaque hôpital (arrondi à la 1re décimale)\n    group_delay_admit = round(mean(days_onset_hosp, na.rm = T), 1),\n    \n    # Différence entre le délai de chaque patient et le délai moyen de son hôpital\n    diff_to_group = round(days_onset_hosp - group_delay_admit, 1)) %>%\n  \n  # Sélectionne colonnes (pour l'affichage)\n  select(case_id, hospital, days_onset_hosp, group_delay_admit, diff_to_group)## # A tibble: 5,888 × 5\n## # Groups:   hospital [6]\n##    case_id hospital                      days_onset_hosp group_delay_admit diff_to_group\n##    <chr>   <chr>                                   <dbl>             <dbl>         <dbl>\n##  1 5fe599  Other                                       2               2             0  \n##  2 8689b7  Missing                                     1               2.1          -1.1\n##  3 11f8ea  St. Mark's Maternity Hospita…               2               2.1          -0.1\n##  4 b8812a  Port Hospital                               2               2.1          -0.1\n##  5 893f25  Military Hospital                           1               2.1          -1.1\n##  6 be99c8  Port Hospital                               1               2.1          -1.1\n##  7 07e3e8  Missing                                     2               2.1          -0.1\n##  8 369449  Missing                                     1               2.1          -1.1\n##  9 f393b4  Missing                                     1               2.1          -1.1\n## 10 1389ca  Missing                                     2               2.1          -0.1\n## # ℹ 5,878 more rows"},{"path":"grouping_data.html","id":"select-sur-les-données-groupées","chapter":"13 Travailler sur des données groupées","heading":"13.10 select() sur les données groupées","text":"La fonction select() fonctionne sur les données groupées, à ce détail près que les colonnes utilisées pour les groupes sont toujours inclues, même si elles n’ont pas été mentionnées dans les colonnes à conserver. Pour se débarrasser de ces colonnes, il faut utiliser ungroup() avant de dégrouper.","code":""},{"path":"grouping_data.html","id":"resources-2","chapter":"13 Travailler sur des données groupées","heading":"13.11 Resources","text":"Pour plus d’information, voici quelques ressources utiles :Vous pouvez utiliser n’importe quelle fonction agrégeant sur des données groupées ; Voir l’antisèche sur la transformation des données avec RstudioLa page de Data Carpentry sur dplyrLa page de référence de l’aide du tidyverse sur group_by() et groupingCette page sur la manipulation des donnéesRésummer les données avec des conditions avec dplyr","code":""},{"path":"joining_matching.html","id":"joining_matching","chapter":"14 Joindre des données","heading":"14 Joindre des données","text":"Ci-dessus : animation d’une jointure par la gauche (source de l’image)Ce chapitre décrit les méthodes permettant de joindre / fusionner / faire correspondre / lier / “merger” / unir / combiner des tableaux.Lors de l’analyse de données épidémiologiques, il est rare que votre processus de nettoyage des données n’implique pas des sources de données multiples, et donc leur mise en relation.\nPar exemple, vous aurez peut-être à joindre des données de laboratoire aux résultats cliniques des patients, ou des données de mobilité Google aux tendances des maladies infectieuses, ou même un jeu de données à un stade donné de l’analyse et une version transformée de lui-même.Dans ce chapitre, nous allons :Réaliser des jointures de deux dataframes en faisant correspondre les lignes sur la base d’une clef primaire (dans une ou plusieurs colonnes).Joindre des jeux de données sur la base de correspondances probabilistes (probables) entre les observationsÉtendre un jeu de données en concaténant des lignes ou des colonnes d’un autre jeu de données.","code":""},{"path":"joining_matching.html","id":"étapes-préliminaires-2","chapter":"14 Joindre des données","heading":"14.1 Étapes préliminaires","text":"","code":""},{"path":"joining_matching.html","id":"importation-des-paquets-3","chapter":"14 Joindre des données","heading":"Importation des paquets","text":"Ces lignes de code chargent les paquets nécessaires aux analyses. Dans ce guide, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire puis l’importe pour l’utiliser. Vous pouvez également charger les paquets installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les paquets R.","code":"\npacman::p_load(\n  rio,            # import des fichiers\n  here,           # chemins d'accès\n  tidyverse,      # gestion des données + graphiques (ggplot2)\n  RecordLinkage,  # correspondances probabilistes\n  fastLink        # correspondances probabilistes\n)"},{"path":"joining_matching.html","id":"importation-des-données-2","chapter":"14 Joindre des données","heading":"Importation des données","text":"Nous importons un jeu de données de cas d’une épidémie d’ébola fictive. Pour reproduire les étapes, cliquez pour télécharger la linelist “propre” (.rds file). Importez vos données avec la fonction import() du paquet rio (elle accepte de nombreux types de fichiers comme .xlsx, .rds, .csv - voir la page Importation et exportation des données pour plus de détails).Les cinquantes premières lignes sont affichées ci-dessous :","code":"\n# importer la linelist dans R\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"joining_matching.html","id":"jeux-de-données-simplifiés","chapter":"14 Joindre des données","heading":"Jeux de données simplifiés","text":"Dans les exemples ci-dessous, nous utiliserons des jeux de données simplifiés pour mieux voir ce qui se passe :Une version “miniature” de la linelist (liste des cas), contenant seulement les colonnes case_id, date_onset, et hospital, et seulement les 10 premières lignes.Une table nommée hosp_info, qui contient des détails sur chaque hôpital.Dans la section sur l’appariement probabiliste, nous utiliserons deux petits ensembles de données différents. Le code pour créer ces jeux de données sera donné dans cette section.","code":""},{"path":"joining_matching.html","id":"joins_llmini","chapter":"14 Joindre des données","heading":"Linelist miniature","text":"Nous générons ici la linelist miniature des cas, qui contient seulement 10 lignes et seulement les colonnes case_id, date_onset, et hospital.","code":"\nlinelist_mini <- linelist %>%                 \n  select(case_id, date_onset, hospital) %>%   # sélectionne les colonnes\n  head(10)                                    # garde les 10 premières lignes"},{"path":"joining_matching.html","id":"joins_hosp_info","chapter":"14 Joindre des données","heading":"Jeu de données des hôpitaux","text":"Le code ci-dessous permet de créer un jeu de données contenant des informations supplémentaires sur sept hôpitaux (la population desservie et le niveau de soins disponible). Notez que le nom “Hôpital militaire” appartient à deux hôpitaux différents, l’un de niveau primaire desservant 10000 résidents et l’autre de niveau secondaire desservant 50280 résidents.Voici le tableau ainsi produit :","code":"\n# Crée des informations sur les hôpitaux : \nhosp_info = data.frame(\n  hosp_name     = c(\"central hospital\", \"military\", \"military\", \n                    \"port\", \"St. Mark's\", \"ignace\", \"sisters\"),\n  catchment_pop = c(1950280, 40500, 10000, 50280, \n                    12000, 5000, 4200),\n  level         = c(\"Tertiary\", \"Secondary\", \"Primary\", \"Secondary\",\n                    \"Secondary\", \"Primary\", \"Primary\")\n)"},{"path":"joining_matching.html","id":"nettoyage-préliminaire","chapter":"14 Joindre des données","heading":"Nettoyage préliminaire","text":"Les jointures “traditionnelles” (.e. non-probabilistes) sont sensibles à la casse et nécessitent des correspondances exactes entre les valeurs des colonnes utilisées comme clef/identifiant. Pour démontrer certaines des étapes de nettoyage que vous pourriez avoir besoin de faire avant de joindre vos données, nous allons commencer par nettoyer et aligner les dataframe linelist_mini et hosp_info.Identifier les différencesLe nom de l’hôpital étant notre identifiant/clef commun aux deux jeux de données, nous avons besoin que les valeurs de la colonne hosp_name dans le tableau hosp_info correspondent aux valeurs de la colonne hospital dans le tableau linelist_mini.Voici le dataframe linelist_mini, affiché avec la fonction base R unique() :… et voici les valeurs dans le dataframe hosp_info :Il est clair que si certains hôpitaux sont présents dans les deux dataframes, leurs noms ne sont pas toujours orthographiés de la même manière.Aligner les valeursNettoyons les valeurs du jeu de données hosp_info. Comme expliqué dans le chapitre sur le Nettoyage de données et fonctions essentielles, il est possible de recoder les valeurs à partir de critères logiques en utilisant la fonction case_when() de dplyr. Pour les quatre hôpitaux communs dans les deux dataframes, nous modifions les noms pour les aligner avec les noms dans le tableau linelist_mini (en ne touchant pas aux noms des autres hôpitaux grâce à l’argument TRUE ~ hosp_name).ATTENTION: Normalement devrait créer une nouvelle colonne pour ce type de nettoyage (hosp_name_clean par exemple), mais pour mieux comprendre ce qui se passe lors des étapes suivantes, nous modifions directement la colonne contenant les données “brutes”Les noms des hôpitaux qui apparaissent dans les deux bases de données sont désormais identiques. Il y deux hôpitaux dans hosp_info qui ne sont pas présents dans linelist_mini, nous les traiterons plus tard, lors de la jointure.Avant une jointure, il est souvent rassurant de convertir une colonne tout en minuscules ou majuscules. Pour cela, peut utiliser mutate() et une des colonnes de stringr (voir le chapitre sur les chaînes de caractères):str_to_upper()str_to_lower()str_to_title()","code":"\nunique(linelist_mini$hospital)## [1] \"Other\"                                \"Missing\"                             \n## [3] \"St. Mark's Maternity Hospital (SMMH)\" \"Port Hospital\"                       \n## [5] \"Military Hospital\"\nunique(hosp_info$hosp_name)## [1] \"central hospital\" \"military\"         \"port\"             \"St. Mark's\"      \n## [5] \"ignace\"           \"sisters\"\nhosp_info <- hosp_info %>% \n  mutate(\n    hosp_name = case_when(\n      # critère                          # nouvelles valeur\n      hosp_name == \"military\"          ~ \"Military Hospital\",\n      hosp_name == \"port\"              ~ \"Port Hospital\",\n      hosp_name == \"St. Mark's\"        ~ \"St. Mark's Maternity Hospital (SMMH)\",\n      hosp_name == \"central hospital\"  ~ \"Central Hospital\",\n      TRUE                             ~ hosp_name\n      )\n    )\nunique(hosp_info$hosp_name)## [1] \"Central Hospital\"                     \"Military Hospital\"                   \n## [3] \"Port Hospital\"                        \"St. Mark's Maternity Hospital (SMMH)\"\n## [5] \"ignace\"                               \"sisters\""},{"path":"joining_matching.html","id":"jointures-à-laide-de-dplyr","chapter":"14 Joindre des données","heading":"14.2 Jointures à l’aide de dplyr","text":"Le package dplyr offre plusieurs fonctions qui permettent d’effectuer des jointures différentes. dplyr est inclus dans le paquet tidyverse.Un grand merci à https://github.com/gadenbuie pour les gifs informatifs !","code":""},{"path":"joining_matching.html","id":"syntaxe-générale","chapter":"14 Joindre des données","heading":"Syntaxe générale","text":"Les fonctions de jointure peuvent s’utiliser seules pour unir deux dataframes et créer un nouveau dataframe, mais aussi au sein d’un enchaînement de commandes (pipe avec %>%) pour fusionner un dataframe dans un autre à la volée.Dans l’exemple ci-dessous, la fonction left_join() est utilisée de manière autonome pour créer un nouveau jeu de données (joined_data). Les arguments à l’entrée sont les dataframes à unir/fusionner/joindre (df1 et df2). Le premier dataframe listé est le dataframe de base, et le deuxième dataframe listé est joint à celui-ci.Le troisième argument = précise quelle(s) colonne(s) sera utilisée pour faire la correspondance entre les lignes des deux dataframes (la clef). Si les noms de ces colonnes sont différents, fournissez-les dans un vecteur c() comme dans l’exemple ci-dessous, les identifiants communs sont dans la colonne ID dans df1 et dans la colonne identifier dans df2.Si la ou les colonnes “clef” à le même nom dans les deux tableaux, alors leur nom peut juste être fourni directement, avec des guillemets :S’il y besoin de plusieurs colonnes pour identifier de manière unique les observations (.e. créer une clef primaire), peut lister plusieurs colonnes dans un vecteur et le passer à .\nDans cet exemple, les lignes des deux dataframes sont unies si les valeurs sont identiques dans les trois colonnes.Les fonctions de jointure peuvent également être exécutées dans un enchaînement d’instructions (ou pipe). Cela modifiera le jeu de données qui est passée dans le pipe.Dans l’exemple ci-dessous, df1 est pipé, df2 lui est joint, et df1 est ainsi modifié et redéfini.ATTENTION: Les jointures respectent les majuscules/minuscules ! Il peut donc être utile de convertir les colonnes utilisées comme clefs en minuscules ou majuscules. Voir le chapitre sur les chaînes de caractères","code":"\n# Jointure basée sur les valeurs communes dans la colonne ID (df1) et la colonne \"identifier\" (df2)\njoined_data <- left_join(df1, df2, \n                         by = c(\"ID\" = \"identifier\"))\n# Jointure basée sur les valeurs communes dans la colonne ID présente dans df1 et df2\njoined_data <- left_join(df1, df2, \n                         by = \"ID\")\n# Jointure basée sur le prénom, le nom de famille et l'age : les lignes sont fusionnées si les valeurs sont alignées exactement\njoined_data <- left_join(df1, df2, \n                         by = c(\"name\"    = \"firstname\", \n                                \"surname\" = \"lastname\", \n                                \"Age\"     = \"age\"))\ndf1 <- df1 %>%\n  filter(date_onset < as.Date(\"2020-03-05\")) %>%  # nettoyage divers\n  left_join(df2, by = c(\"ID\" = \"identifier\"))     # jointure de df2 à df1"},{"path":"joining_matching.html","id":"jointures-à-gauche-et-droite","chapter":"14 Joindre des données","heading":"Jointures à gauche et droite","text":"Une jointure à gauche ou droite est une opération très couramment utilisée pour ajouter des informations à un dataframe, en particulier dans les analyses épidémiologiques. Les nouvelles informations sont ajoutées uniquement aux lignes qui existaient déjà dans le dataframe de “référence”.En utilisant ces jointures, l’ordre d’écriture des dataframes dans la commande est important.Dans une jointure à gauche, le premier dataframe écrit est utilisé comme “référence” à laquelle adjoint les informations venant de l’autre table.Dans une jointure à droite, le second dataframe est la référence à laquelle rajoute les informations venant du premier dataframe.Plus précisement :\n* Toutes les lignes présentes dans le dataframe de référence sont conservées. Les informations contenues dans le dataframe secondaire sont adjointes au dataframe de référence uniquement s’il existe une correspondance via la ou les colonnes d’identification/clefs.Les lignes du dataframe secondaire qui ne correspondent pas sont abandonnées.Les lignes du dataframe secondaire qui ne correspondent pas sont abandonnées.Si plusieurs lignes du dataframe utilisé comme référence correspondent à une ligne dans le dataframe secondaire (many--one), les informations du dataframe secondaire sont ajoutées à chaque ligne du dataframe de référence correspondantes.Si plusieurs lignes du dataframe utilisé comme référence correspondent à une ligne dans le dataframe secondaire (many--one), les informations du dataframe secondaire sont ajoutées à chaque ligne du dataframe de référence correspondantes.Si une ligne du dataframe de référence correspond à plusieurs lignes dans le dataframe secondaire (one--many), toutes les combinaisons sont données, ce qui signifie que de nouvelles lignes sont ajoutées au dataframe de référence !.Si une ligne du dataframe de référence correspond à plusieurs lignes dans le dataframe secondaire (one--many), toutes les combinaisons sont données, ce qui signifie que de nouvelles lignes sont ajoutées au dataframe de référence !.Exemples animés de jointures gauche et droite (source de l’image)ExempleVoici le résultat d’un left_join() de hosp_info (dataframe secondaire, voir ici) dans/vers linelist_mini (dataframe de référence, voir ici). La linelist_mini originale nrow(linelist_mini) lignes. La linelist_mini modifiée est affichée. constate que :Deux nouvelles colonnes, catchment_pop et level ont été ajoutées sur le côté gauche de linelist_mini.Deux nouvelles colonnes, catchment_pop et level ont été ajoutées sur le côté gauche de linelist_mini.Toutes les lignes originales du dataframe de référence linelist_mini ont été conservées.Toutes les lignes originales du dataframe de référence linelist_mini ont été conservées.Toutes les lignes originales de linelist_mini pour “Military Hospital” ont été dupliquées car elles correspondaient à deux lignes dans le dataframe secondaire, et donc les deux combinaisons ont été retournées.Toutes les lignes originales de linelist_mini pour “Military Hospital” ont été dupliquées car elles correspondaient à deux lignes dans le dataframe secondaire, et donc les deux combinaisons ont été retournées.La colonne d’identifiant/clef de jointure du dataframe secondaire (hosp_name) disparu car elle est redondante avec la colonne d’identifiant du dataframe de référence (hospital)La colonne d’identifiant/clef de jointure du dataframe secondaire (hosp_name) disparu car elle est redondante avec la colonne d’identifiant du dataframe de référence (hospital)Lorsqu’une ligne du dataframe de gauche ne correspond à aucune du dataframe de droite (par exemple, lorsque hospital est “Autre” ou “Manquant”), les observations renvoyées dans les colonnes venant du dataframe de droite sont NA.Lorsqu’une ligne du dataframe de gauche ne correspond à aucune du dataframe de droite (par exemple, lorsque hospital est “Autre” ou “Manquant”), les observations renvoyées dans les colonnes venant du dataframe de droite sont NA.Les lignes du dataframe de droite qui ne correspondent pas au dataframe gauche (hôpitaux “sisters” et “ignace”) ont été abandonnées.Les lignes du dataframe de droite qui ne correspondent pas au dataframe gauche (hôpitaux “sisters” et “ignace”) ont été abandonnées.","code":"\nlinelist_mini %>% \n  left_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))## Warning in left_join(., hosp_info, by = c(hospital = \"hosp_name\")): Detected an unexpected many-to-many relationship between `x` and `y`.\n## ℹ Row 5 of `x` matches multiple rows in `y`.\n## ℹ Row 4 of `y` matches multiple rows in `x`.\n## ℹ If a many-to-many relationship is expected, set `relationship = \"many-to-many\"` to\n##   silence this warning."},{"path":"joining_matching.html","id":"jointure-à-gauche-ou-jointure-à-droite","chapter":"14 Joindre des données","heading":"Jointure à gauche ou jointure à droite ?","text":"Pour répondre à la question, il faut décider quel dataframe doit conserver toutes ses lignes, et l’utiliser comme dataframe de référence. Une jonction à gauche conserve toutes les lignes du premier dataframe écrit dans la commande, tandis qu’une jonction à droite conserve toutes les lignes du second dataframe.Les deux instructions ci-dessous retournent le même résultat : 10 lignes de hosp_info jointes dans un dataframe linelist_mini, mais elles utilisent des jointures différentes. Le résultat est que l’ordre des colonnes sera différent selon que hosp_info arrive “par la droite” (dans la jointure à gauche) ou arrive “par la gauche” (dans la jointure à droite). L’ordre des lignes peut également changer en conséquence. Néanmoins ces deux conséquences peuvent être traitées ultérieurement, en utilisant select() pour réordonner les colonnes ou arrange() pour trier les lignes.Voici le résultat d’une fusion de hosp_info dans linelist_mini par une jointure à gauche (nouvelles colonnes ajoutées par la droite) :Voici le résultat de la fusion de hosp_info dans linelist_mini par une jointure à droite (nouvelles colonnes ajoutées par la gauche) :Une autre chose à considérer est si la jointure est réalisée au sein d’une chaîne d’instructions pipées (%>%). Si le dataframe transmis par le pipe doit être utilisé comme référence, utilisez une jointure à gauche pour lui adjoindre de nouvelles données.","code":"\n# On obtient le même jeu de données, mais avec l'ordre des colonnes et des lignes différent\nleft_join(linelist_mini, hosp_info, by = c(\"hospital\" = \"hosp_name\"))\nright_join(hosp_info, linelist_mini, by = c(\"hosp_name\" = \"hospital\"))## Warning in left_join(linelist_mini, hosp_info, by = c(hospital = \"hosp_name\")): Detected an unexpected many-to-many relationship between `x` and `y`.\n## ℹ Row 5 of `x` matches multiple rows in `y`.\n## ℹ Row 4 of `y` matches multiple rows in `x`.\n## ℹ If a many-to-many relationship is expected, set `relationship = \"many-to-many\"` to\n##   silence this warning.## Warning in right_join(hosp_info, linelist_mini, by = c(hosp_name = \"hospital\")): Detected an unexpected many-to-many relationship between `x` and `y`.\n## ℹ Row 4 of `x` matches multiple rows in `y`.\n## ℹ Row 5 of `y` matches multiple rows in `x`.\n## ℹ If a many-to-many relationship is expected, set `relationship = \"many-to-many\"` to\n##   silence this warning."},{"path":"joining_matching.html","id":"jointure-complète","chapter":"14 Joindre des données","heading":"Jointure complète","text":"La jointure complète est la plus inclusive des jointures, elle renvoie toutes les lignes des deux dataframes fusionnés.Si des lignes ne sont présentes que dans l’un des dataframes fusionnés (.e aucune correspondance n’est trouvée), elles seront inclues dans le dataframe final (qui s’allonge donc), avec des NA pour combler les vides.Lorsque vous effectuez une jointure, surveillez attentivement le nombre de colonnes et de lignes pour vérifier le nombre de lignes des dataframes en entrée, et du dataframe fusionné. Cela vous permettra notamment de détecter des problèmes de correspondance dus à la sensibilité à la casse ou à des correspondances inexactes.Le dataframe de référence utilisé comme base est celui qui est écrit en premier dans la commande. Dans une jointure complète, Lequel des deux dataframes est écrit en premier n’affecte que l’ordre des lignes, l’ordre des colonnes et le nom des colonnes clef retenues.Exemple animé d’une jointure complète (image source)ExempleVoici la sortie d’une jointure complète du dataframe hosp_info (originellement nrow(hosp_info) lignes, voir ici) avec linelist_mini (originellement nrow(linelist_mini) lignes, voir ici). constate que :Toutes les lignes du dataframe de référence sont conservées (linelist_mini).Toutes les lignes du dataframe de référence sont conservées (linelist_mini).Les lignes du second dataframe qui n’ont pas de correspondance avec le premier dataframe sont conservées (“ignace” et “sisters”), et les valeurs des colonnes apportées par le dataframe de référence, case_id et onset, sont complétées par des valeurs manquantes.Les lignes du second dataframe qui n’ont pas de correspondance avec le premier dataframe sont conservées (“ignace” et “sisters”), et les valeurs des colonnes apportées par le dataframe de référence, case_id et onset, sont complétées par des valeurs manquantes.De même, les lignes du dataframe de référence qui ne correspondent pas à la ligne secondaire (“Autre” et “Manquant”) sont conservées, les colonnes secondaires catchment_pop et level étant remplies de valeurs manquantes.De même, les lignes du dataframe de référence qui ne correspondent pas à la ligne secondaire (“Autre” et “Manquant”) sont conservées, les colonnes secondaires catchment_pop et level étant remplies de valeurs manquantes.Dans le cas d’une correspondance un-à-plusieurs ou plusieurs-à-un (par exemple, des lignes pour “Hôpital militaire”), toutes les combinaisons possibles sont retournées (ce qui allonge le dataframe final).Dans le cas d’une correspondance un-à-plusieurs ou plusieurs-à-un (par exemple, des lignes pour “Hôpital militaire”), toutes les combinaisons possibles sont retournées (ce qui allonge le dataframe final).Seule la colonne d’identification du dataframe de référence est conservée (hospital).Seule la colonne d’identification du dataframe de référence est conservée (hospital).","code":"\nlinelist_mini %>% \n  full_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))## Warning in full_join(., hosp_info, by = c(hospital = \"hosp_name\")): Detected an unexpected many-to-many relationship between `x` and `y`.\n## ℹ Row 5 of `x` matches multiple rows in `y`.\n## ℹ Row 4 of `y` matches multiple rows in `x`.\n## ℹ If a many-to-many relationship is expected, set `relationship = \"many-to-many\"` to\n##   silence this warning."},{"path":"joining_matching.html","id":"jointure-interne","chapter":"14 Joindre des données","heading":"Jointure interne","text":"La jointure interne est la plus restrictive des jointures : elle renvoie uniquement les lignes avec des correspondances dans les deux dataframes.\nLe nombre de lignes dans le dataframe de référence peut ainsi diminuer. Le choix du dataframe à passer en premier à la fonction n’aura pas d’impact sur les lignes conservées, mais affectera l’ordre des colonnes, l’ordre des lignes et clefs d’identification retenues.Exemple animé d’une jointure complète : (image source)ExempleVoici la sortie d’un inner_join() de la linelist_mini (référence) avec hosp_info (secondaire). constate que :Les lignes du dataframe de référence sans correspondance dans le second dataframe sont supprimées (lignes où hospital est “Missing” ou “”).De même, les lignes du dataframe secondaires qui n’ont pas de correspondance dans le dataframe de référence (lignes où hosp_name est “sisters” ou “ignace”) sont supprimées.Seule la colonne clef du dataframe de référence est conservée (hospital).","code":"\nlinelist_mini %>% \n  inner_join(hosp_info, \n             by = c(\"hospital\" = \"hosp_name\"))## Warning in inner_join(., hosp_info, by = c(hospital = \"hosp_name\")): Detected an unexpected many-to-many relationship between `x` and `y`.\n## ℹ Row 5 of `x` matches multiple rows in `y`.\n## ℹ Row 4 of `y` matches multiple rows in `x`.\n## ℹ If a many-to-many relationship is expected, set `relationship = \"many-to-many\"` to\n##   silence this warning."},{"path":"joining_matching.html","id":"semi-jointure","chapter":"14 Joindre des données","heading":"Semi jointure","text":"Les semi jointures sont des jointures dites “filtrantes”, qui utilisent la correspondance avec un second dataframe pour filtrer le dataframe de référence.La semi jointure garde toutes les observations du dataframe de référence qui ont une correspondance dans le dataframe secondaire. Mais les colonnes du dataframe secondaire ne sont pas ajoutées et les lignes du dataframe de référence ne sont pas dupliquées s’il y des correspondances multiples.Plus d’explications sur les semi-jointures ici.Exemple animé d’une semi jointure (image source)Voici un exemple qui retourne les lignes du dataframe hosp_info qui ont une correspondance dans le dataframe linelist_mini en utilisant le nom de l’hôpital comme clé de jointure/identifiant.","code":"\nhosp_info %>% \n  semi_join(linelist_mini, \n            by = c(\"hosp_name\" = \"hospital\"))##                              hosp_name catchment_pop     level\n## 1                    Military Hospital         40500 Secondary\n## 2                    Military Hospital         10000   Primary\n## 3                        Port Hospital         50280 Secondary\n## 4 St. Mark's Maternity Hospital (SMMH)         12000 Secondary"},{"path":"joining_matching.html","id":"anti-jointure-anti_join","chapter":"14 Joindre des données","heading":"Anti-jointure anti_join()","text":"L’anti-jointure est une autre type de jointure filtrante, qui, à l’opposé du semi-join, ne renvoie que les lignes du dataframe de référence qui n’ont PAS de correspondance dans le dataframe secondaire.Plus de détails sur les jointures filtrantes ici.Voici quelques cas d’usage de l’anti-jointure : identifier les observations non présentes dans un autre dataframe, identifier les typos qui compliquent une jointure (se focaliser sur les observations qui auraient du correspondre), examiner les observations qui ont été exclues d’une jointure etc.Comme pour les jointures à droite (right_join()) et à gauche (left_join()), l’ordre dans lequel sont passés les dataframe de l’importance. Dans les joins filtrants, ne renvoie que les lignes présentes dans le dataframe de référence (écrit en premier), comme peut le voir dans l’animation ci-dessous (la ligne 4, violette, du dataframe secondaire n’est pas retournée, alors qu’elle ne matche avec aucune ligne du dataframe de référence).Exemple animé d’une anti-jointure (image source)","code":""},{"path":"joining_matching.html","id":"exemple-simple-danti-jointure","chapter":"14 Joindre des données","heading":"Exemple simple d’anti-jointure","text":"Un cas d’utilisation simple est de rechercher les hôpitaux dans le tableau hosp_info qui n’ont pas de cas présents dans le tableau linelist_mini.\nNous rentrons hosp_info en premier, comme dataframe de référence, puis linelist_mini, la seconde table à comparer pour trouver les hôpitaux qui n’y sont pas présents.","code":"\nhosp_info %>% \n  anti_join(linelist_mini, by = c(\"hosp_name\" = \"hospital\"))"},{"path":"joining_matching.html","id":"exemple-danti-jointure-plus-complexe","chapter":"14 Joindre des données","heading":"Exemple d’anti-jointure plus complexe","text":"Imaginons cette fois-ci que nous avons exécuté une jointure interne (inner_join()) entre les dataframes linelist_mini et hosp_info. Cette opération ne retourne qu’un sous-ensemble des lignes originales de linelist_mini, car certains hôpitaux ne sont pas présents dans hosp_info.Nous pouvons utiliser une anti jointure pour inspecter les éléments de linelist_mini qui ont été exclus lors de la jointure interne, avec les mêmes paramètres (linelist_mini comme dataframe de référence).Pour voir les lignes d’hosp_info exclues lors de la jointure interne, nous pourrions aussi exécuter une anti-jointure en utilisant hosp_info comme table de référence.","code":"\nlinelist_mini %>% \n  inner_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))## Warning in inner_join(., hosp_info, by = c(hospital = \"hosp_name\")): Detected an unexpected many-to-many relationship between `x` and `y`.\n## ℹ Row 5 of `x` matches multiple rows in `y`.\n## ℹ Row 4 of `y` matches multiple rows in `x`.\n## ℹ If a many-to-many relationship is expected, set `relationship = \"many-to-many\"` to\n##   silence this warning.\nlinelist_mini %>% \n  anti_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))"},{"path":"joining_matching.html","id":"apparienement-probabiliste","chapter":"14 Joindre des données","heading":"14.3 Apparienement probabiliste","text":"Si l’ne dispose pas d’un identifiant unique commun à tous les dataframes sur lequel se baser, il est possible d’utiliser un algorithme de correspondance probabiliste. Cet algorithme cherche des correspondances entre les observations sur la base de la similarité (par exemple, la distance entre les chaînes de caractères Jaro-Winkler ou la distance numérique). Nous illustrons ce concept ci-dessous à l’aide du paquet fastLink.Charger les paquetsNous créons d’abord deux petits jeux de données d’exemple que nous utiliserons pour démontrer l’appariement/la correspondance probabiliste (cases et test_results) :Le dataframe cases 9 observations de patients attendant les résultats de leur test.Le dataframe test_results 14 observations et contient la colonne result, qui contient des informations que nous voudrions rapatrier dans le jeu de données cases en utilisant un algorithme probabiliste pour faire correspondre les observations.","code":"\npacman::p_load(\n  tidyverse,      # manipulation de données et visualisation\n  fastLink        # appariement d'observations\n  )\n# Création des jeux de données\n\ncases <- tribble(\n  ~gender, ~first,      ~middle,     ~last,        ~yr,   ~mon, ~day, ~district,\n  \"M\",     \"Amir\",      NA,          \"Khan\",       1989,  11,   22,   \"River\",\n  \"M\",     \"Anthony\",   \"B.\",        \"Smith\",      1970, 09, 19,      \"River\", \n  \"F\",     \"Marialisa\", \"Contreras\", \"Rodrigues\",  1972, 04, 15,      \"River\",\n  \"F\",     \"Elizabeth\", \"Casteel\",   \"Chase\",      1954, 03, 03,      \"City\",\n  \"M\",     \"Jose\",      \"Sanchez\",   \"Lopez\",      1996, 01, 06,      \"City\",\n  \"F\",     \"Cassidy\",   \"Jones\",      \"Davis\",     1980, 07, 20,      \"City\",\n  \"M\",     \"Michael\",   \"Murphy\",     \"O'Calaghan\",1969, 04, 12,      \"Rural\", \n  \"M\",     \"Oliver\",    \"Laurent\",    \"De Bordow\" , 1971, 02, 04,     \"River\",\n  \"F\",      \"Blessing\",  NA,          \"Adebayo\",   1955,  02, 14,     \"Rural\"\n)\n\nresults <- tribble(\n  ~gender,  ~first,     ~middle,     ~last,          ~yr, ~mon, ~day, ~district, ~result,\n  \"M\",      \"Amir\",     NA,          \"Khan\",         1989, 11,   22,  \"River\", \"positive\",\n  \"M\",      \"Tony\",   \"B\",         \"Smith\",          1970, 09,   19,  \"River\", \"positive\",\n  \"F\",      \"Maria\",    \"Contreras\", \"Rodriguez\",    1972, 04,   15,  \"Cty\",   \"negative\",\n  \"F\",      \"Betty\",    \"Castel\",   \"Chase\",        1954,  03,   30,  \"City\",  \"positive\",\n  \"F\",      \"Andrea\",   NA,          \"Kumaraswamy\",  2001, 01,   05,  \"Rural\", \"positive\",      \n  \"F\",      \"Caroline\", NA,          \"Wang\",         1988, 12,   11,  \"Rural\", \"negative\",\n  \"F\",      \"Trang\",    NA,          \"Nguyen\",       1981, 06,   10,  \"Rural\", \"positive\",\n  \"M\",      \"Olivier\" , \"Laurent\",   \"De Bordeaux\",  NA,   NA,   NA,  \"River\", \"positive\",\n  \"M\",      \"Mike\",     \"Murphy\",    \"O'Callaghan\",  1969, 04,   12,  \"Rural\", \"negative\",\n  \"F\",      \"Cassidy\",  \"Jones\",     \"Davis\",        1980, 07,   02,  \"City\",  \"positive\",\n  \"M\",      \"Mohammad\", NA,          \"Ali\",          1942, 01,   17,  \"City\",  \"negative\",\n  NA,       \"Jose\",     \"Sanchez\",   \"Lopez\",        1995, 01,   06,  \"City\",  \"negative\",\n  \"M\",      \"Abubakar\", NA,          \"Abullahi\",     1960, 01,   01,  \"River\", \"positive\",\n  \"F\",      \"Maria\",    \"Salinas\",   \"Contreras\",    1955, 03,   03,  \"River\", \"positive\"\n  )"},{"path":"joining_matching.html","id":"appariement-probabiliste","chapter":"14 Joindre des données","heading":"Appariement probabiliste","text":"La fonction fastLink() du paquet fastLink peut être utilisée pour appliquer un algorithme probabiliste de correspondance. Voici quelques informations basiques, mais vous pouvez en savoir plus en tapant ?fastLink dans la console.Définir les deux dataframes à comparer grâce aux arguments dfA = et dfB =.Dans varnames =, indiquer les noms de toutes les colonnes à utiliser pour la comparaison. Ces colonnes doivent exister à la fois dans dfA et dfB.Dans stringdist.match =, donner les colonnes sur lesquelles effectuer le calcul de la distance de similarité entre les chaînes de caractère (ce ou ces colonnes doivent être présentes dans varnames).Dans numeric.match =, donner les colonnes sur lesquelles calculer une mesure de distance numérique (ce ou ces colonnes doivent être présentes dans varnames).Les valeurs manquantes sont ignorées.Par défaut, chaque ligne de l’un des deux dataframes est comparée à une ligne au maximum de l’autre dataframe. Si vous voulez voir toutes les correspondances évaluées, choisissez dedupe.matches = FALSE. La dé-duplication est faite en utilisant la technique de programmation linéaire de Winkler.Astuce : divisez une colonne de date en trois colonnes numériques distinctes en utilisant day(), month(), et year() du package lubridate.Le seuil par défaut pour les correspondances est de 0.94 (threshold.match =) mais il peut être ajusté. Un seuil plus élevé peut produire plus de faux négatifs (des lignes qui ne correspondent pas alors qu’elles devraient correspondre) et un seuil plus bas peut produire plus de faux positifs.Ci-dessous, les données sont comparées sur la base de la distance de similarité entre les chaînes de caractères dans les colonnes du nom et du district, et sur la base de la distance numérique pour l’année, le mois et le jour de naissance. Un seuil de correspondance de 95% de probabilité est fixé.Vérification des correspondanceL’objet fl_output contient la sortie de la fonction fastLink(). Cet objet est une liste (classe list) qui contient plusieurs dataframes détaillant les résultats de l’analyse des correspondances. Le dataframe matches contient les correspondances les plus probables entre cases et results. peut y accéder avec la commande fl_output$matches. Ci-dessous, nous l’enregistrons sous le nom de my_matches pour faciliter son accès ultérieur.Le dataframe my_matches contient deux colonnes contenant les numéros de lignes/indices (aussi appelés “rownames”) de cases (“inds.”) et de results (“inds.b”), représentant les meilleures correspondances. Si un numéro de ligne d’un dataframe est manquant, alors aucune correspondance n’été trouvée dans l’autre dataframe au seuil de correspondance spécifié.observe que :Les correspondances ont été trouvées malgré les légères différences dans l’orthographe des noms et les dates de naissance, c’est la beauté de ce type d’approche :\n“Tony B. Smith” correspond à “Anthony B. Smith”.\n“Maria Rodriguez” correspond à “Marialisa Rodrigues”.\n“Betty Chase” correspond à “Elizabeth Chase”.\n“Olivier Laurent De Bordeaux” correspond à “Oliver Laurent De Bordow” (date de naissance manquante ignorée).\n“Tony B. Smith” correspond à “Anthony B. Smith”.“Maria Rodriguez” correspond à “Marialisa Rodrigues”.“Betty Chase” correspond à “Elizabeth Chase”.“Olivier Laurent De Bordeaux” correspond à “Oliver Laurent De Bordow” (date de naissance manquante ignorée).Une ligne de cases (pour “Blessing Adebayo”, ligne 9) n’avait pas de bonne correspondance dans results, elle n’est donc pas présente dans my_matches.Jointure basée sur les correspondances probabilistes.Pour utiliser ces correspondances afin de joindre les results aux cases, une stratégie consiste à :Utiliser left_join() pour joindre my_matches à cases (en faisant correspondre les rownames dans cases à “inds.” dans my_matches)Utiliser ensuite un autre left_join() pour joindre results à cases (en faisant correspondre les “inds.b” nouvellement acquis dans cases aux noms de domaine dans results).Avant les jointures, nous devons nettoyer les trois dataframes :Les numéros de ligne (“rowname”) de dfA et dfB doivent être convertis en une colonne.Les deux colonnes de my_matches sont converties en chaînes de caractères, donc elles peuvent être jointes aux caractères rownames.Le dataframe complete ainsi crée contient toutes les colonnes de cases et de results. Beaucoup d’entre elles se retrouvent ajoutées avec les suffixes “.x” et “.y”, parce que les noms des colonnes seraient dupliqués sinon.Pour obtenir seulement les 9 observations “originales” dans cases avec la ou les nouvelles colonnes de results, utiliser select() sur results avant les jointures, de sorte que e dataframe ne contienne que les rownames et les colonnes que vous voulez ajouter à cases (par exemple la colonne result).Si vous voulez ne garder que les lignes qui avec des correspondances dans l’un ou l’autre des des dataframe, vous pouvez utiliser les codes ci-dessous :Ou pour ne voir que les lignes sans correspondances :","code":"\nfl_output <- fastLink::fastLink(\n  dfA = cases,\n  dfB = results,\n  varnames = c(\"gender\", \"first\", \"middle\", \"last\", \"yr\", \"mon\", \"day\", \"district\"),\n  stringdist.match = c(\"first\", \"middle\", \"last\", \"district\"),\n  numeric.match = c(\"yr\", \"mon\", \"day\"),\n  threshold.match = 0.95)## \n## ==================== \n## fastLink(): Fast Probabilistic Record Linkage\n## ==================== \n## \n## If you set return.all to FALSE, you will not be able to calculate a confusion table as a summary statistic.\n## Calculating matches for each variable.\n## Getting counts for parameter estimation.\n##     Parallelizing calculation using OpenMP. 1 threads out of 12 are used.\n## Running the EM algorithm.\n## Getting the indices of estimated matches.\n##     Parallelizing calculation using OpenMP. 1 threads out of 12 are used.\n## Deduping the estimated matches.\n## Getting the match patterns for each estimated match.\n# print matches\nmy_matches <- fl_output$matches\nmy_matches##   inds.a inds.b\n## 1      1      1\n## 2      2      2\n## 3      3      3\n## 4      4      4\n## 5      8      8\n## 6      7      9\n## 7      6     10\n## 8      5     12\n# Préparation des dataframes avant la jointure\n#############################\n\n# Covertir les numéros de lignes en colonne\ncases_clean   <- cases %>% rownames_to_column()\nresults_clean <- results %>% rownames_to_column()  \n\n# Convertir toutes les colonnes du dataframe des correspondances en texte pour pouvoire les joindre aux numéros de ligne\nmatches_clean <- my_matches %>%\n  mutate(across(everything(), as.character))\n\n\n\n# Joindre `clean_matches` à dfA, puis ajouer dfB\n###################################\n# la colonne \"inds.b\" est ajoutée à dfA\ncomplete <- left_join(cases_clean, matches_clean, by = c(\"rowname\" = \"inds.a\"))\n\n# les colonnes de dfB sont rappatriées \ncomplete <- left_join(complete, results_clean, by = c(\"inds.b\" = \"rowname\"))\ncases_clean <- cases %>% rownames_to_column()\n\nresults_clean <- results %>%\n  rownames_to_column() %>% \n  select(rowname, result)    # Sélectionner certaines colonnes\n\nmatches_clean <- my_matches %>%\n  mutate(across(everything(), as.character))\n\n# jointure\ncomplete <- left_join(cases_clean, matches_clean, by = c(\"rowname\" = \"inds.a\"))\ncomplete <- left_join(complete, results_clean, by = c(\"inds.b\" = \"rowname\"))\ncases_matched <- cases[my_matches$inds.a,]  # Lignes de  `cases` qui matchent une ligne dans 'results'\nresults_matched <- results[my_matches$inds.b,]  # Lignes de 'results qui matchent une ligne dans `cases`\ncases_not_matched <- cases[!rownames(cases) %in% my_matches$inds.a,]  # Lignes dans `cases` sans matchs dans `results`\nresults_not_matched <- results[!rownames(results) %in% my_matches$inds.b,]  # Lignes dans  `results` sans matchs dans `cases`"},{"path":"joining_matching.html","id":"déduplication-probabiliste","chapter":"14 Joindre des données","heading":"Déduplication probabiliste","text":"La correspondance probabiliste peut également être utilisée pour dé-dupliquer un jeu de données. Voir la page sur la dé-duplication pour d’autres méthodes de dé-duplication.Ici, nous modifions le tableau cases, en ajoutant des lignes supplémentaires qui peuvent être des doublons de lignes existantes, et l’appelons cases_dup; voir “Tony” avec “Anthony”, et “Marialisa Rodrigues” avec “Maria Rodriguez”.peut désormais utiliser la fonction fastLink() comme précédemment, mais en comparant le jeu de données cases_dup à lui-même. Lorsque les dataframes fournis en argument sont identiques, la fonction suppose que vous voulez dé-dupliquer.Notez que nous ne spécifions pas stringdist.match = ou numeric.match = comme nous le faisions précédemment.La fonction getMatches() permet d’examiner la sortie de fastLink pour rechercher les doublons potentiels.\nIl faut fournir le dataframe d’origine à dfA = et dfB =, ainsi que la sortie de fastLink() à fl.=.Note : fl.doit nécessairement être de la classe fastLink.dedupe, ou en d’autres termes, le résultat de fastLink().La colonne la plus à droite indique les identifiants des doublons. Ici les deux dernières lignes sont identifiées comme étant des doublons probables des lignes 2 et 3.Pour obtenir les numéros de ligne des lignes qui sont potentiellement des doublons, il suffit de compter le nombre de lignes par valeur unique dans la colonne dedupe.ids, puis de filtrer pour ne garder que celles qui ont plus d’une ligne. Dans ce cas, nous obtenons laisse les lignes 2 et 3.Pour inspecter les doublons, peut utiliser le numéro de ligne pour obtenir la ligne complète :","code":"\n## Utiliser fastLink sur le même jeu de données\ndedupe_output <- fastLink(\n  dfA = cases_dup,\n  dfB = cases_dup,\n  varnames = c(\"gender\", \"first\", \"middle\", \"last\", \"yr\", \"mon\", \"day\", \"district\")\n)## \n## ==================== \n## fastLink(): Fast Probabilistic Record Linkage\n## ==================== \n## \n## If you set return.all to FALSE, you will not be able to calculate a confusion table as a summary statistic.\n## dfA and dfB are identical, assuming deduplication of a single data set.\n## Setting return.all to FALSE.\n## \n## Calculating matches for each variable.\n## Getting counts for parameter estimation.\n##     Parallelizing calculation using OpenMP. 1 threads out of 12 are used.\n## Running the EM algorithm.\n## Getting the indices of estimated matches.\n##     Parallelizing calculation using OpenMP. 1 threads out of 12 are used.\n## Calculating the posterior for each pair of matched observations.\n## Getting the match patterns for each estimated match.\n## Executer getMatches()\ncases_dedupe <- getMatches(\n  dfA = cases_dup,\n  dfB = cases_dup,\n  fl.out = dedupe_output)\ncases_dedupe %>% \n  count(dedupe.ids) %>% \n  filter(n > 1)##   dedupe.ids n\n## 1          2 2\n## 2          3 2\n# Afficher la ligne 2 et ses duplicats probables\ncases_dedupe[cases_dedupe$dedupe.ids == 2,]   ##    gender   first middle  last   yr mon day district dedupe.ids\n## 2       M Anthony     B. Smith 1970   9  19    River          2\n## 10      M    Tony     B. Smith 1970   9  19    River          2"},{"path":"joining_matching.html","id":"assembler-et-aligner-des-dataframes","chapter":"14 Joindre des données","heading":"14.4 Assembler et aligner des dataframes","text":"Une autre manière de combiner deux dataframes consiste à les assembler/concaténer/coller/aligner. peut également considérer cette méthode comme un ajout de lignes ou de colonnes.Cette section explique également comment “aligner” l’ordre des lignes d’un dataframe sur celui d’un autre dataframe. Ce sujet est abordé ci-dessous dans la section consacrée à la liaison des colonnes.","code":""},{"path":"joining_matching.html","id":"assembler-verticallement","chapter":"14 Joindre des données","heading":"Assembler verticallement","text":"La fonction bind_rows() de dplyr permet de coller les lignes d’un dataframe à la suite d’un autre dataframe (verticalement, donc). Elle est très inclusive : toute colonne présente dans l’un ou l’autre des dataframes sera incluse dans la sortie.Quelques notes :Contrairement à la version base de R row.bind(), dplyr’s bind_rows() n’exige pas que l’ordre des colonnes soit le même dans les deux dataframes à assembler. Du moment que les noms des colonnes sont orthographiés de manière identique, la fonction les alignera correctement.Contrairement à la version base de R row.bind(), dplyr’s bind_rows() n’exige pas que l’ordre des colonnes soit le même dans les deux dataframes à assembler. Du moment que les noms des colonnes sont orthographiés de manière identique, la fonction les alignera correctement.Il est possible de fournir une chaîne de caractères à l’argument .id = pour produire une nouvelle colonne qui servira à identifier de quel dataframe chaque ligne provient à l’origine.Il est possible de fournir une chaîne de caractères à l’argument .id = pour produire une nouvelle colonne qui servira à identifier de quel dataframe chaque ligne provient à l’origine.Il est possible d’utiliser bind_rows() sur une liste de dataframes possédant la même structure pour les combiner en un seul. Vous trouverez un exemple de cette action dans la page Itération, boucles et listes qui importe plusieurs linelists avec le paquet purrr.Il est possible d’utiliser bind_rows() sur une liste de dataframes possédant la même structure pour les combiner en un seul. Vous trouverez un exemple de cette action dans la page Itération, boucles et listes qui importe plusieurs linelists avec le paquet purrr.Un exemple classique d’assemblage de dataframes est d’ajouter une ligne “total” à un tableau descriptif créé avec la fonction summarise() de dplyr. Ci-dessous, nous créons un tableau des nombres de cas et des valeurs médianes de CT par hôpital et y ajoutons une ligne de total.La fonction summarise() est utilisée sur des données groupées par hôpital pour retourner un dataframe récapitulatif par hôpital. Malheureusement, elle ne produit pas automatiquement une ligne de “totaux”, donc nous devons la rajouter nous même. Nous l’obtenons en résumant à nouveau ces données, mais sans grouper par hôpital. Cela produit un deuxième dataframe d’une seule ligne, que nous concaténons ensuite au premier pour obtenir le tableau final.Vous trouverez d’autres exemples de ce type dans les pages Tableaux descriptifs et Tableaux de présentation.Voici à quoi ressemble hosp_summary :Maintenant nous créons un dataframe d’une seule ligne contenant les statistiques pour tous les hôpitaux (données non groupées) :Ci-dessous, le dataframe totals. Remarquez qu’il n’y que deux colonnes alors que hosp_summary en contenant trois. Ce n’est pas un problème.Nous utilisons à présent bind_rows() pour assembler les deux dataframes :Pour le résultat ci-dessous. Dans la dernière ligne, une valeur vide NA été automatiquement insérée dans la colonne hospital, qui n’était pas dans hosp_summary. Comme expliqué dans la page Tableaux de présentation, il est possible de “remplir” cette cellule avec “Total” en utilisant replace_na().","code":"\n# Créer la table de base\n###################\nhosp_summary <- linelist %>% \n  group_by(hospital) %>%      # grouper les données par hôpital\n  summarise(                  # Créer résumé :\n    cases = n(),               # NNombre de lignes par hôpital\n    ct_value_med = median(ct_blood, na.rm=T))     # Médiane du CT par hôpital\n# Créer la ligne de totaux\n###############\ntotals <- linelist %>% \n  summarise(\n    cases = n(),                               # Nb lignes dataframe entier\n    ct_value_med = median(ct_blood, na.rm=T))  # Médiane du CT\n# Combiner les deux dataframes ensemble\ncombined <- bind_rows(hosp_summary, totals)"},{"path":"joining_matching.html","id":"assembler-des-colonnes-latéralement","chapter":"14 Joindre des données","heading":"Assembler des colonnes latéralement","text":"De manière assez similaire, il existe une fonction bind_cols() dans dplyr qui combine deux dataframes latéralement. En revanche, contrairement aux jointures, les lignes sont alignées les unes aux autres par position : la ligne X du dataframe 1 sera alignée à la ligne X du dataframe 2.Par exemple, nous allons assembler plusieurs tableaux récapitulatifs. Nous montrerons au passage comment réarranger l’ordre des lignes d’un dataframe pour qu’il corresponde à l’ordre dans un autre dataframe, à l’aide de la fonction match().Ici, nous définissons case_info comme un dataframe récapitulatif des cas de la liste linéaire, par hôpital, avec le nombre de cas et le nombre de décès.Nous définissons également contact_fu, un autre dataframe contenant des informations sur le pourcentage de contacts exposés ayant fait l’objet d’une enquête et d’un “suivi”, toujours par hôpital.Notez que les hôpitaux sont les mêmes, mais dans un ordre différent dans les deux dataframes. La solution la plus simple serait d’utiliser un left_join() sur la colonne hospital, mais il est aussi possible d’utiliser bind_cols() avec une étape supplémentaire.","code":"\n# Information sur les cas \ncase_info <- linelist %>% \n  group_by(hospital) %>% \n  summarise(\n    cases = n(),\n    deaths = sum(outcome == \"Death\", na.rm=T)\n  )\ncontact_fu <- data.frame(\n  hospital = c(\"St. Mark's Maternity Hospital (SMMH)\", \"Military Hospital\", \"Missing\", \"Central Hospital\", \"Port Hospital\", \"Other\"),\n  investigated = c(\"80%\", \"82%\", NA, \"78%\", \"64%\", \"55%\"),\n  per_fu = c(\"60%\", \"25%\", NA, \"20%\", \"75%\", \"80%\")\n)"},{"path":"joining_matching.html","id":"utiliser-match-pour-homogénéiser-lordre-des-lignes","chapter":"14 Joindre des données","heading":"Utiliser match() pour homogénéiser l’ordre des lignes","text":"Comme l’ordre des lignes est différent, un simple bind_cols() entraînerait une mauvaise correspondance des données. Pour résoudre ce problème, nous pouvons utiliser la fonction match() de base R pour aligner les lignes d’un dataframes dans le même ordre que dans un autre. Pour cette approche, nous supposons qu’il n’y pas de doublons dans les dataframes.Lorsque nous utilisons match(), la syntaxe est match(vecteur/colonne dans l'ordre désiré, colonne de dataframe à ordonner), où le premier argument est l’ordre souhaité (soit un vecteur autonome, soit une colonne d’un dataframe), et le second argument est la colonne du dataframe qui sera réordonnée. La sortie de match() est un vecteur de nombres représentant l’ordre correct des positions. Vous pouvez en savoir plus avec ?match.peut utiliser ce vecteur numérique pour réorganiser le dataframe : placez-le entre des crochets [ ] avant la virgule. Pour en savoir plus sur la syntaxe des crochets pour séléctionner les lignes et/ou colonnes d’un dataframe en base R, consultez la page Bases de R. La commande ci-dessous crée un nouveau dataframe, défini comme l’ancien dataframe dans lequel les lignes sont ordonnées selon le tableau numérique ci-dessus.Maintenant nous pouvons lier les colonnes du dataframe ensemble, avec l’ordre correct des lignes respecté. Notez que certaines colonnes sont dupliquées et devront être nettoyées avec rename(). Pour en savoir plus sur bind_rows(), rendez-vous ici.Une alternative base R à bind_cols est cbind(), qui effectue la même opération.","code":"\nmatch(case_info$hospital, contact_fu$hospital)## [1] 4 2 3 6 5 1\ncontact_fu_aligned <- contact_fu[match(case_info$hospital, contact_fu$hospital),]\nbind_cols(case_info, contact_fu)## New names:\n## • `hospital` -> `hospital...1`\n## • `hospital` -> `hospital...4`## # A tibble: 6 × 6\n##   hospital...1                         cases deaths hospital...4     investigated per_fu\n##   <chr>                                <int>  <int> <chr>            <chr>        <chr> \n## 1 Central Hospital                       454    193 St. Mark's Mate… 80%          60%   \n## 2 Military Hospital                      896    399 Military Hospit… 82%          25%   \n## 3 Missing                               1469    611 Missing          <NA>         <NA>  \n## 4 Other                                  885    395 Central Hospital 78%          20%   \n## 5 Port Hospital                         1762    785 Port Hospital    64%          75%   \n## 6 St. Mark's Maternity Hospital (SMMH)   422    199 Other            55%          80%"},{"path":"joining_matching.html","id":"resources-3","chapter":"14 Joindre des données","heading":"14.5 Resources","text":"La page du tidyverse sur les jointuresLe chapitre sur les données relationelles dans R Data ScienceLa page de dplyr sur bind bindingUne vignette surfastLink sur la page Github du paquetPublication décrivant la méthodologie de fastLinkPublication décrivant le paquetRecordLinkage","code":""},{"path":"deduplication.html","id":"deduplication","chapter":"15 De-duplication","heading":"15 De-duplication","text":"Cette page couvre les techniques de déduplication ci-dessous :Identifier et supprimer les lignes dupliquéesUtiliser la fonction “slice” pour garder seulement certaines lignes (par exemple, min ou max) de chaque groupe de lignes.“Rolling-”, ou combinaison des valeurs de plusieurs lignes en une seule ligne.","code":""},{"path":"deduplication.html","id":"préparation","chapter":"15 De-duplication","heading":"15.1 Préparation","text":"","code":""},{"path":"deduplication.html","id":"importation-des-packages","chapter":"15 De-duplication","heading":"Importation des packages","text":"Ces lignes de code importe les packages necessaire pour l’analyse. Dans ce guide, nous mettons l’accent sur p_load() de pacman, qui installe le package si nécessaire puis l’importe pour l’utiliser. Vous pouvez également charger les packages installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les packages en R.","code":"\npacman::p_load(\n  tidyverse,   # fonctions de déduplication, de regroupement et de slicing\n  janitor,     # fonction de gestion des doublons \n  stringr)     # pour la recherche des caractères, peut être utilisé ensembler les valeurs"},{"path":"deduplication.html","id":"importer-les-données","chapter":"15 De-duplication","heading":"Importer les données","text":"Pour la démonstration, nous allons utiliser un ensemble de données exemplaire qui été créé avec le code R ci-dessous.Les données sont des enregistrements des appels téléphoniques sur le COVID-19, y compris les appels avec des contacts et des cas. Les colonnes comprennent recordID (généré par ordinateur), personID, name, date de la rencontre, time de la rencontre, le purpose de la rencontre (soit pour un interview en tant que cas ou en tant que contact), et symptoms_ever (si la personne dans cette appel déclaré avoir jamais eu des symptômes).Voici le code pour créer la base de données obs :","code":"\nobs <- data.frame(\n  recordID  = c(1,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18),\n  personID  = c(1,1,2,2,3,2,4,5,6,7,2,1,3,3,4,5,5,7,8),\n  name      = c(\"adam\", \"adam\", \"amrish\", \"amrish\", \"mariah\", \"amrish\", \"nikhil\", \"brian\", \"smita\", \"raquel\", \"amrish\",\n                \"adam\", \"mariah\", \"mariah\", \"nikhil\", \"brian\", \"brian\", \"raquel\", \"natalie\"),\n  date      = c(\"1/1/2020\", \"1/1/2020\", \"2/1/2020\", \"2/1/2020\", \"5/1/2020\", \"5/1/2020\", \"5/1/2020\", \"5/1/2020\", \"5/1/2020\",\"5/1/2020\", \"2/1/2020\",\n                \"5/1/2020\", \"6/1/2020\", \"6/1/2020\", \"6/1/2020\", \"6/1/2020\", \"7/1/2020\", \"7/1/2020\", \"7/1/2020\"),\n  time      = c(\"09:00\", \"09:00\", \"14:20\", \"14:20\", \"12:00\", \"16:10\", \"13:01\", \"15:20\", \"14:20\", \"12:30\", \"10:24\",\n                \"09:40\", \"07:25\", \"08:32\", \"15:36\", \"15:31\", \"07:59\", \"11:13\", \"17:12\"),\n  encounter = c(1,1,1,1,1,3,1,1,1,1,2,\n                2,2,3,2,2,3,2,1),\n  purpose   = c(\"contact\", \"contact\", \"contact\", \"contact\", \"case\", \"case\", \"contact\", \"contact\", \"contact\", \"contact\", \"contact\",\n                \"case\", \"contact\", \"contact\", \"contact\", \"contact\", \"case\", \"contact\", \"case\"),\n  symptoms_ever = c(NA, NA, \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"No\", \"Yes\", NA, \"Yes\",\n                    \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"No\",\"No\", \"No\")) %>% \n  mutate(date = as.Date(date, format = \"%d/%m/%Y\"))"},{"path":"deduplication.html","id":"dedup_data","chapter":"15 De-duplication","heading":"Voici le tableau de données","text":"Utilisez les boîtes de filtre au-dessous pour examiner les rencontres pour chaque personne.Quelques éléments à noter lors de l’examen des données :Les deux premiers enregistrements sont des doublons complets à 100%, y compris le recordID ( cela doit être un problème informatique !).Les deux secondes lignes sont des doublons, dans toutes les colonnes, sauf pour le recordID.Plusieurs personnes ont été contactées plusieurs fois par téléphone, à des dates et horaires différents, et en tant que contacts et/ou cas.chaque rencontre, il été demandé à la personne si elle avait jamais eu des symptômes, et certaines de ces informations sont manquantes.Et voici un résumé de ces personnes et la raison de leurs rencontres, en utilisant tabyl() de janitor :","code":"\nobs %>% \n  tabyl(name, purpose)##     name case contact\n##     adam    1       2\n##   amrish    1       3\n##    brian    1       2\n##   mariah    1       2\n##  natalie    1       0\n##   nikhil    0       2\n##   raquel    0       2\n##    smita    0       1"},{"path":"deduplication.html","id":"deduplication-1","chapter":"15 De-duplication","heading":"15.2 Deduplication","text":"Cette section décrit comment examiner et supprimer les doublons dans un tableau de données. Elle montre également comment traiter les éléments dupliqués dans un vecteur.","code":""},{"path":"deduplication.html","id":"examiner-les-lignes-dupliquées","chapter":"15 De-duplication","heading":"Examiner les lignes dupliquées","text":"Pour rapidement examiner les lignes qui ont été dupliquées, vous pouvez utiliser get_dupes() du package janitor. Par défaut, toutes les colonnes sont prises en compte lors de l’évaluation des duplications - les lignes retournées par la fonction sont des doublons à 100% en considérant les valeurs de toutes les colonnes.Dans le tableau de données obs, les deux premières lignes sont 100% dupliquées - elles ont la même valeur dans chaque colonne (y compris la colonne recordID, qui est supposée être unique - cela doit être un problème informatique). Le tableau de données obtenu inclut automatiquement une nouvelle colonne dupe_count sur le côté droit, montrant le nombre de lignes avec cette combinaison de valeurs en double.Voir les données originalesCependant, si nous décidons d’ignorer le recordID, les 3e et 4e lignes sont également des doublons entre eux. C’est-à-dire qu’elles ont les mêmes valeurs dans toutes les colonnes sauf pour recordID. Vous pouvez spécifier des colonnes spécifiques à ignorer dans la fonction en utilisant le symbole moins -.Vous pouvez également spécifier les colonnes à considérer. Ci-dessous, seules les lignes qui ont les mêmes valeurs dans les colonnes name et purpose sont retournées. Notez comment “amrish” maintenant un dupe_count égal à 3 pour correspondre à ses trois rencontres “contact”.*Défiler vers la gauche pour plus de lignes**Voir les données originalesVoir ?get_dupes pour plus de details, ou consulter ceci référence en ligne","code":"\n# 100% duplicates across all columns\nobs %>% \n  janitor::get_dupes()\n# Duplications lorsque la colonne recordID est exclue. \nobs %>% \n  janitor::get_dupes(-recordID)         # si multiples colonnes, les inclure dans c()\n# duplications basées sur les colonnes name et purpose uniquement\nobs %>% \n  janitor::get_dupes(name, purpose)"},{"path":"deduplication.html","id":"garder-seulement-les-lignes-uniques","chapter":"15 De-duplication","heading":"Garder seulement les lignes uniques","text":"Pour garder que les lignes uniques d’un tableau de données, utilisez distinct() de dplyr (comme démontré dans la page CNettoyage de données et fonctions essentielles). Les lignes qui sont dupliquées sont enlevées de sorte que seule la première ligne est retenue. Par défaut, la première ligne correspond au plus grand rownumber (ordre des lignes de haut en bas). Seules les lignes uniques sont retenues.Dans l’exemple ci-dessous, nous utilisons distinct() tel que la colonne recordID est exclue - ainsi deux lignes dupliquées sont enlevées. La première ligne (pour “adam”) était dupliquée à 100% et été enlevée. Par ailleurs, la troisième ligne (pour “amrish”) était dupliquée dans chaque colonne sauf recordID (qui n’est pas considéré) donc été supprimée. Le tableau de données obs est maintenant nrow(obs)-2, et non nrow(obs) lignes).Défilez vers la gauche pour voir le tableau de données completCAUTION: Si vous utilisez distinct() sur des données groupées, la fonction s’appliquera à chaque groupe. Déduplication basée sur des colonnes spécifiquesVous pouvez également spécifier des colonnes qui seront la base de la déduplication. Ainsi, la déduplication ne s’applique qu’aux lignes qui sont des duplications dans les colonnes spécifiées. moins que vous ne définissiez .keep_all = TRUE, toutes les colonnes non mentionnées seront ignorées.Dans l’exemple ci-dessous, la déduplication ne s’applique qu’aux lignes qui ont des valeurs identiques pour les colonnes name et purpose. Ainsi, “brian” seulement 2 lignes au lieu de 3 - son premier “contact” et son unique “case”. Pour ajuster afin que la dernière rencontre de brian pour chaque “purpose” soit retenue, voir l’onglet “Slicing within groups”.Défilez vers la gauche pour voir le tableau de données completVoir données originales.","code":"\n# ajouté à une chaîne de pipes (par exemple, nettoyage de données)\nobs %>% \n  distinct(across(-recordID), # réduit le tableau de données à seulement des lignes uniques (retient la première ligne de toute duplication)\n           .keep_all = TRUE) \n\n# si en dehors des pipes, inclure les données comme premier argument  \n# distinct(obs)\n# ajouté à une chaîne de pipes (par exemple, nettoyage de données)\nobs %>% \n  distinct(name, purpose, .keep_all = TRUE) %>%  # garder les lignes uniques par 'name' et par 'purpose', retient toutes les colonnes\n  arrange(name)                                  # arranger pour faciliter la visualisation"},{"path":"deduplication.html","id":"dédupliquer-les-éléments-dun-vecteur","chapter":"15 De-duplication","heading":"Dédupliquer les éléments d’un vecteur","text":"La fonction duplicated() de base R va évaluer un vecteur (colonne) et renvoie un vecteur logique de même longueur (TRUE/FALSE). La première fois qu’une valeur apparaît, elle renvoie FALSE (pas de duplication), et les fois suivantes, elle renvoie VRAI. Notez que NA est traité de la même façon que toute autre valeur.Pour ne retourner que les éléments dupliqués, vous pouvez utiliser des parenthèses pour sous-titrer le vecteur original :Pour ne renvoyer que les éléments uniques, utilisez unique() de base R. Pour supprimer les NA de la sortie, mettez na.omit() dans unique().","code":"\nx <- c(1, 1, 2, NA, NA, 4, 5, 4, 4, 1, 2)\nduplicated(x)##  [1] FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE  TRUE  TRUE  TRUE  TRUE\nx[duplicated(x)]## [1]  1 NA  4  4  1  2\nunique(x)           # alternativement, utilisez x[!duplicated(x)]## [1]  1  2 NA  4  5\nunique(na.omit(x))  # supprimez les NA ## [1] 1 2 4 5"},{"path":"deduplication.html","id":"utilisant-base-r","chapter":"15 De-duplication","heading":"Utilisant base R","text":"Pour retourner les lignes dupliquéesDans base R, vous pouvez également voir quelles lignes sont dupliquées à 100% dans un tableau de données df avec la commande duplicated(df) ( retourne un vecteur logique des lignes).Ainsi, vous pouvez également utiliser le sous-groupe de base [ ] sur le tableau de données pour voir les lignes dupliquées avec df[duplicated(df),] (n’oubliez pas la virgule, qui signifie que vous voulez voir toutes les colonnes !)Pour retourner les lignes uniquesVoir les notes ci-dessus. Pour voir les lignes uniques, ajoutez le négateur logique ! devant la fonction duplicated() :df[!duplicated(df),]Pour retourner les lignes qui sont des duplications de certaines colonnes seulement.Sous-ensembler le df qui se trouve *dans la parenthèse de duplicated(), afin que cette fonction ne traite que certaines colonnes du df.Pour spécifier les colonnes, fournissez les numéros ou les noms des colonnes après une virgule (rappelez-vous, tout ceci est dans la fonction duplicated()).Assurez-vous de garder la virgule , à l’extérieur après la fonction duplicated() également !Par exemple, pour évaluer seulement les colonnes 2 à 5 pour les doublons : df[!duplicated(df[, 2:5]),]``   Pour évaluer seulement les colonnesnameetpurposepour les doublons :df[!duplicated(df[, c(“name”, “purpose)]),]`","code":""},{"path":"deduplication.html","id":"slicing","chapter":"15 De-duplication","heading":"15.3 Slicing","text":"Pour “slice” un tableau de données pour pouvoir appliquer un filtre sur les lignes par numéro/position de ligne. Cette fonction devient particulièrement utile si vous avez plusieurs lignes par groupe fonctionnel (par exemple, par “person”) et que vous ne voulez retenir qu’une ou quelques-unes d’entre elles.La fonction de base slice() accepte des numéros et retourne les lignes dans ces positions. Si les numéros fournis sont positifs, seuls ceux-ci sont retournés. S’ils sont négatifs, ces lignes ne sont pas retournées. Les nombres doivent être soit tous positifs, soit tous négatifs.Voir données originales.Il existe plusieurs variations : Celles-ci doivent être fournies avec une colonne et le nombre de lignes à retourner (à n =).slice_min() et slice_max() ne gardent que la ou les lignes avec la ou les valeurs minimales ou maximales de la colonne spécifiée. Cela permet également de retourner le “min” et le “max” de facteurs ordonnés.slice_head() et slice_tail() - Retient que la ou les premières ou dernières lignes.slice_sample() - ne retenir qu’un échantillon aléatoire des lignes.Utilisez les arguments n = ou prop = pour spécifier le nombre ou la proportion de lignes à retenir. Si vous n’utilisez pas la fonction dans un pipe, fournissez d’abord l’argument data (par exemple, slice(data, n = 2)). Voir ?slice pour plus d’informations.Autres arguments :.order_by = utilisé dans slice_min() et slice_max() ceci est une colonne à ordonner par avant de “slice”.with_ties = TRUE par défaut, ce qui signifie que les liens sont retenus..preserve = FALSE par défaut. Si TRUE, alors la structure de regroupement est recalculée après le slicing.weight_by = Optionnel, colonne numérique pour pondérer par ( un plus grand chiffre est plus probable d’être échantillonné).\nAussi, replace = pour savoir si l’échantillonnage est fait avec/sans remplacement.TIP: En utilisant slice_max() et slice_min(), assurez-vous de spécifier/d’écrire n = (e.g. n = 2, pas seulement 2). Sinon, vous risquez d’obtenir une erreur: Error:…empty. NOTE: Vous pouvez rencontrer la fonction top_n(), qui été remplacées par les fonctions slice.","code":"\nobs %>% slice(4)  # retourne la 4e ligne##   recordID personID   name       date  time encounter purpose symptoms_ever\n## 1        3        2 amrish 2020-01-02 14:20         1 contact            No\nobs %>% slice(c(2,4))  # retourne les lignes 2 et 4##   recordID personID   name       date  time encounter purpose symptoms_ever\n## 1        1        1   adam 2020-01-01 09:00         1 contact          <NA>\n## 2        3        2 amrish 2020-01-02 14:20         1 contact            No\n#obs %>% slice(c(2:4))  # retourne les lignes 2 à 4\nobs %>% slice_max(encounter, n = 1)  # Retourne les lignes avec le plus grand nombre de \"encounter\" ##   recordID personID   name       date  time encounter purpose symptoms_ever\n## 1        5        2 amrish 2020-01-05 16:10         3    case           Yes\n## 2       13        3 mariah 2020-01-06 08:32         3 contact            No\n## 3       16        5  brian 2020-01-07 07:59         3    case            No"},{"path":"deduplication.html","id":"slice-avec-les-groupes","chapter":"15 De-duplication","heading":"Slice avec les groupes","text":"Les fonctions slice_*() peuvent être très utiles si elles sont appliquées à un tableau de données groupées, puisque l’opération de slice est effectuée sur chaque groupe séparément. Utilisez la fonction group_by() en conjonction avec slice() pour regrouper les données et prendre une tranche de chaque groupe.Ceci est utile pour la déduplication si vous avez plusieurs lignes par personne mais que vous ne voulez retenir qu’une seule d’entre elles. Vous utilisez d’abord group_by() avec des colonnes clés qui sont les mêmes pour chaque personne, puis vous utilisez une fonction slice sur une colonne qui sera différente parmi les lignes groupées.Dans l’exemple ci-dessous, pour ne garder que la dernière rencontre par personne, nous regroupons les lignes par name et ensuite nous utilisons slice_max() avec n = 1 sur la colonne date. Mais attention ! Pour appliquer une fonction comme slice_max() sur des dates, la colonne date doit être de la classe Date.Par défaut, les “liens” (par exemple la même date dans ce scénario) sont retenus, et nous aurions toujours plusieurs lignes pour certaines personnes (par exemple adam). Pour éviter cela, nous mettons with_ties = FALSE. Nous ne récupérons qu’une seule ligne par personne.CAUTION: Si utilisant arrange(), specifier .by_group = TRUE pour que les données soient organisées dans chaque groupe.DANGER: Si with_ties = FALSE, la première ligne d’une même égalité est conservée. Cela peut être déceptive. Voyez comment pour Mariah, elle deux rencontres à sa dernière date (6 Jan) et la première (la plus ancienne) été gardée. Il est probable que nous voulions garder la dernière rencontre de ce jour-là. Voyez comment ” séparer ” ces liens dans l’exemple suivant. Ci-dessus, par exemple, nous pouvons voir que seule la ligne d’Amrish du 5 janvier été retenue, et que seule la ligne de Brian du 7 janvier été retenue. Voir les données originales.Séparation des égalitésMultiples lignes de slice peuvent être exécutées pour ” séparer les égalités”. Dans ce cas, si une personne plusieurs rencontres à leur dernière date, la rencontre avec la dernière heure est retenue (lubridate::hm() est utilisé pour convertir les heures des caractères en une classe de temps triable).\nNotez comment maintenant, la seule ligne conservée pour “Mariah” le 6 janvier est la rencontre 3 de 08:32, et non la rencontre 2 de 07:25.Dans l’exemple ci-dessus, il aurait également été possible de slice par le numéro de encounter, mais nous avons montré le slice sur date et time pour illustration.TIP: Pour utiliser slice_max() ou slice_min() sur une colonne e de “caractères”, mutez-la en une classe de facteurs ordonnée !.Voir données originales.","code":"\nobs %>% \n  group_by(name) %>%       # regroupe les lignes par 'name'\n  slice_max(date,          # retenir une ligne par groupe avec la valeur maximale de la date \n            n = 1,         # ne retenir que la ligne la plus élevée \n            with_ties = F) # s'il y a une égalité (de date), prenez le premier ligne\n# Exemple de multiple lignes de slice exécutées pour \" séparer les égalités\"\nobs %>%\n  group_by(name) %>%\n  \n  # PREMIEREMENT - slice par la dernière date\n  slice_max(date, n = 1, with_ties = TRUE) %>% \n  \n  # DEUXIÈMEMENT - s'il y a une égalité, sélectionner la ligne avec l'heure la plus tardive ; égalité interdite\n  slice_max(lubridate::hm(time), n = 1, with_ties = FALSE)"},{"path":"deduplication.html","id":"retenir-tous-les-lignes-mais-les-marquer","chapter":"15 De-duplication","heading":"Retenir tous les lignes mais les marquer","text":"Si vous voulez retenir tous les evenements mais n’en marquer que certains pour l’analyse, envisagez une approche en deux étapes en utilisant un numéro unique de recordID/encounter :Reduire/slice le tableau de données original pour n’avoir que les lignes à analyser. Sauvegardez/retenir ce tableau de données réduit.Dans le tableau de données original, marquez les lignes avec case_when(), selon que leur identifiant unique d’enregistrement (recordID dans cet exemple) est présent ou non dans le tableau de données réduit.Voir données originales.","code":"\n# 1. Definir les lignes de tableau de données à retenir pour l'analyse\nobs_keep <- obs %>%\n  group_by(name) %>%\n  slice_max(encounter, n = 1, with_ties = FALSE) # ne garder que la dernière rencontre par personne\n\n\n# 2. Marquer le tableau de données original\nobs_marked <- obs %>%\n\n  # Créer une nouvelle colonne dup_record\n  mutate(dup_record = case_when(\n    \n    # si record est dans le tableau de données obs_keep\n    recordID %in% obs_keep$recordID ~ \"For analysis\", \n    \n    #tout le reste est marqué comme \"Ignore\" pour l'analyse\n    TRUE                            ~ \"Ignore\"))\n\n# imprimer\nobs_marked##    recordID personID    name       date  time encounter purpose symptoms_ever\n## 1         1        1    adam 2020-01-01 09:00         1 contact          <NA>\n## 2         1        1    adam 2020-01-01 09:00         1 contact          <NA>\n## 3         2        2  amrish 2020-01-02 14:20         1 contact            No\n## 4         3        2  amrish 2020-01-02 14:20         1 contact            No\n## 5         4        3  mariah 2020-01-05 12:00         1    case            No\n## 6         5        2  amrish 2020-01-05 16:10         3    case           Yes\n## 7         6        4  nikhil 2020-01-05 13:01         1 contact           Yes\n## 8         7        5   brian 2020-01-05 15:20         1 contact            No\n## 9         8        6   smita 2020-01-05 14:20         1 contact           Yes\n## 10        9        7  raquel 2020-01-05 12:30         1 contact          <NA>\n## 11       10        2  amrish 2020-01-02 10:24         2 contact           Yes\n## 12       11        1    adam 2020-01-05 09:40         2    case            No\n## 13       12        3  mariah 2020-01-06 07:25         2 contact            No\n## 14       13        3  mariah 2020-01-06 08:32         3 contact            No\n## 15       14        4  nikhil 2020-01-06 15:36         2 contact           Yes\n## 16       15        5   brian 2020-01-06 15:31         2 contact           Yes\n## 17       16        5   brian 2020-01-07 07:59         3    case            No\n## 18       17        7  raquel 2020-01-07 11:13         2 contact            No\n## 19       18        8 natalie 2020-01-07 17:12         1    case            No\n##      dup_record\n## 1        Ignore\n## 2        Ignore\n## 3        Ignore\n## 4        Ignore\n## 5        Ignore\n## 6  For analysis\n## 7        Ignore\n## 8        Ignore\n## 9  For analysis\n## 10       Ignore\n## 11       Ignore\n## 12 For analysis\n## 13       Ignore\n## 14 For analysis\n## 15 For analysis\n## 16       Ignore\n## 17 For analysis\n## 18 For analysis\n## 19 For analysis"},{"path":"deduplication.html","id":"calcul-de-la-complétude-des-lignes","chapter":"15 De-duplication","heading":"Calcul de la complétude des lignes","text":"Créez une colonne qui contient une métrique pour la complétude des lignes (pas de valeurs manquantes). Cela peut être utile pour décider des lignes à prioriser par rapport aux autres lors de la déduplication.Dans cet exemple, les colonnes “clés” sur lesquelles vous voulez mesurer la complétude sont sauvegardées dans un vecteur de noms de colonnes.Ensuite, la nouvelle colonne key_completeness est créée avec mutate(). La nouvelle valeur dans chaque ligne est définie comme une fraction calculée : le nombre de valeurs non manquantes dans cette ligne parmi les colonnes clés, divisé par le nombre de colonnes clés.Cela fait appel à la fonction rowSums() de base R. utilise également ., qui, dans le cadre d’un pipe, fait référence au tableau de données à ce point du pipe (dans ce cas, il est sous-ensemble avec les crochets []).Défiler vers la droite pour voir plus de lignes.Voir données originales.","code":"\n# créer une colonne \"complétude des variables clés\".\n# il s'agit de la *proportion* des colonnes désignées comme \"key_cols\" qui ont des valeurs non manquantes.\n\nkey_cols = c(\"personID\", \"name\", \"symptoms_ever\")\n\nobs %>% \n  mutate(key_completeness = rowSums(!is.na(.[,key_cols]))/length(key_cols)) "},{"path":"deduplication.html","id":"str_rollup","chapter":"15 De-duplication","heading":"15.4 Réunir les valeurs de plusieurs lignes","text":"Cette section décrit :Comment “réunir” les valeurs de plusieurs lignes en une seule ligne, avec quelques variations.Une fois les valeurs sont “réunit”, comment remplacer/prioriser les valeurs dans chaque cellule.Cet onglet utilise le jeu de données d’exemple de l’onglet Préparation.","code":""},{"path":"deduplication.html","id":"réunir-les-valeurs-en-une-seule-ligne","chapter":"15 De-duplication","heading":"Réunir les valeurs en une seule ligne","text":"L’exemple de code ci-dessous utilise group_by() et summarise() pour regrouper les lignes par personne, puis rassembler toutes les valeurs uniques dans les lignes groupées. Ainsi, vous obtenez un résumé de ligne par personne. Quelques notes :\n* Un suffixe est ajouté à toutes les nouvelles colonnes (“_roll” dans cet exemple).\n* Si vous ne voulez afficher que les valeurs uniques par cellule, enveloppez le na.omit() avec unique().\n* na.omit() supprime les valeurs NA, mais si cela n’est pas souhaité, il peut être supprimé paste0(.x) …Le résultat est une ligne par groupe (ID), avec des entrées classées par date et assemblées. Défiler vers la gauche pour voir plus de lignesVoir données originales.Cette variation ne présente que des valeurs uniques:Cette variation ajoute un suffixe à chaque colonne.\nDans ce cas, “_roll” pour signifier qu’elle été roulée :","code":"\n# Réunir les valeurs en une seule ligne par groupe (par \"personID\") \ncases_rolled <- obs %>% \n  \n  # créer des groupes par nom\n  group_by(personID) %>% \n  \n  # ordonner les lignes à l'intérieur de chaque groupe (par exemple par date)\n  arrange(date, .by_group = TRUE) %>% \n  \n  # Pour chaque colonne, rassemblez toutes les valeurs des lignes groupées, en les séparant par \" ;\".\n  summarise(\n    across(everything(),                           # appliquer à toutes les colonnes\n           ~paste0(na.omit(.x), collapse = \"; \"))) # on définit une fonction qui combine les valeurs non-NA \n# Cette variation ne présente que des valeurs uniques \ncases_rolled <- obs %>% \n  group_by(personID) %>% \n  arrange(date, .by_group = TRUE) %>% \n  summarise(\n    across(everything(),                                   # appliquer à toutes les colonnes\n           ~paste0(unique(na.omit(.x)), collapse = \"; \"))) # on définit une fonction qui combine les valeurs non-NA \n# Cette variation ajoute un suffixe à chaque colonne\ncases_rolled <- obs %>% \n  group_by(personID) %>% \n  arrange(date, .by_group = TRUE) %>% \n  summarise(\n    across(everything(),                \n           list(roll = ~paste0(na.omit(.x), collapse = \"; \")))) # _roll est ajouté aux noms des colonnes"},{"path":"deduplication.html","id":"remplacer-les-valeurshiérarchie","chapter":"15 De-duplication","heading":"Remplacer les valeurs/hiérarchie","text":"Si vous voulez ensuite évaluer toutes les valeurs reunit, et ne garder qu’une valeur spécifique (par exemple la “meilleure” ou la “valeur maximale”), vous pouvez utiliser mutate() sur les colonnes souhaitées, pour implémenter case_when(), qui utilise str_detect() du package stringr pour rechercher séquentiellement des séquences de caractères et remplacer le contenu de la cellule.Maintenant vous pouvez voir dans la colonne symptoms_ever que si la personne JAMAIS dit “Oui” aux symptômes, alors seul “Oui” est affiché.Voir données originales.","code":"\n# CLEAN CASES\n#############\ncases_clean <- cases_rolled %>% \n    \n    # nettoie les variables Yes-No-Unknown : remplace le texte par la valeur \"la plus élevée\" présente dans la séquence des caracteres\n    mutate(across(c(contains(\"symptoms_ever\")),                     # fonctionne sur les colonnes spécifiées (Y/N/U)\n             list(mod = ~case_when(                                 # ajoute le suffixe \"_mod\" aux nouvelles cols ; implémente case_when() \n               \n               str_detect(.x, \"Yes\")       ~ \"Yes\",                 # si \"Yes\" est détecté, alors la valeur de la cellule est convertie en Yes\n               str_detect(.x, \"No\")        ~ \"No\",                  # # alors, si \"No\" est détecté, la valeur de la cellule est convertie en No\n               str_detect(.x, \"Unknown\")   ~ \"Unknown\",             # alors, si \"Unknown\" est détecté, la valeur de la cellule est convertie en Unknown \n               TRUE                        ~ as.character(.x)))),   # alors, si quelque chose d'autre est retenu comme tel\n      .keep = \"unused\")                                             # anciennes colonnes enlevées, ne laissant que des colonnes _mod"},{"path":"deduplication.html","id":"déduplication-probabiliste-1","chapter":"15 De-duplication","heading":"15.5 Déduplication probabiliste","text":"Parfois, vous souhaitez identifier les doublons “probables” en vous basant sur la similarité (par exemple, la sequence des caractères “distance”) entre plusieurs colonnes telles que le nom, l’âge, le sexe, la date de naissance, etc. Vous pouvez appliquer un algorithme de correspondance probabiliste pour identifier les doublons probables.Voir la page Joindre des données pour une explication de cette méthode. La section sur l’Appariement Probabiliste contient un exemple d’application de ces algorithmes pour comparer un tableau de données à soi-même, effectuant ainsi une déduplication probabiliste.","code":""},{"path":"deduplication.html","id":"ressources-4","chapter":"15 De-duplication","heading":"15.6 Ressources","text":"La plupart des informations contenues dans cette page sont adaptées de ces ressources et des vignettes en ligne :datanoviadplyr tidyverse referencecran janitor vignette","code":""},{"path":"iteration.html","id":"iteration","chapter":"16 Itération, boucles et listes","heading":"16 Itération, boucles et listes","text":"Les épidémiologistes sont souvent confrontés à la répétition d’analyses sur des sous-groupes tels que des pays, des districts ou des groupes d’âge. Ce ne sont là que quelques-unes des nombreuses situations impliquant l’itération. Le codage de vos opérations itératives à l’aide des approches ci-dessous vous aidera à effectuer ces tâches répétitives plus rapidement, à réduire les risques d’erreur et à réduire la longueur du code.Cette page présente deux approches des opérations itératives : l’utilisation de boucles et l’utilisation du package purrr.Les boucles permettent d’itérer le code sur une série d’entrées, mais sont moins courantes en R que dans d’autres langages de programmation. Néanmoins, nous les introduisons ici en tant qu’outil d’apprentissage et de référence.Le paquet purrr est l’approche tidyverse des opérations itératives - il fonctionne en “mappant” une fonction sur plusieurs entrées (valeurs, colonnes, ensembles de données, etc.).En cours de route, nous montrerons des exemples tels que :L’importation et l’exportation de plusieurs fichiersCréation d’épicurves pour plusieurs juridictionsExécution de tests T pour plusieurs colonnes dans un cadre de données.Dans la section purrr section, nous fournirons également plusieurs exemples de création et de manipulation de listes.","code":""},{"path":"iteration.html","id":"préparation-1","chapter":"16 Itération, boucles et listes","heading":"16.1 Préparation","text":"","code":""},{"path":"iteration.html","id":"chargement-des-paquets-1","chapter":"16 Itération, boucles et listes","heading":"Chargement des paquets","text":"Ce morceau de code montre le chargement des paquets nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire et le charge pour l’utiliser. Vous pouvez également charger les paquets installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les paquets R.","code":"\npacman::p_load(\n     rio, # import/export\n     here, # localisateur de fichiers\n     purrr, # itération\n     tidyverse, # gestion et visualisation des données\n     grates\n)"},{"path":"iteration.html","id":"importer-des-données-1","chapter":"16 Itération, boucles et listes","heading":"Importer des données","text":"Nous importons le jeu de données des cas d’une épidémie d’Ebola simulée. Si vous voulez suivre le mouvement, cliquez pour télécharger la linelist “propre” (en tant que fichier .rds). Importez des données avec la fonction import() du paquet rio (elle gère de nombreux types de fichiers comme .xlsx, .csv, .rds - voir la page Importation et exportation pour plus de détails).Les 50 premières lignes de la linelist sont affichées ci-dessous.","code":"\n# Importez la liste de cas\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"iteration.html","id":"for-loops","chapter":"16 Itération, boucles et listes","heading":"16.2 for loops","text":"","code":""},{"path":"iteration.html","id":"iter_loops","chapter":"16 Itération, boucles et listes","heading":"for loops en R","text":"Les loops ne sont pas mis en avant dans R, mais sont courants dans d’autres langages de programmation. En tant que débutant, elles peuvent être utiles à l’apprentissage et à la pratique car elles sont plus faciles à “explorer”, à “déboguer” et à comprendre exactement ce qui se passe à chaque itération, en particulier lorsque vous n’êtes pas encore à l’aise pour écrire vos propres fonctions.Vous pouvez passer rapidement des boucles à l’itération avec des fonctions mappées avec purrr (voir section ci-dessous).","code":""},{"path":"iteration.html","id":"composants-principaux","chapter":"16 Itération, boucles et listes","heading":"Composants principaux","text":"Une boucle comporte trois éléments essentiels :la séquence d’éléments à parcourir par itérationLes opérations à effectuer pour chaque élément de la séquence.le contenu des résultats (facultatif).La syntaxe de base est la suivante : pour (élément dans la séquence) {faire des opérations avec l'élément}. Notez les parenthèses et les accolades. Les résultats peuvent être imprimés sur la console, ou stockés dans un objet R conteneur.Voici un exemple simple de boucle .","code":"\nfor (num in c(1,2,3,4,5)) { # la SEQUENCE est définie (numéros 1 à 5) et la boucle est ouverte avec \"{\"\n  print(num + 2) # Les OPERATIONS (ajouter deux à chaque numéro de séquence et imprimer)\n}                            # La boucle est fermée avec \"}\"                            ## [1] 3\n## [1] 4\n## [1] 5\n## [1] 6\n## [1] 7\n                             # Il n'y a pas de \"conteneur\" dans cet exemple."},{"path":"iteration.html","id":"séquence-.unnumbered-sans-numéro","chapter":"16 Itération, boucles et listes","heading":"16.2.1 Séquence {.unnumbered} (sans numéro)","text":"Il s’agit de la partie “” d’une boucle - les opérations seront exécutées “pour” chaque élément de la séquence. La séquence peut être une série de valeurs (par exemple, des noms de juridictions, de maladies, des noms de colonnes, des éléments de listes, etc), ou bien une série de nombres consécutifs (par exemple, 1,2,3,4,5). Chaque approche ses propres utilitaires, décrits ci-dessous.La structure de base d’une déclaration de séquence est item vector.Vous pouvez écrire n’importe quel caractère ou mot à la place de “item” (par exemple “”, “num”, “hosp”, “district”, etc.). La valeur de cet “item” change à chaque itération de la boucle, en passant par chaque valeur du vecteur.Le vecteur peut être constitué de valeurs de caractères, de noms de colonnes, ou peut-être d’une séquence de nombres - ce sont les valeurs qui changeront à chaque itération. Vous pouvez les utiliser dans les opérations loop en utilisant le terme “item”.Exemple : séquence de valeurs de caractèresDans cet exemple, une boucle est exécutée pour chaque valeur d’un vecteur de caractères prédéfini de noms d’hôpitaux.Nous avons choisi le terme hosp pour représenter les valeurs du vecteur hospital_names. Pour la première itération de la boucle, la valeur de hosp sera hospital_names[[1]]. Pour la deuxième boucle, elle sera noms_hospitaliers[[2]]. Et ainsi de suite…Exemple : séquence de noms de colonnesIl s’agit d’une variation de la séquence de caractères ci-dessus, dans laquelle les noms d’un objet R existant sont extraits et deviennent le vecteur. Par exemple, les noms des colonnes d’un cadre de données. De façon pratique, dans le code d’opérations de la boucle , les noms de colonnes peuvent être utilisés pour indexer (sous-ensemble) leur cadre de données original.Ci-dessous, la séquence est constituée des names() (noms des colonnes) du cadre de données linelist. Notre nom d’“élément” est col, qui représentera chaque nom de colonne au fur et à mesure que les boucles se déroulent.Pour les besoins de l’exemple, nous incluons le code des opérations à l’intérieur de la boucle , qui est exécutée pour chaque valeur de la séquence. Dans ce code, les valeurs de la séquence (noms de colonnes) sont utilisées pour indexer (sous-ensemble) linelist, une par une. Comme enseigné dans la page bases de R, les doubles branchements [[ ]] sont utilisés pour sous-indexer. La colonne résultante est passée à .na(), puis à sum() pour produire le nombre de valeurs manquantes dans la colonne. Le résultat est imprimé sur la console - un nombre pour chaque colonne.Une remarque sur l’indexation avec les noms de colonnes - lorsque vous faites référence à la colonne elle-même, ne vous contentez pas d’écrire “col”! col ne représente que le nom de la colonne en caractères! Pour faire référence à la colonne entière, vous devez utiliser le nom de la colonne comme index sur linelist via linelist[[col]].Séquence de nombresDans cette approche, la séquence est une série de nombres consécutifs. Ainsi, la valeur de l’“item” n’est pas une valeur de caractère (par exemple, “Central Hospital” ou “date_onset”) mais un nombre. Ceci est utile pour boucler des cadres de données, car vous pouvez utiliser le numéro de “item” dans la boucle pour indexer le cadre de données par numéro de ligne.Par exemple, disons que vous souhaitez parcourir chaque ligne de votre cadre de données et extraire certaines informations. Vos “éléments” seraient des numéros de ligne numériques. Dans ce cas, les “éléments” sont souvent écrits sous la forme .Le processus loop pourrait s’expliquer par la phrase suivante: “pour chaque élément d’une séquence de nombres allant de 1 au nombre total de lignes de mon cadre de données, faire X”. Pour la première itération de la boucle, la valeur de l’“élément” sera 1. Pour la deuxième itération, sera 2, etc.Voici à quoi ressemble la séquence en code: (1:nrow(linelist)) {CODE DES OPERATIONS} où représente l’“élément” et 1:nrow(linelist) produit une séquence de nombres consécutifs allant de 1 au nombre de lignes de linelist.Si vous voulez que la séquence soit des nombres, mais que vous partez d’un vecteur (et non d’un cadre de données), utilisez le raccourci seq_along() pour retourner une séquence de nombres pour chaque élément du vecteur. Par exemple, (seq_along(hospital_names) {CODE D'OPÉRATIONS}.Le code ci-dessous renvoie en fait des nombres, qui deviendront la valeur de dans leur boucle respective.Un avantage de l’utilisation de nombres dans la séquence est qu’il est facile d’utiliser le nombre pour indexer un conteneur qui stocke les sorties de la boucle. Il y un exemple de ceci dans la section Opérations ci-dessous.","code":"\n# faire un vecteur des noms d'hôpitaux\nhospital_names <- unique(linelist$hospital)\nhospital_names # print## [1] \"Other\"                                \"Missing\"                             \n## [3] \"St. Mark's Maternity Hospital (SMMH)\" \"Port Hospital\"                       \n## [5] \"Military Hospital\"                    \"Central Hospital\"\n# une 'boucle for' avec une séquence de caractères\n\nfor (hosp in hospital_names){ # séquence\n  \n       # OPÉRATIONS ICI\n  }\nfor (col in names(linelist)){ # La boucle est exécutée pour chaque colonne de la linelist ; le nom de la colonne est représenté par \"col\". \n  \n  # Exemple de code d'opérations - impression du nombre de valeurs manquantes dans la colonne\n  print(sum(is.na(linelist[[col]])))  # La linelist est indexée par la valeur actuelle de \"col\".\n     \n}## [1] 0\n## [1] 0\n## [1] 2087\n## [1] 256\n## [1] 0\n## [1] 936\n## [1] 1323\n## [1] 278\n## [1] 86\n## [1] 0\n## [1] 86\n## [1] 86\n## [1] 86\n## [1] 0\n## [1] 0\n## [1] 0\n## [1] 2088\n## [1] 2088\n## [1] 0\n## [1] 0\n## [1] 0\n## [1] 249\n## [1] 249\n## [1] 249\n## [1] 249\n## [1] 249\n## [1] 149\n## [1] 765\n## [1] 0\n## [1] 256\nfor (i in 1:nrow(linelist)) { # utilisation sur un cadre de données\n  # OPÉRATIONS ICI\n}  \nseq_along(hospital_names) # utilisation sur un vecteur nommé## [1] 1 2 3 4 5 6"},{"path":"iteration.html","id":"opérations","chapter":"16 Itération, boucles et listes","heading":"Opérations","text":"C’est le code entre les crochets { } de la boucle . Vous voulez que ce code soit exécuté pour chaque “élément” de la séquence. Par conséquent, faites attention à ce que chaque partie de votre code qui change en fonction de l’“item” soit correctement codée pour qu’elle change réellement ! Par exemple, n’oubliez pas d’utiliser [[ ]] pour l’indexation.Dans l’exemple ci-dessous, nous itérons à travers chaque ligne de la linelist. Les valeurs gender et age de chaque ligne sont collées ensemble et stockées dans le vecteur de caractères conteneur cases_demographics. Notez comment nous utilisons également l’indexation [[]] pour enregistrer la sortie de la boucle à la bonne position dans le vecteur “conteneur”.","code":"\n# créer un conteneur pour stocker les résultats - un vecteur de caractères\ncases_demographics <- vector(mode = \"character\", length = nrow(linelist))\n\n# la boucle for\nfor (i in 1:nrow(linelist)){\n  \n  # OPERATIONS\n  # extraire les valeurs de la linelist pour la ligne i, en utilisant les parenthèses pour l'indexation.\n  row_gender <- linelist$gender[[i]]\n  row_age <- linelist$age_years[[i]]    # n'oubliez pas d'indexer!\n     \n  # combinez sexe-âge et stockez dans un vecteur conteneur à l'emplacement indexé\n  cases_demographics[[i]] <- str_c(row_gender, row_age, sep = \",\") \n\n}  # fin de la boucle for\n\n\n# affiche les 10 premières lignes du conteneur\nhead(cases_demographics, 10)##  [1] \"m,2\"  \"f,3\"  \"m,56\" \"f,18\" \"m,3\"  \"f,16\" \"f,16\" \"f,0\"  \"m,61\" \"f,27\""},{"path":"iteration.html","id":"conteneur","chapter":"16 Itération, boucles et listes","heading":"Conteneur","text":"Parfois, les résultats de votre boucle seront imprimés sur la console ou dans le panneau Plots de RStudio. D’autres fois, vous voudrez stocker les résultats dans un “conteneur” pour une utilisation ultérieure. Ce conteneur peut être un vecteur, un cadre de données ou même une liste.Il est plus efficace de créer le conteneur pour les résultats avant même de commencer la boucle . En pratique, cela signifie créer un vecteur, un cadre de données ou une liste vide. peut les créer avec les fonctions vector() pour les vecteurs ou les listes, ou avec matrix() et data.frame() pour un cadre de données.Vecteur videUtilisez vector() et spécifiez le mode = en fonction de la classe attendue des objets que vous allez insérer - soit “double” (pour contenir des nombres), “caractère”, ou “logique”. Vous devez également définir la valeur length = à l’avance. Il s’agit de la longueur de votre séquence loop.Disons que vous voulez stocker le délai médian d’admission pour chaque hôpital. Vous utiliserez “double” et définirez la longueur comme étant le nombre de sorties attendues (le nombre d’hôpitaux uniques dans l’ensemble de données).**Cadre de données videVous pouvez créer un cadre de données vide en spécifiant le nombre de lignes et de colonnes comme ceci :Liste videVous pouvez vouloir stocker certains graphiques créés par une boucle dans une liste. Une liste est comme un vecteur, mais elle contient d’autres objets R qui peuvent être de différentes classes. Les éléments d’une liste peuvent être un nombre unique, un cadre de données, un vecteur et même une autre liste.Vous pouvez initialiser une liste vide en utilisant la même commande vector() que ci-dessus, mais avec mode = \"list\". Spécifiez la longueur comme vous le souhaitez.","code":"\ndelays <- vector(\n  mode = \"double\", # nous nous attendons à stocker des nombres\n  length = length(unique(linelist$hospital))) # le nombre d'hôpitaux uniques dans l'ensemble de données\ndelays <- data.frame(matrix(ncol = 2, nrow = 3))\nplots <- vector(mode = \"list\", length = 16)"},{"path":"iteration.html","id":"impression","chapter":"16 Itération, boucles et listes","heading":"Impression","text":"Notez que pour imprimer à partir d’une boucle , vous aurez probablement besoin d’envelopper explicitement avec la fonction print().Dans l’exemple ci-dessous, la séquence est un vecteur de caractères explicite, qui est utilisé pour sous-titrer la linelist par hôpital. Les résultats ne sont pas stockés dans un conteneur, mais sont imprimés sur la console avec la fonction print().","code":"\nfor (hosp in hospital_names){ \n     hospital_cases <- linelist %>% filter(hospital == hosp)\n     print(nrow(hospital_cases))\n}## [1] 885\n## [1] 1469\n## [1] 422\n## [1] 1762\n## [1] 896\n## [1] 454"},{"path":"iteration.html","id":"tester-votre-boucle-for","chapter":"16 Itération, boucles et listes","heading":"Tester votre boucle for","text":"Pour tester votre boucle, vous pouvez lancer une commande pour effectuer une affectation temporaire de l’“élément”, comme <- 10 ou hosp <- \"Central Hospital\". Faites cela en dehors de la boucle, puis exécutez votre code d’opérations uniquement (le code entre les accolades) pour voir si les résultats attendus sont produits.","code":""},{"path":"iteration.html","id":"plots-de-bouclage","chapter":"16 Itération, boucles et listes","heading":"Plots de bouclage","text":"Pour rassembler les trois composants (conteneur, séquence et opérations), essayons de tracer une épicurve pour chaque hôpital (voir la page sur les Courbes épidémiques).Nous pouvons faire une belle épicurve de tous les cas par sexe en utilisant le paquet incidence2 comme ci-dessous:Pour produire un graphique distinct pour les cas de chaque hôpital, nous pouvons placer ce code épicurve dans une boucle .Tout d’abord, nous enregistrons un vecteur nommé des noms uniques des hôpitaux, hospital_names. La boucle sera exécutée une fois pour chacun de ces noms : (hosp hospital_names). chaque itération de la boucle , le nom de l’hôpital actuel du vecteur sera représenté par hosp pour être utilisé dans la boucle.Dans les opérations de la boucle, vous pouvez écrire du code R comme d’habitude, mais utiliser l’“élément” (hosp dans ce cas) en sachant que sa valeur va changer. Dans cette boucle :Un filter() est appliqué à linelist, de telle sorte que la colonne hospital doit être égale à la valeur actuelle de hosp.L’objet incidence est créé sur la liste de lignes filtrée.Le graphique de l’hôpital actuel est créé, avec un titre auto-ajustable qui utilise hosp.Le graphique de l’hôpital actuel est temporairement sauvegardé puis imprimé.La boucle se répète ensuite avec l’hôpital suivant dans hospital_names.","code":"\n# créer un objet 'incidence\noutbreak <- incidence2::incidence(   \n     x = linelist, # dataframe - linelist complet\n     date_index = \"date_onset\", # colonne de date\n     interval = \"week\", # aggregate counts weekly\n     groups = \"gender\") # regroupe les valeurs par sexe\n     #na_as_group = TRUE , deprecated incidence version 2.0.0\n\n# tracer la courbe d'épidémie\nggplot(outbreak, # nom de l'objet d'incidence\n        aes(x = date_index, #aesthetiques et axes\n            y = count, \n            fill = gender), # couleur des barres par sexe\n       color = \"black\"      # couleur de contour des barres\n       ) +  \n     geom_col() + \n     facet_wrap(~gender) +\n     theme_bw() + \n     labs(title = \"Outbreak of all cases\", #titre\n          x = \"Counts\", \n          y = \"Date\", \n          fill = \"Gender\", \n          color = \"Gender\")\n# fabrique un vecteur des noms d'hôpitaux\nhospital_names <- unique(linelist$hospital)\n\n# pour chaque nom (\"hosp\") dans hospital_names, créer et imprimer la courbe épi\nfor (hosp in hospital_names) {\n     \n     # créer un objet d'incidence spécifique à l'hôpital actuel\n     outbreak_hosp <- incidence2::incidence(\n          x = linelist %>% filter(hospital == hosp), # linelist est filtré sur l'hôpital actuel\n          date_index = \"date_onset\",\n          interval = \"week\", \n          groups = \"gender\",\n          #na_as_group = TRUE , deprecated incidence version 2.0.0\n     )\n     \n     \n     # tracer la courbe d'épidémie\n\n     plot_hosp <- ggplot(outbreak_hosp, # nom de l'objet d'incidence\n                         aes(x = date_index, #aesthetiques et axes\n                             y = count, \n                             fill = gender), # couleur des barres par sexe\n                         color = \"black\"      # couleur de contour des barres\n                         ) +  \n          geom_col() + \n          facet_wrap(~gender) +\n          theme_bw() + \n          labs(title = stringr::str_glue(\"Epidemic of cases admitted to {hosp}\"), #titre\n               x = \"Counts\", \n               y = \"Date\", \n               fill = \"Gender\", \n               color = \"Gender\")\n     \n     # Créez et enregistrez le graphique. Le titre s'ajuste automatiquement à l'hôpital actuel\n    # plot_hosp <- plot(\n#       outbreak_hosp,\n#       fill = \"gender\",\n#       color = \"black\",\n#       title = stringr::str_glue(\"Epidemic of cases admitted to {hosp}\")\n#     )\n     \n     # imprimer le graphique pour l'hôpital actuel\n     print(plot_hosp)\n     \n} # terminez la boucle for lorsqu'elle a été exécutée pour chaque hôpital dans hospital_names "},{"path":"iteration.html","id":"suivi-de-la-progression-dune-boucle","chapter":"16 Itération, boucles et listes","heading":"Suivi de la progression d’une boucle","text":"Une boucle comportant de nombreuses itérations peut s’exécuter pendant plusieurs minutes, voire plusieurs heures. Ainsi, il peut être utile d’imprimer la progression dans la console R. L’instruction ci-dessous peut être placée dans les opérations de la boucle pour imprimer chaque 100ème nombre. Il suffit de l’ajuster pour que soit l’“élément” de votre boucle.","code":"# boucle avec code pour imprimer la progression toutes les 100 itérations\nfor (i in seq_len(nrow(linelist))){\n\n  # imprimer la progression\n  if(i %% 100==0){ # L'opérateur %% est le restant\n    print(i)\n\n}"},{"path":"iteration.html","id":"iter_purrr","chapter":"16 Itération, boucles et listes","heading":"16.3 purrr et listes","text":"Une autre approche des opérations itératives est le paquet purrr - c’est l’approche tidyverse de l’itération.Si vous devez effectuer la même tâche plusieurs fois, il est probablement utile de créer une solution généralisée que vous pouvez utiliser sur plusieurs entrées. Par exemple, produire des tracés pour plusieurs juridictions, ou importer et combiner de nombreux fichiers.Il y aussi quelques autres avantages à purrr - vous pouvez l’utiliser avec des tubes %>%, il gère mieux les erreurs que les boucles normales, et la syntaxe est assez propre et simple ! Si vous utilisez une boucle , vous pouvez probablement le faire plus clairement et succinctement avec purrr !Gardez à l’esprit que purrr est un outil de programmation fonctionnel. C’est-à-dire que les opérations qui doivent être appliquées de manière itérative sont regroupées dans des fonctions. Consultez la page Écrire des fonctions pour apprendre à écrire vos propres fonctions.purrr est également presque entièrement basé sur des listes et des vecteurs - pensez-y comme si vous appliquiez une fonction à chaque élément de cette liste/ce vecteur !","code":""},{"path":"iteration.html","id":"chargement-des-paquets-2","chapter":"16 Itération, boucles et listes","heading":"Chargement des paquets","text":"purrr fait partie de tidyverse, il n’y donc pas besoin d’installer/charger un paquet séparé.","code":"\npacman::p_load(\n     rio, # import/export\n     here, # chemins de fichiers relatifs\n     tidyverse, # gestion et visualisation des données\n     writexl, # écriture d'un fichier Excel à feuilles multiples\n     readxl # importer Excel avec plusieurs feuilles\n)"},{"path":"iteration.html","id":"map","chapter":"16 Itération, boucles et listes","heading":"map()","text":"Une fonction essentielle de purrr est map(), qui “mappe” (applique) une fonction à chaque élément d’entrée d’une liste/vecteur que vous fournissez.La syntaxe de base est map(.x = SEQUENCE, .f = FONCTION, AUTRES ARGUMENTS). Un peu plus en détail :.x = sont les entrées sur lesquelles la fonction .f sera appliquée de manière itérative - par exemple un vecteur de noms de juridiction, des colonnes dans un cadre de données, ou une liste de cadres de données..f = est la fonction à appliquer à chaque élément de l’entrée .x - cela peut être une fonction comme print() qui existe déjà, ou une fonction personnalisée que vous définissez. La fonction est souvent écrite après un tilde ~ (détails ci-dessous).Quelques notes supplémentaires sur la syntaxe :Si la fonction n’pas besoin de spécifier d’autres arguments, elle peut être écrite sans parenthèses et sans tilde (par exemple, .f = mean). Pour fournir des arguments qui auront la même valeur à chaque itération, fournissez-les dans map() mais en dehors de l’argument .f =, comme le na.rm = T dans map(.x = ma_liste, .f = mean, na.rm=T).Vous pouvez utiliser .x (ou simplement .) * à l’intérieur* de la fonction .f = comme substitut pour la valeur .x de cette itération.Utilisez la syntaxe du tilde (~) pour avoir un meilleur contrôle sur la fonction - écrivez la fonction normalement avec des parenthèses, par exemple : map(.x = ma_liste, .f = ~mean(., na.rm = T)). Utilisez cette syntaxe particulièrement si la valeur d’un argument change à chaque itération, ou si c’est la valeur .x elle-même (voir les exemples ci-dessous)Le résultat de l’utilisation de map() est une liste  - une liste est une classe d’objets comme un vecteur mais dont les éléments peuvent être de classes différentes. Ainsi, une liste produite par map() peut contenir de nombreux cadres de données, ou de nombreux vecteurs, de nombreuses valeurs individuelles, ou même de nombreuses listes ! Il existe des versions alternatives de map() expliquées ci-dessous qui produisent d’autres types de sorties (par exemple, map_dfr() pour produire un cadre de données, map_chr() pour produire des vecteurs de caractères, et map_dbl() pour produire des vecteurs numériques).","code":""},{"path":"iteration.html","id":"iter_combined","chapter":"16 Itération, boucles et listes","heading":"Exemple - Importer et combiner des feuilles Excel","text":"Démontrons avec une tâche courante d’épidémiologiste: - *Vous voulez importer un classeur Excel avec des données de cas, mais les données sont réparties sur différentes feuilles nommées dans le classeur. Comment importer et combiner efficacement les feuilles en un seul cadre de données ?Imaginons que l’nous envoie le classeur Excel ci-dessous. Chaque feuille contient les cas d’un hôpital donné.Voici une approche qui utilise map() :map() la fonction import() pour qu’elle s’exécute pour chaque feuille Excel.Combinez les cadres de données importés en un seul en utilisant bind_rows().En cours de route, conservez le nom de la feuille originale pour chaque ligne, en stockant cette information dans une nouvelle colonne du cadre de données final.Tout d’abord, nous devons extraire les noms des feuilles et les enregistrer. Nous fournissons le chemin du fichier du classeur Excel à la fonction excel_sheets() du package readxl, qui extrait les noms des feuilles. Nous les stockons dans un vecteur de caractères appelé sheet_names.Voici les noms :Maintenant que nous avons ce vecteur de noms, map() peut les fournir un par un à la fonction import(). Dans cet exemple, les sheet_names sont .x et import() est la fonction .f.Rappelez-vous de la page Importation et exportation que lorsqu’il est utilisé sur des classeurs Excel, import() peut accepter l’argument = spécifiant la feuille à importer. Dans la fonction .f import(), nous fournissons = .x, dont la valeur changera à chaque itération dans le vecteur sheet_names - d’abord “Central Hospital”, puis “Military Hospital”, etc.noter - parce que nous avons utilisé map(), les données de chaque feuille Excel seront enregistrées comme un cadre de données séparé dans une liste. Nous voulons que chacun de ces éléments de liste (cadres de données) ait un nom, donc avant de passer sheet_names à map(), nous le passons à travers set_names() de purrr, ce qui garantit que chaque élément de liste reçoit le nom approprié.Nous enregistrons la liste de sortie comme combined (combiné en francais).Lorsque nous inspectons la sortie, nous voyons que les données de chaque feuille Excel sont enregistrées dans la liste avec un nom. C’est bien, mais nous n’avons pas tout à fait terminé.Enfin, nous utilisons la fonction bind_rows() (de dplyr) qui accepte la liste des cadres de données structurés de manière similaire et les combine en un seul cadre de données. Pour créer une nouvelle colonne à partir de l’élément de liste names, nous utilisons l’argument .id = et lui fournissons le nom souhaité pour la nouvelle colonne.Voici la séquence complète des commandes :Et maintenant nous avons un cadre de données avec une colonne contenant la feuille d’origine !Il existe des variantes de map() que vous devez connaître. Par exemple, map_dfr() renvoie un cadre de données, et non une liste. Ainsi, nous aurions pu l’utiliser pour la tâche ci-dessus et ne pas avoir à lier les rangées. Mais alors nous n’aurions pas été en mesure de capturer de quelle feuille (hôpital) chaque cas provenait.D’autres variations incluent map_chr(), map_dbl(). Ces fonctions sont très utiles pour deux raisons. Premièrement, elles convertissent automatiquement la sortie d’une fonction itérative en un vecteur (et non en une liste). Deuxièmement, elles peuvent contrôler explicitement la classe dans laquelle les données reviennent - vous vous assurez que vos données reviennent sous forme de vecteur de caractères avec map_chr(), ou de vecteur numérique avec map_dbl(). Nous y reviendrons plus tard dans cette section !Les fonctions map_at() et map_if() sont aussi très utiles pour l’itération - elles vous permettent de spécifier quels éléments d’une liste vous devez itérer ! Elles fonctionnent en appliquant simplement un vecteur d’index/noms (dans le cas de map_at()) ou un test logique (dans le cas de map_if()).Prenons un exemple où nous ne voulons pas lire la première feuille de données de l’hôpital. Nous utilisons map_at() au lieu de map(), et spécifions l’argument .= à c(-1) ce qui signifie ne pas utiliser le premier élément de .x. Alternativement, vous pouvez fournir un vecteur de nombres positifs, ou de noms, à .= pour spécifier les éléments à utiliser.Notez que le nom de la première feuille apparaîtra toujours comme un élément de la liste de sortie - mais ce n’est qu’un nom à un seul caractère (pas un cadre de données). Vous devrez supprimer cet élément avant de lier les lignes. Nous verrons comment supprimer et modifier des éléments de liste dans une section ultérieure.","code":"\nsheet_names <- readxl::excel_sheets(\"hospital_linelists.xlsx\")\nsheet_names## [1] \"Central Hospital\"              \"Military Hospital\"            \n## [3] \"Missing\"                       \"Other\"                        \n## [5] \"Port Hospital\"                 \"St. Mark's Maternity Hospital\"\ncombined <- sheet_names %>% \n  purrr::set_names() %>% \n  map(.f = ~import(\"hospital_linelists.xlsx\", which = .x))\nsheet_names <- readxl::excel_sheets(\"hospital_linelists.xlsx\") # extrait les noms des feuilles\n \ncombined <- sheet_names %>% # commence avec les noms de feuilles\n  purrr::set_names() %>% # définit leurs noms\n  map(.f = ~import(\"hospital_linelists.xlsx\", which = .x)) %>% # itère, importe, sauvegarde dans la liste\n  bind_rows(.id = \"origin_sheet\") # combine la liste des cadres de données, en préservant l'origine dans une nouvelle colonne  \nsheet-names <- readxl::excel_sheets(\"hospital_linelinest.xlsx\")\n\ncombined <- sheet_names %>% \n     purrr::set_names() %>% \n     # exclure la première feuille\n     map_at(.f = ~import( \"hospital_linelists.xlsx\", which = .x),\n            .at = c(-1))"},{"path":"iteration.html","id":"diviser-lensemble-de-données-et-exporter","chapter":"16 Itération, boucles et listes","heading":"Diviser l’ensemble de données et exporter","text":"Ci-dessous, nous donnons un exemple de la façon de diviser un jeu de données en plusieurs parties, puis d’utiliser l’itération map() pour exporter chaque partie comme une feuille Excel séparée, ou comme un fichier CSV séparé.","code":""},{"path":"iteration.html","id":"diviser-lensemble-de-données","chapter":"16 Itération, boucles et listes","heading":"Diviser l’ensemble de données","text":"Disons que nous avons le cas complet linelist en tant que cadre de données, et que nous voulons maintenant créer une linelist séparée pour chaque hôpital et l’exporter comme un fichier CSV séparé. Ci-dessous, nous effectuons les étapes suivantes :Utilisez group_split() (de dplyr) pour diviser le cadre de données linelist par des valeurs uniques dans la colonne hospital. La sortie est une liste contenant un cadre de données par sous-ensemble hospitalier.Nous pouvons exécuter View(linelist_split) et voir que cette liste contient 6 cadres de données (“tibbles”), chacun représentant les cas d’un hôpital.Cependant, notez que les cadres de données de la liste n’ont pas de nom par défaut ! Nous voulons que chacun d’eux ait un nom, et que ce nom soit utilisé lors de l’enregistrement du fichier CSV.Une approche pour extraire les noms est d’utiliser pull() (de dplyr) pour extraire la colonne hospital de chaque cadre de données dans la liste. Ensuite, pour être sûr, nous convertissons les valeurs en caractères et utilisons ensuite unique() pour obtenir le nom de ce cadre de données particulier. Toutes ces étapes sont appliquées à chaque cadre de données via map().Nous pouvons maintenant voir que chacun des éléments de la liste un nom. peut accéder à ces noms via `names(linelist_split)``.","code":"\nlinelist_split <- linelist %>% \n     group_split(hospital)\nnames(linelist_split) <- linelist_split %>% # Affectation aux noms des blocs de données listés \n     # Extrayez les noms en effectuant ce qui suit pour chaque cadre de données : \n     map(.f = ~pull(.x, hospital)) %>% # Extraire la colonne hôpital\n     map(.f = ~as.character(.x)) %>% # Convertir en caractères, juste au cas où\n     map(.f = ~unique(.x))                    # Prendre le nom unique de l'hôpital\nnames(linelist_split)## [1] \"Central Hospital\"                     \"Military Hospital\"                   \n## [3] \"Missing\"                              \"Other\"                               \n## [5] \"Port Hospital\"                        \"St. Mark's Maternity Hospital (SMMH)\""},{"path":"iteration.html","id":"plus-dune-colonne-group_split","chapter":"16 Itération, boucles et listes","heading":"Plus d’une colonne group_split()","text":"Si vous souhaitez diviser la linelist par plusieurs colonnes de regroupement, par exemple pour produire un sous-ensemble linelist par intersection de l’hôpital ET du sexe, vous aurez besoin d’une approche différente pour nommer les éléments de la liste. Cela implique de collecter les “clés de groupe” uniques en utilisant group_keys() de dplyr - elles sont retournées comme un cadre de données. Vous pouvez ensuite combiner les clés de groupe en valeurs avec unite() comme indiqué ci-dessous, et attribuer ces noms de conglomérat à linelist_split.Maintenant nous combinons les groupements ensemble, séparés par des tirets, et nous les assignons comme noms des éléments de la liste dans linelist_split. Cela prend quelques lignes supplémentaires car nous remplaçons NA par “Missing”, nous utilisons unite() de dplyr pour combiner les valeurs des colonnes ensemble (séparées par des tirets), puis nous les convertissons en un vecteur sans nom pour qu’il puisse être utilisé comme noms de linelist_split.","code":"\n# divise la linelist par les combinaisons uniques hôpital-sexe\nlinelist_split <- linelist %>% \n     group_split(hospital, gender)\n\n# extraire group_keys() sous forme de dataframe\ngroupings <- linelist %>% \n     group_by(hospital, gender) %>%       \n     group_keys()\n\ngroupings # montre les groupements uniques ## # A tibble: 18 × 2\n##    hospital                             gender\n##    <chr>                                <chr> \n##  1 Central Hospital                     f     \n##  2 Central Hospital                     m     \n##  3 Central Hospital                     <NA>  \n##  4 Military Hospital                    f     \n##  5 Military Hospital                    m     \n##  6 Military Hospital                    <NA>  \n##  7 Missing                              f     \n##  8 Missing                              m     \n##  9 Missing                              <NA>  \n## 10 Other                                f     \n## 11 Other                                m     \n## 12 Other                                <NA>  \n## 13 Port Hospital                        f     \n## 14 Port Hospital                        m     \n## 15 Port Hospital                        <NA>  \n## 16 St. Mark's Maternity Hospital (SMMH) f     \n## 17 St. Mark's Maternity Hospital (SMMH) m     \n## 18 St. Mark's Maternity Hospital (SMMH) <NA>\n# Combinez en une seule valeur de nom \nnames(linelist_split) <- groupings %>% \n     mutate(across(everything(), replace_na, \"Missing\")) %>% # Remplacer NA par \"Missing\" dans toutes les colonnes\n     unite(\"combined\", sep = \"-\") %>% # Réunit toutes les valeurs des colonnes en une seule\n     setNames(NULL) %>% # d'unification de toutes les valeurs de colonnes en une seule \n     as_vector() %>% \n     as.list()"},{"path":"iteration.html","id":"exporter-en-tant-que-feuilles-excel","chapter":"16 Itération, boucles et listes","heading":"Exporter en tant que feuilles Excel","text":"Pour exporter les listes de lignes de l’hôpital comme un classeur Excel avec une liste de lignes par feuille, nous pouvons simplement fournir la liste nommée linelist_split à la fonction write_xlsx() du paquet writexl. Cela permet d’enregistrer un classeur Excel avec plusieurs feuilles. Les noms des éléments de la liste sont automatiquement appliqués comme noms de feuilles.Vous pouvez maintenant ouvrir le fichier Excel et voir que chaque hôpital sa propre feuille.","code":"\nlinelist_split %>% \n     writexl::write_xlsx(path = here(\"data\", \"hospital_linelists.xlsx\"))"},{"path":"iteration.html","id":"exportation-en-fichiers-csv","chapter":"16 Itération, boucles et listes","heading":"Exportation en fichiers CSV","text":"C’est une commande un peu plus complexe, mais vous pouvez également exporter chaque liste de lignes spécifique à un hôpital sous forme de fichier CSV distinct, avec un nom de fichier spécifique à l’hôpital.Encore une fois, nous utilisons map() : nous prenons le vecteur des noms des éléments de la liste (montré ci-dessus) et utilisons map() pour les parcourir, en appliquant export() (du paquet rio, voir la page Importation et exportation) sur le cadre de données dans la liste linelist_split qui ce nom. Nous utilisons également le nom pour créer un nom de fichier unique. Voici comment cela fonctionne :Nous commençons avec le vecteur de noms de caractères, passé à map() sous la forme .x.La fonction .f est export(), qui requiert un cadre de données et un chemin de fichier pour l’écriture.L’entrée .x (le nom de l’hôpital) est utilisée *dans .f pour extraire/indexer cet élément spécifique de la liste linelist_split. Il en résulte qu’un seul cadre de données à la fois est fourni à export().Par exemple, lorsque map() cherche “Military Hospital”, alors linelist_split[[.x]] est en fait linelist_split[[\"Military Hospital\"]], retournant ainsi le deuxième élément de linelist_split - qui est tous les cas de Military Hospital.Le chemin du fichier fourni à export() est dynamique grâce à l’utilisation de str_glue() (voir la page Caractères et chaînes de caractères) :\n() est utilisé pour obtenir la base du chemin du fichier et spécifier le dossier “data” (notez les guillemets simples pour ne pas interrompre les guillemets doubles de str_glue()).\n() est utilisé pour obtenir la base du chemin du fichier et spécifier le dossier “data” (notez les guillemets simples pour ne pas interrompre les guillemets doubles de str_glue()).Puis une barre oblique /, et encore le .x qui imprime le nom de l’hôpital actuel pour rendre le fichier identifiableEnfin, l’extension “.csv” que export() utilise pour créer un fichier CSV.Maintenant vous pouvez voir que chaque fichier est enregistré dans le dossier “data” du projet R “Epi_R_handbook” !","code":"\nnames(linelist_split) %>%\n     map(.f = ~export(linelist_split[[.x]], file = str_glue(\"{here('data')}/{.x}.csv\")))"},{"path":"iteration.html","id":"fonctions-personnalisées","chapter":"16 Itération, boucles et listes","heading":"Fonctions personnalisées","text":"Vous pouvez créer votre propre fonction à fournir à map().Disons que nous voulons créer des courbes épidémiques pour les cas de chaque hôpital. Pour faire cela en utilisant purrr, notre fonction .f peut être ggplot() et les extensions avec + comme d’habitude. Comme la sortie de map() est toujours une liste, les graphiques sont stockés dans une liste. Comme ce sont des tracés, ils peuvent être extraits et tracés avec la fonction ggarrange() du paquet ggpubr ( documentation).Si ce code map() vous semble trop compliqué, vous pouvez obtenir le même résultat en enregistrant votre commande ggplot() spécifique comme une fonction personnalisée définie par l’utilisateur, par exemple nous pouvons la nommer make_epicurve()). Cette fonction est ensuite utilisée dans la fonction map(). .x sera itérativement remplacé par le nom de l’hôpital, et utilisé comme hosp_name dans la fonction make_epicurve(). Voir la page sur les Fonctions d’écriture.","code":"\n# charger le paquetage pour tracer les éléments d'une liste\npacman::p_load(ggpubr)\n\n# cartographier le vecteur des 6 \"noms\" d'hôpitaux (créé précédemment)\n# utiliser la fonction ggplot spécifiée\n# la sortie est une liste avec 6 ggplots\n\nhospital_names <- unique(linelist$hospital)\n\nmy_plots <- map(\n  .x = hospital_names,\n  .f = ~ggplot(data = linelist %>% filter(hospital == .x)) +\n                geom_histogram(aes(x = date_onset)) +\n                labs(title = .x)\n)\n\n# imprimer les ggplots (ils sont stockés dans une liste)\nggarrange(plotlist = my_plots, ncol = 2, nrow = 3)\n# Créer une fonction\nmake_epicurve <- function(hosp_name){\n  \n  ggplot(data = linelist %>% filter(hospital == hosp_name)) +\n    geom_histogram(aes(x = date_onset)) +\n    theme_classic()+\n    labs(title = hosp_name)\n  \n}\n# cartographie\nmy_plots <- map(hospital_names, ~make_epicurve(hosp_name = .x))\n\n# imprimer les ggplots (ils sont stockés dans une liste)\nggarrange(plotlist = my_plots, ncol = 2, nrow = 3)"},{"path":"iteration.html","id":"mappage-dune-fonction-sur-plusieurs-colonnes","chapter":"16 Itération, boucles et listes","heading":"Mappage d’une fonction sur plusieurs colonnes","text":"Un autre cas d’utilisation courant est de mapper une fonction sur plusieurs colonnes. Ci-dessous, nous mappons() la fonction t.test() sur les colonnes numériques du cadre de données linelist, en comparant les valeurs numériques par sexe.Rappelez-vous de la page sur les Tests statistiques simples que t.test() peut prendre des entrées dans un format de formule, comme t.test(colonne numérique ~ colonne binaire). Dans cet exemple, nous faisons ce qui suit :Les colonnes numériques intéressantes sont sélectionnées dans linelist - elles deviennent les entrées .x de map().La fonction t.test() est fournie comme fonction .f, qui est appliquée à chaque colonne numérique.Dans les parenthèses de t.test():\nle premier ~ précède la fonction .f que map() va itérer sur .x\nLe .x représente la colonne courante fournie à la fonction t.test().\nLe deuxième ~ fait partie de l’équation du test t décrit ci-dessus.\nLa fonction t.test() attend une colonne binaire du côté droit de l’équation. Nous fournissons le vecteur linelist$gender indépendamment et statiquement (notez qu’il n’est pas inclus dans select()).\nle premier ~ précède la fonction .f que map() va itérer sur .xLe .x représente la colonne courante fournie à la fonction t.test().Le deuxième ~ fait partie de l’équation du test t décrit ci-dessus.La fonction t.test() attend une colonne binaire du côté droit de l’équation. Nous fournissons le vecteur linelist$gender indépendamment et statiquement (notez qu’il n’est pas inclus dans select()).map() retourne une liste, donc la sortie est une liste de résultats de tests t - un élément de liste pour chaque colonne numérique analysée.Voici à quoi ressemble la liste t.test_results lorsqu’elle est ouverte (visualisée) dans RStudio. Nous avons mis en évidence les parties qui sont importantes pour les exemples de cette page.Vous pouvez voir en haut que la liste entière est nommée t.test_results et cinq éléments. Ces cinq éléments sont nommés age, wt_km, ht_cm, ct_blood, temp après chaque variable qui été utilisée dans un test t avec gender de la linelist.Chacun de ces cinq éléments sont eux-mêmes des listes, avec des éléments à l’intérieur comme p.value et conf.int. Certains de ces éléments, comme p.value, sont des nombres simples, tandis que d’autres, comme estimate, sont composés de deux éléments ou plus (mean group f et mean group m).Remarque : N’oubliez pas que si vous voulez appliquer une fonction à certaines colonnes seulement d’un cadre de données, vous pouvez aussi utiliser simplement mutate() et across(), comme expliqué dans la page Nettoyage des données et fonctions de base. Vous trouverez ci-dessous un exemple d’application de .character() aux seules colonnes “age”. Notez l’emplacement des parenthèses et des virgules.","code":"\n# Les résultats sont enregistrés sous forme de liste\nt.test_results <- linelist %>% \n  select(age, wt_kg, ht_cm, ct_blood, temp) %>% # Ne garder que certaines colonnes numériques pour les mapper entre elles\n  map(.f = ~t.test(.x ~ linelist$gender))        # fonction t.test, avec équation NUMERIC ~ CATEGORICAL\n# convertit les colonnes dont le nom contient \"age\" en classe Character\nlinelist <- linelist %>% \n  mutate(across(.cols = contains(\"age\"), .fns = as.character))  "},{"path":"iteration.html","id":"extraire-des-listes","chapter":"16 Itération, boucles et listes","heading":"Extraire des listes","text":"Comme map() produit une sortie de la classe List, nous allons passer un peu de temps à discuter de la façon d’extraire des données de listes en utilisant les fonctions purrr qui les accompagnent. Pour le démontrer, nous allons utiliser la liste t.test_results de la section précédente. C’est une liste de 5 listes - chacune des 5 listes contient les résultats d’un test t entre une colonne du cadre de données linelist et sa colonne binaire gender. Voir l’image dans la section ci-dessus pour un visuel de la structure de la liste.","code":""},{"path":"iteration.html","id":"noms-des-éléments","chapter":"16 Itération, boucles et listes","heading":"Noms des éléments","text":"Pour extraire les noms des éléments eux-mêmes, utilisez simplement names() de base R. Dans ce cas, nous utilisons names() sur t.test_results pour retourner les noms de chaque sous-liste, qui sont les noms des 5 variables qui ont eu des tests t effectués.","code":"\nnames(t.test_results)## [1] \"age\"      \"wt_kg\"    \"ht_cm\"    \"ct_blood\" \"temp\""},{"path":"iteration.html","id":"éléments-par-nom-ou-par-position","chapter":"16 Itération, boucles et listes","heading":"Éléments par nom ou par position","text":"Pour extraire les éléments d’une liste par nom ou par position, vous pouvez utiliser des crochets “[[ ]]” comme décrit dans la page bases de R. Ci-dessous, nous utilisons des doubles crochets pour indexer la liste t.tests_results et afficher le premier élément qui est le résultat du test t sur age.Cependant, nous allons démontrer ci-dessous l’utilisation des fonctions purrr simples et flexibles map() et pluck() pour obtenir les mêmes résultats.","code":"\nt.test_results[[1]] # premier élément par position## \n##  Welch Two Sample t-test\n## \n## data:  .x by linelist$gender\n## t = -21.3, df = 4902.9, p-value < 2.2e-16\n## alternative hypothesis: true difference in means between group f and group m is not equal to 0\n## 95 percent confidence interval:\n##  -7.544409 -6.272675\n## sample estimates:\n## mean in group f mean in group m \n##        12.66085        19.56939\nt.test_results[[1]][ \"p.value\"] # retourne l'élément nommé \"p.value\" à partir du premier élément  ## $p.value\n## [1] 2.350374e-96"},{"path":"iteration.html","id":"pluck","chapter":"16 Itération, boucles et listes","heading":"pluck()","text":"pluck() extrait les éléments par nom ou par position. Par exemple - pour extraire les résultats du test t pour l’âge, vous pouvez utiliser pluck() comme ceci :Indexez des niveaux plus profonds en spécifiant les autres niveaux avec des virgules. L’exemple ci-dessous extrait l’élément nommé “p.value” de la liste age dans la liste t.test_results. Vous pouvez également utiliser des nombres à la place des noms de caractères.Vous pouvez extraire ces éléments internes de tous les éléments de premier niveau en utilisant map() pour exécuter la fonction pluck() sur chaque élément de premier niveau. Par exemple, le code ci-dessous extrait les éléments “p.value” de toutes les listes de t.test_results. La liste des résultats du test t est le .x itéré, pluck() est la fonction .f itérée, et la valeur “p-value” est fournie à la fonction.Comme autre alternative, map() offre un raccourci qui vous permet d’écrire le nom de l’élément entre guillemets, et il le récupérera. Si vous utilisez map(), la sortie sera une liste, alors que si vous utilisez map_chr(), ce sera un tableau de caractères nommé et si vous utilisez map_dbl(), ce sera un tableau numérique nommé.Vous pouvez en savoir plus sur pluck() dans sa purrr documentation. Elle une fonction sour chuck() qui retournera une erreur au lieu de NULL si un élément n’existe pas.","code":"\nt.test_results %>% \n  pluck(\"age\") # Ou bien, utilisez pluck(1)## \n##  Welch Two Sample t-test\n## \n## data:  .x by linelist$gender\n## t = -21.3, df = 4902.9, p-value < 2.2e-16\n## alternative hypothesis: true difference in means between group f and group m is not equal to 0\n## 95 percent confidence interval:\n##  -7.544409 -6.272675\n## sample estimates:\n## mean in group f mean in group m \n##        12.66085        19.56939\nt.test_results %>% \n  pluck(\"age\", \"p.value\")## [1] 2.350374e-96\nt.test_results %>%\n  map(pluck, \"p.value\") # renvoie chaque valeur p## $age\n## [1] 2.350374e-96\n## \n## $wt_kg\n## [1] 2.664367e-182\n## \n## $ht_cm\n## [1] 3.515713e-144\n## \n## $ct_blood\n## [1] 0.4473498\n## \n## $temp\n## [1] 0.5735923\nt.test_results %>% \n  map_dbl(\"p.value\") # renvoie les valeurs p sous la forme d'un tableau numérique nommé##           age         wt_kg         ht_cm      ct_blood          temp \n##  2.350374e-96 2.664367e-182 3.515713e-144  4.473498e-01  5.735923e-01"},{"path":"iteration.html","id":"convertir-une-liste-en-cadre-de-données","chapter":"16 Itération, boucles et listes","heading":"Convertir une liste en cadre de données","text":"Ceci est un sujet complexe - voir la section Ressources pour des tutoriels plus complets. Néanmoins, nous allons démontrer la conversion de la liste des résultats du test t en un cadre de données. Nous allons créer un cadre de données avec des colonnes pour la variable, sa valeur p, et les moyennes des deux groupes (hommes et femmes).Voici quelques-unes des nouvelles approches et fonctions qui seront utilisées :La fonction tibble() sera utilisée pour créer un tibble (comme un cadre de données).\nNous entourons la fonction tibble() de crochets { } pour éviter que la totalité de t.test_results soit stockée dans la première colonne du tibble.\nNous entourons la fonction tibble() de crochets { } pour éviter que la totalité de t.test_results soit stockée dans la première colonne du tibble.Dans tibble(), chaque colonne est créée explicitement, de façon similaire à la syntaxe de mutate() :\nLe . représente t.test_results\nPour créer une colonne avec les noms des variables t-test (les noms de chaque élément de la liste), nous utilisons names() comme décrit ci-dessus.\nPour créer une colonne avec les valeurs p, nous utilisons map_dbl() comme décrit ci-dessus pour extraire les éléments p.value et les convertir en un tableau numérique.\nLe . représente t.test_resultsPour créer une colonne avec les noms des variables t-test (les noms de chaque élément de la liste), nous utilisons names() comme décrit ci-dessus.Pour créer une colonne avec les valeurs p, nous utilisons map_dbl() comme décrit ci-dessus pour extraire les éléments p.value et les convertir en un tableau numérique.Mais maintenant, ajoutons des colonnes contenant les moyennes pour chaque groupe (hommes et femmes).Nous devrions extraire l’élément estimate, mais celui-ci contient en fait deux éléments (mean group f et mean group m). ne peut donc pas le simplifier en vecteur avec map_chr() ou map_dbl(). la place, nous utilisons map(), qui utilisé dans tibble() créera une colonne de liste de classe dans le tibble ! Oui, c’est possible !Une fois que vous avez cette colonne de liste, il existe plusieurs fonctions tidyr (faisant partie de tidyverse) qui vous aident à “rectangler” ou à “désimbriquer” ces colonnes de “liste imbriquée”. Vous pouvez en savoir plus à leur sujet ici, ou en exécutant vignette(\"rectangle\"). En bref:unnest_wider() - donne à chaque élément d’une colonne de liste sa propre colonne.unnest_longer() - donne à chaque élément d’une liste-colonne sa propre lignehoist() - agit comme unnest_wider() mais vous spécifiez les éléments à dépiler.Ci-dessous, nous passons le tibble à unnest_wider() en spécifiant la colonne means du tibble (qui est une liste imbriquée). Le résultat est que means est remplacé par deux nouvelles colonnes, chacune reflétant les deux éléments qui étaient précédemment dans chaque cellule means.","code":"\nt.test_results %>% {\n  tibble(\n    variables = names(.),\n    p = map_dbl(., \"p.value\"))\n  }## # A tibble: 5 × 2\n##   variables         p\n##   <chr>         <dbl>\n## 1 age       2.35e- 96\n## 2 wt_kg     2.66e-182\n## 3 ht_cm     3.52e-144\n## 4 ct_blood  4.47e-  1\n## 5 temp      5.74e-  1\nt.test_results %>% \n  {tibble(\n    variables = names(.),\n    p = map_dbl(., \"p.value\"),\n    means = map(., \"estimation\"))}## # A tibble: 5 × 3\n##   variables         p means       \n##   <chr>         <dbl> <named list>\n## 1 age       2.35e- 96 <NULL>      \n## 2 wt_kg     2.66e-182 <NULL>      \n## 3 ht_cm     3.52e-144 <NULL>      \n## 4 ct_blood  4.47e-  1 <NULL>      \n## 5 temp      5.74e-  1 <NULL>\nt.test_results %>% \n  {tibble(\n    variables = names(.),\n    p = map_dbl(., \"p.value\"),\n    means = map(., \"estimate\")\n    )} %>% \n  unnest_wider(means)## # A tibble: 5 × 4\n##   variables         p `mean in group f` `mean in group m`\n##   <chr>         <dbl>             <dbl>             <dbl>\n## 1 age       2.35e- 96              12.7              19.6\n## 2 wt_kg     2.66e-182              45.8              59.6\n## 3 ht_cm     3.52e-144             109.              142. \n## 4 ct_blood  4.47e-  1              21.2              21.2\n## 5 temp      5.74e-  1              38.6              38.6"},{"path":"iteration.html","id":"jeter-conserver-et-compacter-les-listes","chapter":"16 Itération, boucles et listes","heading":"Jeter, conserver et compacter les listes","text":"Parce que le travail avec purrr implique si souvent des listes, nous allons explorer brièvement certaines fonctions purrr pour modifier les listes. Voir la section Ressources pour des tutoriels plus complets sur les fonctions purrr.list_modify() de nombreuses utilisations, dont l’une peut être de supprimer un élément de listekeep() conserve les éléments spécifiés dans .p =, ou lorsqu’une fonction fournie dans .p = évalue VRAI.discard() supprime les éléments spécifiés dans .p, ou lorsqu’une fonction fournie à .p = vaut VRAI.compact() supprime tous les éléments vides.Voici quelques exemples utilisant la liste combined créée dans la section ci-dessus sur l’utilisation de map() pour importer et combiner plusieurs fichiers (elle contient 6 cadres de données de listes de cas) :Les éléments peuvent être supprimés par leur nom avec list_modify() et en mettant le nom égal à NULL.Vous pouvez également supprimer des éléments par critère, en fournissant une équation “prédicat” à .p = (une équation qui évalue à VRAI ou FAUX). Placez un tilde ~ devant la fonction et utilisez .x pour représenter l’élément de la liste. En utilisant keep(), les éléments de la liste qui valent VRAI seront conservés. Inversement, si vous utilisez discard(), les éléments de la liste qui valent VRAI seront supprimés.Dans l’exemple ci-dessous, les éléments de liste sont éliminés si leur classe n’est pas un cadre de données.Votre fonction prédicat peut également faire référence à des éléments/colonnes dans chaque élément de la liste. Par exemple, ci-dessous, les éléments de liste dont la moyenne de la colonne ct_blood est supérieure à 25 sont éliminés.Cette commande supprimerait tous les éléments de liste vides :","code":"\ncombined %>% \n  list_modify(\"Central Hospital\" = NULL) # Suppression d'un élément de liste par son nom\n# ne conserve que les éléments de liste de plus de 500 lignes\ncombined %>% \n  keep(.p = ~nrow(.x) > 500)  \n# Suppression des éléments de liste qui ne sont pas des cadres de données\ncombinws %>% \n  discard(.p = ~class(.x) != \"data.frame\")\n# ne conserve que les éléments de liste dont la moyenne de la colonne ct_blood est supérieure à 25\ncombined %>% \n  discard(.p = ~mean(.x$ct_blood) > 25)  \n# Supprime tous les éléments de liste vides\ncombined %>% \n  compact()"},{"path":"iteration.html","id":"pmap","chapter":"16 Itération, boucles et listes","heading":"pmap()","text":"CETTE SECTION EST EN CONSTRUCTION","code":""},{"path":"iteration.html","id":"fonctions-dapplication","chapter":"16 Itération, boucles et listes","heading":"16.4 Fonctions d’application","text":"La famille de fonctions “apply” est une alternative base R à purrr pour les opérations itératives. Vous pouvez en savoir plus à leur sujet ici.","code":""},{"path":"iteration.html","id":"resources-4","chapter":"16 Itération, boucles et listes","heading":"16.5 Resources","text":"loops Data CarpentryThe R Data Science page iterationVignette write/read Excel filesA purrr tutorial jennybcAnother purrr tutorial Rebecca BarterA purrr tutorial map, pmap, imappurrr cheatsheetpurrr tips trickskeep discard","code":""},{"path":"descriptive_tables.html","id":"descriptive_tables","chapter":"17 Tableaux descriptifs","heading":"17 Tableaux descriptifs","text":"Cette page montre l’utilisation de janitor, dplyr, gtsummary, rstatix et extension/package R base pour résumer des données et créer des tableaux avec des statistiques descriptives.Cette page explique comment créer les tableaux de base, tandis que la page Tableaux pour la présentation explique comment les mettre en forme et les imprimer.Chacun de ces packages présente des avantages et des inconvénients dans les domaines de la simplicité du code, de l’accessibilité des sorties, de la qualité des sorties imprimées. Utilisez cette page pour décider quelle approche convient à votre scénario.Plusieurs choix s’offrent à vous lorsque vous produisez des tableaux de synthèse et des tableaux croisés. Parmi les facteurs à prendre en compte, la simplicité du code, les possibilités de personnalisation, la sortie que vous souhaitez obtenir ( affichée sur la console R, en tant que tableau de données, ou en tant que “bonne” image .png/.jpeg/.html), et la facilité de traitement ultérieur. Tenez compte des points ci-dessous pour choisir l’outil adapté à votre situation.Utilisez la fonction tabyl() de janitor pour produire et ” personnaliser ” des tableaux et des tableaux croisésUtilisez la fonction tabyl() de janitor pour produire et ” personnaliser ” des tableaux et des tableaux croisésUtilisez la fonction get_summary_stats() de rstatix pour générer facilement des tableaux de données de synthèse de statistiques numériques pour plusieurs colonnes et/ou groupesUtilisez la fonction get_summary_stats() de rstatix pour générer facilement des tableaux de données de synthèse de statistiques numériques pour plusieurs colonnes et/ou groupesUtilisez les fonctions summarise() et count() de dplyr pour des statistiques plus complexes, des sorties de tableaux de données ordonnées ou la préparation de données pour ggplot()Utilisez les fonctions summarise() et count() de dplyr pour des statistiques plus complexes, des sorties de tableaux de données ordonnées ou la préparation de données pour ggplot()Utilisez la fonction tbl_summary() de gtsummary pour produire des tableaux détaillés prêts à être publiésUtilisez la fonction tbl_summary() de gtsummary pour produire des tableaux détaillés prêts à être publiésUtilisez la fonction table() de extension/package R base si vous n’avez pas accès aux packages ci-dessusUtilisez la fonction table() de extension/package R base si vous n’avez pas accès aux packages ci-dessus","code":""},{"path":"descriptive_tables.html","id":"préparation-2","chapter":"17 Tableaux descriptifs","heading":"17.1 Préparation","text":"","code":""},{"path":"descriptive_tables.html","id":"chargement-des-packages","chapter":"17 Tableaux descriptifs","heading":"Chargement des packages","text":"Ce bloc de code montre le chargement des packages nécessaires pour les analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le package si nécessaire et le charge pour utilisation. Vous pouvez également charger les packages installés avec library() de extension/package R base. Voir la page sur Bases de R pour plus d’informations sur les packages R.","code":"\npacman::p_load(\n  rio,          # importation de fichier\n  here,         # répertoire de fichiers\n  skimr,        # obtenir un aperçu des données\n  tidyverse,    # gestion de données + ggplot2 graphiques \n  gtsummary,    # sommaire des statistiques et tests\n  rstatix,      # sommaire des statistiques et tests statistiques\n  janitor,      # ajouter des totaux et des pourcentages à des tableaux\n  scales,       # convertir facilement les proportions en pourcentages  \n  flextable     # convertir les tableaux en belles images\n  )"},{"path":"descriptive_tables.html","id":"importer-les-données-1","chapter":"17 Tableaux descriptifs","heading":"Importer les données","text":"Nous importons le jeu de données des cas d’une épidémie d’Ebola simulée. Si vous voulez suivre,cliquez pour télécharger la linelist ” nettoyé “.(.rds file). Importez vos données avec la fonction import() du package rio (elle accepte de nombreux types de fichiers comme .xlsx, .rds, .csv - voir la page Importation et exportation pour plus de détails.first 50 rows linelist displayed .","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"descriptive_tables.html","id":"explorer-les-données","chapter":"17 Tableaux descriptifs","heading":"17.2 Explorer les données","text":"","code":""},{"path":"descriptive_tables.html","id":"skimr-package","chapter":"17 Tableaux descriptifs","heading":"skimr package","text":"En utilisant le package skimr, vous pouvez obtenir un aperçu détaillé et esthétique de chacune des variables de votre ensemble de données. Pour en savoir plus sur skimr, consultez sa page github.Ci-dessous, la fonction skim() est appliquée à l’ensemble du tableau de données linelist. Un aperçu du tableau de données et un résumé de chaque colonne (par classe) est produit.\nTable 17.1: Data summary\nVariable type: characterVariable type: DateVariable type: factorVariable type: numericVous pouvez également utiliser la fonction summary()de extension/package R base, pour obtenir des informations sur un jeu de données entier, mais cette sortie peut être plus difficile à lire qu’en utilisant skimr. C’est pourquoi la sortie n’est pas montrée ci-dessous, afin de conserver de l’espace sur la page.","code":"\n## obtenir des informations sur chaque variable d'un jeu de données\nskim(linelist)\n## obtenir des informations sur chaque colonne d'un jeu de données\nsummary(linelist)"},{"path":"descriptive_tables.html","id":"statistiques-sommaires","chapter":"17 Tableaux descriptifs","heading":"Statistiques sommaires","text":"Vous pouvez utiliser les fonctions extension/package R base pour renvoyer des synthèses statistiques sur une colonne numérique. Vous pouvez retourner la plupart des synthèses statistiques utiles pour une colonne numérique en utilisant summary(), comme ci-dessous. Notez que le nom du tableau de données doit également être spécifié comme indiqué ci-dessous.Vous pouvez accéder à une partie spécifique et l’enregistrer avec les crochets d’indexation \\[ \\] :Vous pouvez renvoyer des statistiques individuelles avec des fonctions extension/package R base comme max(), min(), median(), mean(), quantile(), sd(), et range(). Consultez la page Bases de R pour obtenir une liste complète.CAUTION: Si vos données contiennent des valeurs manquantes, R veut que vous le sachiez et retournera donc NA, sauf si vous spécifiez aux fonctions mathématiques ci-dessus que vous voulez que R ignore les valeurs manquantes, via l’argument na.rm = TRUE.Vous pouvez utiliser la fonction get_summary_stats() de rstatix pour retourner des synthèses statistiques dans un format de tableau de données. Cela peut être utile pour effectuer des opérations ultérieures ou des tracés sur les chiffres. Consultez la page Tests statistiques simples pour plus de détails sur le package rstatix et ses fonctions.","code":"\nsummary(linelist$age_years)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n##    0.00    6.00   13.00   16.02   23.00   84.00      86\nsummary(linelist$age_years)[[2]]            # retourne uniquement le 2ème élément## [1] 6\n# équivalent, alternative au précédent par nom d'élément\n# summary(linelist$age_years)[[\"1st Qu.\"]]  \nlinelist %>% \n  get_summary_stats(\n    age, wt_kg, ht_cm, ct_blood, temp,  # colonnes à calculer pour\n    type = \"common\")                    # sommaire des statistiques à retourner## # A tibble: 5 × 10\n##   variable     n   min   max median   iqr  mean     sd    se    ci\n##   <fct>    <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl>\n## 1 age       5802   0    84     13      17  16.1 12.6   0.166 0.325\n## 2 wt_kg     5888 -11   111     54      25  52.6 18.6   0.242 0.475\n## 3 ht_cm     5888   4   295    129      68 125.  49.5   0.645 1.26 \n## 4 ct_blood  5888  16    26     22       2  21.2  1.69  0.022 0.043\n## 5 temp      5739  35.2  40.8   38.8     1  38.6  0.977 0.013 0.025"},{"path":"descriptive_tables.html","id":"tbl_janitor","chapter":"17 Tableaux descriptifs","heading":"17.3 janitor package","text":"Les packages janitor offrent la fonction tabyl() pour produire des tableaux et des tableaux croisés, qui peuvent être ” améliorés ” ou modifiés avec des fonctions d’aide pour afficher des pourcentages, des proportions, des comptes, etc.Ci-dessous, nous envoyons le tableau de données linelist aux fonctions janitor et nous affichons le résultat. Si vous le souhaitez, vous pouvez également enregistrer les tableaux résultants avec l’opérateur d’affectation <-.","code":""},{"path":"descriptive_tables.html","id":"simple-tabyl","chapter":"17 Tableaux descriptifs","heading":"Simple tabyl","text":"L’utilisation par défaut de tabyl() sur une colonne spécifique produit les valeurs uniques, les nombres, et les “pourcentages” par colonne ( proportion en fait). Les proportions peuvent avoir plusieurs chiffres. Vous pouvez ajuster le nombre de décimales avec adorn_rounding() comme décrit ci-dessous.Comme vous pouvez le voir ci-dessus, s’il y des valeurs manquantes, elles s’affichent dans une ligne étiquetée <NA>. Vous pouvez les supprimer avec show_na = FALSE. S’il n’y pas de valeurs manquantes, cette ligne n’apparaîtra pas. S’il y des valeurs manquantes, toutes les proportions sont données à la fois brutes (dénominateur incluant les comptes NA) et “valide” (dénominateur excluant les comptes NA).Si la colonne est un facteur de classe et que seuls certains niveaux sont présents dans vos données, tous les niveaux apparaîtront quand même dans le tableau. Vous pouvez supprimer cette fonctionnalité en spécifiant show_missing_levels = FALSE. Pour en savoir plus, consultez la page Facteurs.","code":"\nlinelist %>% tabyl(age_cat)##  age_cat    n     percent valid_percent\n##      0-4 1095 0.185971467   0.188728025\n##      5-9 1095 0.185971467   0.188728025\n##    10-14  941 0.159816576   0.162185453\n##    15-19  743 0.126188859   0.128059290\n##    20-29 1073 0.182235054   0.184936229\n##    30-49  754 0.128057065   0.129955188\n##    50-69   95 0.016134511   0.016373664\n##      70+    6 0.001019022   0.001034126\n##     <NA>   86 0.014605978            NA"},{"path":"descriptive_tables.html","id":"tableau-croisé","chapter":"17 Tableaux descriptifs","heading":"Tableau croisé","text":"Les chiffres des tableaux croisés sont obtenus en ajoutant une ou plusieurs colonnes supplémentaires dans tabyl(). Notez que maintenant, seuls les chiffres sont retournés - les proportions et les pourcentages peuvent être ajoutés avec les étapes supplémentaires montrées ci-dessous.","code":"\nlinelist %>% tabyl(age_cat, gender)##  age_cat   f   m NA_\n##      0-4 640 416  39\n##      5-9 641 412  42\n##    10-14 518 383  40\n##    15-19 359 364  20\n##    20-29 468 575  30\n##    30-49 179 557  18\n##    50-69   2  91   2\n##      70+   0   5   1\n##     <NA>   0   0  86"},{"path":"descriptive_tables.html","id":"tbl_adorn","chapter":"17 Tableaux descriptifs","heading":"“Habillage” du tabyl","text":"Utilisez les fonctions “adorn” de janitor pour ajouter des totaux ou convertir en proportions, en pourcentages, ou ajuster l’affichage. Souvent, vous ferez passer le tabyle par plusieurs de ces fonctions.Faites attention à l’ordre dans lequel vous appliquez les fonctions ci-dessus. Voici quelques exemples.Un simple tableau à sens unique avec des pourcentages au lieu des proportions par défaut.Un tableau croisé avec une ligne totale et des pourcentages de ligne.Un tableau croisé ajusté de façon à ce que les nombres et les pourcentages soient affichés.","code":"\nlinelist %>%               # cas linelist\n  tabyl(age_cat) %>%       # calculer les effectifs et les proportions par catégorie d'âge\n  adorn_pct_formatting()   # convertir les proportions en pourcentages##  age_cat    n percent valid_percent\n##      0-4 1095   18.6%         18.9%\n##      5-9 1095   18.6%         18.9%\n##    10-14  941   16.0%         16.2%\n##    15-19  743   12.6%         12.8%\n##    20-29 1073   18.2%         18.5%\n##    30-49  754   12.8%         13.0%\n##    50-69   95    1.6%          1.6%\n##      70+    6    0.1%          0.1%\n##     <NA>   86    1.5%             -\nlinelist %>%                                  \n  tabyl(age_cat, gender) %>%                  # comptage par âge et par sexe\n  adorn_totals(where = \"row\") %>%             # ajouter une ligne totale\n  adorn_percentages(denominator = \"row\") %>%  # convertir les comptages en proportions\n  adorn_pct_formatting(digits = 1)            # convertir les proportions en pourcentages##  age_cat     f     m    NA_\n##      0-4 58.4% 38.0%   3.6%\n##      5-9 58.5% 37.6%   3.8%\n##    10-14 55.0% 40.7%   4.3%\n##    15-19 48.3% 49.0%   2.7%\n##    20-29 43.6% 53.6%   2.8%\n##    30-49 23.7% 73.9%   2.4%\n##    50-69  2.1% 95.8%   2.1%\n##      70+  0.0% 83.3%  16.7%\n##     <NA>  0.0%  0.0% 100.0%\n##    Total 47.7% 47.6%   4.7%\nlinelist %>%                                  # cas linelist\n  tabyl(age_cat, gender) %>%                  # croiser les comptages\n  adorn_totals(where = \"row\") %>%             # ajouter une ligne de total\n  adorn_percentages(denominator = \"col\") %>%  # convertir en proportions\n  adorn_pct_formatting() %>%                  # convertir en pourcentages\n  adorn_ns(position = \"front\") %>%            # afficher comme: \"count (percent)\"\n  adorn_title(                                # ajuster les titres\n    row_name = \"Age Category\",\n    col_name = \"Gender\")##                       Gender                            \n##  Age Category              f              m          NA_\n##           0-4   640  (22.8%)   416  (14.8%)  39  (14.0%)\n##           5-9   641  (22.8%)   412  (14.7%)  42  (15.1%)\n##         10-14   518  (18.5%)   383  (13.7%)  40  (14.4%)\n##         15-19   359  (12.8%)   364  (13.0%)  20   (7.2%)\n##         20-29   468  (16.7%)   575  (20.5%)  30  (10.8%)\n##         30-49   179   (6.4%)   557  (19.9%)  18   (6.5%)\n##         50-69     2   (0.1%)    91   (3.2%)   2   (0.7%)\n##           70+     0   (0.0%)     5   (0.2%)   1   (0.4%)\n##          <NA>     0   (0.0%)     0   (0.0%)  86  (30.9%)\n##         Total 2,807 (100.0%) 2,803 (100.0%) 278 (100.0%)"},{"path":"descriptive_tables.html","id":"impression-du-tableau","chapter":"17 Tableaux descriptifs","heading":"Impression du tableau","text":"Par défaut, le tableau s’affichera brute sur votre console R.Vous pouvez également passer le tableau à flextable ou à un package similaire pour qu’il s’imprime comme une “jolie” image dans la visionneuse RStudio, qui peut être exportée en .png, .jpeg, .html, etc. Ce sujet est abordé à la page Tableaux pour la présentation. Notez que si vous imprimez de cette manière en utilisant adorn_titles(), vous devez spécifier placement = \"combined\".Age Category/GenderfmNA_Total0-4640 (22.8%)416 (14.8%)39 (14.0%)1,095 (18.6%)5-9641 (22.8%)412 (14.7%)42 (15.1%)1,095 (18.6%)10-14518 (18.5%)383 (13.7%)40 (14.4%)941 (16.0%)15-19359 (12.8%)364 (13.0%)20  (7.2%)743 (12.6%)20-29468 (16.7%)575 (20.5%)30 (10.8%)1,073 (18.2%)30-49179  (6.4%)557 (19.9%)18  (6.5%)754 (12.8%)50-692  (0.1%)91  (3.2%)2  (0.7%)95  (1.6%)70+0  (0.0%)5  (0.2%)1  (0.4%)6  (0.1%)0  (0.0%)0  (0.0%)86 (30.9%)86  (1.5%)","code":"\nlinelist %>%\n  tabyl(age_cat, gender) %>% \n  adorn_totals(where = \"col\") %>% \n  adorn_percentages(denominator = \"col\") %>% \n  adorn_pct_formatting() %>% \n  adorn_ns(position = \"front\") %>% \n  adorn_title(\n    row_name = \"Age Category\",\n    col_name = \"Gender\",\n    placement = \"combined\") %>% # c'est nécessaire pour afficher comme image\n  flextable::flextable() %>%    # convertir en une belle image\n  flextable::autofit()          # format à une ligne par rangée "},{"path":"descriptive_tables.html","id":"utiliser-sur-dautres-tables","chapter":"17 Tableaux descriptifs","heading":"Utiliser sur d’autres tables","text":"Vous pouvez utiliser les fonctions adorn_*() de janitor sur d’autres tables, comme celles crées par summarise() et count() de dplyr, ou table() de extension/package R base. Il suffit de passer la table à la fonction janitor désirée. Par exemple :","code":"\nlinelist %>% \n  count(hospital) %>%   # dplyr fonction\n  adorn_totals()        # janitor fonction##                              hospital    n\n##                      Central Hospital  454\n##                     Military Hospital  896\n##                               Missing 1469\n##                                 Other  885\n##                         Port Hospital 1762\n##  St. Mark's Maternity Hospital (SMMH)  422\n##                                 Total 5888"},{"path":"descriptive_tables.html","id":"enregistrer-le-tableau","chapter":"17 Tableaux descriptifs","heading":"Enregistrer le tableau","text":"Si vous convertissez le tableau en une ” jolie ” image avec un package comme flextable, vous pouvez l’enregistrer avec les fonctions de ce package - comme save_as_html(), save_as_word(), save_as_ppt(), et save_as_image() de flextable (comme discuté plus en détail dans la page Tableaux de présentation). Ci-dessous, le tableau est enregistré sous forme de document Word, dans lequel il peut être modifié manuellement.","code":"\nlinelist %>%\n  tabyl(age_cat, gender) %>% \n  adorn_totals(where = \"col\") %>% \n  adorn_percentages(denominator = \"col\") %>% \n  adorn_pct_formatting() %>% \n  adorn_ns(position = \"front\") %>% \n  adorn_title(\n    row_name = \"Age Category\",\n    col_name = \"Gender\",\n    placement = \"combined\") %>% \n  flextable::flextable() %>%                     # convertir en image\n  flextable::autofit() %>%                       # assurer une seule ligne par rangée\n  flextable::save_as_docx(path = \"tabyl.docx\")   # enregistrer en tant que document Word dans le chemin de fichier"},{"path":"descriptive_tables.html","id":"janitor_age_out_stats","chapter":"17 Tableaux descriptifs","heading":"Statistiques","text":"Vous pouvez appliquer des tests statistiques sur les tableaux, comme chisq.test() ou fisher.test() du package stats, comme indiqué ci-dessous. Notez que les valeurs manquantes ne sont pas autorisées, elles sont donc exclues du tableau avec show_na = FALSEConsultez la page sur les Tests statistiques simples pour obtenir plus de code et de conseils sur les statistiques.","code":"\nage_by_outcome <- linelist %>% \n  tabyl(age_cat, outcome, show_na = FALSE) \n\nchisq.test(age_by_outcome)## \n##  Pearson's Chi-squared test\n## \n## data:  age_by_outcome\n## X-squared = 6.4931, df = 7, p-value = 0.4835"},{"path":"descriptive_tables.html","id":"autres-conseils","chapter":"17 Tableaux descriptifs","heading":"Autres conseils","text":"Incluez l’argument na.rm = TRUE pour exclure les valeurs manquantes de tous les calculs ci-dessus.Si vous appliquez des fonctions d’aide adorn_*() à des tables qui n’ont pas été crées par tabyl(), vous pouvez spécifier une ou plusieurs colonnes particulières auxquelles les appliquer comme adorn_percentage(,,,c(cas,décès)) (spécifiez-les au 4ème argument non nommé). La syntaxe n’est pas simple. Pensez à utiliser summarise() à la place.Vous pouvez obtenir plus de détails dans le janitor page et ce tabyl vignette.","code":""},{"path":"descriptive_tables.html","id":"dplyr-package","chapter":"17 Tableaux descriptifs","heading":"17.4 dplyr package","text":"dplyr fait partie des packages tidyverse et est un outil de gestion de données très courant. Créer des tableaux avec les fonctions dplyr summarise() et count() est une méthode très utile pour calculer des statistiques sommaires, résumer par groupe, ou passer des tableaux à ggplot().summarise() crée un nouveau tableau de données récapitulatif. Si les données sont non groupées, il renvoie un tableau de données à une ligne avec les statistiques récapitulatives spécifiées pour l’ensemble du tableau de données. Si les données sont groupées, le nouveau tableau de données aura une ligne par groupe (voir la page Regroupement de données).Entre les parenthèses de summarise(), vous indiquez le nom de chaque nouvelle colonne du résumé, suivi d’un signe égal et d’une fonction statistique à appliquer.TIP: La fonction summarise fonctionne avec les orthographes britannique et américaine (summarise() et summarize()).","code":""},{"path":"descriptive_tables.html","id":"obtenir-des-nombres","chapter":"17 Tableaux descriptifs","heading":"Obtenir des nombres","text":"La fonction la plus simple à appliquer dans summarise() est n(). Laissez les parenthèses vides pour compter le nombre de lignes.Cela devient plus intéressant si nous avons regroupé les données au préalable.La commande ci-dessus peut être réduite en utilisant la fonction count() à la place. La fonction count() effectue les opérations suivantes :Regroupe les données selon les colonnes qui lui sont fournies.Les résume avec n() (en créant la colonne n).Dé-grouper les donnéesVous pouvez changer le nom de la colonne des comptages de la valeur par défaut n à quelque chose d’autre en le spécifiant à name =.Les résultats de la mise en tableau de deux colonnes de regroupement ou plus sont toujours renvoyés au format “long”, avec les effectifs dans la colonne n. Consultez la page Pivoter les données pour en savoir plus sur les formats de données “long” et “large”.","code":"\nlinelist %>%                 # commencer par une liste de lignes\n  summarise(n_rows = n())    # retourne un nouveau tableau de données avec la colonne n_rows##   n_rows\n## 1   5888\nlinelist %>% \n  group_by(age_cat) %>%     # regrouper les données par valeurs uniques dans une colonne age_cat\n  summarise(n_rows = n())   # retourne le nombre de lignes *per group*## # A tibble: 9 × 2\n##   age_cat n_rows\n##   <fct>    <int>\n## 1 0-4       1095\n## 2 5-9       1095\n## 3 10-14      941\n## 4 15-19      743\n## 5 20-29     1073\n## 6 30-49      754\n## 7 50-69       95\n## 8 70+          6\n## 9 <NA>        86\nlinelist %>% \n  count(age_cat)##   age_cat    n\n## 1     0-4 1095\n## 2     5-9 1095\n## 3   10-14  941\n## 4   15-19  743\n## 5   20-29 1073\n## 6   30-49  754\n## 7   50-69   95\n## 8     70+    6\n## 9    <NA>   86\nlinelist %>% \n  count(age_cat, outcome)##    age_cat outcome   n\n## 1      0-4   Death 471\n## 2      0-4 Recover 364\n## 3      0-4    <NA> 260\n## 4      5-9   Death 476\n## 5      5-9 Recover 391\n## 6      5-9    <NA> 228\n## 7    10-14   Death 438\n## 8    10-14 Recover 303\n## 9    10-14    <NA> 200\n## 10   15-19   Death 323\n## 11   15-19 Recover 251\n## 12   15-19    <NA> 169\n## 13   20-29   Death 477\n## 14   20-29 Recover 367\n## 15   20-29    <NA> 229\n## 16   30-49   Death 329\n## 17   30-49 Recover 238\n## 18   30-49    <NA> 187\n## 19   50-69   Death  33\n## 20   50-69 Recover  38\n## 21   50-69    <NA>  24\n## 22     70+   Death   3\n## 23     70+ Recover   3\n## 24    <NA>   Death  32\n## 25    <NA> Recover  28\n## 26    <NA>    <NA>  26"},{"path":"descriptive_tables.html","id":"voir-tous-les-niveaux","chapter":"17 Tableaux descriptifs","heading":"Voir tous les niveaux","text":"Si vous mettez en tableau une colonne de classe facteur, vous pouvez vous assurer que tous les niveaux sont affichés (et pas seulement les niveaux avec des valeurs dans les données) en ajoutant .drop = FALSE dans la commande summarise() ou count().Cette technique est utile pour standardiser vos tableaux/graphiques. Par exemple, si vous créez des chiffres pour plusieurs sous-groupes, ou si vous créez plusieurs fois le même chiffre pour des rapports de routine. Dans chacune de ces circonstances, la présence de valeurs dans les données peut fluctuer, mais vous pouvez définir des niveaux qui restent constants.Consultez la page sur les Facteurs pour plus d’informations.","code":""},{"path":"descriptive_tables.html","id":"tbl_dplyr_prop","chapter":"17 Tableaux descriptifs","heading":"Proportions","text":"Les proportions peuvent être ajoutées en passant le tableau à mutate() pour créer une nouvelle colonne. Définissez la nouvelle colonne comme la colonne des comptages (n par défaut) divisée par la sum() de la colonne des comptages (ceci retournera une proportion).Notez que dans ce cas, sum() dans la commande mutate() retournera la somme de la colonne entière n pour l’utiliser comme dénominateur de la proportion. Comme expliqué dans la page Regroupement des données, si sum() est utilisé dans des données groupées (par exemple, si la commande mutate() suit immédiatement une commande group_by()), il retournera les sommes par groupe. Comme indiqué juste au-dessus, count() termine ses actions en dégroupant. Ainsi, dans ce scénario, nous obtenons les proportions de la colonne entière.Pour afficher facilement les pourcentages, vous pouvez inclure la proportion dans la fonction percent() du package scales (notez cette conversion en caractère de classe).Vous trouverez ci-dessous une méthode permettant de calculer les proportions dans les groupes. Elle repose sur l’application et la suppression sélectives de différents niveaux de regroupement des données. Tout d’abord, les données sont regroupées en fonction du résultat via group_by(). Ensuite, la fonction count() est appliquée. Cette fonction regroupe à nouveau les données par age_cat et retourne les résultats pour chaque combinaison outcome-age-cat. Il est important de noter qu’en terminant son processus, count() également dégroupé le regroupement par age_cat, de sorte que le seul regroupement de données restant est le regroupement original par outcome. Ainsi, l’étape finale du calcul des proportions (dénominateur sum(n)) est toujours groupée par outcome.","code":"\nage_summary <- linelist %>% \n  count(age_cat) %>%                     # grouper et compter par sexe (produit la colonne \"n\")\n  mutate(                                # créer le pourcentage de la colonne - noter le dénominateur\n    percent = scales::percent(n / sum(n))) \n\n# print\nage_summary##   age_cat    n percent\n## 1     0-4 1095  18.60%\n## 2     5-9 1095  18.60%\n## 3   10-14  941  15.98%\n## 4   15-19  743  12.62%\n## 5   20-29 1073  18.22%\n## 6   30-49  754  12.81%\n## 7   50-69   95   1.61%\n## 8     70+    6   0.10%\n## 9    <NA>   86   1.46%\nage_by_outcome <- linelist %>%                  # commencer par la linelist\n  group_by(outcome) %>%                         # groupe par résultats\n  count(age_cat) %>%                            # regrouper et compter par age_cat, puis supprimer le regroupement age_cat\n  mutate(percent = scales::percent(n / sum(n))) # calculer le pourcentage - noter que le dénominateur est par groupe de résultats"},{"path":"descriptive_tables.html","id":"plotting","chapter":"17 Tableaux descriptifs","heading":"Plotting","text":"Afficher un tableau “long” comme celui ci-dessus avec ggplot() est relativement simple. Les données sont naturellement au format “long”, qui est naturellement accepté par ggplot(). Voir d’autres exemples dans les pages ggplot basics et Astuces de ggplot.","code":"\nlinelist %>%                      # commencer par la linelist\n  count(age_cat, outcome) %>%     # regrouper et présenter les comptages par deux colonnes\n  ggplot()+                       # passer le nouveau tableau de données à ggplot\n    geom_col(                     # créer un bar plot\n      mapping = aes(   \n        x = outcome,              # mappez le résultat sur l'axe des x\n        fill = age_cat,           # mappe age_cat au remplissage\n        y = n))                  # associer la colonne de comptage `n` à la hauteur"},{"path":"descriptive_tables.html","id":"synthèse-des-statistiques","chapter":"17 Tableaux descriptifs","heading":"Synthèse des statistiques","text":"Un avantage majeur de dplyr et de summarise() est la possibilité de retourner des résumés statistiques plus avancés comme median(), mean(), max(), min(), sd() (écart-type), et les percentiles. Vous pouvez également utiliser sum() pour retourner le nombre de lignes qui répondent à certains critères logiques. Comme ci-dessus, ces sorties peuvent être produites pour l’ensemble du cadre de données, ou par groupe.La syntaxe est la même - entre les parenthèses de summarise(), vous fournissez les noms de chaque nouvelle colonne de résumé, suivis d’un signe égal et d’une fonction statistique à appliquer. Dans la fonction statistique, donnez la ou les colonnes sur lesquelles vous voulez travailler et tous les arguments pertinents (par exemple na.rm = TRUE pour la plupart des fonctions mathématiques).Vous pouvez également utiliser sum() pour retourner le nombre de lignes qui répondent à un critère logique. L’expression qu’il contient est comptée si elle vaut TRUE. Par exemple :sum(age_years < 18, na.rm=T)sum(gender == \"male\", na.rm=T)sum(response %% c(\"Likely\", \"Likely\"))Ci-dessous, les données linelist sont résumées pour décrire le délai en jours entre l’apparition des symptômes et l’admission à l’hôpital (colonne days_onset_hosp), par hôpital.Quelques conseils :Utilisez sum() avec une instruction logique pour “compter” les lignes qui répondent à certains critères (==).Utilisez sum() avec une instruction logique pour “compter” les lignes qui répondent à certains critères (==).Notez l’utilisation de na.rm = TRUE dans les fonctions mathématiques comme sum(), sinon NA sera retourné s’il y des valeurs manquantes ``.Notez l’utilisation de na.rm = TRUE dans les fonctions mathématiques comme sum(), sinon NA sera retourné s’il y des valeurs manquantes ``.Utilisez la fonction percent() du package scales pour convertir facilement en pourcentages.\nDéfinissez accuracy = à 0,1 ou 0,01 pour garantir respectivement 1 ou 2 décimales.\nUtilisez la fonction percent() du package scales pour convertir facilement en pourcentages.Définissez accuracy = à 0,1 ou 0,01 pour garantir respectivement 1 ou 2 décimales.Utilisez la fonction round() de extension/package R base pour spécifier les décimales.Utilisez la fonction round() de extension/package R base pour spécifier les décimales.Pour calculer ces statistiques sur l’ensemble des données, utilisez summarise() sans group_by().Pour calculer ces statistiques sur l’ensemble des données, utilisez summarise() sans group_by().Vous pouvez créer des colonnes pour les besoins de calculs ultérieurs (par exemple, les dénominateurs) que vous supprimez éventuellement de votre cadre de données avec select().Vous pouvez créer des colonnes pour les besoins de calculs ultérieurs (par exemple, les dénominateurs) que vous supprimez éventuellement de votre cadre de données avec select().","code":"\nsummary_table <- linelist %>%                                        # commencez avec la linelist, enregistrez comme un nouvel objet\n  group_by(hospital) %>%                                             # regrouper tous les calculs par hopital\n  summarise(                                                         # seules les colonnes de résumé ci-dessous seront retournées\n    cases       = n(),                                                # nombre de lignes par groupe\n    delay_max   = max(days_onset_hosp, na.rm = T),                    # délai max\n    delay_mean  = round(mean(days_onset_hosp, na.rm=T), digits = 1),  # délai moyen, arrondi\n    delay_sd    = round(sd(days_onset_hosp, na.rm = T), digits = 1),  # Déviation standard des délais, arrondie\n    delay_3     = sum(days_onset_hosp >= 3, na.rm = T),               # nombre de lignes avec un délai de 3 jours ou plus\n    pct_delay_3 = scales::percent(delay_3 / cases)                    # convertir en pourcentage une colonne de délai précédemment définie\n  )\n\nsummary_table  # Afficher## # A tibble: 6 × 7\n##   hospital                       cases delay_max delay_mean delay_sd delay_3 pct_delay_3\n##   <chr>                          <int>     <dbl>      <dbl>    <dbl>   <int> <chr>      \n## 1 Central Hospital                 454        12        1.9      1.9     108 24%        \n## 2 Military Hospital                896        15        2.1      2.4     253 28%        \n## 3 Missing                         1469        22        2.1      2.3     399 27%        \n## 4 Other                            885        18        2        2.2     234 26%        \n## 5 Port Hospital                   1762        16        2.1      2.2     470 27%        \n## 6 St. Mark's Maternity Hospital…   422        18        2.1      2.3     116 27%"},{"path":"descriptive_tables.html","id":"statistiques-conditionnelles","chapter":"17 Tableaux descriptifs","heading":"Statistiques conditionnelles","text":"Vous pouvez souhaiter renvoyer des statistiques conditionnelles - par exemple, le maximum de lignes qui répondent à certains critères. Pour ce faire, il suffit de subdiviser la colonne avec des parenthèses “\\[ \\]”. L’exemple ci-dessous renvoie la température maximale pour les patients classés comme ayant ou n’ayant pas de fièvre. Attention cependant - il peut être plus approprié d’ajouter une autre colonne à la commandegroup_by()etpivot_wider()\\ (comme démontré ci-dessous).","code":"\nlinelist %>% \n  group_by(hospital) %>% \n  summarise(\n    max_temp_fvr = max(temp[fever == \"yes\"], na.rm = T),\n    max_temp_no = max(temp[fever == \"no\"], na.rm = T)\n  )## # A tibble: 6 × 3\n##   hospital                             max_temp_fvr max_temp_no\n##   <chr>                                       <dbl>       <dbl>\n## 1 Central Hospital                             40.4        38  \n## 2 Military Hospital                            40.5        38  \n## 3 Missing                                      40.6        38  \n## 4 Other                                        40.8        37.9\n## 5 Port Hospital                                40.6        38  \n## 6 St. Mark's Maternity Hospital (SMMH)         40.6        37.9"},{"path":"descriptive_tables.html","id":"coller-ensemble","chapter":"17 Tableaux descriptifs","heading":"Coller ensemble","text":"La fonction str_glue() de stringr est utile pour combiner les valeurs de plusieurs colonnes en une nouvelle colonne. Dans ce contexte, elle est généralement utilisée après la commande summarise().Dans la page Caractères et chaînes de caractères, diverses options pour combiner des colonnes sont discutées, notamment unite(), et paste0(). Dans ce cas d’utilisation, nous préconisons str_glue() parce qu’il est plus flexible que unite() et une syntaxe plus simple que paste0().Ci-dessous, le tableau de données summary_table (créé plus haut) est modifié de telle sorte que les colonnes delay_mean et delay_sd sont combinées, la mise en forme entre parenthèses est ajoutée à la nouvelle colonne, et leurs anciennes colonnes respectives sont supprimées.Ensuite, pour rendre le tableau plus présentable, une ligne de total est ajoutée avec adorn_totals() de janitor (qui ignore les colonnes non-numériques). Enfin, nous utilisons select() de dplyr pour réordonner et renommer les colonnes avec des noms plus appropriés.Maintenant, vous pouvez passer à flextable et imprimer le tableau dans Word, .png, .jpeg, .html, Powerpoint, RMarkdown, etc. ! (voir la page Tableaux pour la présentation).","code":"\nsummary_table %>% \n  mutate(delay = str_glue(\"{delay_mean} ({delay_sd})\")) %>%  # fusionner et formater d'autres valeurs\n  select(-c(delay_mean, delay_sd)) %>%                       # supprimer deux anciennes colonnes  \n  adorn_totals(where = \"row\") %>%                            # ajouter la ligne totale\n  select(                                                    # ordonner et renommer les colonnes\n    \"Hospital Name\"   = hospital,\n    \"Cases\"           = cases,\n    \"Max delay\"       = delay_max,\n    \"Mean (sd)\"       = delay,\n    \"Delay 3+ days\"   = delay_3,\n    \"% delay 3+ days\" = pct_delay_3\n    )##                         Hospital Name Cases Max delay Mean (sd) Delay 3+ days\n##                      Central Hospital   454        12 1.9 (1.9)           108\n##                     Military Hospital   896        15 2.1 (2.4)           253\n##                               Missing  1469        22 2.1 (2.3)           399\n##                                 Other   885        18   2 (2.2)           234\n##                         Port Hospital  1762        16 2.1 (2.2)           470\n##  St. Mark's Maternity Hospital (SMMH)   422        18 2.1 (2.3)           116\n##                                 Total  5888       101         -          1580\n##  % delay 3+ days\n##              24%\n##              28%\n##              27%\n##              26%\n##              27%\n##              27%\n##                -"},{"path":"descriptive_tables.html","id":"percentiles","chapter":"17 Tableaux descriptifs","heading":"Percentiles","text":"Les percentiles et les quantiles dans dplyr méritent une mention spéciale. Pour retourner les quantiles, utilisez quantile() avec les valeurs par défaut ou spécifiez la ou les valeurs que vous souhaitez avec probs =.Si vous voulez retourner les quantiles par groupe, vous pouvez rencontrer des sorties longues et moins utiles si vous ajoutez simplement une autre colonne à group_by(). Donc, essayez plutôt cette approche - créez une colonne pour chaque niveau de quantile désiré.Bien que dplyr summarise() offre certainement un contrôle plus précis, vous trouverez peut-être que toutes les synthèses statistiques dont vous avez besoin peuvent être produites avec get_summary_stat() du package rstatix. Si l’opère sur des données groupées, retournera 0%, 25%, 50%, 75%, et 100%. Si elle est appliquée à des données non groupées, vous pouvez spécifier les percentiles avec probs = c(.05, .5, .75, .98).","code":"\n# obtenir les valeurs percentile par défaut de l'âge (0%, 25%, 50%, 75%, 100%)\nlinelist %>% \n  summarise(age_percentiles = quantile(age_years, na.rm = TRUE))## Warning: Returning more (or less) than 1 row per `summarise()` group was deprecated in dplyr\n## 1.1.0.\n## ℹ Please use `reframe()` instead.\n## ℹ When switching from `summarise()` to `reframe()`, remember that `reframe()` always\n##   returns an ungrouped data frame and adjust accordingly.\n## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated.##   age_percentiles\n## 1               0\n## 2               6\n## 3              13\n## 4              23\n## 5              84\n# obtenir des valeurs percentiles d'âge spécifiées manuellement (5%, 50%, 75%, 98%)\nlinelist %>% \n  summarise(\n    age_percentiles = quantile(\n      age_years,\n      probs = c(.05, 0.5, 0.75, 0.98), \n      na.rm=TRUE)\n    )## Warning: Returning more (or less) than 1 row per `summarise()` group was deprecated in dplyr\n## 1.1.0.\n## ℹ Please use `reframe()` instead.\n## ℹ When switching from `summarise()` to `reframe()`, remember that `reframe()` always\n##   returns an ungrouped data frame and adjust accordingly.\n## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated.##   age_percentiles\n## 1               1\n## 2              13\n## 3              23\n## 4              48\n# obtenir des valeurs percentiles d'âge spécifiées manuellement (5%, 50%, 75%, 98%)\nlinelist %>% \n  group_by(hospital) %>% \n  summarise(\n    p05 = quantile(age_years, probs = 0.05, na.rm=T),\n    p50 = quantile(age_years, probs = 0.5, na.rm=T),\n    p75 = quantile(age_years, probs = 0.75, na.rm=T),\n    p98 = quantile(age_years, probs = 0.98, na.rm=T)\n    )## # A tibble: 6 × 5\n##   hospital                               p05   p50   p75   p98\n##   <chr>                                <dbl> <dbl> <dbl> <dbl>\n## 1 Central Hospital                         1    12    21  48  \n## 2 Military Hospital                        1    13    24  45  \n## 3 Missing                                  1    13    23  48.2\n## 4 Other                                    1    13    23  50  \n## 5 Port Hospital                            1    14    24  49  \n## 6 St. Mark's Maternity Hospital (SMMH)     2    12    22  50.2\nlinelist %>% \n  group_by(hospital) %>% \n  rstatix::get_summary_stats(age, type = \"quantile\")## # A tibble: 6 × 8\n##   hospital                             variable     n  `0%` `25%` `50%` `75%` `100%`\n##   <chr>                                <fct>    <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl>\n## 1 Central Hospital                     age        445     0     6    12    21     58\n## 2 Military Hospital                    age        884     0     6    14    24     72\n## 3 Missing                              age       1441     0     6    13    23     76\n## 4 Other                                age        873     0     6    13    23     69\n## 5 Port Hospital                        age       1739     0     6    14    24     68\n## 6 St. Mark's Maternity Hospital (SMMH) age        420     0     7    12    22     84\nlinelist %>% \n  rstatix::get_summary_stats(age, type = \"quantile\")## # A tibble: 1 × 7\n##   variable     n  `0%` `25%` `50%` `75%` `100%`\n##   <fct>    <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl>\n## 1 age       5802     0     6    13    23     84"},{"path":"descriptive_tables.html","id":"synthèse-des-données-agrégées","chapter":"17 Tableaux descriptifs","heading":"Synthèse des données agrégées","text":"Si vous commencez avec des données agrégées, l’utilisation de n() renvoie le nombre de lignes, et non la somme des comptes agrégés. Pour obtenir la somme, utilisez sum() sur la colonne des comptages des données.Par exemple, disons que vous commencez avec le tableau de données de comptage ci-dessous, appelé linelist_agg - il montre en format “long” le nombre de cas par résultat et par sexe.Ci-dessous, nous créons cet exemple de tableau de données de comptage de linelist par résultat et par sexe (les valeurs manquantes sont supprimées pour plus de clarté).Pour additionner les valeurs (dans la colonne n) par groupe, vous pouvez utiliser summarise() mais définissez la nouvelle colonne égale à sum(n, na.rm=T). Pour ajouter un élément de condition à l’opération de somme, vous pouvez utiliser la syntaxe des sous-ensembles \\[ \\] sur la colonne des comptages.","code":"\nlinelist_agg <- linelist %>% \n  drop_na(gender, outcome) %>% \n  count(outcome, gender)\n\nlinelist_agg##   outcome gender    n\n## 1   Death      f 1227\n## 2   Death      m 1228\n## 3 Recover      f  953\n## 4 Recover      m  950\nlinelist_agg %>% \n  group_by(outcome) %>% \n  summarise(\n    total_cases  = sum(n, na.rm=T),\n    male_cases   = sum(n[gender == \"m\"], na.rm=T),\n    female_cases = sum(n[gender == \"f\"], na.rm=T))## # A tibble: 2 × 4\n##   outcome total_cases male_cases female_cases\n##   <chr>         <int>      <int>        <int>\n## 1 Death          2455       1228         1227\n## 2 Recover        1903        950          953"},{"path":"descriptive_tables.html","id":"across-multiples-colonnes","chapter":"17 Tableaux descriptifs","heading":"across() multiples colonnes","text":"Vous pouvez utiliser summarise() sur plusieurs colonnes en utilisant across(). Cela vous facilite la tâche lorsque vous voulez calculer les mêmes statistiques pour plusieurs colonnes. Placez across() dans summarise() et spécifiez ce qui suit :.cols = comme un vecteur de noms de colonnes c() ou des fonctions d’aide “tidyselect” (expliquées ci-dessous)`.fns = la fonction à exécuter (sans parenthèses) - vous pouvez en fournir plusieurs dans une list().Ci-dessous, la fonction mean() est appliquée à plusieurs colonnes numériques. Un vecteur de colonnes est nommé explicitement dans .cols = et une seule fonction mean est spécifiée (sans parenthèses) dans .fns =. Tout argument supplémentaire pour la fonction (par exemple na.rm=TRUE) est fourni après .fns =, séparé par une virgule.Il peut être difficile de respecter l’ordre des parenthèses et des virgules lorsqu’utilise across(). N’oubliez pas qu’à l’intérieur de across(), vous devez inclure les colonnes, les fonctions et tous les arguments supplémentaires nécessaires aux fonctions.Plusieurs fonctions peuvent être exécutées en même temps. Ci-dessous, les fonctions mean et sd sont fournies à .fns = dans une list(). Vous avez la possibilité de fournir des noms de caractères (par exemple “mean” et “sd”) qui sont ajoutés dans les nouveaux noms de colonnes.Voici les fonctions d’aide “tidyselect” que vous pouvez fournir à .cols = pour sélectionner des colonnes :everything() - toutes les autres colonnes non mentionnéeslast_col() - la dernière colonnewhere() - applique une fonction à toutes les colonnes et sélectionne celles qui sont VRAIESstarts_with() - correspond à un préfixe spécifié. Exemple : starts_with(\"date\")ends_with() - correspond à un suffixe spécifié. Exemple : `ends_with(“_end”)``contains() - colonnes contenant une chaîne de caractères. Exemple : contains(\"time\")matches() - pour appliquer une expression régulière (regex). Exemple : contains(\"[pt]al\")num_range() -any_of() - correspond si la colonne est nommée. Utile si le nom peut ne pas exister. Exemple : any_of(date_onset, date_death, cardiac_arrest)Par exemple, pour retourner la moyenne de chaque colonne numérique, utilisez () et fournissez la fonction .numeric() (sans parenthèses). Tout cela reste dans la commande across().","code":"\nlinelist %>% \n  group_by(outcome) %>% \n  summarise(across(.cols = c(age_years, temp, wt_kg, ht_cm),  # colonnes\n                   .fns = mean,                               # fonction\n                   na.rm=T))                                  # arguments supplémentaires## # A tibble: 3 × 5\n##   outcome age_years  temp wt_kg ht_cm\n##   <chr>       <dbl> <dbl> <dbl> <dbl>\n## 1 Death        15.9  38.6  52.6  125.\n## 2 Recover      16.1  38.6  52.5  125.\n## 3 <NA>         16.2  38.6  53.0  125.\nlinelist %>% \n  group_by(outcome) %>% \n  summarise(across(.cols = c(age_years, temp, wt_kg, ht_cm), # colonnes\n                   .fns = list(\"mean\" = mean, \"sd\" = sd),    # fonctions multiples \n                   na.rm=T))                                 # arguments supplémentaires## # A tibble: 3 × 9\n##   outcome age_years_mean age_years_sd temp_mean temp_sd wt_kg_mean wt_kg_sd ht_cm_mean\n##   <chr>            <dbl>        <dbl>     <dbl>   <dbl>      <dbl>    <dbl>      <dbl>\n## 1 Death             15.9         12.3      38.6   0.962       52.6     18.4       125.\n## 2 Recover           16.1         13.0      38.6   0.997       52.5     18.6       125.\n## 3 <NA>              16.2         12.8      38.6   0.976       53.0     18.9       125.\n## # ℹ 1 more variable: ht_cm_sd <dbl>\nlinelist %>% \n  group_by(outcome) %>% \n  summarise(across(\n    .cols = where(is.numeric),  # toutes les colonnes numériques dans le tableau de données\n    .fns = mean,\n    na.rm=T))## # A tibble: 3 × 12\n##   outcome generation   age age_years   lon   lat wt_kg ht_cm ct_blood  temp   bmi\n##   <chr>        <dbl> <dbl>     <dbl> <dbl> <dbl> <dbl> <dbl>    <dbl> <dbl> <dbl>\n## 1 Death         16.7  15.9      15.9 -13.2  8.47  52.6  125.     21.3  38.6  45.6\n## 2 Recover       16.4  16.2      16.1 -13.2  8.47  52.5  125.     21.1  38.6  47.7\n## 3 <NA>          16.5  16.3      16.2 -13.2  8.47  53.0  125.     21.2  38.6  48.3\n## # ℹ 1 more variable: days_onset_hosp <dbl>"},{"path":"descriptive_tables.html","id":"tbls_pivot_wider","chapter":"17 Tableaux descriptifs","heading":"Pivot élargi","text":"Si vous préférez votre tableau en format “large”, vous pouvez le transformer en utilisant la fonction tidyr pivot_wider(). Vous devrez probablement renommer les colonnes avec rename(). Pour plus d’informations, consultez la page sur le pivotement des données.L’exemple ci-dessous commence avec la table “longue” age_by_outcome de la \\[section proportions\\](#tbl_dplyr_prop). Nous le créons à nouveau et le présentons à l’impression, pour plus de clarté :Pour effectuer un pivot plus large, nous créons les nouvelles colonnes à partir des valeurs de la colonne existante age_cat (en définissant names_from = age_cat). Nous spécifions également que les nouvelles valeurs de la table proviendront de la colonne existante n, avec values_from = n. Les colonnes non mentionnées dans notre commande de pivotement (outcome) resteront inchangées à l’extrême gauche.","code":"\nage_by_outcome <- linelist %>%                  # commencez par la linelist\n  group_by(outcome) %>%                         # groupe par outcome \n  count(age_cat) %>%                            # regrouper et compter par age_cat, puis supprimer le regroupement age_cat\n  mutate(percent = scales::percent(n / sum(n))) # calculer le pourcentage - noter que le dénominateur est par groupe de outcome\nage_by_outcome %>% \n  select(-percent) %>%   # maintenir seulement compte pour la simplicité\n  pivot_wider(names_from = age_cat, values_from = n)  ## # A tibble: 3 × 10\n## # Groups:   outcome [3]\n##   outcome `0-4` `5-9` `10-14` `15-19` `20-29` `30-49` `50-69` `70+`  `NA`\n##   <chr>   <int> <int>   <int>   <int>   <int>   <int>   <int> <int> <int>\n## 1 Death     471   476     438     323     477     329      33     3    32\n## 2 Recover   364   391     303     251     367     238      38     3    28\n## 3 <NA>      260   228     200     169     229     187      24    NA    26"},{"path":"descriptive_tables.html","id":"tbl_dplyr_totals","chapter":"17 Tableaux descriptifs","heading":"Total de lignes","text":"Lorsque summarise() opère sur des données groupées, il ne produit pas automatiquement des statistiques “totales”. Ci-dessous, deux approches pour ajouter une ligne de total sont présentées :","code":""},{"path":"descriptive_tables.html","id":"janitors-adorn_totals","chapter":"17 Tableaux descriptifs","heading":"janitor’s adorn_totals()","text":"Si votre table consiste uniquement en des nombres ou des proportions/pourcentages qui peuvent être additionnés en un total, alors vous pouvez ajouter des totaux sum en utilisant adorn_totals() de janitor comme décrit dans la section ci-dessus. Notez que cette fonction ne peut additionner que les colonnes numériques - si vous voulez calculer d’autres statistiques totales, voyez l’approche suivante avec dplyr.Ci-dessous, linelist est groupé par sexe et résumé dans un tableau qui décrit le nombre de cas dont l’issue est connue, les décès et les guéris. En passant le tableau à adorn_totals(), ajoute une ligne de total en bas reflétant la somme de chaque colonne. Les autres fonctions adorn_*() ajustent l’affichage comme indiqué dans le code.","code":"\nlinelist %>% \n  group_by(gender) %>%\n  summarise(\n    known_outcome = sum(!is.na(outcome)),           # Nombre de lignes dans le groupe où le outcome n'est pas manquant\n    n_death  = sum(outcome == \"Death\", na.rm=T),    # Nombre de lignes dans le groupe où outcome est égale a Death.\n    n_recover = sum(outcome == \"Recover\", na.rm=T), # Nombre de lignes dans le groupe où outcome est egale à Recovered.\n  ) %>% \n  adorn_totals() %>%                                # Adorn total ligne (somme de chaque colonne numérique)\n  adorn_percentages(\"col\") %>%                      # Obtenir les proportions des colonnes\n  adorn_pct_formatting() %>%                        # Convertir les proportions en pourcentages\n  adorn_ns(position = \"front\")                      # Afficher les % et les comptes (avec les comptes en avant)##  gender  known_outcome        n_death      n_recover\n##       f 2,180  (47.8%) 1,227  (47.5%)   953  (48.1%)\n##       m 2,178  (47.7%) 1,228  (47.6%)   950  (47.9%)\n##    <NA>   207   (4.5%)   127   (4.9%)    80   (4.0%)\n##   Total 4,565 (100.0%) 2,582 (100.0%) 1,983 (100.0%)"},{"path":"descriptive_tables.html","id":"summarise-sur-total-des-données-et-ensuite-bind_rows","chapter":"17 Tableaux descriptifs","heading":"summarise() Sur “total” des données et ensuite bind_rows()","text":"Si votre tableau est composé de données de synthèse statistiques telles que median(), mean(), etc, l’approche adorn_totals() présentée ci-dessus ne sera pas suffisante. Pour obtenir des données de synthèse pour l’ensemble des données, vous devez les calculer avec une commande séparée summarise() et ensuite lier les résultats au tableau de synthèse original. Pour faire la liaison, vous pouvez utiliser bind_rows() de dplyr comme décrit dans la page Joining data. Vous trouverez ci-dessous un exemple :Vous pouvez faire un tableau de synthèse des résultats par hôpital avec group_by() et summarise() comme ceci :Pour obtenir les totaux, exécutez la même commande summarise() mais regroupez les données uniquement par résultat (et non par hôpital), comme ceci :Nous pouvons lier ces deux tableaux ensemble. Notez que by_hospital 4 colonnes alors que totals 3 colonnes. En utilisant bind_rows(), les colonnes sont combinées par nom, et tout espace supplémentaire est rempli avec NA (par exemple les valeurs de la colonne hospital pour les deux nouvelles lignes totals). Après avoir lié les lignes, nous convertissons ces espaces vides en “Total” en utilisant replace_na() (voir la page Nettoyage des données et des fonctions de base).Voici le nouveau tableau avec les lignes “Total” en bas.Ce tableau est dans un format “long”, ce qui peut correspondre à ce que vous souhaitez. En option, vous pouvez pivoter ce tableau plus large pour le rendre plus lisible. Consultez la section sur le pivotement plus large ci-dessus, ainsi que la page Pivoter les données. Vous pouvez également ajouter plus de colonnes, et les arranger joliment. Ce code se trouve ci-dessous.Et vous pouvez ensuite afficher ce tableau sous la forme d’une image. Vous trouverez ci-dessous le résultat imprimé avec flextable. Vous pouvez lire plus en détail cet exemple et la façon d’obtenir ce “joli” tableau sur la page Tableaux pour la présentation.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\nby_hospital <- linelist %>% \n  filter(!is.na(outcome) & hospital != \"Missing\") %>%  # Supprimez les cas avec outcome ou  hôpital manquant\n  group_by(hospital, outcome) %>%                      # Données du groupe\n  summarise(                                           # Créer de nouvelles colonnes de résumé des indicateurs intéressants\n    N = n(),                                            # Nombre de lignes par groupe d'hôpitaux et outcome     \n    ct_value = median(ct_blood, na.rm=T))               # Valeur médiane du CT par groupe\n  \nby_hospital # Afficher la table## # A tibble: 10 × 4\n## # Groups:   hospital [5]\n##    hospital                             outcome     N ct_value\n##    <chr>                                <chr>   <int>    <dbl>\n##  1 Central Hospital                     Death     193       22\n##  2 Central Hospital                     Recover   165       22\n##  3 Military Hospital                    Death     399       21\n##  4 Military Hospital                    Recover   309       22\n##  5 Other                                Death     395       22\n##  6 Other                                Recover   290       21\n##  7 Port Hospital                        Death     785       22\n##  8 Port Hospital                        Recover   579       21\n##  9 St. Mark's Maternity Hospital (SMMH) Death     199       22\n## 10 St. Mark's Maternity Hospital (SMMH) Recover   126       22\ntotals <- linelist %>% \n      filter(!is.na(outcome) & hospital != \"Missing\") %>%\n      group_by(outcome) %>%                            # Regroupés uniquement par outcome, et non par hôpital    \n      summarise(\n        N = n(),                                       # Ces statistiques sont maintenant par outcome seulement     \n        ct_value = median(ct_blood, na.rm=T))\n\ntotals # print table## # A tibble: 2 × 3\n##   outcome     N ct_value\n##   <chr>   <int>    <dbl>\n## 1 Death    1971       22\n## 2 Recover  1469       22\ntable_long <- bind_rows(by_hospital, totals) %>% \n  mutate(hospital = replace_na(hospital, \"Total\"))\ntable_long %>% \n  \n  # Pivot wider and format\n  ########################\n  mutate(hospital = replace_na(hospital, \"Total\")) %>% \n  pivot_wider(                                         # Passer du long au large\n    values_from = c(ct_value, N),                       # les nouvelles valeurs proviennent des colonnes ct et count\n    names_from = outcome) %>%                           # les nouveaux noms de colonnes proviennent des outcomes\n  mutate(                                              # Ajouter de nouvelles colonnes\n    N_Known = N_Death + N_Recover,                               # nombre avec résultat connu\n    Pct_Death = scales::percent(N_Death / N_Known, 0.1),         # Pourcentage des cas qui sont morts (à une décimale près)\n    Pct_Recover = scales::percent(N_Recover / N_Known, 0.1)) %>% # Pourcentage de guérison (à une décimale près)\n  select(                                              # Réorganiser les colonnes\n    hospital, N_Known,                                   # Introduction de colonnes\n    N_Recover, Pct_Recover, ct_value_Recover,            # Colonnes récupérées\n    N_Death, Pct_Death, ct_value_Death)  %>%             # Colonnes de décès\n  arrange(N_Known)                                  # Ranger les rangées du plus bas au plus haut (rangée totale en bas)## # A tibble: 6 × 8\n## # Groups:   hospital [6]\n##   hospital              N_Known N_Recover Pct_Recover ct_value_Recover N_Death Pct_Death\n##   <chr>                   <int>     <int> <chr>                  <dbl>   <int> <chr>    \n## 1 St. Mark's Maternity…     325       126 38.8%                     22     199 61.2%    \n## 2 Central Hospital          358       165 46.1%                     22     193 53.9%    \n## 3 Other                     685       290 42.3%                     21     395 57.7%    \n## 4 Military Hospital         708       309 43.6%                     22     399 56.4%    \n## 5 Port Hospital            1364       579 42.4%                     21     785 57.6%    \n## 6 Total                    3440      1469 42.7%                     22    1971 57.3%    \n## # ℹ 1 more variable: ct_value_Death <dbl>"},{"path":"descriptive_tables.html","id":"tbl_gt","chapter":"17 Tableaux descriptifs","heading":"17.5 gtsummary package","text":"Si vous voulez afficher vos synthèses statistiques dans un joli graphique, vous pouvez utiliser le package gtsummary et sa fonction tbl_summary(). Le code peut sembler complexe au début, mais les résultats sont très jolis et apparaissent dans votre panneau de visualisation RStudio sous forme d’image HTML. Lire une vignette ici.Vous pouvez également ajouter les résultats des tests statistiques aux tableaux gtsummary. Ce processus est décrit dans la section gtsummary de la page Tests statistiques simples.Pour présenter tbl_summary(), nous allons d’abord montrer le comportement le plus basique, qui produit effectivement un grand et beau tableau. Ensuite, nous examinerons en détail comment faire des ajustements et des tableaux plus adaptés.","code":""},{"path":"descriptive_tables.html","id":"tableau-de-synthèse","chapter":"17 Tableaux descriptifs","heading":"Tableau de synthèse","text":"Le comportement par défaut de tbl_summary() est assez incroyable - il prend les colonnes que vous fournissez et crée un tableau de synthèse en une seule commande. La fonction affiche les statistiques appropriées à la classe de la colonne : la médiane et l’écart inter-quartile (IQR) pour les colonnes numériques, et le nombre (%) pour les colonnes catégorielles. Les valeurs manquantes sont converties en “Inconnu”. Des notes de bas de page sont ajoutées en bas de page pour expliquer les statistiques, tandis que le N total est affiché en haut de page.","code":"\nlinelist %>% \n  select(age_years, gender, outcome, fever, temp, hospital) %>%  # ne gardez que les colonnes d'intérêt\n  tbl_summary()                                                  # defaut"},{"path":"descriptive_tables.html","id":"ajustements","chapter":"17 Tableaux descriptifs","heading":"Ajustements","text":"Nous allons maintenant expliquer le fonctionnement de la fonction et la manière de procéder aux ajustements. Les principaux arguments sont détaillés ci-dessous :=\nVous pouvez stratifier votre tableau par une colonne (par exemple par outcome), créant ainsi un tableau à 2 dimensions.statistic =\nUtilisez une équation pour spécifier les statistiques à afficher et comment les afficher. L’équation comporte deux côtés, séparés par un tilde ~. Sur le côté droit, entre guillemets, se trouve l’affichage statistique souhaité, et sur la gauche se trouvent les colonnes auxquelles cet affichage s’appliquera.Le côté droit de l’équation utilise la syntaxe de str_glue() de stringr (voir Caractères et chaînes de caractères), avec la chaîne d’affichage souhaitée entre guillemets et les statistiques elles-mêmes entre crochets. Vous pouvez inclure des statistiques comme “n” (pour les comptes), “N” (pour le dénominateur), “mean”, “median”, “sd”, “max”, “min”, les percentiles comme “p##” comme “p25”, ou le pourcentage du total comme “p”. Voir ?tbl_summary pour plus de détails.Pour le côté gauche de l’équation, vous pouvez spécifier les colonnes par leur nom (par exemple, age ou c(age, gender)) ou en utilisant des aides telles que all_continuous(), all_categorical(), contains(), starts_with(), etc.Un exemple simple d’équation statistic = pourrait ressembler à ce qui suit, pour afficher uniquement la moyenne de la colonne age_years :Une équation un peu plus complexe pourrait ressembler à ““({min}, {max})”`, incorporant les valeurs max et min entre parenthèses et séparées par une virgule :Vous pouvez également différencier la syntaxe pour des colonnes ou des types de colonnes distincts. Dans l’exemple plus complexe ci-dessous, la valeur fournie à statistc = est une liste indiquant que pour toutes les colonnes continues, le tableau doit afficher la moyenne avec l’écart-type entre parenthèses, tandis que pour toutes les colonnes catégorielles, il doit afficher le n, le dénominateur et le pourcentage.digits =\nAjuste les chiffres et les arrondis. En option, il est possible de spécifier que cela ne concerne que les colonnes continues (comme ci-dessous).label =\nAjustez la façon dont le nom de la colonne doit être affiché. Fournissez le nom de la colonne et son étiquette souhaitée, séparés par un tilde. La valeur par défaut est le nom de la colonne.missing_text =\nAjustez la façon dont les valeurs manquantes sont affichées. La valeur par défaut est “Inconnu”.type =\nPermet de régler le nombre de niveaux de statistiques à afficher. La syntaxe est similaire à statistic = en ce sens que vous fournissez une équation avec des colonnes à gauche et une valeur à droite. Voici deux scénarios courants :type = all_categorical() ~ \"categorical\" Force les colonnes dichotomiques (par exemple, fièvre oui/non) à montrer tous les niveaux au lieu de ne montrer que la ligne “oui”type = all_continuous() ~ \"continuous2\" Permet des statistiques multi-lignes par variable, comme indiqué dans une section ultérieure.Dans l’exemple ci-dessous, chacun de ces arguments est utilisé pour modifier le tableau de synthèse original :","code":"\nlinelist %>% \n  select(age_years) %>%         #  Ne gardez que les colonnes d'intérêt \n  tbl_summary(                  #  créer un tableau récapitulatif\n    statistic = age_years ~ \"{mean}\") # Impression de la moyenne d'âge\nlinelist %>% \n  select(age_years) %>%                       #  Ne gardez que les colonnes d'intérêt \n  tbl_summary(                                # créer un tableau résumé\n    statistic = age_years ~ \"({min}, {max})\") # Impression des valeurs minimale et maximale de l'âge\nlinelist %>% \n  select(age_years, gender, outcome, fever, temp, hospital) %>% #  Ne gardez que les colonnes d'intérêt \n  tbl_summary(     \n    by = outcome,                                               # stratifier le tableau entier par résultat\n    statistic = list(all_continuous() ~ \"{mean} ({sd})\",        # stats et format pour les colonnes continues\n                     all_categorical() ~ \"{n} / {N} ({p}%)\"),   # stats et format pour les colonnes catégorielles\n    digits = all_continuous() ~ 1,                              # arrondi pour les colonnes continues\n    type   = all_categorical() ~ \"categorical\",                 # force l'affichage de tous les niveaux catégoriels\n    label  = list(                                              # affichage des étiquettes pour les noms de colonnes\n      outcome   ~ \"Outcome\",                           \n      age_years ~ \"Age (years)\",\n      gender    ~ \"Gender\",\n      temp      ~ \"Temperature\",\n      hospital  ~ \"Hospital\"),\n    missing_text = \"Missing\"                                    # comment les valeurs manquantes doivent être affichées\n  )## 1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_na_value_to_level()` on `outcome` column before passing to `tbl_summary()`."},{"path":"descriptive_tables.html","id":"statistiques-multi-lignes-pour-les-variables-continues","chapter":"17 Tableaux descriptifs","heading":"Statistiques multi-lignes pour les variables continues","text":"Si vous souhaitez afficher plusieurs lignes statistiques pour des variables continues, vous pouvez l’indiquer en définissant le type = à “continuous2”. Vous pouvez combiner tous les éléments présentés précédemment dans un seul tableau en choisissant les statistiques que vous voulez afficher. Pour cela, vous devez indiquer à la fonction que vous voulez récupérer un tableau en entrant le type comme “continuous2”. Le nombre de valeurs manquantes est indiqué comme “Inconnu”.Il existe de nombreuses autres façons de modifier ces tableaux, notamment en ajoutant des valeurs p, en ajustant la couleur et les titres, etc. La plupart sont décrites dans la documentation (entrez ?tbl_summary dans Console), et certaines sont données dans la section sur les tests statistiques.","code":"\nlinelist %>% \n  select(age_years, temp) %>%                      # Ne garder que les colonnes d'intérêt\n  tbl_summary(                                     # # créer un tableau résume\n    type = all_continuous() ~ \"continuous2\",       # indique que vous voulez imprimer plusieurs statistiques \n    statistic = all_continuous() ~ c(\n      \"{mean} ({sd})\",                             # ligne 1 : moyenne et SD\n      \"{median} ({p25}, {p75})\",                   # ligne 2 : médiane et IQR\n      \"{min}, {max}\")                              # ligne 3: min et max\n    )"},{"path":"descriptive_tables.html","id":"extensionpackage-r-base","chapter":"17 Tableaux descriptifs","heading":"17.6 extension/package R base","text":"Vous pouvez utiliser la fonction table() pour faire des tableaux et des tableaux croisés de colonnes. Contrairement aux options ci-dessus, vous devez spécifier le tableau de données chaque fois que vous faites référence à un nom de colonne, comme indiqué ci-dessous.CAUTION: Les valeursNA(manquantes) ne seront **pas** affichées en tableau, à moins que vous n'incluiez l'argumentuseNA = “always”` (qui peut également être défini sur “” ou “ifany”).TIP: Vous pouvez utiliser le %$% de magrittr pour supprimer la répétition des enregistrements de données du tableaux dans les fonctions base. Par exemple, pourrait écrire linelist %$% table(outcome, useNA = \"always\").Plusieurs colonnes peuvent être croisées en les listant l’une après l’autre, séparées par des virgules. En option, vous pouvez attribuer à chaque colonne un “nom” comme Outcome = linelist$outcome.","code":"\ntable(linelist$outcome, useNA = \"always\")## \n##   Death Recover    <NA> \n##    2582    1983    1323\nage_by_outcome <- table(linelist$age_cat, linelist$outcome, useNA = \"always\") # sauvegarder le tableau comme objet\nage_by_outcome   # imprimer le tableau##        \n##         Death Recover <NA>\n##   0-4     471     364  260\n##   5-9     476     391  228\n##   10-14   438     303  200\n##   15-19   323     251  169\n##   20-29   477     367  229\n##   30-49   329     238  187\n##   50-69    33      38   24\n##   70+       3       3    0\n##   <NA>     32      28   26"},{"path":"descriptive_tables.html","id":"proportions","chapter":"17 Tableaux descriptifs","heading":"Proportions","text":"Pour retourner les proportions, passez le tableau ci-dessus à la fonction prop.table(). Utilisez l’argument margins = pour spécifier si vous voulez que les proportions soient des lignes (1), des colonnes (2), ou du tableau entier (3). Pour plus de précisions, nous envoyons le tableau à la fonction round() de base R, en spécifiant 2 chiffres.","code":"\n# obtenir les proportions du tableau défini ci-dessus, par lignes, arrondies\nprop.table(age_by_outcome, 1) %>% round(2)##        \n##         Death Recover <NA>\n##   0-4    0.43    0.33 0.24\n##   5-9    0.43    0.36 0.21\n##   10-14  0.47    0.32 0.21\n##   15-19  0.43    0.34 0.23\n##   20-29  0.44    0.34 0.21\n##   30-49  0.44    0.32 0.25\n##   50-69  0.35    0.40 0.25\n##   70+    0.50    0.50 0.00\n##   <NA>   0.37    0.33 0.30"},{"path":"descriptive_tables.html","id":"totals","chapter":"17 Tableaux descriptifs","heading":"Totals","text":"Pour ajouter les totaux des lignes et des colonnes, passez le tableau à addmargins(). Cela fonctionne à la fois pour les nombres et les proportions.","code":"\naddmargins(age_by_outcome)##        \n##         Death Recover <NA>  Sum\n##   0-4     471     364  260 1095\n##   5-9     476     391  228 1095\n##   10-14   438     303  200  941\n##   15-19   323     251  169  743\n##   20-29   477     367  229 1073\n##   30-49   329     238  187  754\n##   50-69    33      38   24   95\n##   70+       3       3    0    6\n##   <NA>     32      28   26   86\n##   Sum    2582    1983 1323 5888"},{"path":"descriptive_tables.html","id":"convertir-en-tableau-de-données","chapter":"17 Tableaux descriptifs","heading":"Convertir en tableau de données","text":"Convertir un objet table() directement en tableau de données n’est pas simple. Une approche est démontrée ci-dessous :Créez la table, *sans utiliser useNA = \"always\". la place, convertissez les valeurs NA en “(Missing)” avec fct_explicit_na() de forcats.Ajoutez les totaux (facultatif) en utilisant `addmargins()``.Passez le tableau dans la fonction R base `.data.frame.matrix()``.Passez le tableau dans la fonction tibble rownames_to_column(), en spécifiant le nom de la première colonne.Affichez, visualisez ou exportez comme vous le souhaitez. Dans cet exemple, nous utilisons flextable() du package flextable comme décrit dans la page Tableaux pour la présentation. Cela permettra d’afficher dans le volet de visualisation de RStudio une jolie image HTML.Age CategoryDeathRecover(Missing)Sum0-44713642601,0955-94763912281,09510-1443830320094115-1932325116974320-294773672291,07330-4932923818775450-693338249570+3306(Missing)32282686Sum2,5821,9831,3235,888","code":"\ntable(fct_explicit_na(linelist$age_cat), fct_explicit_na(linelist$outcome)) %>% \n  addmargins() %>% \n  as.data.frame.matrix() %>% \n  tibble::rownames_to_column(var = \"Age Category\") %>% \n  flextable::flextable()"},{"path":"descriptive_tables.html","id":"ressources-5","chapter":"17 Tableaux descriptifs","heading":"17.7 Ressources","text":"La plupart des informations contenues dans cette page sont issues de ces ressources et des sites Internet :gtsummarydplyr","code":""},{"path":"stats_test.html","id":"stats_test","chapter":"18 Tests statistiques simples","heading":"18 Tests statistiques simples","text":"Cette page décrit comment réaliser des tests statistiques simples en utilisant base R, rstatix et gtsummary.Test TTest de Shapiro-WilkTest de la somme des rangs de WilcoxonTest de Kruskal-WallisTest du khi carréCorrélations entre variables numériques… plusieurs d’autres tests peuvent être effectués, mais nous ne présentons que ceux qui sont les plus utilisés et nous fournissons des liens vers plus de documentation.Chacun des packages susmentionnés des avantages et des désavantages :Utilisez les fonctions de base R pour afficher les résultats statistiques dans la Console R.Utilisez les fonctions de rstatix package pour afficher les résultats dans un tableau de données, ou si vous voulez que les tests soient effectués par groupe.Utilisez gtsummary package si vous souhaitez produire des tableaux prêts à être publiés.","code":""},{"path":"stats_test.html","id":"préparation-3","chapter":"18 Tests statistiques simples","heading":"18.1 Préparation","text":"","code":""},{"path":"stats_test.html","id":"importation-des-packages-1","chapter":"18 Tests statistiques simples","heading":"Importation des packages","text":"Ce bloc de code montre l’importation des packages nécessaires pour les analyses. Dans ce manuel, nous soulignons la fonction p_load() de pacman, qui installe le package si nécessaire et l’importe pour utilisation. Vous pouvez aussi importer les packages déjà installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les packages R.","code":"\npacman::p_load(\n  rio,          # pour importation des fichiers\n  here,         # chemins de fichiers\n  skimr,        # obtenir un aperçu des données\n  tidyverse,    # gestion des données + graphiques ggplot2, \n  gtsummary,    # statistiques et tests sommaires\n  rstatix,      # statistiques\n  corrr,        # analyse de corrélation pour les variables numériques\n  janitor,      # ajouter des totaux et des pourcentages à des tableaux\n  flextable     # transformer les tableaux en HTML\n  )"},{"path":"stats_test.html","id":"importation-des-données-3","chapter":"18 Tests statistiques simples","heading":"Importation des données","text":"Nous importons les données des cas d’une épidémie d’Ebola simulée. Si vous souhaitez suivre, cliquez pour télécharger le “clean” linelist (.rds file). Importez les données avec la fonction import() du package rio (cette fonction supporte de nombreux types de fichiers comme .xlsx, .csv, .rds - voir la page Importation et exportation pour plus de détails).Les 50 premières lignes de la liste des lignes sont affichées ci-dessous.","code":"\n# importez linelist \nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"stats_test.html","id":"base-r-1","chapter":"18 Tests statistiques simples","heading":"18.2 Base R","text":"Vous pouvez utiliser les fonctions de base R pour effectuer des tests statistiques. Les commandes sont relativement simples et les résultats sont affichés dans la Console R pour une visualisation simple. Cependant, les résultats sont généralement des listes et sont donc plus difficiles à manipuler si vous souhaitez utiliser les résultats dans des opérations ultérieures.","code":""},{"path":"stats_test.html","id":"test-t","chapter":"18 Tests statistiques simples","heading":"Test T","text":"Un t-test, aussi appelé “test t de Student”, est généralement utilisé pour déterminer s’il existe une différence significative entre les moyennes d’une variable numérique entre deux groupes. Nous allons montrer ici quelle syntaxe utiliser pour effectuer ce test selon si les colonnes se trouvent dans le même tableau de données.Syntaxe 1: Voici la syntaxe à utiliser lorsque les colonnes numériques et catégorielles se trouvent dans le même tableau de données. Fournissez la colonne numérique sur la gauche de l’équation et la colonne catégorielle sur la droite. Précisez le tableau de données à data =. Optionnellement, définissezpaired = TRUE, et conf.level = (0.95 par défaut), et alternative = (soit “two.sided”, “less”, “greater”). Entrez ?t.test pour plus de détails.Syntaxe 2: Vous pouvez comparer deux vecteurs numériques distincts en utilisant cette syntaxe alternative. Par exemple, si les deux colonnes se trouvent dans des tableau de données différents.Vous pouvez aussi utiliser un test t pour déterminer si la moyenne d’un échantillon est significativement différente d’une valeur spécifique. Ici, nous effectuons un one-sample t-test avec une moyenne de population connue/hypothétique mu = :","code":"\n## comparer l'âge moyen par groupe avec un test t.\nt.test(age_years ~ gender, data = linelist)## \n##  Welch Two Sample t-test\n## \n## data:  age_years by gender\n## t = -21.344, df = 4902.3, p-value < 2.2e-16\n## alternative hypothesis: true difference in means between group f and group m is not equal to 0\n## 95 percent confidence interval:\n##  -7.571920 -6.297975\n## sample estimates:\n## mean in group f mean in group m \n##        12.60207        19.53701\nt.test(df1$age_years, df2$age_years)\nt.test(linelist$age_years, mu = 45)"},{"path":"stats_test.html","id":"test-de-shapiro-wilk","chapter":"18 Tests statistiques simples","heading":"Test de Shapiro-Wilk","text":"Le Shapiro-Wilk test peut être utilisé pour déterminer si un échantillon provient d’une population normalement distribuée (une hypothèse de nombreux autres tests et analyses, tels que le test t). Cependant, il ne peut être utilisé que sur un échantillon de 3 à 5000 observations. Pour des échantillons plus importants, un quantile-quantile plot peut être utile.","code":"\nshapiro.test(linelist$age_years)"},{"path":"stats_test.html","id":"test-de-la-somme-des-rangs-de-wilcoxon","chapter":"18 Tests statistiques simples","heading":"Test de la somme des rangs de Wilcoxon","text":"Le test de la somme des rangs de Wilcoxon, aussi appelé test U de Mann-Whitney, est souvent utilisé pour déterminer si deux échantillons numériques proviennent de la même distribution lorsque leurs populations ne sont pas normalement distribuées ou présentent une variance inégale.","code":"\n## comparer la distribution des âges par groupe de résultats avec un test de Wilcox.\nwilcox.test(age_years ~ outcome, data = linelist)## \n##  Wilcoxon rank sum test with continuity correction\n## \n## data:  age_years by outcome\n## W = 2501868, p-value = 0.8308\n## alternative hypothesis: true location shift is not equal to 0"},{"path":"stats_test.html","id":"test-de-kruskal-wallis","chapter":"18 Tests statistiques simples","heading":"Test de Kruskal-Wallis","text":"Le test de Kruskal-Wallis est une extension du test de la somme des rangs de Wilcoxon qui peut être utilisé pour tester les différences dans la distribution de plus de deux échantillons. Lorsque deux échantillons sont utilisés, ce test donne des résultats identiques à ceux du test de la somme des rangs de Wilcoxon.","code":"\n## comparer la distribution des âges par groupe de résultats avec un test de Kruskal-Wallis.\nkruskal.test(age_years ~ outcome, linelist)## \n##  Kruskal-Wallis rank sum test\n## \n## data:  age_years by outcome\n## Kruskal-Wallis chi-squared = 0.045675, df = 1, p-value = 0.8308"},{"path":"stats_test.html","id":"test-du-khi-carré","chapter":"18 Tests statistiques simples","heading":"Test du khi carré","text":"Pearson’s Chi-squared test est utilisé pour tester des différences significatives entre des groupes catégorielles.","code":"\n## comparer les proportions dans chaque groupe avec un test de chi-carré\nchisq.test(linelist$gender, linelist$outcome)## \n##  Pearson's Chi-squared test with Yates' continuity correction\n## \n## data:  linelist$gender and linelist$outcome\n## X-squared = 0.0011841, df = 1, p-value = 0.9725"},{"path":"stats_test.html","id":"le-rstatix-package","chapter":"18 Tests statistiques simples","heading":"18.3 Le rstatix package","text":"Le package rstatix offre la possibilité d’exécuter des tests statistiques et de recueillir les résultats dans un cadre “pipe-friendly”. Les résultats sont automatiquement intégrés dans un tableau de données afin que vous puissiez effectuer des opérations ultérieures sur les résultats. Il est aussi facile de regrouper les données transmises dans les fonctions, afin que les statistiques soient exécutées pour chaque groupe.","code":""},{"path":"stats_test.html","id":"statistiques-sommaires-1","chapter":"18 Tests statistiques simples","heading":"Statistiques sommaires","text":"La fonction get_summary_stats() est un moyen rapide de retourner des statistiques sommaires. Il suffit de passer vos données à cette fonction et de préciser les colonnes à analyser. Si aucune colonne n’est précisée, les statistiques sont calculées pour toutes les colonnes.Par défaut, une gamme complète de statistiques sommaires est retournée : n, max, min, médiane, 25%ile, 75%ile, IQR, écart absolu médian (mad), moyenne, écart-type, erreur-type, et un intervalle de confiance de la moyenne.Vous pouvez préciser un sous-groupe de statistiques sommaires à retourner en fournissant l’une des valeurs suivantes à type = : “full”, “common”, “robust”, “five_number”, “mean_sd”, “mean_se”, “mean_ci”, “median_iqr”, “median_mad”, “quantile”, “mean”, “median”, “min”, “max”.Elle peut également être utilisée avec des données groupées, de sorte qu’une ligne est renvoyée pour chaque variable de groupement :Vous pouvez aussi utiliser rstatix pour effectuer des tests statistiques :","code":"\nlinelist %>%\n  rstatix::get_summary_stats(age, temp)## # A tibble: 2 × 13\n##   variable     n   min   max median    q1    q3   iqr    mad  mean     sd    se    ci\n##   <fct>    <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl>  <dbl> <dbl>  <dbl> <dbl> <dbl>\n## 1 age       5802   0    84     13     6    23      17 11.9    16.1 12.6   0.166 0.325\n## 2 temp      5739  35.2  40.8   38.8  38.2  39.2     1  0.741  38.6  0.977 0.013 0.025\nlinelist %>%\n  group_by(hospital) %>%\n  rstatix::get_summary_stats(age, temp, type = \"common\")## # A tibble: 12 × 11\n##    hospital             variable     n   min   max median   iqr  mean     sd    se    ci\n##    <chr>                <fct>    <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl>\n##  1 Central Hospital     age        445   0    58     12    15    15.7 12.5   0.591 1.16 \n##  2 Central Hospital     temp       450  35.2  40.4   38.8   1    38.5  0.964 0.045 0.089\n##  3 Military Hospital    age        884   0    72     14    18    16.1 12.4   0.417 0.818\n##  4 Military Hospital    temp       873  35.3  40.5   38.8   1    38.6  0.952 0.032 0.063\n##  5 Missing              age       1441   0    76     13    17    16.0 12.9   0.339 0.665\n##  6 Missing              temp      1431  35.8  40.6   38.9   1    38.6  0.97  0.026 0.05 \n##  7 Other                age        873   0    69     13    17    16.0 12.5   0.422 0.828\n##  8 Other                temp       862  35.7  40.8   38.8   1.1  38.5  1.01  0.034 0.067\n##  9 Port Hospital        age       1739   0    68     14    18    16.3 12.7   0.305 0.598\n## 10 Port Hospital        temp      1713  35.5  40.6   38.8   1.1  38.6  0.981 0.024 0.046\n## 11 St. Mark's Maternit… age        420   0    84     12    15    15.7 12.4   0.606 1.19 \n## 12 St. Mark's Maternit… temp       410  35.9  40.6   38.8   1.1  38.5  0.983 0.049 0.095"},{"path":"stats_test.html","id":"test-t-1","chapter":"18 Tests statistiques simples","heading":"Test T","text":"Utilisez une syntaxe de formule pour préciser les colonnes numériques et catégorielles :Ou utilisez ~ 1 et spécifiez mu = pour un one-sample T-test. Cela peut aussi être fait par groupe.Si applicable, les tests statistiques peuvent être effectués par groupe, comme illustré ci-dessous :","code":"\nlinelist %>% \n  t_test(age_years ~ gender)## # A tibble: 1 × 10\n##   .y.       group1 group2    n1    n2 statistic    df        p    p.adj p.adj.signif\n## * <chr>     <chr>  <chr>  <int> <int>     <dbl> <dbl>    <dbl>    <dbl> <chr>       \n## 1 age_years f      m       2807  2803     -21.3 4902. 9.89e-97 9.89e-97 ****\nlinelist %>% \n  t_test(age_years ~ 1, mu = 30)## # A tibble: 1 × 7\n##   .y.       group1 group2         n statistic    df     p\n## * <chr>     <chr>  <chr>      <int>     <dbl> <dbl> <dbl>\n## 1 age_years 1      null model  5802     -84.2  5801     0\nlinelist %>% \n  group_by(gender) %>% \n  t_test(age_years ~ 1, mu = 18)## # A tibble: 3 × 8\n##   gender .y.       group1 group2         n statistic    df         p\n## * <chr>  <chr>     <chr>  <chr>      <int>     <dbl> <dbl>     <dbl>\n## 1 f      age_years 1      null model  2807    -29.8   2806 7.52e-170\n## 2 m      age_years 1      null model  2803      5.70  2802 1.34e-  8\n## 3 <NA>   age_years 1      null model   192     -3.80   191 1.96e-  4"},{"path":"stats_test.html","id":"test-de-shapiro-wilk-1","chapter":"18 Tests statistiques simples","heading":"Test de Shapiro-Wilk","text":"Comme indiqué précédemment, la taille de l’échantillon doit être entre 3 et 5000.","code":"\nlinelist %>% \n  head(500) %>%            # les 500 premières lignes du case linelist, pour illustration seulement \n  shapiro_test(age_years)## # A tibble: 1 × 3\n##   variable  statistic        p\n##   <chr>         <dbl>    <dbl>\n## 1 age_years     0.917 6.67e-16"},{"path":"stats_test.html","id":"test-de-la-somme-des-rangs-de-wilcoxon-1","chapter":"18 Tests statistiques simples","heading":"Test de la somme des rangs de Wilcoxon","text":"","code":"\nlinelist %>% \n  wilcox_test(age_years ~ gender)## # A tibble: 1 × 9\n##   .y.       group1 group2    n1    n2 statistic        p    p.adj p.adj.signif\n## * <chr>     <chr>  <chr>  <int> <int>     <dbl>    <dbl>    <dbl> <chr>       \n## 1 age_years f      m       2807  2803   2829274 3.47e-74 3.47e-74 ****"},{"path":"stats_test.html","id":"test-de-kruskal-wallis-1","chapter":"18 Tests statistiques simples","heading":"Test de Kruskal-Wallis","text":"Aussi appelé le test U de Mann-Whitney.","code":"\nlinelist %>% \n  kruskal_test(age_years ~ outcome)## # A tibble: 1 × 6\n##   .y.           n statistic    df     p method        \n## * <chr>     <int>     <dbl> <int> <dbl> <chr>         \n## 1 age_years  5888    0.0457     1 0.831 Kruskal-Wallis"},{"path":"stats_test.html","id":"test-du-khi-carré-1","chapter":"18 Tests statistiques simples","heading":"Test du khi carré","text":"La fonction de khi carré peut accepter un tableau, donc nous allons d’abord créer un tableau croisé. Il existe de plusieurs méthodes de créer un tableau croisé (voir Tableaux descriptifs) mais ici nous utilisons tabyl() de janitor et nous supprimons la colonne la plus à gauche des labels de valeur avant de passer à chisq_test().De nombreuses autres fonctions et tests statistiques peuvent être exécutés avec les fonctions de rstatix. Consultez la documentation de rstatix online ou en entrant ?rstatix.","code":"\nlinelist %>% \n  tabyl(gender, outcome) %>% \n  select(-1) %>% \n  chisq_test()## # A tibble: 1 × 6\n##       n statistic     p    df method          p.signif\n## * <dbl>     <dbl> <dbl> <int> <chr>           <chr>   \n## 1  5888      3.53 0.473     4 Chi-square test ns"},{"path":"stats_test.html","id":"stats_gt","chapter":"18 Tests statistiques simples","heading":"18.4 Le gtsummary package","text":"Utilisez gtsummary si vous cherchez à ajouter les résultats d’un test statistique à un beau tableau qui été créé avec ce package (comme décrit dans la section gtsummary de la page Tableaux descriptifs).Effectuer des tests statistiques de comparaison avec tbl_summary se fait en ajoutant la fonction add_p à une table et en précisant le test à utiliser. Il est possible d’obtenir des valeurs p ajustées pour multiples tests en utilisant la fonction add_q. Exécutez ?tbl_summary pour plus de détails.","code":""},{"path":"stats_test.html","id":"test-du-khi-carré-2","chapter":"18 Tests statistiques simples","heading":"Test du khi carré","text":"Comparez les proportions d’une variable catégorielle dans deux groupes. Le test statistique par défaut pour add_p() lorsqu’il est appliqué à une variable catégorielle est d’effectuer un test d’indépendance du khi-carré avec correction de continuité, mais si le nombre d’appels attendus est inférieur à 5, alors un test exact de Fisher est utilisé.","code":"\nlinelist %>% \n  select(gender, outcome) %>%    # garder les variables d'intérêt\n  tbl_summary(by = outcome) %>%  # produire un tableau sommaire et préciser la variable de groupement\n  add_p()                        # préciser le test à effectuer## 1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_na_value_to_level()` on `outcome` column before passing to `tbl_summary()`."},{"path":"stats_test.html","id":"test-t-2","chapter":"18 Tests statistiques simples","heading":"Test T","text":"Comparez la différence de moyennes entre deux groupes de variables continues.\nPar exemple, comparez l’âge moyen selon le statut du patient.","code":"\nlinelist %>% \n  select(age_years, outcome) %>%             # garder les variables d'intérêt\n  tbl_summary(                               # produire un tableau sommaire\n    statistic = age_years ~ \"{mean} ({sd})\", # préciser quel statistique a afficher\n    by = outcome) %>%                        # préciser la variable de groupement\n  add_p(age_years ~ \"t.test\")                # préciser le test à effectuer## 1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_na_value_to_level()` on `outcome` column before passing to `tbl_summary()`."},{"path":"stats_test.html","id":"test-de-la-somme-des-rangs-de-wilcoxon-2","chapter":"18 Tests statistiques simples","heading":"Test de la somme des rangs de Wilcoxon","text":"Comparez la distribution d’une variable continue dans deux groupes. La méthode par défaut\nest d’utiliser le test de la somme des rangs de Wilcoxon et la médiane (IQR) pour comparer deux groupes.\nCependant, pour les données de distribution non normale ou la comparaison de plusieurs groupes,\nle test de Kruskal-wallis est plus approprié.","code":"\nlinelist %>% \n  select(age_years, outcome) %>%                       # garder les variables d'intérêt\n  tbl_summary(                                         # produire un tableau sommaire\n    statistic = age_years ~ \"{median} ({p25}, {p75})\", # préciser quel statistique a afficher (ceci est par défaut et peut donc être supprimé)\n    by = outcome) %>%                                  # préciser la variable de groupement\n  add_p(age_years ~ \"wilcox.test\")                     # préciser le test à effectuer## 1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_na_value_to_level()` on `outcome` column before passing to `tbl_summary()`."},{"path":"stats_test.html","id":"test-de-kruskal-wallis-2","chapter":"18 Tests statistiques simples","heading":"Test de Kruskal-Wallis","text":"Comparer la distribution d’une variable continue dans deux ou plusieurs groupes, peu importe si les données sont normalement distribuées ou pas.","code":"\nlinelist %>% \n  select(age_years, outcome) %>%                       # garder les variables d'intérêt\n  tbl_summary(                                         # produire un tableau sommaire\n    statistic = age_years ~ \"{median} ({p25}, {p75})\", # préciser quel statistique a afficher (ceci est par défaut et peut donc être supprimé)\n    by = outcome) %>%                                  # préciser la variable de groupement\n  add_p(age_years ~ \"kruskal.test\")                    # préciser le test à effectuer## 1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_na_value_to_level()` on `outcome` column before passing to `tbl_summary()`."},{"path":"stats_test.html","id":"corrélations","chapter":"18 Tests statistiques simples","heading":"18.5 Corrélations","text":"La corrélation entre les variables numériques peut être étudiée en utilisant le package tidyversecorrr. Il vous permet de calculer les corrélations en utilisant Pearson, Kendall\ntau ou Spearman rho. Le package crée un tableau et dispose également d’une fonction pour\npour tracer automatiquement les valeurs.","code":"\ncorrelation_tab <- linelist %>% \n  select(generation, age, ct_blood, days_onset_hosp, wt_kg, ht_cm) %>%   # garder les variables numeriques d'intérêt\n  correlate()      # créer une table de corrélation (en utilisant le pearson par défaut)\n\ncorrelation_tab    # afficher## # A tibble: 6 × 7\n##   term            generation       age ct_blood days_onset_hosp    wt_kg    ht_cm\n##   <chr>                <dbl>     <dbl>    <dbl>           <dbl>    <dbl>    <dbl>\n## 1 generation        NA       -0.0222    0.179         -0.288    -0.0302  -0.00942\n## 2 age               -0.0222  NA         0.00849       -0.000635  0.833    0.877  \n## 3 ct_blood           0.179    0.00849  NA             -0.600    -0.00636  0.0181 \n## 4 days_onset_hosp   -0.288   -0.000635 -0.600         NA         0.0153  -0.00953\n## 5 wt_kg             -0.0302   0.833    -0.00636        0.0153   NA        0.884  \n## 6 ht_cm             -0.00942  0.877     0.0181        -0.00953   0.884   NA\n## supprimer les entrées dupliquées (le tableau précédent est dupliqué) \ncorrelation_tab <- correlation_tab %>% \n  shave()\n\n## voir le tableau de corrélation\ncorrelation_tab## # A tibble: 6 × 7\n##   term            generation       age ct_blood days_onset_hosp  wt_kg ht_cm\n##   <chr>                <dbl>     <dbl>    <dbl>           <dbl>  <dbl> <dbl>\n## 1 generation        NA       NA        NA              NA       NA        NA\n## 2 age               -0.0222  NA        NA              NA       NA        NA\n## 3 ct_blood           0.179    0.00849  NA              NA       NA        NA\n## 4 days_onset_hosp   -0.288   -0.000635 -0.600          NA       NA        NA\n## 5 wt_kg             -0.0302   0.833    -0.00636         0.0153  NA        NA\n## 6 ht_cm             -0.00942  0.877     0.0181         -0.00953  0.884    NA\n## graphique des corrélations \nrplot(correlation_tab)"},{"path":"stats_test.html","id":"ressources-6","chapter":"18 Tests statistiques simples","heading":"18.6 Ressources","text":"La plupart des informations contenues dans cette page sont adaptées de ces ressources et vignettes disponibles en ligne :gtsummary\ndplyr\ncorrr\nsthda correlation","code":""},{"path":"regression.html","id":"regression","chapter":"19 Régression univariée et multivariable","heading":"19 Régression univariée et multivariable","text":"Cette page montre comment utiliser des fonctions de régression base de R telles que glm() et le package gtsummary pour\nexaminer les relations entre les variables (par exemple, les rapports de cotes, les rapports de risque et les\nratios de risque). Il utilise également des fonctions comme tidy() du package broom pour nettoyer les sorties de régression.Univarié : tableaux deux par deuxStratifié : estimations mantel-haenszelMultivariable : sélection des variables, sélection du modèle, tableau finalForest graphePour la régression des risques proportionnels de Cox, voir la page Analyse d’enquête.NOTE: Nous utilisons le terme multivariable pour faire référence à une régression avec plusieurs variables explicatives. En effet, un modèle multivarié serait une régression avec plusieurs résultats - voir ceci éditorial pour plus de detail ","code":""},{"path":"regression.html","id":"preparation-2","chapter":"19 Régression univariée et multivariable","heading":"19.1 Preparation","text":"","code":""},{"path":"regression.html","id":"chargement-des-packages-1","chapter":"19 Régression univariée et multivariable","heading":"Chargement des packages","text":"Ce bout de code montre le chargement des packages nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur p_load() du package pacman, qui installe le package si nécessaire et le charge pour l’utiliser. Vous pouvez également charger les packages installés avec library() de base R. Voir la page sur R basics pour plus d’informations sur les packages de R.","code":"\npacman::p_load(\n  rio, # Importation du fichier\n  here, # Localisation de fichiers\n  tidyverse, # gestion des données + graphiques ggplot2, \n  stringr, # manipuler des chaînes de texte \n  purrr, # boucle sur les objets d'une manière ordonnée\n  gtsummary, # statistiques et tests sommaires \n  broom, # met de l'ordre dans les résultats des régressions\n  lmtest, # tests du rapport de vraisemblance\n  parameters, # alternative pour mettre de l'ordre dans les résultats des régressions\n  see # alternative pour visualiser les parcelles forestières\n  )"},{"path":"regression.html","id":"importation-de-données-1","chapter":"19 Régression univariée et multivariable","heading":"Importation de données","text":"Nous importons le jeu de données des cas d’une épidémie d’Ebola simulée. Si vous voulez continuer dans le processus d’acquisition de données suivait ce lien, cliquer pour téléchager le jeu de données linelist “propre” (.rds file). Importez vos données avec la fonction import() du packages rio (elle accepte de nombreux types de fichiers comme .xlsx, .rds, .csv - voir la page Importer et exporter des données pour plus de détails)..Les 50 premières lignes de linelist sont affichées ci-dessous.","code":"\n# importer la liste de lignes\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"regression.html","id":"nettoyer-les-données","chapter":"19 Régression univariée et multivariable","heading":"Nettoyer les données","text":"","code":""},{"path":"regression.html","id":"stocker-les-variables-explicatives","chapter":"19 Régression univariée et multivariable","heading":"Stocker les variables explicatives","text":"Nous stockons les noms des colonnes explicatives sous la forme d’un vecteur de caractères. Il sera référencé plus tard.","code":"\n## definir les variables d'interet \nexplanatory_vars <- c(\"gender\", \"fever\", \"chills\", \"cough\", \"aches\", \"vomit\")"},{"path":"regression.html","id":"convertir-en-1-et-0-.non-numéroté","chapter":"19 Régression univariée et multivariable","heading":"19.1.0.1 Convertir en 1 et 0 {.non numéroté}","text":"Ci-dessous, nous convertissons les colonnes explicatives de “yes”/“”, “m”/“f”, et “dead”/“alive” en 1 / 0, pour se conformer avec les attentes des modèles de régression logistique. Pour faire cela efficacement, nous avons utilisé across() de dplyr pour transformer plusieurs colonnes en une seule fois. La fonction que nous appliquons à chaque colonne est case_when() (également dplyr) qui applique une logique pour convertir les valeurs spécifiées en 1 et 0. Voir les sections sur across() et case_when() dans la page Nettoyage de données et fonctions essentielles).Note : le “.” ci-dessous représente la colonne qui est traitée par across() à ce moment-là.","code":"\n## convertir les  variables dichotomique   en  0/1 \nlinelist <- linelist %>%  \n  mutate(across(                                      \n    .cols = all_of(c(explanatory_vars, \"outcome\")),  ## pour chaque colonne listée et \"résultat\"\n    .fns = ~case_when(                              \n      . %in% c(\"m\", \"yes\", \"Death\")   ~ 1,           ## recoder male, yes et death en 1\n      . %in% c(\"f\", \"no\",  \"Recover\") ~ 0)           ## female, no and recover en 0\n                                                     ## autre definir comme valeurs manquantes\n    )\n  )"},{"path":"regression.html","id":"supprimer-les-lignes-avec-des-valeurs-manquantes","chapter":"19 Régression univariée et multivariable","heading":"Supprimer les lignes avec des valeurs manquantes","text":"Pour supprimer les lignes avec des valeurs manquantes, vous pouvez utiliser la fonction tidyr drop_na(). Cependant, nous ne voulons l’utiliser que pour les lignes qui ont des valeurs manquantes dans les colonnes qui nous intéressent.La première chose que nous devons faire est de nous assurer que notre vecteur explanatory_vars exlu la colonne age (age aurait produit une erreur dans l’opération précédente case_when(), qui ne concernait que les variables dichotomiques). Ensuite, nous envoyons la liste de lignes à drop_na() pour enlever toutes les lignes avec des valeurs manquantes dans la colonne outcome ou dans l’une des colonnes explanatory_vars.Avant d’exécuter le code, le nombre de lignes dans la linelist est nrow(linelist).le nombre de lignes restant dans linelist est de nrow(linelist).","code":"\n## ajout de la catégorie d'âge aux variables explicatives \nexplanatory_vars <- c(explanatory_vars, \"age_cat\")\n\n## supprimer les lignes avec des informations manquantes pour les variables d'intérêt \nlinelist <- linelist %>% \n  drop_na(any_of(c(\"outcome\", explanatory_vars)))"},{"path":"regression.html","id":"univarié","chapter":"19 Régression univariée et multivariable","heading":"19.2 Univarié","text":"Tout comme dans la page sur les Tableaux descriptifs, votre cas d’utilisation déterminera le package R que vous utiliserez. Nous vous présentons deux options pour effectuer une analyse univariée :Utiliser les fonctions disponibles dans base R pour afficher rapidement les résultats sur la console. Utilisez le package broom pour mettre de l’ordre dans les résultats.Utilisez le package gtsummary pour modéliser et obtenir des résultats prêts à être publiés.","code":""},{"path":"regression.html","id":"base-r-2","chapter":"19 Régression univariée et multivariable","heading":"base R","text":"","code":""},{"path":"regression.html","id":"régression-linéaire","chapter":"19 Régression univariée et multivariable","heading":"Régression linéaire","text":"La fonction base R lm() effectue une régression linéaire, évaluant la relation entre une réponse numérique et des variables explicatives qui sont supposées avoir une relation linéaire.Fournissez l’équation sous forme de formule, avec les noms des colonnes de réponse et d’explication séparés par un tilde ~. Spécifiez également l’ensemble de données à data =. Définissez les résultats du modèle comme un objet R, à utiliser ultérieurement.Vous pouvez ensuite exécuter summary() sur les résultats du modèle pour voir les coefficients (Estimations), la valeur P, les résidus, et d’autres mesures.Vous pouvez également utiliser la fonction tidy() du package broom pour afficher les résultats dans un tableau.\nles résultats dans un tableau. Les résultats nous indiquent que pour chaque année de plus dans l’âge d’un individu, la taille augmente de de 3,5 cm, ce qui est statistiquement significatif.Vous pouvez également utiliser cette régression pour l’ajouter à un ggplot.\nd’abord prendre les points des données observées et la colonne predite à partir de la ligne ajustée dans un dataframe en utilisant la fonction augment() de broom.Il est également possible d’ajouter une droite de régression linéaire simple dans ggplot\nen utilisant la fonction geom_smooth().Consultez la section Ressources à la fin de ce chapitre pour obtenir des didacticiels plus détaillés.","code":"\nlm_results <- lm(ht_cm ~ age, data = linelist)\nsummary(lm_results)## \n## Call:\n## lm(formula = ht_cm ~ age, data = linelist)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -128.579  -15.854    1.177   15.887  175.483 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  69.9051     0.5979   116.9   <2e-16 ***\n## age           3.4354     0.0293   117.2   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 23.75 on 4165 degrees of freedom\n## Multiple R-squared:  0.7675, Adjusted R-squared:  0.7674 \n## F-statistic: 1.375e+04 on 1 and 4165 DF,  p-value: < 2.2e-16\ntidy(lm_results)## # A tibble: 2 × 5\n##   term        estimate std.error statistic p.value\n##   <chr>          <dbl>     <dbl>     <dbl>   <dbl>\n## 1 (Intercept)    69.9     0.598       117.       0\n## 2 age             3.44    0.0293      117.       0\n## rassembler les points de régression et les données observées dans un seul ensemble de données\npoints <- augment(lm_results)\n\n## creer un graphique  avec age comme   axe  des abscisses\nggplot(points, aes(x = age)) + \n  ## ajouter point pour l'ordonné\n  geom_point(aes(y = ht_cm)) + \n  ## ajouter de la droite de régression linéaire\n  geom_line(aes(y = .fitted), colour = \"red\")\n## ajoute ta donnée dans le graphe\n ggplot(linelist, aes(x = age, y = ht_cm)) + \n  ## montrer les points\n  geom_point() + \n  ## ajouter une regression linéaire\n  geom_smooth(method = \"lm\", se = FALSE)## `geom_smooth()` using formula = 'y ~ x'"},{"path":"regression.html","id":"régression-logistique","chapter":"19 Régression univariée et multivariable","heading":"Régression logistique","text":"La fonction glm() du package stats (faisant partie de base R) est utilisée pour ajuster les modèles linéaires généralisés (GLM).glm() peut être utilisée pour la régression logistique univariée et multivariée (par exemple pour obtenir des Odds Ratios). Voici les parties principales :formula = Le modèle est fourni à glm() sous forme d’équation, avec le résultat à gauche et les variables explicatives à droite d’un tilde ~.family = Ceci détermine le type de modèle à exécuter. Pour la régression logistique, utilisez famille = \"binomiale\", pour le poisson utilisez famille = \"poisson\". D’autres exemples sont dans le tableau ci-dessous.data = Spécifiez votre dataframeSi nécessaire, vous pouvez également spécifier la fonction de lien via la syntaxe family = familytype(link = \"linkfunction\")). Vous pouvez en savoir plus dans la documentation sur les autres familles et les arguments optionnels tels que weights = et subset = (?glm).Lorsque vous exécutez glm(), il est plus courant de sauvegarder les résultats comme un objet R nommé. Vous pouvez ensuite afficher les résultats sur votre console en utilisant summary() comme indiqué ci-dessous, ou effectuer d’autres opérations sur les résultats (par exemple, exponentiation).Si vous avez besoin d’exécuter une régression binomiale négative, vous pouvez utiliser le package MASS ; le glm.nb() utilise la même syntaxe que glm().\nPour une présentation des différentes régressions, consultez la UCLA stats page.","code":"\n# arguments for glm()\nglm(formula, family, data, weights, subset, ...)"},{"path":"regression.html","id":"univarié-glm","chapter":"19 Régression univariée et multivariable","heading":"Univarié glm()","text":"Dans cet exemple, nous évaluons la relation entre différentes catégories d’âge et le résultat du décès (codé 1 dans la section Préparation). Nous présentons ci-dessous un modèle univarié de outcome par age_cat. Nous enregistrons la sortie du modèle sous le nom de model et nous l’affichons ensuite avec summary() sur la console. Notez que les estimations fournies sont les log odds et que le niveau de base est le premier niveau du facteur age_cat (“0-4”).Pour modifier le niveau de base d’une variable donnée, assurez-vous que la colonne est de classe facteur et déplacez le niveau désiré à la première position avec fct_relevel() (voir la page sur Factors). Par exemple, ci-dessous, nous prenons la colonne age_cat et définissons “20-29” comme niveau de base avant de passer le dataframe modifié dans glm().","code":"\nmodel <- glm(outcome ~ age_cat, family = \"binomial\", data = linelist)\nsummary(model)## \n## Call:\n## glm(formula = outcome ~ age_cat, family = \"binomial\", data = linelist)\n## \n## Coefficients:\n##               Estimate Std. Error z value Pr(>|z|)   \n## (Intercept)   0.233738   0.072805   3.210  0.00133 **\n## age_cat5-9   -0.062898   0.101733  -0.618  0.53640   \n## age_cat10-14  0.138204   0.107186   1.289  0.19726   \n## age_cat15-19 -0.005565   0.113343  -0.049  0.96084   \n## age_cat20-29  0.027511   0.102133   0.269  0.78765   \n## age_cat30-49  0.063764   0.113771   0.560  0.57517   \n## age_cat50-69 -0.387889   0.259240  -1.496  0.13459   \n## age_cat70+   -0.639203   0.915770  -0.698  0.48518   \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for binomial family taken to be 1)\n## \n##     Null deviance: 5712.4  on 4166  degrees of freedom\n## Residual deviance: 5705.1  on 4159  degrees of freedom\n## AIC: 5721.1\n## \n## Number of Fisher Scoring iterations: 4\nlinelist %>%\n  mutate(age_cat = fct_relevel(age_cat, \"20-29\", after = 0)) %>% \n  glm(formula = outcome ~ age_cat, family = \"binomial\") %>% \n  summary()## \n## Call:\n## glm(formula = outcome ~ age_cat, family = \"binomial\", data = .)\n## \n## Coefficients:\n##              Estimate Std. Error z value Pr(>|z|)    \n## (Intercept)   0.26125    0.07163   3.647 0.000265 ***\n## age_cat0-4   -0.02751    0.10213  -0.269 0.787652    \n## age_cat5-9   -0.09041    0.10090  -0.896 0.370220    \n## age_cat10-14  0.11069    0.10639   1.040 0.298133    \n## age_cat15-19 -0.03308    0.11259  -0.294 0.768934    \n## age_cat30-49  0.03625    0.11302   0.321 0.748390    \n## age_cat50-69 -0.41540    0.25891  -1.604 0.108625    \n## age_cat70+   -0.66671    0.91568  -0.728 0.466546    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for binomial family taken to be 1)\n## \n##     Null deviance: 5712.4  on 4166  degrees of freedom\n## Residual deviance: 5705.1  on 4159  degrees of freedom\n## AIC: 5721.1\n## \n## Number of Fisher Scoring iterations: 4"},{"path":"regression.html","id":"affichage-des-résultats","chapter":"19 Régression univariée et multivariable","heading":"Affichage des résultats","text":"Pour la plupart des utilisations, plusieurs modifications doivent être apportées aux sorties ci-dessus. La fonction tidy() du package broom est pratique pour rendre les résultats du modèle lisibles et comprehensibles.Nous montrons ici comment combiner les sorties du modèle avec une table de comptage.Obtenez les estimations du logarithm de l’odd ratio exponentiées et les intervalles de confiance en passant le modèle à tidy() et en définissant exponentiate = TRUE et conf.int = TRUE.Voici la sortie du tibble model :Combinez les résultats de ces modèles avec un tableau de comptage. Ci-dessous, nous créons un tableau de comptage croisé avec la fonction tabyl() de janitor, comme indiqué dans la page Tableaux descriptifs.Voici à quoi ressemble ce dataframe counts_table :Maintenant, nous pouvons lier les résultats de counts_table et de model ensemble horizontalement avec bind_cols() (dplyr). Rappelez-vous qu’avec bind_cols() les lignes des deux dataframes doivent être parfaitement alignées. Dans ce code, comme nous effectuons des liaisons dans une chaîne de commandes, nous utilisons . pour représenter l’objet counts_table lorsque nous le lions à model. Pour terminer le processus, nous utilisons select() pour choisir les colonnes souhaitées et leur ordre, et enfin nous appliquons la fonction base R round() sur toutes les colonnes numériques pour spécifier 2 décimales.Voici à quoi ressemble le dataframe combiné, affiché joliment comme une image avec une fonction de flextable. La section Tableau pour la presentationn explique comment personnaliser de tels tableaux avec flextable, ou vous pouvez utiliser de nombreux autres packages tels que knitr ou GT.","code":"\nmodel <- glm(outcome ~ age_cat, family = \"binomial\", data = linelist) %>% \n  tidy(exponentiate = TRUE, conf.int = TRUE) %>%        # exponentiée et  généré IC\n  mutate(across(where(is.numeric), round, digits = 2))  # arrondir tous les colonnes numeriques\ncounts_table <- linelist %>% \n  janitor::tabyl(age_cat, outcome)\ncombined <- counts_table %>%           # debutons avec un tableau de comptage\n  bind_cols(., model) %>%              # combiner avec les sorties de la regression\n  select(term, 2:3, estimate,          # selectionner and arranger les cols\n         conf.low, conf.high, p.value) %>% \n  mutate(across(where(is.numeric), round, digits = 2)) ## arrondir à deux chiffres apres la virgule\ncombined <- combined %>% \n  flextable::qflextable()"},{"path":"regression.html","id":"mettre-en-boucle-plusieurs-modèles-univariés","chapter":"19 Régression univariée et multivariable","heading":"Mettre en Boucle plusieurs modèles univariés","text":"Nous présentons ci-dessous une méthode utilisant glm() et tidy() pour une approche plus simple, voir la section sur gtsummary.Pour exécuter les modèles sur plusieurs variables d’explicative afin de produire des odds ratios univariés (c’est-à-dire sans contrôle des autres variables), vous pouvez utiliser l’approche ci-dessous. Elle utilise str_c() de stringr pour créer des formules univariées (voir Caractères et chaînes de caractères), exécute la régression glm() sur chaque formule, passe chaque sortie glm() à tidy() et enfin rassemble toutes les sorties du modèle avec bind_rows() de tidyr. Cette approche utilise map() du packages purrr pour itérer - voir la page sur [Iteration, loops, lists] pour plus d’informations sur cet outil.Créez un vecteur de noms de colonnes des variables explicatives. Nous l’avons déjà en tant que explanatory_vars dans la section Préparation de cette page.Créez un vecteur de noms de colonnes des variables explicatives. Nous l’avons déjà en tant que explanatory_vars dans la section Préparation de cette page.Utilisez str_c() pour créer plusieurs formules de chaîne, avec outcome à gauche, et un nom de colonne de explanatory_vars à droite. Le point . remplace le nom de la colonne dans explanatory_vars.Utilisez str_c() pour créer plusieurs formules de chaîne, avec outcome à gauche, et un nom de colonne de explanatory_vars à droite. Le point . remplace le nom de la colonne dans explanatory_vars.Passez ces formules de chaîne à map() et définissez ~glm() comme la fonction à appliquer à chaque entrée. Dans glm(), définissez la formule de régression comme .formula(.x) où .x sera remplacé par la formule de chaîne définie dans l’étape précédente. map() bouclera sur chacune des formules en format chaîne de caractères, en effectuant des régressions pour chacune d’entre elles.Passez ces formules de chaîne à map() et définissez ~glm() comme la fonction à appliquer à chaque entrée. Dans glm(), définissez la formule de régression comme .formula(.x) où .x sera remplacé par la formule de chaîne définie dans l’étape précédente. map() bouclera sur chacune des formules en format chaîne de caractères, en effectuant des régressions pour chacune d’entre elles.Les résultats de cette première map() sont passés à une seconde commande map(), qui applique tidy() aux résultats de la régression.Les résultats de cette première map() sont passés à une seconde commande map(), qui applique tidy() aux résultats de la régression.Finalement, la sortie de la seconde commande map() (une liste de dataframe triés) est condensée avec bind_rows(), qui donne un dataframe avec tous les résultats univariés.Finalement, la sortie de la seconde commande map() (une liste de dataframe triés) est condensée avec bind_rows(), qui donne un dataframe avec tous les résultats univariés.Cette fois, l’objet final models est plus long car il représente maintenant les résultats combinés de plusieurs régressions univariées. Cliquez pour voir toutes les lignes de model.Comme précédemment, nous pouvons créer une table des effectifs à partir de la linelist pour chaque variable explicative, la lier à models, et faire une belle table. Nous commençons par les variables, et nous les parcourons avec map(). Nous itérons à travers une fonction définie par l’utilisateur qui implique la création d’une table d’effectifs avec les fonctions dplyr. Ensuite, les résultats sont combinés et liés aux résultats du modèle models.Voici à quoi ressemble le dataframe. Voir la page sur les Tableau pour la presentationn pour des idées sur la façon de convertir ce tableau en une jolie sortie HTML (par exemple avec flextable).","code":"\nexplanatory_vars %>% str_c(\"outcome ~ \", .)## [1] \"outcome ~ gender\"  \"outcome ~ fever\"   \"outcome ~ chills\"  \"outcome ~ cough\"  \n## [5] \"outcome ~ aches\"   \"outcome ~ vomit\"   \"outcome ~ age_cat\"\nmodels <- explanatory_vars %>%       # commencer avec les variables d'interets\n  str_c(\"outcome ~ \", .) %>%         # combiner chaque variable dans une formule (\"outcome ~ variable of interest\")\n  \n  # itérer à travers chaque formule univariée\n  map(                               \n    .f = ~glm(                       # passer les formules une par une à glm()\n      formula = as.formula(.x),      # dans glm(), la formule de la chaîne de caractère est .x\n      family = \"binomial\",           # spécifier le type de glm (logistique)\n      data = linelist)) %>%          # jeu de données\n  \n  # mettre en ordre chacun des résultats de la régression glm ci-dessus\n  map(\n    .f = ~tidy(\n      .x, \n      exponentiate = TRUE,           # exponentiation \n      conf.int = TRUE)) %>%          # retourne les intervalles de confiance\n  \n  # réduire la liste des résultats de la régression en un seul dataframe\n  bind_rows() %>% \n  \n  # arrondir tous les colonnes numeriques\n  mutate(across(where(is.numeric), round, digits = 2))\n## pour chaque variable explicative\nuniv_tab_base <- explanatory_vars %>% \n  map(.f = \n    ~{linelist %>%                ## debuter avec  linelist\n        group_by(outcome) %>%     ## grouper le jeu de donnée par outcome\n        count(.data[[.x]]) %>%    ## produire des comptages pour la variable d'intérêt\n        pivot_wider(              ## étendre à un format large (comme dans un tableau croisé)\n          names_from = outcome,\n          values_from = n) %>% \n        drop_na(.data[[.x]]) %>%         ## éliminer les lignes avec des valeurs manquantes\n        rename(\"variable\" = .x) %>%      ## changer la colonne de la variable d'intérêt en \"variable\".\n        mutate(variable = as.character(variable))} ## convertir en caractères, sinon les variables non-dichotomiques (catégorielles) apparaissent comme des facteurs et ne peuvent pas être fusionnées.\n      ) %>% \n  \n  ## Réduire la liste des sorties de comptage à un seul dataframe\n  bind_rows() %>% \n  \n  ## fusionner avec les sorties de la régression \n  bind_cols(., models) %>% \n  \n  ## ne garder que les colonnes intéressées \n  select(term, 2:3, estimate, conf.low, conf.high, p.value) %>% \n  \n  ## arrondir les décimales\n  mutate(across(where(is.numeric), round, digits = 2))"},{"path":"regression.html","id":"reg_gt_uni","chapter":"19 Régression univariée et multivariable","heading":"gtsummary package","text":"Nous présentons ci-dessous l’utilisation de tbl_uvregression() du package gtsummary. Tout comme dans la page sur les Tableaux descriptifs, les fonctions gtsummary font un bon travail pour exécuter des statistiques et produire des résultats à usage professionnel. Cette fonction produit un tableau des résultats d’une régression univariée.Nous ne sélectionnons que les colonnes nécessaires de la linelist (les variables explicatives et la variable de résultat) et les introduisons dans tbl_uvregression(). Nous allons exécuter une régression univariée sur chacune des colonnes que nous avons définies comme explanatory_vars dans la section Préparation des données (sexe, fièvre, frissons, toux, courbatures, vomissements, et age_cat).Dans la fonction elle-même, nous fournissons la method = comme glm (sans guillemets), la colonne y = outcome (outcome), nous spécifions à method.args = que nous voulons exécuter une régression logistique via family = binomial, et nous lui disons d’exponentiser les résultats.La sortie est en HTML et contient les comptesVous pouvez apporter de nombreuses modifications à ce tableau, par exemple en ajustant les étiquettes de texte, en mettant en gras les lignes en fonction de leur valeur p, etc. Voir les didacticiels ici et ailleurs en ligne.","code":"\nuniv_tab <- linelist %>% \n  dplyr::select(explanatory_vars, outcome) %>% ## selectionner variables d'interet\n\n  tbl_uvregression(                         ## produire un tableau univarié\n    method = glm,                           ## définir la régression que l'on veut exécuter (modèle linéaire généralisé)\n    y = outcome,                            ## définir la variable de résultat\n    method.args = list(family = binomial),  ## définir le type de glm que l'on veut exécuter (logistique)\n    exponentiate = TRUE                     ## exponentiez pour produire des odds ratios (plutôt que des odds logarithmiques)\n  )\n\n## visualiser le tableau des résultats univariés \nuniv_tab"},{"path":"regression.html","id":"stratifié","chapter":"19 Régression univariée et multivariable","heading":"19.3 Stratifié","text":"L’analyse stratifiée est actuellement en cours de développement pour gtsummary,\ncette page sera mise à jour en temps voulu.","code":""},{"path":"regression.html","id":"multivariable","chapter":"19 Régression univariée et multivariable","heading":"19.4 Multivariable","text":"Pour l’analyse multivariable, nous présentons à nouveau deux approches :glm() et tidy().package gtsummary.La methodologie est similaire pour chacune d’entre elles et seule la dernière étape, celle de l’élaboration d’un tableau final, est différente.","code":""},{"path":"regression.html","id":"conduite-multivariable","chapter":"19 Régression univariée et multivariable","heading":"Conduite multivariable","text":"Ici, nous utilisons glm() mais ajoutons plus de variables au côté droit de l’équation, séparées par des symboles plus (+).Pour exécuter le modèle avec toutes nos variables explicatives, nous devrions exécuter :Si vous voulez inclure deux variables et une interaction entre elles, vous pouvez les séparer avec un astérisque * au lieu d’un +. Séparez-les par un deux-points : si vous ne spécifiez que l’interaction. Par exemple :Optionnellement, vous pouvez utiliser ce code pour exploiter le vecteur prédéfini des noms de colonnes et recréer la commande ci-dessus en utilisant str_c(). Cela peut être utile si les noms de vos variables explicatives changent, ou si vous ne voulez pas les taper à nouveau.","code":"\nmv_reg <- glm(outcome ~ gender + fever + chills + cough + aches + vomit + age_cat, family = \"binomial\", data = linelist)\n\nsummary(mv_reg)## \n## Call:\n## glm(formula = outcome ~ gender + fever + chills + cough + aches + \n##     vomit + age_cat, family = \"binomial\", data = linelist)\n## \n## Coefficients:\n##               Estimate Std. Error z value Pr(>|z|)\n## (Intercept)   0.069054   0.131726   0.524    0.600\n## gender        0.002448   0.065133   0.038    0.970\n## fever         0.004309   0.080522   0.054    0.957\n## chills        0.034112   0.078924   0.432    0.666\n## cough         0.138584   0.089909   1.541    0.123\n## aches        -0.070705   0.104078  -0.679    0.497\n## vomit         0.086098   0.062618   1.375    0.169\n## age_cat5-9   -0.063562   0.101851  -0.624    0.533\n## age_cat10-14  0.136372   0.107275   1.271    0.204\n## age_cat15-19 -0.011074   0.113640  -0.097    0.922\n## age_cat20-29  0.026552   0.102780   0.258    0.796\n## age_cat30-49  0.059569   0.116402   0.512    0.609\n## age_cat50-69 -0.388964   0.262384  -1.482    0.138\n## age_cat70+   -0.647443   0.917375  -0.706    0.480\n## \n## (Dispersion parameter for binomial family taken to be 1)\n## \n##     Null deviance: 5712.4  on 4166  degrees of freedom\n## Residual deviance: 5700.2  on 4153  degrees of freedom\n## AIC: 5728.2\n## \n## Number of Fisher Scoring iterations: 4\nglm(outcome ~ gender + age_cat * fever, family = \"binomial\", data = linelist)\n## effectuer une régression avec toutes les variables d'intérêt \nmv_reg <- explanatory_vars %>%  ## commencer par un vecteur de noms de colonnes explicatives\n  str_c(collapse = \"+\") %>%     ## combiner tous les noms des variables d'intérêt séparés par un plus\n  str_c(\"outcome ~ \", .) %>%    ## combiner les noms des variables d'intérêt avec le résultat dans le style d'une formule\n  glm(family = \"binomial\",      ## définir le type de glm comme logistique,\n      data = linelist)          ## définir votre jeu de données"},{"path":"regression.html","id":"construire-le-modèle","chapter":"19 Régression univariée et multivariable","heading":"Construire le modèle","text":"Vous pouvez construire votre modèle étape par étape, en enregistrant plusieurs modèles qui incluent certaines variables explicatives. Vous pouvez comparer ces modèles avec des tests de rapport de vraisemblance en utilisant lrtest() du package lmtest, comme ci-dessous :NOTE: L’utilisation de base anova(model1, model2, test = \"Chisq) produit les mêmes résultats Une autre option consiste à prendre l’objet modèle et à appliquer la fonction step() du package stats. Spécifiez la direction de sélection des variables que vous souhaitez utiliser lors de la construction du modèle.Vous pouvez également désactiver la notation scientifique dans votre session R, pour plus de clarté :Comme décrit dans la section sur l’analyse univariée, nous passons la sortie du modèle à tidy() pour exponentialiser les probabilités logarithmiques et les IC. Enfin, nous arrondissons toutes les colonnes numériques à deux décimales. Faites défiler pour voir toutes les lignes.Voici à quoi ressemble le dataframe obtenu :","code":"\nmodel1 <- glm(outcome ~ age_cat, family = \"binomial\", data = linelist)\nmodel2 <- glm(outcome ~ age_cat + gender, family = \"binomial\", data = linelist)\n\nlmtest::lrtest(model1, model2)## Likelihood ratio test\n## \n## Model 1: outcome ~ age_cat\n## Model 2: outcome ~ age_cat + gender\n##   #Df  LogLik Df  Chisq Pr(>Chisq)\n## 1   8 -2852.6                     \n## 2   9 -2852.6  1 0.0002     0.9883\n## choisir un modèle en utilisant la sélection avant basée sur l'AIC\n## vous pouvez aussi faire \"backward\" ou \"both\" en ajustant la direction.\nfinal_mv_reg <- mv_reg %>%\n  step(direction = \"forward\", trace = FALSE)\noptions(scipen=999)\nmv_tab_base <- final_mv_reg %>% \n  broom::tidy(exponentiate = TRUE, conf.int = TRUE) %>%  ## obtenir un tidy  dataframe d'estimations \n  mutate(across(where(is.numeric), round, digits = 2))          ## arrondir"},{"path":"regression.html","id":"combiner-univarié-et-multivariable","chapter":"19 Régression univariée et multivariable","heading":"Combiner univarié et multivariable","text":"","code":""},{"path":"regression.html","id":"combinez-avec-gtsummary","chapter":"19 Régression univariée et multivariable","heading":"Combinez avec gtsummary","text":"Le package gtsummary fournit la fonction tbl_regression(), qui prendra . les sorties d’une régression (glm() dans ce cas) et produira un joli tableau de synthèse.\ntableau récapitulatif.Voyons le tableau :Vous pouvez également combiner plusieurs tableaux de sortie différents produits par gtsummary avec\nla fonction tbl_merge(). Nous combinons maintenant les résultats multivariables avec les résultats univariés de gtsummary que nous avons créés ci-dessus:","code":"\n## montrer le tableau des résultats de la régression finale \nmv_tab <- tbl_regression(final_mv_reg, exponentiate = TRUE)\nmv_tab\n## combiner avec les résultats univariés \ntbl_merge(\n  tbls = list(univ_tab, mv_tab),                          # combiner\n  tab_spanner = c(\"**Univariate**\", \"**Multivariable**\")) # definier les entetes des colonnes"},{"path":"regression.html","id":"combiner-avec-dplyr","chapter":"19 Régression univariée et multivariable","heading":"Combiner avec dplyr","text":"Une autre façon de combiner les sorties univariées et multivariées de glm()/tidy() est d’utiliser les fonctions de jonction dplyr.fusionner les résultats univariés de tout à l’heure (univ_tab_base, qui contient les comptages) avec les résultats multivariables triés mv_tab_base.Utilisez select() pour ne garder que les colonnes que nous voulons, spécifier leur ordre, et les renommer.Utilisez round() avec deux décimales sur toutes les colonnes qui sont classe Double","code":"\n## combiner des tableaux univariés et multivariés \nleft_join(univ_tab_base, mv_tab_base, by = \"term\") %>% \n  ##choisir les colonnes et les renommer\n  select( # nouveau nom = ancien nom\n    \"characteristic\" = term, \n    \"recovered\"      = \"0\", \n    \"dead\"           = \"1\", \n    \"univ_or\"        = estimate.x, \n    \"univ_ci_low\"    = conf.low.x, \n    \"univ_ci_high\"   = conf.high.x,\n    \"univ_pval\"      = p.value.x, \n    \"mv_or\"          = estimate.y, \n    \"mvv_ci_low\"     = conf.low.y, \n    \"mv_ci_high\"     = conf.high.y,\n    \"mv_pval\"        = p.value.y \n  ) %>% \n  mutate(across(where(is.double), round, 2))   ## # A tibble: 20 × 11\n##    characteristic recovered  dead univ_or univ_ci_low univ_ci_high univ_pval mv_or\n##    <chr>              <dbl> <dbl>   <dbl>       <dbl>        <dbl>     <dbl> <dbl>\n##  1 (Intercept)          909  1168    1.28        1.18         1.4       0     1.07\n##  2 gender               916  1174    1           0.88         1.13      0.97  1   \n##  3 (Intercept)          340   436    1.28        1.11         1.48      0     1.07\n##  4 fever               1485  1906    1           0.85         1.17      0.99  1   \n##  5 (Intercept)         1472  1877    1.28        1.19         1.37      0     1.07\n##  6 chills               353   465    1.03        0.89         1.21      0.68  1.03\n##  7 (Intercept)          272   309    1.14        0.97         1.34      0.13  1.07\n##  8 cough               1553  2033    1.15        0.97         1.37      0.11  1.15\n##  9 (Intercept)         1636  2114    1.29        1.21         1.38      0     1.07\n## 10 aches                189   228    0.93        0.76         1.14      0.51  0.93\n## 11 (Intercept)          931  1144    1.23        1.13         1.34      0     1.07\n## 12 vomit                894  1198    1.09        0.96         1.23      0.17  1.09\n## 13 (Intercept)          338   427    1.26        1.1          1.46      0     1.07\n## 14 age_cat5-9           365   433    0.94        0.77         1.15      0.54  0.94\n## 15 age_cat10-14         273   396    1.15        0.93         1.42      0.2   1.15\n## 16 age_cat15-19         238   299    0.99        0.8          1.24      0.96  0.99\n## 17 age_cat20-29         345   448    1.03        0.84         1.26      0.79  1.03\n## 18 age_cat30-49         228   307    1.07        0.85         1.33      0.58  1.06\n## 19 age_cat50-69          35    30    0.68        0.41         1.13      0.13  0.68\n## 20 age_cat70+             3     2    0.53        0.07         3.2       0.49  0.52\n## # ℹ 3 more variables: mvv_ci_low <dbl>, mv_ci_high <dbl>, mv_pval <dbl>"},{"path":"regression.html","id":"forest-plot","chapter":"19 Régression univariée et multivariable","heading":"19.5 Forest plot","text":"Cette section montre comment produire un graphique avec les résultats de votre régression.\nIl y deux options, vous pouvez construire un graphique vous-même en utilisant ggplot2 ou utiliser un méta-package appelé easystats (un package qui inclut plusieurs packages).\nméta-package appelé easystats (un package qui inclut plusieurs packages).Consultez la page sur Les bases de ggplot si vous n’êtes pas familier avec le package de traçage ggplot2.","code":""},{"path":"regression.html","id":"ggplot2-package","chapter":"19 Régression univariée et multivariable","heading":"ggplot2 package","text":"Vous pouvez construire un graphique forest avec ggplot() en traçant les éléments des résultats de la régression multivariable. Ajoutez les couches des tracés en utilisant ces “geoms” :estimations avec geom_point()intervalles de confiance avec “geom_errorbar()`”.une ligne verticale à = 1 avec geom_vline().Avant de tracer un graphique, vous pouvez utiliser fct_relevel() du package forcats pour définir l’ordre des variables/niveaux sur l’axe des ordonnées. ggplot() peut les afficher dans l’ordre alpha-numérique, ce qui ne fonctionnerait pas bien pour ces valeurs de catégories d’âge (“30” apparaîtrait avant “5”). Voir la page sur les facteurs pour plus de détails.","code":"\n## enlever le terme intercept dans le resultats multivariables\nmv_tab_base %>% \n  \n  #definir l'odre d'apparition des niveaux  le long de l'axe y \n  mutate(term = fct_relevel(\n    term,\n    \"vomit\", \"gender\", \"fever\", \"cough\", \"chills\", \"aches\",\n    \"age_cat5-9\", \"age_cat10-14\", \"age_cat15-19\", \"age_cat20-29\",\n    \"age_cat30-49\", \"age_cat50-69\", \"age_cat70+\")) %>%\n  \n  # supprimer la ligne denommé \"intercept\" dans le graphique\n  filter(term != \"(Intercept)\") %>% \n  \n  ## concevoir un graphe avec la variable sur l'axe des y et l'estimation (OR) sur l'axe des x\n  \n  ggplot(aes(x = estimate, y = term)) +\n  \n  ## montrer  estimate  comme un point\n  geom_point() + \n  \n  ## ajouter une barre d'erreur pour les intervalles de confiance\n  geom_errorbar(aes(xmin = conf.low, xmax = conf.high)) + \n  \n  ## montrer où OR = 1 est pour référence comme une ligne pointillée\n  geom_vline(xintercept = 1, linetype = \"dashed\")"},{"path":"regression.html","id":"packages-easystats","chapter":"19 Régression univariée et multivariable","heading":"Packages easystats","text":"Une alternative, si vous ne voulez pas le bon niveau de contrôle que ggplot2 fournit, est d’utiliser une combinaison des packages easystats.La fonction model_parameters() du package parameters fait l’équivalent de la fonction du package broom.\nde la fonction tidy() du package broom. Le package see accepte alors ces sorties\net crée un graphique forest par défaut sous la forme d’un objet ggplot().","code":"\npacman::p_load(easystats)\n\n## supprimer le terme interception de vos résultats multivariables\nfinal_mv_reg %>% \n  model_parameters(exponentiate = TRUE) %>% \n  plot()"},{"path":"regression.html","id":"ressources-7","chapter":"19 Régression univariée et multivariable","heading":"19.6 Ressources","text":"Le contenu de cette page été alimenté par ces ressources et vignettes en ligne :Linear regression RgtsummaryUCLA stats pagesthda stepwise regression","code":""},{"path":"missing_data.html","id":"missing_data","chapter":"20 Données manquantes","heading":"20 Données manquantes","text":"Dans ce chapitre nous allons :\n1) Évaluer l’ampleur des données manquantes\n2) Filtrer les lignes en contenant des données manquantes\n3) Visualiser les données manquantes au cours du temps\n4) Gérer comment les NA apparaissent dans les graphes\n5) Imputer des données manquantes : MMCA, MA, MOP","code":""},{"path":"missing_data.html","id":"étapes-préliminaires-3","chapter":"20 Données manquantes","heading":"20.1 Étapes préliminaires","text":"","code":""},{"path":"missing_data.html","id":"importation-des-paquets-4","chapter":"20 Données manquantes","heading":"Importation des paquets","text":"Ces lignes de code chargent les paquets nécessaires aux analyses. Dans ce guide, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire puis l’importe pour l’utiliser. Vous pouvez également charger les paquets installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les paquets R.","code":"\npacman::p_load(\n  rio,           # import des fichiers\n  tidyverse,     # gestion des données + graphiques (ggplot2)\n  naniar,        # bilan des données manquantes\n  mice           # imputation\n)"},{"path":"missing_data.html","id":"importation-des-données-4","chapter":"20 Données manquantes","heading":"Importation des données","text":"Nous importons un jeu de données de cas d’une épidémie d’ébola fictive. Pour reproduire les étapes, cliquez pour télécharger la linelist “propre” (.rds file). Importez vos données avec la fonction import() du paquet rio (elle accepte de nombreux types de fichiers comme .xlsx, .rds, .csv - voir la page Importation et exportation des données pour plus de détails).Les cinquantes premières lignes sont affichées ci-dessous :","code":"\n# importer la linelist dans R\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"missing_data.html","id":"conversion-des-données-manquantes-lors-de-limport","chapter":"20 Données manquantes","heading":"Conversion des données manquantes lors de l’import","text":"Il faut être particulièrement attentif aux valeurs qui doivent être classifiées comme “manquantes” lors de l’import des données. Des données manquantes peuvent par exemple être indiquées par 99, 999, “Manquant”, un espace vide (” “) ou des cellules vides (”“). Vous pouvez les convertir en NA via la fonction d’importation des données.\nPour plus de détails, consultez la page sur l’importation des Données manquantes, car la syntaxe exacte varie selon le type de fichier.","code":""},{"path":"missing_data.html","id":"valeurs-manquantes-dans-r","chapter":"20 Données manquantes","heading":"20.2 Valeurs manquantes dans R","text":"Nous explorons ci-dessous les façons dont les données manquantes sont représentées et évaluées dans R.","code":""},{"path":"missing_data.html","id":"na","chapter":"20 Données manquantes","heading":"NA","text":"En R, les valeurs manquantes sont représentées par un mot réservé (spécial) : NA (pour “Non available”). Notez que ce mot est tapé sans guillemets, et ne doit pas être confondu avec une chaîne de caractères “NA” (également une parole des Beatles de la chanson Hey Jude).Les données manquantes peuvent avoir été encodées de divers manières dans les données brutes, telles que “99”, “Manquant”, “Inconnu”, une valeur de caractère vide “” qui ressemble à un “blanc”, ou un espace simple ” “. Tenez-en compte et réfléchissez à l’opportunité de les convertir en NA pendant l’importation ou pendant le nettoyage des données avec na_if().l’inverse, lors du nettoyage des données, il peut également être pertinent de convertir des NA en “Manquant” (ou autre) avec les fonctions replace_na() ou fct_explicit_na() dans le cas des facteurs.","code":""},{"path":"missing_data.html","id":"na-et-ses-dérivés","chapter":"20 Données manquantes","heading":"NA et ses dérivés","text":"La plupart du temps, NA représente une valeur manquante et il n’y pas besoin de se poser plus de questions que ça. Cependant, dans certaines circonstances, il peut y avoir besoin de variations de NA spécifiques à une classe d’objet (caractère, numérique, etc.). C’est rare, mais ça peut arriver.Parmi ces cas rares, la création d’une nouvelle colonne avec la fonction dplyr case_when() est le plus commun. Comme décrit dans la page Nettoyage des données et fonctions de base, cette fonction évalue chaque ligne du dataframe, détermine si les lignes répondent à des critères logiques spécifiés (partie droite du code), et attribue la nouvelle valeur correcte (partie gauche du code). Important : toutes les valeurs du côté droit doivent être de la même classe.Afin que toutes les valeurs spécifiées du côté droit des équations aient le même type, il faut utiliser des dérivés de NA avec un type connu. Si les autres valeurs de droite sont des chaines de caractères, peut utiliser NA_character_ ou envisager d’utiliser “Manquant” à la place. Si les valeurs sont toutes numériques, utiliser NA_real_. S’il s’agit de dates ou de valeurs logiques, peut conserver NA.NA - à utiliser pour les dates ou les booléens VRAI/FAUXNA_character_ - à utiliser pour les chaines de caractèresNA_real_ - pour les valeurs numériquesEncore une fois, il est peu probable que vous rencontriez ces variations, hors utilisation de case_when() pour créer une nouvelle colonne. Consultez la documentation R sur NA pour plus d’informations.","code":"\nlinelist <- linelist %>% \n  \n  # Créer une nouvelle colonne \"age_years\" à partir de la colonne \"age\"\n  mutate(age_years = case_when(\n    age_unit == \"years\"  ~ age,    # si l'unité est années => garder la valeur originale\n    age_unit == \"months\" ~ age/12, # l'unité est en mois, diviser par 12\n    is.na(age_unit)      ~ age,    # si l'unité est manquante, supposer que l'age est en années\n    TRUE                 ~ NA_real_)) # sinon, définir age comme valeur manquante"},{"path":"missing_data.html","id":"null","chapter":"20 Données manquantes","heading":"NULL","text":"NULL est un autre mot réservée en R. C’est la représentation logique d’une déclaration qui n’est ni vraie ni fausse. Elle est retournée par des expressions ou des fonctions dont les valeurs sont indéfinies. En général, n’assignez pas NULL comme valeur, à moins d’écrire des fonctions ou peut-être une shiny app pour retourner NULL dans des scénarios spécifiques.La nullité peut être évaluée avec .null() et la conversion peut être faite avec .null().Voir cet article de blog sur la différence entre NULL et NA.","code":""},{"path":"missing_data.html","id":"nan","chapter":"20 Données manquantes","heading":"NaN","text":"Les valeurs impossibles sont représentées par le mot spécial NaN. Par exemple, R renvoi NaN si vous lui demandez de diviser 0 par 0. NaN peut être évalué avec .nan(). Il existe également des fonctions complémentaires comme .infinite() et .finite().","code":""},{"path":"missing_data.html","id":"inf","chapter":"20 Données manquantes","heading":"Inf","text":"Inf représente une valeur infinie, telle que l’peut par exemple obtenir en divisant un nombre par zéro.","code":""},{"path":"missing_data.html","id":"exemples-1","chapter":"20 Données manquantes","heading":"Exemples","text":"Pour comprendre comment ce type de valeurs peuvent affecter vos analyses, imaginons que vous avez un vecteur z qui contient ces valeurs : z <- c(1, 22, NA, Inf, NaN, 5).Si vous voulez utiliser la fonction max() sur la colonne pour trouver la valeur la plus élevée, vous pouvez utiliser le na.rm = TRUE pour omettre le NA du calcul. Mais cela n’enlèvera pas les Inf et NaN, ce qui fait que le résultat retourné sera Inf. Pour résoudre ce problème, vous pouvez utiliser les crochets [ ] et .finite() pour effectuer un sous-ensemble de sorte que seules les valeurs finies soient utilisées pour le calcul : max(z[.finite(z)]).Un message d’avertissement que vous rencontrerez certainement est “NAs introduits par coercition”. Cela peut se produire si vous tentez d’effectuer une conversion illégale, par exemple en insérant une chaîne caractères dans un vecteur qui contient des valeurs numériques.Note : NULL est ignoré dans un vecteur.Note : tenter de calculer la variance sur une valeur unique retourne également un NA.","code":"\nz <- c(1, 22, NA, Inf, NaN, 5)\nmax(z)                           # retourne NA\nmax(z, na.rm=T)                  # retourne Inf\nmax(z[is.finite(z)])             # retourne 22\nas.numeric(c(\"10\", \"20\", \"thirty\", \"40\"))## Warning: NAs introduced by coercion## [1] 10 20 NA 40\nmy_vector <- c(25, NA, 10, NULL)  # définit\nmy_vector                         # affiche## [1] 25 NA 10\nvar(22)## [1] NA"},{"path":"missing_data.html","id":"fonctions-utiles","chapter":"20 Données manquantes","heading":"20.3 Fonctions utiles","text":"Voici quelques fonctions utiles en base R pour détecter et gérer les valeurs manquantes.","code":""},{"path":"missing_data.html","id":"is.na-et-is.na","chapter":"20 Données manquantes","heading":"is.na() et !is.na()","text":".na() permet d’identifier les valeurs manquantes. Pour identifier les valeurs non manquantes il suffit d’utiliser son opposé en ajoutant ! devant l’instruction. Ces deux méthodes retournent une valeur logique (TRUE ou FALSE). Pour rappel, il est possible de sommer le vecteur résultant avec sum() pour compter le nombre de TRUE. Par exemple : sum(.na(linelist$date_outcome)).","code":"\nmy_vector <- c(1, 4, 56, NA, 5, NA, 22)\nis.na(my_vector)## [1] FALSE FALSE FALSE  TRUE FALSE  TRUE FALSE\n!is.na(my_vector)## [1]  TRUE  TRUE  TRUE FALSE  TRUE FALSE  TRUE\nsum(is.na(my_vector))## [1] 2"},{"path":"missing_data.html","id":"na.omit","chapter":"20 Données manquantes","heading":"na.omit()","text":"Appliquée à un dataframe, cette fonction de base R supprimera les lignes dont toutes les valeurs sont manquantes. Appliquée à un vecteur, elle supprimera les valeurs NA de ce vecteur. Par exemple :","code":"\nna.omit(my_vector)## [1]  1  4 56  5 22\n## attr(,\"na.action\")\n## [1] 4 6\n## attr(,\"class\")\n## [1] \"omit\""},{"path":"missing_data.html","id":"drop_na","chapter":"20 Données manquantes","heading":"drop_na()","text":"Il s’agit d’une fonction de tidyr utile pour nettoyer des données dans un pipeline. Si elle est exécutée sans argument, elle supprime également les lignes dont toutes les valeurs sont manquantes. Mais si des noms de colonnes sont spécifiés comme arguments, seules les lignes avec des valeurs manquantes dans ces colonnes seront supprimées.Note : peut utiliser la syntaxe “tidyselect” pour spécifier les colonnes.","code":"\nlinelist %>% \n  drop_na(case_id, date_onset, age) # omet les lignes contenant des valeurs manquantes dans une de ces colonnes au moins"},{"path":"missing_data.html","id":"na.rm-true","chapter":"20 Données manquantes","heading":"na.rm = TRUE","text":"Lorsque vous exécutez une fonction mathématique telle que max(), min(), sum() ou mean(), la valeur retournée est NA si des valeurs NA sont présentes dans les données. Ce comportement par défaut est intentionnel, afin que vous soyez alerté si l’une de vos données est manquante.Vous pouvez éviter cela en supprimant les valeurs manquantes du calcul. Pour ce faire, incluez l’argument na.rm = TRUE (le “rm” étant une abréviation de “remove”).","code":"\nmy_vector <- c(1, 4, 56, NA, 5, NA, 22)\n\nmean(my_vector)     ## [1] NA\nmean(my_vector, na.rm = TRUE)## [1] 17.6"},{"path":"missing_data.html","id":"identifier-les-valeurs-manquantes-dans-un-dataframe","chapter":"20 Données manquantes","heading":"20.4 Identifier les valeurs manquantes dans un dataframe","text":"Le package naniar permet de détecter et de visualiser l’ampleur de la complétude des données (et donc de leur non-complétude) dans un tableau de données.","code":"\n# installer et charger le paquet\npacman::p_load(naniar)"},{"path":"missing_data.html","id":"quantifier-les-données-manquantes","chapter":"20 Données manquantes","heading":"Quantifier les données manquantes","text":"La fonction pct_miss() permet de calculer le pourcentage de toutes les valeurs manquantes. La fonction n_miss() renvoi le nombre de valeurs manquantes.Les deux fonctions ci-dessous renvoient le pourcentage de lignes dont une valeur est manquante ou qui sont entièrement complètes.Note : NA signifie manquant, mais que `\"\" ou \"\" ne sont pas considérées comme des valeurs manquantes.","code":"\n# pourcentage de données manquantes sur TOUTES les valeurs du dataframe\npct_miss(linelist)## [1] 6.688745\n# Pourcentage des lignes avec au moins une valeur manquante\npct_miss_case(linelist)   # utiliser n_miss() pour le nombre de lignes## [1] 69.12364\n# Pourcentage des lignes sans valeur manquante\npct_complete_case(linelist) # utiliser n_complete() pour le nombre## [1] 30.87636"},{"path":"missing_data.html","id":"visualiser-les-données-manquantes","chapter":"20 Données manquantes","heading":"Visualiser les données manquantes","text":"La fonction gg_miss_var() renvoi le nombre (ou %) de valeurs manquantes dans chaque colonne. Quelques notes :Il est possible d’ajouter un nom de colonne (pas entre guillemets) à l’argument facet = pour voir le graphique par groupe.Il est possible d’ajouter un nom de colonne (pas entre guillemets) à l’argument facet = pour voir le graphique par groupe.Les nombres sont affichés par défaut. Utilisez show_pct = TRUE pour voir les pourcentages, .Les nombres sont affichés par défaut. Utilisez show_pct = TRUE pour voir les pourcentages, .Il est possible d’ajouter des étiquettes d’axe et de titre comme pour un ggplot() normal avec + labs(...).Il est possible d’ajouter des étiquettes d’axe et de titre comme pour un ggplot() normal avec + labs(...).Ici, les données sont passées à la fonction à l’aide d’un pipe %>%. L’argument facet = est utilisé pour séparer les données par outcome.La fonction vis_miss() permet de visualiser le dataframe sous forme de carte thermique qui indique quelle valeur est manquante. Vous pouvez également select() certaines colonnes du cadre de données et ne fournir que ces colonnes à la fonction.","code":"\ngg_miss_var(linelist, show_pct = TRUE)\nlinelist %>% \n  gg_miss_var(show_pct = TRUE, facet = outcome)\n# Carte thermique de la complétude des données à l'échelle du dataframe\nvis_miss(linelist)"},{"path":"missing_data.html","id":"explorer-et-visualiser-les-relations-entre-données-manquantes","chapter":"20 Données manquantes","heading":"Explorer et visualiser les relations entre données manquantes","text":"Comment visualiser quelque chose qui n’existe pas ??? Par défaut, ggplot() n’affiche pas les points avec des valeurs manquantes dans les graphiques.Le package naniar propose une solution via la fonction geom_miss_point(). Lors de la création d’un nuage de points à partir de deux variables, les paires de valeurs dont l’une est manquante sont montrés en fixant les valeurs manquante à 10% plus bas que la valeur minimale de la colonne, et en les colorant différemment.Dans le nuage de points ci-dessous, les points rouges sont des enregistrements où la valeur d’une des deux colonne est présente mais où l’autre est manquante. Cela permet de visualiser la distribution des valeurs manquantes par rapport à celle des valeurs non manquantes.Pour évaluer les données manquantes dans un dataframe en stratifiant par une autre colonne, peut utiliser la fonction gg_miss_fct(), qui retourne une carte thermique du pourcentage de valeurs manquantes dans le dataframe pour chaque catégorie d’une autre variable :Cette fonction peut aussi être utilisée sur une colonne contenant des dates pour voir comment la complétude des données change au cours du temps :","code":"\nggplot(\n  data = linelist,\n  mapping = aes(x = age_years, y = temp)) +     \n  geom_miss_point()\ngg_miss_fct(linelist, age_cat5)\ngg_miss_fct(linelist, date_onset)## Warning: Removed 29 rows containing missing values (`geom_tile()`)."},{"path":"missing_data.html","id":"colonnes-fantômes","chapter":"20 Données manquantes","heading":"Colonnes “fantômes”","text":"naniar donne la possibilité de créer un jeu de données “fantôme” (“shadow matrix” en Anglais) pour aller plus loin dans l’étude de la distribution des données manquantes. Essentiellement, pour chaque colonne existante la fonction bind_shadow() crée une nouvelle colonne binaire contenant soit NA, soit !NA (pour “non NA”), et lie toutes ces nouvelles colonnes au jeu de données original avec l’appendice “_NA”. Cela double le nombre de colonnes du jeu de données :Ces colonnes “fantômes” peuvent être utilisées pour visualiser la proportion de valeurs manquantes dans une colonne en fonction d’une autre colonne.Par exemple, le graphique ci-dessous montre la proportion de données manquantes dans la colonne days_onset_hosp (le nombre de jours entre l’apparition des symptômes et l’hospitalisation), en fonction de la date_hospitalisation. Ici trace la densité de données manquantes et non manquantes (color =) en fonction de la date d’hospitalisation.Ce type de visualisation fonctionne mieux si la variable tracée en sur l’axe des abscisses est numérique ou temporelle.Les colonnes fantômes peuvent aussi être utilisé comme stratification dans des statistiques descriptives :naniar n’est pas le seul outil pour représenter la proportion de valeurs manquantes dans une colonne en fonction du temps. peut aussi manuellement :Agréger les données dans une unité de temps pertinente (jours, semaines, etc.), en résumant la proportion d’observations avec NA (et toute autre valeur d’intérêt).Agréger les données dans une unité de temps pertinente (jours, semaines, etc.), en résumant la proportion d’observations avec NA (et toute autre valeur d’intérêt).Tracez la proportion de données manquantes comme une ligne en utilisant ggplot().Tracez la proportion de données manquantes comme une ligne en utilisant ggplot().Dans l’exemple ci-dessous, nous ajoutons une nouvelle colonne pour la semaine à la linelist, regroupons les données par semaine, puis calculons le pourcentage des enregistrements de cette semaine où la valeur est manquante. (note : si vous voulez le % de 7 jours, le calcul sera légèrement différent).Ensuite, nous traçons la proportion de données manquantes par semaine, sous forme de ligne.\nRéférez vous à la page bases de ggplot si vous n’êtes pas familier avec le package ggplot2.","code":"\nshadowed_linelist <- linelist %>% \n  bind_shadow()\n\nnames(shadowed_linelist)##  [1] \"case_id\"                 \"generation\"              \"date_infection\"         \n##  [4] \"date_onset\"              \"date_hospitalisation\"    \"date_outcome\"           \n##  [7] \"outcome\"                 \"gender\"                  \"age\"                    \n## [10] \"age_unit\"                \"age_years\"               \"age_cat\"                \n## [13] \"age_cat5\"                \"hospital\"                \"lon\"                    \n## [16] \"lat\"                     \"infector\"                \"source\"                 \n## [19] \"wt_kg\"                   \"ht_cm\"                   \"ct_blood\"               \n## [22] \"fever\"                   \"chills\"                  \"cough\"                  \n## [25] \"aches\"                   \"vomit\"                   \"temp\"                   \n## [28] \"time_admission\"          \"bmi\"                     \"days_onset_hosp\"        \n## [31] \"case_id_NA\"              \"generation_NA\"           \"date_infection_NA\"      \n## [34] \"date_onset_NA\"           \"date_hospitalisation_NA\" \"date_outcome_NA\"        \n## [37] \"outcome_NA\"              \"gender_NA\"               \"age_NA\"                 \n## [40] \"age_unit_NA\"             \"age_years_NA\"            \"age_cat_NA\"             \n## [43] \"age_cat5_NA\"             \"hospital_NA\"             \"lon_NA\"                 \n## [46] \"lat_NA\"                  \"infector_NA\"             \"source_NA\"              \n## [49] \"wt_kg_NA\"                \"ht_cm_NA\"                \"ct_blood_NA\"            \n## [52] \"fever_NA\"                \"chills_NA\"               \"cough_NA\"               \n## [55] \"aches_NA\"                \"vomit_NA\"                \"temp_NA\"                \n## [58] \"time_admission_NA\"       \"bmi_NA\"                  \"days_onset_hosp_NA\"\nggplot(data = shadowed_linelist,   # dataframe augmenté avec les colonnes fantômes\n  mapping = aes(x = date_hospitalisation, # colonne numérique ou date\n                colour = age_years_NA)) + # colonne fantôme d'intérêt\n  geom_density()                          # trace les courbes de densité\nlinelist %>%\n  bind_shadow() %>%                # création des colonnes fantômes\n  group_by(date_outcome_NA) %>%    # groupe par la colonne fantôme de date_outcome\n  summarise(across(\n    .cols = age_years,             # variable d'intérêt à résumer\n    .fns = list(\"mean\" = mean,     # statistiques\n                \"sd\"  = sd,\n                \"var\" = var,\n                \"min\" = min,\n                \"max\" = max),  \n    na.rm = TRUE))                 # autres arguments des fonctions statistiques## # A tibble: 2 × 6\n##   date_outcome_NA age_years_mean age_years_sd age_years_var age_years_min age_years_max\n##   <fct>                    <dbl>        <dbl>         <dbl>         <dbl>         <dbl>\n## 1 !NA                       16.0         12.6          158.             0            84\n## 2 NA                        16.2         12.9          167.             0            69\noutcome_missing <- linelist %>%\n  mutate(week = lubridate::floor_date(date_onset, \"week\")) %>%   # crée colonne semaine\n  group_by(week) %>%      # groupe les lignes par semaine\n  summarise(              # pour chaque semaine, résumme : \n    n_obs = n(),          # nombre total d'observations\n    outcome_missing = sum(is.na(outcome) | outcome == \"\"),  # nombre d'obs avec valeur manquante\n    outcome_p_miss  = outcome_missing / n_obs,    # proportion d'obs avec valeur manquante\n  \n    outcome_dead    = sum(outcome == \"Death\", na.rm=T),     # nb de morts\n    outcome_p_dead  = outcome_dead / n_obs) %>%             # prop morts\n  \n  tidyr::pivot_longer(-week, names_to = \"statistic\") %>%    # pivote toutes les colonnes sauf la semaine en format long\n  filter(stringr::str_detect(statistic, \"_p_\"))   # garde uniquement les proportions\nggplot(data = outcome_missing) +\n    geom_line(\n      mapping = aes(x = week, \n                    y = value, \n                    group = statistic, \n                    color = statistic),\n      size = 2,\n      stat = \"identity\") +\n    labs(title = \"Weekly outcomes\",\n         x = \"Week\",\n         y = \"Proportion of weekly records\") + \n     scale_color_discrete(\n       name = \"\",\n       labels = c(\"Died\", \"Missing outcome\")) +\n    scale_y_continuous(breaks = c(seq(0, 1, 0.1))) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")"},{"path":"missing_data.html","id":"utiliser-des-données-avec-des-valeurs-manquantes","chapter":"20 Données manquantes","heading":"20.5 Utiliser des données avec des valeurs manquantes","text":"","code":""},{"path":"missing_data.html","id":"filtrer-les-lignes-avec-valeurs-manquantes","chapter":"20 Données manquantes","heading":"Filtrer les lignes avec valeurs manquantes","text":"La fonction drop_na() de dplyr permet de se débarrasser rapidement des lignes avec des valeurs manquantes.La linelist originale contient nrow(linelist) lignes. La linelist sans lignes avec des valeurs manquantes contient moins de lignes :peut choisir de ne se débarrasser des lignes avec des valeurs manquantes que dans certaines colonnes :peut passer plusieurs colonnes l’une après l’autre à la fonction, ou utiliser des fonctions utilitaires de “tidyselect”:","code":"\nlinelist %>% \n  drop_na() %>%     # filtre les lignes sans aucune valeur manquante\n  nrow()## [1] 1818\nlinelist %>% \n  drop_na(date_onset) %>% # omet les lignes avec des valeurs manquantes dans date_onset\n  nrow()## [1] 5632\nlinelist %>% \n  drop_na(contains(\"date\")) %>% # omet lignes avec NA dans n'importe quelle colonne dont le nom contient \"date\"\n  nrow()## [1] 3029"},{"path":"missing_data.html","id":"gérer-les-na-dans-ggplot","chapter":"20 Données manquantes","heading":"Gérer les NA dans ggplot()","text":"Il est souvent judicieux de signaler le nombre de valeurs exclues d’un graphique au lecteur du graphique.Dans ggplot(), la fonction labs()un argument caption = qui ajoute un texte de légende sous le graphique. peut utiliser str_glue() du package stringr pour concaténer valeurs et chaînes de caractères ensemble dans une phrase qui s’ajuste automatiquement aux données (voir exemple ci-dessous).Notes :\n* l’utilisation de \\n pour aller à la ligne.\n* si plusieurs colonnes contribuent à ce que des valeurs ne soient pas affichées (par exemple, l’âge ou le sexe si ceux-ci sont reflétés dans le graphique), il faut également filtrer sur ces colonnes pour calculer correctement le nombre de valeurs non affichées.\n* peut sauvegarder la chaîne de caractères en tant qu’objet dans des commandes antérieures à la commande ggplot(), et simplement la référencer dans la str_glue().","code":"\nlabs(\n  title = \"\",\n  y = \"\",\n  x = \"\",\n  caption  = stringr::str_glue(\n  \"n = {nrow(central_data)} du Central Hospital;\n  {nrow(central_data %>% filter(is.na(date_onset)))} cas sans date de début des symptomes et non représentés\"))  "},{"path":"missing_data.html","id":"na-dans-les-facteurs","chapter":"20 Données manquantes","heading":"NA dans les facteurs","text":"Si votre colonne d’intérêt est un facteur, utilisez fct_explicit_na() du package forcats pour convertir les valeurs NA en une chaîne de caractères (plus de détails dans la page Facteurs. Par défaut, la nouvelle valeur est “(Missing)” mais cela peut être ajusté via l’argument na_level =.","code":"\npacman::p_load(forcats)   # charge le package\n\nlinelist <- linelist %>% \n  mutate(gender = fct_explicit_na(gender, na_level = \"Missing\"))\n\nlevels(linelist$gender)## [1] \"f\"       \"m\"       \"Missing\""},{"path":"missing_data.html","id":"imputation","chapter":"20 Données manquantes","heading":"20.6 Imputation","text":"Lors de certaines analyses de données, il est nécessaire de “combler les lacunes” et d’imputer les données manquantes. En effet, s’il est souvent possible d’analyser un jeu de données après en avoir supprimé toutes les valeurs manquantes, cela peut néanmoins poser des problèmes à plusieurs égards. Voici deux exemples :Supprimer toutes les observations avec des valeurs manquantes, ou les variables avec beaucoup de données manquantes peut réduire considérablement la puissance et la capacité à effectuer certains types d’analyse. Par exemple, nous avons vu que seule une faible fraction des lignes de notre linelist ne comporte aucune donnée manquante. Si nous supprimions toutes les lignes contenant au moins une donnée manquante, nous perdrions beaucoup d’informations ! De plus, la plupart de nos variables comportent une certaine quantité de données manquantes - pour la plupart des analyses, il n’est probablement pas raisonnable de toutes les éliminer.Supprimer toutes les observations avec des valeurs manquantes, ou les variables avec beaucoup de données manquantes peut réduire considérablement la puissance et la capacité à effectuer certains types d’analyse. Par exemple, nous avons vu que seule une faible fraction des lignes de notre linelist ne comporte aucune donnée manquante. Si nous supprimions toutes les lignes contenant au moins une donnée manquante, nous perdrions beaucoup d’informations ! De plus, la plupart de nos variables comportent une certaine quantité de données manquantes - pour la plupart des analyses, il n’est probablement pas raisonnable de toutes les éliminer.Selon la raison pour laquelle vos données sont manquantes, l’analyse des données non manquantes seules peut conduire à des biais et des résultats trompeurs. Par exemple, nous avons vu que de nombreux patients ont des données manquantes dans les colonnes concernant des symptômes importants, comme la fièvre ou la toux. Il est possible que cette information n’ait pas été enregistrée pour les personnes qui ne paraissaient pas sévèrement malades. Dans ce cas, si nous supprimions simplement ces observations, nous exclurions une partie des patients en meilleure santé de notre analyse, ce qui pourrait vraiment biaiser les résultats.Selon la raison pour laquelle vos données sont manquantes, l’analyse des données non manquantes seules peut conduire à des biais et des résultats trompeurs. Par exemple, nous avons vu que de nombreux patients ont des données manquantes dans les colonnes concernant des symptômes importants, comme la fièvre ou la toux. Il est possible que cette information n’ait pas été enregistrée pour les personnes qui ne paraissaient pas sévèrement malades. Dans ce cas, si nous supprimions simplement ces observations, nous exclurions une partie des patients en meilleure santé de notre analyse, ce qui pourrait vraiment biaiser les résultats.ne suffit pas seulement d’estimer la quantité de données manquantes, il est également capital de réfléchir à la raison pour laquelle les données peuvent manquer. Cela va guider vos choix quant à l’importance de l’imputation des données manquantes, ainsi que de la méthode d’imputation la plus appropriée à votre situation.","code":""},{"path":"missing_data.html","id":"types-de-données-manquantes","chapter":"20 Données manquantes","heading":"Types de données manquantes","text":"Voici les trois grands types de données manquantes, qui correspondent à des mécanismes différents de non-réponse :Données manquantes de manière complètement aléatoire (MMCA) (trouvera souvent l’acronyme anglais MCAR, pour “Missing Completely Random”). Dans ce cas, il n’y pas de relation entre la probabilité de manquer et les autres variables de vos données (ou avec des variables non mesurées). La probabilité d’être manquante est la même pour tous les cas. C’est une situation rare. Néanmoins, si vous avez de bonnes raisons de penser que vos données sont MMCA, l’analyse des données non manquantes (sans imputation) ne faussera pas les résultats (malgré une possible perte de puissance).Données manquantes de manière complètement aléatoire (MMCA) (trouvera souvent l’acronyme anglais MCAR, pour “Missing Completely Random”). Dans ce cas, il n’y pas de relation entre la probabilité de manquer et les autres variables de vos données (ou avec des variables non mesurées). La probabilité d’être manquante est la même pour tous les cas. C’est une situation rare. Néanmoins, si vous avez de bonnes raisons de penser que vos données sont MMCA, l’analyse des données non manquantes (sans imputation) ne faussera pas les résultats (malgré une possible perte de puissance).Données manquantes aléatoirement (MA, ou MAR en Anglais pour “Missing Random”. Ce nom est en fait un peu trompeur car MA signifie que les données sont manquantes de manière systématique et prévisible en fonction d’autres variables mesurées. Par exemple, dans notre cas, les docteurs auraient pu considérer que les patients présentant des frissons et des courbatures ont nécessairement de la fièvre, et n’ont pas pris leur température. Cela aboutit à des observations manquantes dans la colonne fièvre, aisément prévisibles grâce aux colonnes frissons et courbatures. Si c’est vrai, nous pourrions facilement prédire que chaque observation manquante avec des frissons et des courbatures également de la fièvre et utiliser cette information pour imputer nos données manquantes. Dans la pratique, c’est souvent plus compliqué: si un patient présente à la fois des frissons et des courbatures, il est probable qu’il ait également de la fièvre, mais pas toujours. Les données MA sont prévisibles, mais la prédiction n’est jamais parfaite. Il s’agit d’un type très courant de données manquantesDonnées manquantes aléatoirement (MA, ou MAR en Anglais pour “Missing Random”. Ce nom est en fait un peu trompeur car MA signifie que les données sont manquantes de manière systématique et prévisible en fonction d’autres variables mesurées. Par exemple, dans notre cas, les docteurs auraient pu considérer que les patients présentant des frissons et des courbatures ont nécessairement de la fièvre, et n’ont pas pris leur température. Cela aboutit à des observations manquantes dans la colonne fièvre, aisément prévisibles grâce aux colonnes frissons et courbatures. Si c’est vrai, nous pourrions facilement prédire que chaque observation manquante avec des frissons et des courbatures également de la fièvre et utiliser cette information pour imputer nos données manquantes. Dans la pratique, c’est souvent plus compliqué: si un patient présente à la fois des frissons et des courbatures, il est probable qu’il ait également de la fièvre, mais pas toujours. Les données MA sont prévisibles, mais la prédiction n’est jamais parfaite. Il s’agit d’un type très courant de données manquantesDonnées manquantes par omission prévisible (MOP) aussi appelées Données manquantes non aléatoirement (MNAR ou NMAR en Anglais, pour “Missing Random” ou “Missing Random”). Dans ce cas, la probabilité qu’une valeur soit manquante n’est PAS systématique ou prévisible à l’aide des autres informations dont nous disposons, mais elle n’est pas non plus manquante au hasard. Les données manquent pour des raisons inconnues, sur lesquelles vous n’avez aucune information. La valeur de la variable manquante est liée à la raison pour laquelle elle est manquante. Par exemple, dans nos données, l’age du patient peut manquer parce que certains patients très âgés ne savent pas ou refusent de dire quel âge ils ont. Dans cette situation, les données manquantes sur l’âge sont liées à la valeur elle-même, ne sont donc pas aléatoires ni prévisibles sur la base des autres informations dont nous disposons. Ce mécanisme de non-réponse est non-ignorable, complexe et souvent, la meilleure façon d’y faire face est d’essayer de collecter plus de données ou d’informations sur la raison pour laquelle les données sont manquantes plutôt que de tenter de les imputer.Données manquantes par omission prévisible (MOP) aussi appelées Données manquantes non aléatoirement (MNAR ou NMAR en Anglais, pour “Missing Random” ou “Missing Random”). Dans ce cas, la probabilité qu’une valeur soit manquante n’est PAS systématique ou prévisible à l’aide des autres informations dont nous disposons, mais elle n’est pas non plus manquante au hasard. Les données manquent pour des raisons inconnues, sur lesquelles vous n’avez aucune information. La valeur de la variable manquante est liée à la raison pour laquelle elle est manquante. Par exemple, dans nos données, l’age du patient peut manquer parce que certains patients très âgés ne savent pas ou refusent de dire quel âge ils ont. Dans cette situation, les données manquantes sur l’âge sont liées à la valeur elle-même, ne sont donc pas aléatoires ni prévisibles sur la base des autres informations dont nous disposons. Ce mécanisme de non-réponse est non-ignorable, complexe et souvent, la meilleure façon d’y faire face est d’essayer de collecter plus de données ou d’informations sur la raison pour laquelle les données sont manquantes plutôt que de tenter de les imputer.En général, imputer des données MA est relativement simple, mais imputer des données MOP est complexe, difficile et souvent impossible. La plupart des méthodes d’imputation les plus répandues font l’hypothèse que les données sont de type MA.","code":""},{"path":"missing_data.html","id":"packages-utiles","chapter":"20 Données manquantes","heading":"Packages utiles","text":"Voici un certain nombre de packages utiles pour l’imputation des données : Mmisc, missForest (qui utilise les forêts aléatoires pour imputer les données manquantes) et mice (Multivariate Imputation Chained Equations). Dans cette section, nous nous focaliserons sur le paquet mice, qui met en œuvre diverses techniques. Le responsable du paquet mice publié un livre détaillé accessible en ligne gratuitement sur l’imputation des données manquantes.Voici le code pour charger le paquetage mice :","code":"\npacman::p_load(mice)"},{"path":"missing_data.html","id":"imputation-par-la-moyenne","chapter":"20 Données manquantes","heading":"Imputation par la moyenne","text":"Parfois, dans le cas d’analyses simples ou s’il y de bonnes raisons de penser que que les données sont de type MA, il est possible de simplement remplacer les valeurs manquantes d’une variable par la moyenne de cette variable. Par exemple, nous pourrions avoir de bonnes raisons de penser que les mesures de température manquantes dans nos données étaient MA ou normales. Voici le code permettant de créer une nouvelle variable qui remplace les valeurs de température manquantes par la valeur de température moyenne de notre ensemble de données.Il faut rester prudent, car dans de nombreuses situations, le remplacement des données manquantes par la moyenne peut entraîner un biais.peut procéder de la même manière pour remplacer des données catégoriques par une valeur spécifique. Dans nos données, imaginez que vous sachiez que toutes les observations pour lesquelles il manque une valeur de décharge (qui peut être “Décès” ou “Guéri”) sont en fait des personnes décédées (remarque : ce n’est pas réellement vrai pour cet ensemble de données).","code":"\nlinelist <- linelist %>%\n  mutate(temp_replace_na_with_mean = replace_na(temp, mean(temp, na.rm = T)))\nlinelist <- linelist %>%\n  mutate(outcome_replace_na_with_death = replace_na(outcome, \"Death\"))"},{"path":"missing_data.html","id":"imputation-par-régression","chapter":"20 Données manquantes","heading":"Imputation par régression","text":"Une méthode un peu plus avancée consiste à utiliser un modèle statistique pour prédire les valeurs manquantes et les remplacer. Par exemple, pourrait imaginer utiliser une régression linéaire simple avec l’état de la fièvre et l’age pour prédire la température lorsque celle-ci est manquante. Dans la vie réelle, il vaut mieux utiliser des modèles plus avancés qu’une approche aussi simple.peut utiliser la même approche d’imputation par régression avec le package mice pour imputer les les observations de température manquantes :Il est possible d’utiliser des modèles plus avancés que la régression linéaire simple pour prédire les valeurs manquantes à l’aide d’autres variables. Par exemple, le package missForest utilise les forêts aléatoires pour prédire les valeurs des données manquantes.Quel que soit le modèle statistique utilisé pour modéliser les valeurs manquantes, il faut se rappeler que cette approche fonctionne bien avec des données MMCA, mais il faut être très prudent si vous pensez que vos données sont de type MA ou MOP.La qualité de l’imputation dépend de la qualité du modèle de prédiction et même avec un très bon modèle, la variabilité de vos données imputées peut être sous-estimée.","code":"\nsimple_temperature_model_fit <- lm(temp ~ fever + age_years, \n                                   data = linelist)\n\n# Nous utilisons un modèle linéaire simple avec la température comme variable réponse pour prédire les valeurs de température manquantes\npredictions_for_missing_temps <- predict(simple_temperature_model_fit,\n                                         newdata = linelist %>%\n                                              filter(is.na(temp))) \nmodel_dataset <- linelist %>%\n  select(temp, fever, age_years)  \n\ntemp_imputed <- mice(model_dataset,\n                            method = \"norm.predict\",\n                            seed = 1,\n                            m = 1,\n                            print = FALSE)## Warning: Number of logged events: 1\ntemp_imputed_values <- temp_imputed$imp$temp"},{"path":"missing_data.html","id":"report-de-la-dernière-observation-et-baseline","chapter":"20 Données manquantes","heading":"Report de la dernière observation et baseline","text":"Lorsque l’des données longitudinales ou des séries temporelles, il est parfois pertinent d’utiliser des méthodes d’imputations basées sur le report de la dernière valeur connue (LOCF, pour “Last Observation Carried Forward”) ou le report de la valeur “baseline” (BOCF pour “Baseline Observation Carried Forward”). Concrètement, il s’agit d’utiliser une valeur observée dans le passé et de l’utiliser comme remplacement des données manquantes. Dans le cas de l’imputation LOCF, si plusieurs valeurs sont manquantes à la suite, il faut remonter à la dernière observation non manquante pour ce patient.La fonction fill() du package tidyr peut être utilisée pour l’imputation LOCF et BOCF (mais d’autres packages tels que HMISC, zoo, et data.table peuvent aussi être utilisés). Pour illustrer la syntaxe de fill(), nous allons créer un simple ensemble de données de séries temporelles contenant le nombre de cas d’une maladie pour chaque trimestre des années 2000 et 2001. Cependant, la valeur de l’année pour les trimestres postérieurs à Q1 est manquante et nous devrons donc les imputer. La jonction fill() est également démontrée dans la page Restructurer les données.Note : il faut que les données soient correctement triées avant d’utiliser la fonction fill()! Par défaut, la fonction fill() remplit les données vers le bas, mais il est possible d’imputer des valeurs dans différentes directions à l’aide du paramètre .direction. Si nous créons un jeu de données similaire où la valeur de l’année est enregistrée uniquement à la fin de l’année et manquante pour les trimestres précédents :Dans cet exemple, l’imputation avec les méthodes LOCF et BOCF sont clairement les solutions les plus adaptée. Néanmoins, dans des situations plus complexes, il peut être difficile de décider si ces méthodes sont appropriées ou non. Par exemple, vous pouvez avoir des valeurs de laboratoire manquantes pour un patient hospitalisé après le premier jour. Cela pourrait signifier que les valeurs de laboratoire n’ont pas changé… ou que le patient s’est rétabli et donc que ses valeurs seraient très différentes après le premier jour ! Utilisez ces méthodes avec prudence.","code":"\n# Création d'un jeu de données\ndisease <- tibble::tribble(\n  ~quarter, ~year, ~cases,\n  \"Q1\",    2000,    66013,\n  \"Q2\",      NA,    69182,\n  \"Q3\",      NA,    53175,\n  \"Q4\",      NA,    21001,\n  \"Q1\",    2001,    46036,\n  \"Q2\",      NA,    58842,\n  \"Q3\",      NA,    44568,\n  \"Q4\",      NA,    50197)\n\n# Imputation ds données manquantes pour l'année (vers le bas par défaut)\ndisease %>% fill(year)## # A tibble: 8 × 3\n##   quarter  year cases\n##   <chr>   <dbl> <dbl>\n## 1 Q1       2000 66013\n## 2 Q2       2000 69182\n## 3 Q3       2000 53175\n## 4 Q4       2000 21001\n## 5 Q1       2001 46036\n## 6 Q2       2001 58842\n## 7 Q3       2001 44568\n## 8 Q4       2001 50197\n# Création d'un jeu de données\ndisease <- tibble::tribble(\n  ~quarter, ~year, ~cases,\n  \"Q1\",      NA,    66013,\n  \"Q2\",      NA,    69182,\n  \"Q3\",      NA,    53175,\n  \"Q4\",    2000,    21001,\n  \"Q1\",      NA,    46036,\n  \"Q2\",      NA,    58842,\n  \"Q3\",      NA,    44568,\n  \"Q4\",    2001,    50197)\n\n# Imputation des données de l'année \"vers le haut\"\ndisease %>% fill(year, .direction = \"up\")## # A tibble: 8 × 3\n##   quarter  year cases\n##   <chr>   <dbl> <dbl>\n## 1 Q1       2000 66013\n## 2 Q2       2000 69182\n## 3 Q3       2000 53175\n## 4 Q4       2000 21001\n## 5 Q1       2001 46036\n## 6 Q2       2001 58842\n## 7 Q3       2001 44568\n## 8 Q4       2001 50197"},{"path":"missing_data.html","id":"imputation-multiple","chapter":"20 Données manquantes","heading":"Imputation multiple","text":"Nous n’avons pas la place ici de faire une explication détaillée de l’imputation multiple et de quand l’utiliser. Nous vous réferrons au livre (en ligne et gratuit) écrit par l’auteur du paquet mice et ne présentons ici qu’une explication de base de la méthode :L’imputation multiple consiste à créer plusieurs jeux de données dans lesquels les valeurs manquantes sont imputées à des valeurs de données “plausibles”. Dans chacun des jeux de données, chaque valeur imputée est tirée aléatoirement dans une distribution estimée (les données non manquantes restent, elles, intouchées), ce qui crée des jeux de données légèrement différents les uns des autres. La distribution utilisée d’où sont tirée les valeurs imputées vient ici encore d’un modèle statistique prédictif (mice propose de nombreuses options pour les méthodes de prédiction, notamment Predictive Mean Matching, Régression logistique et Forêt aléatoire), mais mice prend en charge de nombreux détails de la modélisation. Ensuite, l’analyse que vous aviez planifiée est effectuée sur chacun des jeux de données, et les paramètres estimés par les modèles sont ensuite poolés et leur variance estimée.Cette méthode fonctionne très bien pour réduire le biais dans les configurations MMCA et MA et permet souvent d’obtenir des estimations plus précises de l’erreur standard.Note : en fonction des données, peut créer plus ou moins de jeux de données avec les données imputées. Le package mice fixe le nombre par défaut à 5.Voici un exemple d’application de l’imputation multiple pour prédire la température dans notre jeu de données de liste linéaire, en utilisant l’age et la présence/absence de fièvre :Ici, nous avons utilisé la méthode d’imputation par défaut de mice, à savoir “Predictive Mean Matching”. Nous avons ensuite utilisé ces jeux de données imputées pour estimer séparément, puis mettre en commun les résultats de régressions linéaires simples sur chacun de ces ensembles de données.Il existe de nombreux détails que nous avons survolés et de nombreux paramètres que vous pouvez ajuster pendant le processus d’imputation multiple en utilisant le package mice. Par exemple, vous n’aurez pas toujours des données numériques et vous devrez peut-être utiliser d’autres méthodes d’imputation (mice permet d’imputer de nombreux types de données, avec de nombreuses méthodes). Mais, pour une analyse plus robuste lorsque les données manquantes constituent un problème important, l’imputation multiple est une bonne solution qui ne demande pas toujours beaucoup plus de travail que l’analyse complète des cas.","code":"\n# imputation des valurs manquantes pour notre jeu de données modèle, et création de 10 jeux de données imputés : \nmultiple_imputation = mice(\n  model_dataset,\n  seed = 1,\n  m = 10,\n  print = FALSE) ## Warning: Number of logged events: 1\nmodel_fit <- with(multiple_imputation, \n                  lm(temp ~ age_years + fever))\n\nbase::summary(mice::pool(model_fit))##          term     estimate    std.error     statistic        df       p.value\n## 1 (Intercept) 3.703143e+01 0.0270863456 1367.16240465  26.83673  1.583113e-66\n## 2   age_years 3.867829e-05 0.0006090202    0.06350905 171.44363  9.494351e-01\n## 3    feveryes 1.978044e+00 0.0193587115  102.17849544 176.51325 5.666771e-159"},{"path":"missing_data.html","id":"resources-5","chapter":"20 Données manquantes","heading":"20.7 Resources","text":"Vignette sur le package naniarGalerie de visualisation de données manquantesLivre gratuit sur l’imputation multiple par l’auteur et le gestionnaire du package mice","code":""},{"path":"standardisation.html","id":"standardisation","chapter":"21 Taux standardisés","heading":"21 Taux standardisés","text":"Cette page vous montre deux façons de normaliser un résultat, tel que les hospitalisations ou la mortalité, en fonction de caractéristiques telles que l’âge et le sexe.Utilisation du paquet dsrUtilisation du paquet PHEindicatormethods.Nous commençons par démontrer de manière extensive les processus de préparation/nettoyage/jonction des données, car cela est courant lorsqu’combine des données de population provenant de plusieurs pays, des données de population standard, des décès, etc.","code":""},{"path":"standardisation.html","id":"vue-densemble-1","chapter":"21 Taux standardisés","heading":"21.1 Vue d’ensemble","text":"Il existe deux manières principales de normaliser : la normalisation directe et la normalisation indirecte.\nSupposons que nous voulions normaliser le taux de mortalité par âge et par sexe pour le pays et le pays B, et comparer les taux normalisés entre ces pays.Pour une standardisation directe, vous devrez connaître le nombre de personnes à risque et le nombre de décès pour chaque strate d’âge et de sexe, pour le pays et le pays B. Une strate dans notre exemple pourrait être les femmes âgées de 15 à 44 ans.Pour une standardisation indirecte, il suffit de connaître le nombre total de décès et la structure d’âge et de sexe de chaque pays. Cette option est donc envisageable si les taux de mortalité ou les chiffres de population par âge et par sexe ne sont pas disponibles. La standardisation indirecte est en outre préférable en cas de petits effectifs par strate, car les estimations en standardisation directe seraient influencées par une variation d’échantillonnage importante.","code":""},{"path":"standardisation.html","id":"préparation-4","chapter":"21 Taux standardisés","heading":"21.2 Préparation","text":"Pour montrer comment se fait la standardisation, nous allons utiliser des comptages fictifs de population et de décès du pays et du pays B, par âge (en catégories de 5 ans) et par sexe (femme, homme). Pour que les ensembles de données soient prêts à être utilisés, nous allons effectuer les étapes de préparation suivantes :Charger les paquetsCharger les jeux de donnéesJoignez les données de population et de décès des deux pays.Pivoter plus longtemps pour qu’il y ait une ligne par strate âge-sexe.Nettoyez la population de référence (population standard mondiale) et joignez-la aux données du pays.Dans votre scénario, vos données peuvent se présenter sous un format différent. Peut-être vos données sont-elles présentées par province, ville ou autre zone d’attraction. Vous avez peut-être une ligne pour chaque décès et des informations sur l’âge et le sexe pour chacun (ou une proportion importante) de ces décès. Dans ce cas, consultez les pages sur le Travailler sur des données groupées, Pivoter les données, Tableaux descriptifs pour créer un ensemble de données avec des comptes d’événements et de population par strate âge-sexe.Nous avons également besoin d’une population de référence, la population standard. Pour les besoins de cet exercice, nous utiliserons la world_standard_population_by_sex (population standard mondiale par sexe). La population standard mondiale est basée sur les populations de 46 pays et été développée en 1960. Il existe de nombreuses populations “standard” - à titre d’exemple, le site web de NHS Scotland est assez informatif sur la population standard européenne, la population standard mondiale et la population standard écossaise.","code":""},{"path":"standardisation.html","id":"chargement-des-paquets-3","chapter":"21 Taux standardisés","heading":"Chargement des paquets","text":"Ce chunk de code montre le chargement des paquets nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire et le charge pour l’utiliser. Vous pouvez également charger les paquets installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les paquets R.**ATTENTION:_** Si vous avez une version plus récente de R, le paquet dsr ne peut pas être téléchargé directement avec CRAN. Cependant, il est toujours disponible de l’archive CRAN. Vous pouvez installer et utiliser celui-ci. Pour les utilisateurs non-Mac :Pour les utilisateurs de Mac :","code":"\npacman::p_load(\n     rio, # importer/exporter des données\n     here, # localisation des fichiers\n     tidyverse, # gestion et visualisation des données\n     stringr, # nettoyage des caractères et des chaînes de caractères\n     frailtypack, # nécessaire pour dsr, pour les modèles de frailty\n     dsr, # standardiser les taux\n     PHEindicatormethods) # alternative pour la standardisation des taux\npackageurl <- \"https://cran.r-project.org/src/contrib/Archive/dsr/dsr_0.2.2.tar.gz\"\ninstall.packages(packageurl, repos=NULL, type=\"source\")\n# Autre solution qui peut fonctionner\nrequire(devtools)\ndevtools::install_version(\"dsr\", version=\"0.2.2\", repos=\"http:/cran.us.r.project.org\")\nrequire(devtools)\ndevtools::install_version(\"dsr\", version=\"0.2.2\", repos=\"https://mac.R-project.org\")"},{"path":"standardisation.html","id":"charger-les-données-de-la-population","chapter":"21 Taux standardisés","heading":"Charger les données de la population","text":"Voir la page Télécharger le manuel et les données pour savoir comment télécharger tous les exemples de données du manuel. Vous pouvez importer les données de la page de normalisation directement dans R depuis notre dépôt Github en exécutant les commandes import() suivantes :Tout d’abord, nous chargeons les données démographiques (comptage des hommes et des femmes par catégorie d’âge de 5 ans) pour les deux pays que nous allons comparer, le “pays ” et le “pays B”.","code":"\n# importer les données démographiques du pays A directement depuis Github\nA_demo <- import(\"https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/standardization/country_demographics.csv\")\n\n# importer les décès pour le pays A directement depuis Github\nA_deaths <- import(\"https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/standardization/deaths_countryA.csv\")\n\n# Importez les données démographiques pour le pays B directement depuis Github.\nB_demo <- import(\"https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/standardization/country_demographics_2.csv\")\n\n# importer les décès pour le pays B directement depuis Github.\nB_deaths <- import(\"https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/standardization/deaths_countryB.csv\")\n\n# Importez les données démographiques pour le pays B directement depuis Github.\nstandard_pop_data <- import(\"https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/standardization/world_standard_population_by_sex.csv\")\n# Pays A\nA_demo <- import(\"country_demographics.csv\")\n# Pays B\nB_demo <- import(\"country_demographics_2.csv\")"},{"path":"standardisation.html","id":"chargement-du-nombre-de-morts","chapter":"21 Taux standardisés","heading":"Chargement du nombre de morts","text":"De manière pratique, nous disposons également du nombre de décès survenus pendant la période qui nous intéresse, par âge et par sexe. Les chiffres de chaque pays sont dans un fichier séparé, comme indiqué ci-dessous.Décès dans le pays ADécès dans le pays B","code":""},{"path":"standardisation.html","id":"nettoyer-les-populations-et-les-décès","chapter":"21 Taux standardisés","heading":"Nettoyer les populations et les décès","text":"Nous devons joindre et transformer ces données de la manière suivante :Combiner les populations des pays en un seul ensemble de données et faire un pivot “long” pour que chaque strate âge-sexe soit une ligne.Combiner le nombre de décès par pays dans un ensemble de données et faire pivoter “long” pour que chaque strate âge-sexe soit une ligne.Joindre les décès aux populationsTout d’abord, nous combinons les ensembles de données sur les populations des pays, nous effectuons un pivot plus long et un nettoyage mineur. Voir la page Pivoter les données pour plus de détails.Les données de population combinées ressemblent maintenant à ceci (cliquez pour voir les pays et B) :Et maintenant, nous effectuons des opérations similaires sur les deux ensembles de données de décès.Les données de décès ressemblent maintenant à ceci, et contiennent les données des deux pays :Nous joignons maintenant les données de décès et de population sur la base des colonnes communes Country, age_cat5, et Sex. Cela ajoute la colonne Deaths.Nous pouvons maintenant classer Country, age_cat5, et Sex comme facteurs et définir l’ordre des niveaux en utilisant la fonction fct_relevel() du paquet forcats, comme décrit dans la page sur Facteurs. Notez que le classement des niveaux des facteurs ne change pas visiblement les données, mais la commande arrange() les trie par Pays, catégorie d’âge et sexe.**__ATTENTION:_** Si vous avez peu de décès par strate, envisagez d’utiliser des catégories de 10, ou 15 ans, au lieu de catégories de 5 ans pour l’âge.","code":"\npop_countries <- A_demo %>% # Commencez avec l'ensemble de données du pays A\n     bind_rows(B_demo) %>% # lier les lignes, car les colonnes portent le même nom\n     pivot_longer( # pivot plus long\n          cols = c(m, f), # colonnes à combiner en une seule\n          names_to = \"Sex\", # nom de la nouvelle colonne contenant la catégorie (\"m\" ou \"f\") \n          values_to = \"Population\") %>% # nom de la nouvelle colonne contenant les valeurs numériques pivotées\n     mutate(Sex = recode(Sex, # re-code les valeurs pour plus de clarté\n          \"m\" = \"Male\",\n          \"f\" = \"Female\"))\ndeaths_countries <- A_deaths %>% # Commencez avec l'ensemble de données des décès du pays A\n     bind_rows(B_deaths) %>% # lier les lignes avec l'ensemble de données B, parce que les colonnes sont nommées de manière identique\n     pivot_longer( # pivot plus long\n          cols = c(Male, Female), # colonne à transformer en une seule\n          names_to = \"Sex\", # nom de la nouvelle colonne contenant la catégorie (\"m\" ou \"f\") \n          values_to = \"Deaths\") %>% # nom pour la nouvelle colonne contenant les valeurs numériques pivotées\n     rename(age_cat5 = AgeCat) # renomme pour plus de clarté\ncountry_data <- pop_countries %>% \n     left_join(deaths_countries, by = c(\"Country\", \"age_cat5\", \"Sex\"))\ncountry_data <- country_data %>% \n  mutate(\n    Country = fct_relevel(Country, \"A\", \"B\"),\n      \n    Sex = fct_relevel(Sex, \"Male\", \"Female\"),\n        \n    age_cat5 = fct_relevel(\n      age_cat5,\n      \"0-4\", \"5-9\", \"10-14\", \"15-19\",\n      \"20-24\", \"25-29\",  \"30-34\", \"35-39\",\n      \"40-44\", \"45-49\", \"50-54\", \"55-59\",\n      \"60-64\", \"65-69\", \"70-74\",\n      \"75-79\", \"80-84\", \"85\")) %>% \n          \n  arrange(Country, age_cat5, Sex)"},{"path":"standardisation.html","id":"chargement-de-la-population-de-référence","chapter":"21 Taux standardisés","heading":"Chargement de la population de référence","text":"Enfin, pour la standardisation directe, nous importons la population de référence (la “population standard” mondiale par sexe).","code":"\n# Population de référence\nstandard_pop_data <- import(\"world_standard_population_by_sex.csv\")"},{"path":"standardisation.html","id":"nettoyer-la-population-de-référence","chapter":"21 Taux standardisés","heading":"Nettoyer la population de référence","text":"Les valeurs des catégories d’âge dans les cadres de données country_data et standard_pop_data devront être alignées.Actuellement, les valeurs de la colonne age_cat5 du cadre de données standard_pop_data contiennent le mot “years” et “plus”, alors que celles du cadre de données country_data ne le font pas. Nous devrons faire correspondre les valeurs des catégories d’âge. Nous utilisons str_replace_all() du paquet stringr, comme décrit dans la page Caractères et chaînes de caractères, pour remplacer ces motifs par des \"\" sans espace.De plus, le paquet dsr s’attend à ce que dans la population standard, la colonne contenant les comptes soit appelée \"pop\". Nous renommons donc cette colonne en conséquence.CAUTION: Si vous essayez d’utiliser str_replace_all() pour supprimer un symbole plus, cela ne fonctionnera pas car c’est un symbole spécial. “Échappez” au spécial en mettant deux barres obliques inverses devant, comme dans str_replace_call(column, \"\\\\+\", \"\"). ","code":"\n# Suppression d'une chaîne spécifique des valeurs de la colonne\nstandard_pop_clean <- standard_pop_data %>%\n     mutate(\n          age_cat5 = str_replace_all(age_cat5, \"years\", \"\"), # supprime \"year\" (année)\n          age_cat5 = str_replace_all(age_cat5, \"plus\", \"\"), # supprimez \"plus\".\n          age_cat5 = str_replace_all(age_cat5, \" \", \"\")) %>% # supprime l'espace \" \".\n     \n     rename(pop = WorldStandardPopulation) # change le nom de la colonne en \"pop\", car cela est attendu par le paquet dsr"},{"path":"standardisation.html","id":"standard_all","chapter":"21 Taux standardisés","heading":"21.2.1 Créer un jeu de données avec une population standard","text":"Enfin, le package PHEindicatormethods, détaillé ci-dessous, attend les populations standards jointes aux événements et aux comptages de population du pays. Nous allons donc créer un jeu de données all_data à cet effet.Cet ensemble de données complet ressemble à ceci :","code":"\nall_data <- left_join(country_data, standard_pop_clean, by=c(\"age_cat5\", \"Sex\"))"},{"path":"standardisation.html","id":"dsr-package","chapter":"21 Taux standardisés","heading":"21.3 dsr package","text":"Nous démontrons ci-dessous le calcul et la comparaison de taux directement standardisés à l’aide du package dsr. Le package dsr vous permet de calculer et de comparer des taux directement standardisés (pas de taux indirectement standardisés !).Dans la section Préparation des données, nous avons créé des jeux de données distincts pour le nombre de pays et la population standard :l’objet country_data, qui est un tableau de population avec le nombre de population et le nombre de décès par strate par paysl’objet standard_pop_clean, contenant le nombre de personnes par strate pour notre population de référence, la population standard mondiale.Nous utiliserons ces ensembles de données distincts pour l’approche dsr.","code":""},{"path":"standardisation.html","id":"taux-standardisés","chapter":"21 Taux standardisés","heading":"Taux standardisés","text":"Ci-dessous, nous calculons les taux par pays directement standardisés pour l’âge et le sexe. Nous utilisons la fonction dsr().noter - dsr() s’attend à un cadre de données pour les populations des pays et le nombre d’événements (décès), et un autre cadre de données avec la population de référence. Il s’attend également à ce que dans cette base de données de la population de référence, le nom de la colonne unité-temps soit “pop” (nous nous en sommes assurés dans la section Préparation des données).Il y de nombreux arguments, comme annoté dans le code ci-dessous. Notamment, event = est fixé à la colonne Deaths, et le fu = (“follow-”) est fixé à la colonne Population. Nous définissons les sous-groupes de comparaison comme la colonne Country et nous standardisons sur la base de age_cat5 et Sex. Ces deux dernières colonnes n’ont pas d’argument nommé particulier. Voir ?dsr pour plus de détails.Ci-dessus, nous voyons que même si le pays avait un taux de mortalité brut plus faible que le pays B, il un taux standardisé plus élevé après standardisation directe par âge et par sexe.","code":"\n# Calculez les taux par pays directement standardisés pour l'âge et le sexe\nmortality_rate <- dsr::dsr(\n     data = country_data, # spécifier l'objet contenant le nombre de décès par strate\n     event = Deaths, # colonne contenant le nombre de décès par strate \n     fu = Population, # colonne contenant le nombre de population par strate\n     subgroup = Country, # unités que nous souhaitons comparer\n     age_cat5, # autres colonnes - les taux seront standardisés par celles-ci\n     Sex,\n     refdata = standard_pop_clean, # cadre de données de la population de référence, avec une colonne appelée \"pop\".\n     method = \"gamma\", # méthode pour calculer l'IC à 95%.\n     sig = 0,95, # niveau de signification\n     mp = 100000, # nous voulons les taux pour 100.000 habitants\n     decimals = 2) # nombre de décimales)\n\n\n# Imprimez la sortie sous la forme d'un joli tableau HTML\nknitr::kable(mortality_rate) # Afficher le taux de mortalité avant et après la standardisation directe"},{"path":"standardisation.html","id":"ratios-de-taux-standardisés","chapter":"21 Taux standardisés","heading":"Ratios de taux standardisés","text":"Le taux de mortalité standardisé est 1,22 fois plus élevé dans le pays que dans le pays B (IC 95 % 1.17-1.27).","code":"\n# Calculer le RR\nmortality_rr <- dsr::dsrr(\n     data = country_data, # spécifier l'objet contenant le nombre de décès par strate\n     event = Deaths, # colonne contenant le nombre de décès par strate \n     fu = Population, # colonne contenant le nombre de population par strate\n     subgroup = Country, # unités que nous souhaitons comparer\n     age_cat5,\n     Sex, # caractéristiques sur lesquelles nous aimerions nous standardiser \n     refdata = standard_pop_clean, # population de référence, avec des chiffres dans la colonne appelée pop\n     refgroup = \"B\", # référence pour la comparaison\n     estimate = \"ratio\", # type d'estimation\n     sig = 0.95, # niveau de signification\n     mp = 100000, # nous voulons des taux pour 100.000 habitants\n     decimals = 2) # nombre de décimales\n\n# Imprimer le tableau\nknitr::kable(mortality_rr) "},{"path":"standardisation.html","id":"différence-de-taux-standardisé","chapter":"21 Taux standardisés","heading":"Différence de taux standardisé","text":"Le pays 4.24 décès supplémentaires pour 100.000 habitants (IC 95% 3.24-5.24) par rapport au pays .","code":"\n# Calculer RD\nmortality_rd <- dsr::dsrr(\n     data = country_data, # spécifier l'objet contenant le nombre de décès par strate\n     event = Deaths, # colonne contenant le nombre de décès par strate \n     fu = Population, # colonne contenant le nombre de population par strate\n     subgroup = Country, # unités que nous souhaitons comparer\n     age_cat5, # caractéristiques sur lesquelles nous voulons nous standardiser\n     Sex,                        \n     refdata = standard_pop_clean, # population de référence, avec des chiffres dans la colonne appelée pop\n     refgroup = \"B\", # référence pour la comparaison\n     estimate = \"difference\", # type d'estimation\n     sig = 0.95, # niveau de signification\n     mp = 100000, # nous voulons des taux pour 100.000 habitants\n     decimals = 2) # nombre de décimales\n\n# Imprimer le tableau\nknitr::kable(mortality_rd) "},{"path":"standardisation.html","id":"standard_phe","chapter":"21 Taux standardisés","heading":"21.4 PHEindicatormethods package","text":"Une autre façon de calculer les taux standardisés est avec le paquet PHEindicatormethods. Ce package vous permet de calculer les taux standardisés directement et indirectement. Nous allons montrer les deux.Cette section utilisera le cadre de données all_data créé à la fin de la section Préparation. Ce cadre de données inclut les populations des pays, les événements de décès, et la population de référence standard mondiale. Vous pouvez le visualiser ici.","code":""},{"path":"standardisation.html","id":"taux-directement-standardisés","chapter":"21 Taux standardisés","heading":"Taux directement standardisés","text":"Ci-dessous, nous regroupons d’abord les données par Pays, puis nous les passons à la fonction phe_dsr() pour obtenir les taux directement standardisés par pays.noter - la population de référence (standard) peut être fournie comme une colonne dans le cadre de données spécifique au pays ou comme un vecteur séparé. Si elle est fournie dans le cadre de données spécifique au pays, vous devez définir stdpoptype = \"field\". Si elle est fournie sous forme de vecteur, définissez stdpoptype = \"vector\". Dans ce dernier cas, vous devez vous assurer que l’ordre des rangées par strate est similaire dans le cadre de données spécifique au pays et dans la population de référence, car les enregistrements seront appariés par position. Dans notre exemple ci-dessous, nous avons fourni la population de référence sous forme de colonne dans le cadre de données spécifique au pays.Consultez l’aide de ?phe_dsr ou les liens dans la section Références pour plus d’informations.","code":"\n# Calculez les taux par pays directement normalisés pour l'âge et le sexe.\nmortality_ds_rate_phe <- all_data %>%\n     group_by(Country) %>%\n     PHEindicatormethods::phe_dsr(\n          x = Deaths, # colonne avec le nombre d'événements observés\n          n = Population, # colonne avec les pops non standard pour chaque strate\n          stdpop = pop, # populations standard pour chaque strate\n          stdpoptype = \"field\")       # soit \"vector\" pour un vecteur autonome, soit \"field\" pour signifier que les populations std sont dans les données.  \n\n# Imprimer le tableau\nknitr::kable(mortality_ds_rate_phe)"},{"path":"standardisation.html","id":"standard_indirect","chapter":"21 Taux standardisés","heading":"Taux standardisés indirectement","text":"Pour la standardisation indirecte, vous avez besoin d’une population de référence avec le nombre de décès et le nombre de population par strate. Dans cet exemple, nous allons calculer les taux pour le pays en utilisant le pays B comme population de référence, car la population de référence standard_pop_clean n’inclut pas le nombre de décès par strate.Ci-dessous, nous créons d’abord la population de référence du pays B. Ensuite, nous passons les données de mortalité et de population pour le pays , nous les combinons avec la population de référence, et nous les passons à la fonction phe_isr(), pour obtenir des taux indirectement standardisés. Bien sûr, vous pouvez aussi faire l’inverse.noter - dans notre exemple ci-dessous, la population de référence est fournie comme un cadre de données séparé. Dans ce cas, nous nous assurons que les vecteurs x =, n =, x_ref = et n_ref = sont tous ordonnés par les mêmes valeurs de catégorie de standardisation (strate) que celles de notre cadre de données spécifique au pays, puisque les enregistrements seront appariés par position.Consultez l’aide de ?phe_isr (maintenant calculate_ISRate depuis dec 2022) ou les liens dans la section Références pour plus d’informations.","code":"\n# Créez la population de référence\nrefpopCountryB <- country_data %>% \n  filter(Country == \"B\") \n\n# Calculer les taux pour le pays A indirectement standardisés par âge et sexe\nmortality_is_rate_phe_A <- country_data %>%\n     filter(Country == \"A\") %>%\n     PHEindicatormethods::calculate_ISRate( #avant c'etait phe_isr()\n          x = Deaths, # colonne avec le nombre d'événements observés\n          n = Population, # colonne avec les pops non standard pour chaque strate\n          x_ref = refpopCountryB$Deaths, # nombre de décès de référence pour chaque strate\n          n_ref = refpopCountryB$Population) # population de référence pour chaque strate\n\n# Imprimez le tableau\nknitr::kable(mortality_is_rate_phe_A)"},{"path":"standardisation.html","id":"ressources-8","chapter":"21 Taux standardisés","heading":"21.5 Ressources","text":"Si vous souhaitez voir un autre exemple reproductible utilisant dsr, veuillez consulter cette vignette.Pour un autre exemple utilisant PHEindicatormethods, veuillez vous rendre sur ce site WebVoir les PHEindicatormethods fichier pdf de référence","code":""},{"path":"moving_average.html","id":"moving_average","chapter":"22 Moyennes mobiles","heading":"22 Moyennes mobiles","text":"Cette page va couvrir deux méthodes pour calculer et visualiser les moyennes mobiles :Calculer avec le paquet slider.Calculer dans une commande ggplot() avec le paquet tidyquant.","code":""},{"path":"moving_average.html","id":"préparation-5","chapter":"22 Moyennes mobiles","heading":"22.1 Préparation","text":"","code":""},{"path":"moving_average.html","id":"chargement-des-paquets-4","chapter":"22 Moyennes mobiles","heading":"Chargement des paquets","text":"Ce morceau de code montre le chargement des paquets nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire et le charge pour l’utiliser. Vous pouvez également charger les paquets installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les paquets R.","code":"\npacman::p_load(\n  tidyverse, # pour la gestion des données et le viz\n  slider, # pour le calcul des moyennes mobiles\n  tidyquant # pour le calcul des moyennes mobiles dans ggplot\n)"},{"path":"moving_average.html","id":"importer-des-données-2","chapter":"22 Moyennes mobiles","heading":"Importer des données","text":"Nous importons le jeu de données des cas d’une épidémie d’Ebola simulée. Si vous voulez suivre, cliquez pour télécharger la liste de lignes “propre” (en tant que fichier .rds). Importez des données avec la fonction import() du paquet rio (elle gère de nombreux types de fichiers comme .xlsx, .csv, .rds - voir la page Importation et exportation pour plus de détails).Les 50 premières lignes de la linelist sont affichées ci-dessous.","code":"\n# Importez la liste de cas\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"moving_average.html","id":"calculer-avec-slider","chapter":"22 Moyennes mobiles","heading":"22.2 Calculer avec slider","text":"Utilisez cette approche pour calculer une moyenne mobile dans un cadre de données avant de tracer.Le paquet slider fournit plusieurs fonctions de “fenêtre glissante” pour calculer des moyennes glissantes, des sommes cumulatives, des régressions glissantes, etc. Il traite un cadre de données comme un vecteur de lignes, permettant une itération par ligne sur un cadre de données.Voici quelques-unes des fonctions les plus courantes :slide_dbl() - itère à travers une colonne numérique (“_dbl”) en effectuant une opération utilisant une fenêtre glissante.\nslide_sum() - fonction de raccourci de la somme glissante pour slide_dbl().\nslide_mean() - fonction de raccourci de la moyenne glissante pour slide_dbl().\nslide_sum() - fonction de raccourci de la somme glissante pour slide_dbl().slide_mean() - fonction de raccourci de la moyenne glissante pour slide_dbl().slide_index_dbl() - applique la fenêtre glissante sur une colonne numérique en utilisant une colonne séparée pour indexer la progression de la fenêtre (utile si la fenêtre est glissante par date et que certaines dates sont absentes).\nslide_index_sum() - fonction de raccourci de la somme roulante avec indexation.\nslide_index_mean() - fonction de raccourci de la moyenne mobile avec indexation.\nslide_index_sum() - fonction de raccourci de la somme roulante avec indexation.slide_index_mean() - fonction de raccourci de la moyenne mobile avec indexation.Le paquet slider possède de nombreuses autres fonctions qui sont couvertes dans la section Ressources de cette page. Nous abordons brièvement les plus courantes.Arguments de base.x, le premier argument par défaut, est le vecteur sur lequel il faut itérer et auquel il faut appliquer la fonction..= pour les versions “index” des fonctions slider - fournir une colonne pour “indexer” le rouleau (voir section ci-dessous).f =, le deuxième argument par défaut, soit :\nUne fonction, écrite sans parenthèses, comme mean, ou bien\nUne formule, qui sera convertie en fonction. Par exemple ~ .x - mean(.x) retournera le résultat de la valeur courante moins la moyenne de la valeur de la fenêtre.\nUne fonction, écrite sans parenthèses, comme mean, ou bienUne formule, qui sera convertie en fonction. Par exemple ~ .x - mean(.x) retournera le résultat de la valeur courante moins la moyenne de la valeur de la fenêtre.Pour plus de détails, voir ce matériel de référenceTaille de la fenêtreSpécifiez la taille de la fenêtre en utilisant soit ., soit ., soit les deux arguments :.= - Fournir un nombre entier.= - Fournir un nombre entier.complete = - Donnez-lui la valeur TRUE si vous voulez que le calcul soit effectué uniquement sur des fenêtres complètes.Par exemple, pour obtenir une fenêtre de 7 jours incluant la valeur actuelle et les six précédentes, utilisez .= 6. Pour obtenir une fenêtre “centrée”, donnez le même nombre à .= et .=.Par défaut, .complete = sera FAUX, donc si la fenêtre complète de lignes n’existe pas, les fonctions utiliseront les lignes disponibles pour effectuer le calcul. Si vous mettez la valeur TRUE, les calculs ne seront effectués que sur des fenêtres complètes.Extension de la fenêtrePour réaliser des opérations cumulatives, définissez l’argument .= à Inf. Ceci effectuera l’opération sur la valeur courante et toutes celles qui la précèdent.","code":""},{"path":"moving_average.html","id":"roll_index","chapter":"22 Moyennes mobiles","heading":"Rouler par date","text":"Le cas le plus probable d’utilisation d’un calcul glissant en épidémiologie appliquée est d’examiner une métrique dans le temps. Par exemple, une mesure continue de l’incidence des cas, basée sur le nombre de cas quotidiens.Si vous avez des séries temporelles propres avec des valeurs pour chaque date, vous pouvez utiliser slide_dbl(), comme démontré ici dans la page Série chronologique et détection des épidémies.Cependant, dans de nombreuses circonstances d’épidémiologie appliquée, vous pouvez avoir des dates absentes de vos données, où il n’y aucun événement enregistré. Dans ces cas, il est préférable d’utiliser les versions “index” des fonctions slider.","code":""},{"path":"moving_average.html","id":"données-indexées","chapter":"22 Moyennes mobiles","heading":"Données indexées","text":"Ci-dessous, nous montrons un exemple d’utilisation de slide_index_dbl() sur la liste de cas. Disons que notre objectif est de calculer une incidence glissante sur 7 jours - la somme des cas utilisant une fenêtre glissante de 7 jours. Si vous cherchez un exemple de moyenne glissante, consultez la section ci-dessous sur le roulement groupé.Pour commencer, le jeu de données daily_counts est créé pour refléter le nombre de cas quotidiens de la linelist, tel que calculé avec count() de dplyr.Voici le cadre de données daily_counts - il y nrow(daily_counts) lignes, chaque jour est représenté par une ligne, mais surtout au début de l’épidémie certains jours ne sont pas présents (il n’y avait pas de cas admis ces jours-là).Il est crucial de reconnaître qu’une fonction de roulement standard (comme slide_dbl() utiliserait une fenêtre de 7 lignes, et non de 7 jours. Ainsi, s’il y des dates absentes, certaines fenêtres s’étendront en fait sur plus de 7 jours calendaires !Une fenêtre déroulante “intelligente” peut être obtenue avec slide_index_dbl(). L’“index” signifie que la fonction utilise une colonne séparée comme “index” pour la fenêtre de roulement. La fenêtre n’est pas simplement basée sur les lignes du cadre de données.Si la colonne d’index est une date, vous avez la possibilité supplémentaire de spécifier l’étendue de la fenêtre à .= et/ou .= en unités de lubridate days() ou months(). Si vous faites ces choses, la fonction inclura les jours absents dans les fenêtres comme s’ils étaient là (comme des valeurs NA).Montrons une comparaison. Ci-dessous, nous calculons l’incidence des cas sur 7 jours glissants avec des fenêtres régulières et indexées.Observez comment, dans la colonne normale, pour les 7 premières lignes, le nombre augmente régulièrement malgré le fait que les lignes ne sont pas à moins de 7 jours les unes des autres! La colonne adjacente “indexée” tient compte de ces jours calendaires absents, de sorte que ses sommes sur 7 jours sont beaucoup plus faibles, du moins à cette période de l’épidémie où les cas sont plus espacés.Vous pouvez maintenant tracer ces données avec ggplot() :","code":"\n# créez un jeu de données des comptages quotidiens\ndaily_counts <- linelist %>% \n  count(date_hospitalisation, name = \"new_cases\")\nrolling <- daily_counts %>% \n  mutate( # créer de nouvelles colonnes\n    # Utiliser slide_dbl()\n    ###################\n    reg_7day = slide_dbl(\n      new_cases, # calculer sur les new_cases\n      .f = ~sum(.x, na.rm = T), # la fonction est sum() avec les valeurs manquantes supprimées\n      .before = 6), # la fenêtre est le ROW et 6 ROWS précédents\n    \n    # Utilisation de slide_index_dbl()\n    #########################\n    indexed_7day = slide_index_dbl(\n        new_cases, # calculer sur les new_cases\n        .i = date_hospitalisation, # indexé avec date_onset \n        .f = ~sum(.x, na.rm = TRUE), # la fonction est sum() avec les valeurs manquantes supprimées\n        .before = days(6))               # la fenêtre est le JOUR et les 6 JOURS précédents\n    )\nggplot(data = rolling)+\n  geom_line(mapping = aes(x = date_hospitalisation, y = indexed_7day), size = 1)"},{"path":"moving_average.html","id":"roll_slider_group","chapter":"22 Moyennes mobiles","heading":"Rouler par groupe","text":"Si vous regroupez vos données avant d’utiliser une fonction slider, les fenêtres de glissement seront appliquées par groupe. Veillez à disposer vos lignes dans l’ordre souhaité par groupe.Chaque fois qu’un nouveau groupe commence, la fenêtre coulissante recommence. Par conséquent, une nuance à prendre en compte est que si vos données sont groupées et que vous avez défini .complete = TRUE, vous aurez des valeurs vides à chaque transition entre les groupes. Au fur et à mesure que la fonction se déplace vers le bas dans les lignes, chaque transition dans la colonne de regroupement redémarre l’accumulation de la taille minimale de la fenêtre pour permettre un calcul.Voir la page du manuel sur le Regroupement des données pour plus de détails sur le regroupement des données.Ci-dessous, nous comptons les cas de la linelist par date et par hôpital. Ensuite, nous classons les lignes par ordre croissant, d’abord par hôpital, puis par date. Ensuite, nous définissons group_by(). Nous pouvons alors créer notre nouvelle moyenne mobile.Voici le nouvel ensemble de données :Nous pouvons maintenant tracer les moyennes mobiles, en affichant les données par groupe en spécifiant ~ hospital à facet_wrap() dans ggplot(). Pour le plaisir, nous traçons deux géométries - un geom_col() montrant le nombre de cas quotidiens et un geom_line() montrant la moyenne mobile sur 7 jours.**ATTENTION:_** Si vous obtenez une erreur disant “slide() deprecated tsibble 0.9.0 now defunct. Please use slider::slide() instead.”, cela signifie que la fonction slide() du paquet tsibble masque la fonction slide() du paquet slider. Corrigez cela en spécifiant le package dans la commande, comme slider::slide_dbl()..\nVous pouvez regrouper les données avant d’utiliser une fonction slider. Par exemple, si vous voulez calculer la même somme glissante de 7 jours que ci-dessus, mais par hôpital. ci-dessus le délai moyen glissant entre l’apparition des symptômes et l’admission à l’hôpital (colonne days_onset_hosp). –>","code":"\ngrouped_roll <- linelist %>%\n\n  count(hospital, date_hospitalisation, name = \"new_cases\") %>% \n\n  arrange(hospital, date_hospitalisation) %>% # arranger les lignes par hôpital puis par date\n  \n  group_by(hospital) %>% # groupage par hôpital \n    \n  mutate( # moyenne mobile  \n    mean_7day_hosp = slide_index_dbl(\n      .x = new_cases, # le nombre de cas par jour d'hospitalisation\n      .i = date_hospitalisation, # indice sur la date d'admission\n      .f = mean, # utiliser mean()                   \n      .before = days(6) # utilise le jour et les 6 jours précédents\n      )\n  )\nggplot(data = grouped_roll)+\n  geom_col( # Trace le nombre de cas de daly sous forme de barres grises\n     mapping = aes(\n      x = date_hospitalisation,\n      y = new_cases),\n    fill = \"grey\",\n    width = 1)+\n  geom_line(   # tracer la moyenne mobile sous forme de ligne colorée par hôpital\n    mapping = aes(\n      x = date_hospitalisation,\n      y = mean_7day_hosp,\n      color = hospital),\n    size = 1)+\n  facet_wrap(~hospital, ncol = 2)+ # créer des mini-plots par hôpital\n  theme_classic()+ # simplifie le fond d'écran  \n  theme(legend.position = \"none\")+ # supprimer la légende\n  labs( # ajout d'étiquettes pour les graphiques\n      title = \"7-day rolling average of daily case incidence\",\n    x = \"Date of admission\",\n    y = \"Case incidence\")"},{"path":"moving_average.html","id":"calculer-avec-tidyquant-dans-ggplot","chapter":"22 Moyennes mobiles","heading":"22.3 Calculer avec tidyquant dans ggplot()","text":"Le paquet tidyquant offre une autre approche du calcul des moyennes mobiles - cette fois-ci à partir dans une commande ggplot() elle-même.En dessous de la linelist, les données sont comptées par date d’apparition et sont représentées par une ligne fondue (alpha < 1). La ligne superposée est créée avec geom_ma() du paquet tidyquant, avec une fenêtre de 7 jours (n = 7) avec une couleur et une épaisseur spécifiées.Par défaut, geom_ma() utilise une moyenne mobile simple (ma_fun = \"SMA\"), mais d’autres types peuvent être spécifiés, tels que :“EMA” - moyenne mobile exponentielle (plus de poids aux observations récentes)“WMA” - moyenne mobile pondérée (wts sont utilisés pour pondérer les observations dans la moyenne mobile)D’autres peuvent être trouvées dans la documentation de la fonctionVoir cette vignette pour plus de détails sur les options disponibles dans tidyquant.","code":"\nlinelist %>% \n  count(date_onset) %>% # compte les cas par jour\n  drop_na(date_onset) %>% # Suppression des cas pour lesquels la date d'apparition est manquante\n  ggplot(aes(x = date_onset, y = n))+ # démarrer ggplot\n    geom_line( # tracer les valeurs brutes\n      size = 1,\n      alpha = 0.2 # ligne semi-transparente\n      )+             \n    tidyquant::geom_ma( # tracer la moyenne mobile\n      n = 7,           \n      size = 1,\n      color = \"blue\")+ \n  theme_minimal() # fond simple"},{"path":"moving_average.html","id":"ressources-9","chapter":"22 Moyennes mobiles","heading":"22.4 Ressources","text":"Voir la vignette en ligne utile pour le paquet slider.La page slider githubUne slider vignetteVignette tidyquantSi votre cas d’utilisation exige que vous “passiez” les week-ends et même les jours fériés, vous aimerez peut-être le paquet almanac.","code":""},{"path":"time_series.html","id":"time_series","chapter":"23 Série temporelle et détection des épidémies","heading":"23 Série temporelle et détection des épidémies","text":"","code":""},{"path":"time_series.html","id":"aperçu-1","chapter":"23 Série temporelle et détection des épidémies","heading":"23.1 Aperçu","text":"Cet onglet démontre l’utilisation de plusieurs paquets pour l’analyse des séries temporelles. Il s’appuie principalement sur les paquets de la famille tidyverts mais utilise également le paquet RECON trending pour ajuster des modèles qui sont plus appropriés à l’épidémiologie des maladies infectieuses.Notez que dans l’exemple ci-dessous, nous utilisons un ensemble de données provenant du paquet surveillance. sur Campylobacter en Allemagne (voir le chapitre sur les données, du manuel pour plus de détails). Cependant, si vous vouliez exécuter le même code sur un ensemble de données avec plusieurs pays ou d’autres strates, il y un exemple de code pour cela dans le fichier r4epis github repo.Les sujets abordés sont les suivants :Données de séries temporellesAnalyse descriptiveRégressions ajustéesRelation de deux séries temporellesDétection de l’épidémieSéries chronologiques interrompues","code":""},{"path":"time_series.html","id":"préparation-6","chapter":"23 Série temporelle et détection des épidémies","heading":"23.2 Préparation","text":"","code":""},{"path":"time_series.html","id":"paquets","chapter":"23 Série temporelle et détection des épidémies","heading":"Paquets","text":"Ce morceau de code montre le chargement des paquets nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire et le charge pour l’utiliser. Vous pouvez également charger des paquets avec library() depuis base R. Voir la page sur bases de R pour plus d’informations sur les paquets R.","code":"\npacman::p_load(rio, # Importation du fichier\n               here, # Localisation de fichiers\n               tidyverse, # gestion des données + graphiques ggplot2\n               tsibble, # gère les ensembles de données de séries temporelles\n               slider, # pour calculer les moyennes mobiles\n               imputeTS, # pour remplir les valeurs manquantes\n               feasts, # pour la décomposition des séries temporelles et l'autocorrélation\n               forecast, # ajustement des termes sin et cosin aux données (note : doit être chargé après feasts)\n               trending, # ajustement et évaluation des modèles \n               tmaptools, # pour obtenir des géocoordonnées (lon/lat) à partir de noms de lieux\n               ecmwfr, # pour interagir avec l'API CDS de copernicus sateliate\n               stars, # pour lire les fichiers .nc (données climatiques)\n               units, # pour définir les unités de mesure (données climatiques)\n               yardstick, # pour l'examen de la précision du modèle\n               surveillance # pour la détection des aberrations\n               )"},{"path":"time_series.html","id":"chargement-des-données","chapter":"23 Série temporelle et détection des épidémies","heading":"Chargement des données","text":"Vous pouvez télécharger toutes les données utilisées dans ce manuel en suivant les instructions de la page Télécharger le manuel et les données.L’ensemble de données d’exemple utilisé dans cette section est le décompte hebdomadaire des cas de campylobacter signalés en Allemagne entre 2001 et 2011. \nVous pouvez cliquer ici pour télécharger ce fichier de données (.xlsx)..Cet ensemble de données est une version réduite de l’ensemble de données disponible dans le paquet surveillance (pour plus de détails, chargez le paquet surveillance et voyez ?campyDE)Importez ces données avec la fonction import() du paquet rio (elle gère de nombreux types de fichiers comme .xlsx, .csv, .rds - voir la page Importation et exportation pour plus de détails).Les 10 premières lignes des comptages sont affichées ci-dessous.","code":"\n# Importez les comptes dans R\ncounts <- rio::import(\"campylobacter_germany.xlsx\")"},{"path":"time_series.html","id":"nettoyer-les-données-1","chapter":"23 Série temporelle et détection des épidémies","heading":"Nettoyer les données","text":"Le code ci-dessous s’assure que la colonne de date est dans le format approprié.\nPour cet onglet, nous utiliserons le package tsibble et donc la fonction yearweek sera utilisée pour créer une variable de semaine calendaire. Il existe plusieurs autres façons de le faire (voir la page Manipuler les dates pour plus de détails), mais pour les séries temporelles, il est préférable de rester dans un seul cadre (tsibble).","code":"\n## s'assurer que la colonne date est dans le format approprié\ncounts$date <- as.Date(counts$date)\n\n## créer une variable de semaine calendaire \n## adapter les définitions ISO des semaines commençant un lundi\ncounts <- counts %>% \n     mutate(epiweek = yearweek(date, week_start = 1))"},{"path":"time_series.html","id":"télécharger-les-données-climatiques","chapter":"23 Série temporelle et détection des épidémies","heading":"Télécharger les données climatiques","text":"Dans la partie relation de deux séries temporelles de cette page, nous allons comparer le nombre de cas de campylobacter aux données climatiques.Les données climatiques de n’importe quel endroit du monde peuvent être téléchargées à partir du satellite Copernicus de l’UE. Il ne s’agit pas de mesures exactes, mais de données basées sur un modèle (similaire à l’interpolation), mais l’avantage est une couverture horaire globale ainsi que des prévisions.Vous pouvez télécharger chacun de ces fichiers de données climatiques à partir de la page Télécharger le manuel et les données.Pour les besoins de la démonstration, nous allons présenter le code R permettant d’utiliser le paquet ecmwfr pour extraire ces données du magasin de données climatiques Copernicus Climate Data Store. Vous devrez créer un compte gratuit pour que cela fonctionne. Le site Web du paquet contient un demo utile sur la manière de procéder. Vous trouverez ci-dessous un exemple de code expliquant comment procéder, une fois que vous les clés API appropriées. Vous devez remplacer les X ci-dessous par les identifiants de votre compte. Vous devrez télécharger une année de données à la fois, sinon le serveur s’arrête.Si vous n’êtes pas sûr des coordonnées d’un lieu pour lequel vous voulez télécharger des données, vous pouvez utiliser le paquet tmaptools pour extraire les coordonnées des cartes routières ouvertes. Une autre option est le paquet photon\nmais il n’pas encore été publié sur CRAN. photon fournit plus de données contextuelles lorsqu’il y plusieurs correspondances pour votre recherche.","code":"\n## récupérer les coordonnées de l'emplacement\ncoords <- geocode_OSM(\"Germany\", geometry = \"point\")\n\n## rassembler les long/lats dans un format pour les requêtes ERA-5 (bounding box) \n## (comme on ne veut qu'un seul point, on peut répéter les coordonnées)\nrequest_coords <- str_glue_data(coords$coords, \"{y}/{x}/{y}/{x}\")\n\n\n## Extraction des données modélisées à partir du satellite copernicus (réanalyse ERA-5)\n## https://cds.climate.copernicus.eu/cdsapp#!/software/app-era5-explorer?tab=app\n## https://github.com/bluegreen-labs/ecmwfr\n\n## Configurer la clé pour les données météo \nwf_set_key(user = \"XXXXX\",\n           key = \"XXXXXXXXX-XXXX-XXXX-XXXX-XXXXXX-XXXXXXXXX\",\n           service = \"cds\") \n\n## Exécution pour chaque année d'intérêt (sinon le serveur s'arrête)\nfor (i in 2002:2011) {\n  \n  ## construire une requête \n  ## voir ici pour savoir comment faire : https://bluegreen-labs.github.io/ecmwfr/articles/cds_vignette.html#the-request-syntax\n  ## changer la requête en une liste en utilisant le bouton addin ci-dessus (python to list)\n  ## La cible est le nom du fichier de sortie ! !!\n   request <- request <- list(\n    product_type = \"reanalysis\",\n    format = \"netcdf\",\n    variable = c(\"2m_temperature\", \"total_precipitation\"),\n    year = c(i),\n    month = c(\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"),\n    day = c(\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\",\n            \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\",\n            \"25\", \"26\", \"27\", \"28\", \"29\", \"30\", \"31\"),\n    time = c(\"00:00\", \"01:00\", \"02:00\", \"03:00\", \"04:00\", \"05:00\", \"06:00\", \"07:00\",\n             \"08:00\", \"09:00\", \"10:00\", \"11:00\", \"12:00\", \"13:00\", \"14:00\", \"15:00\",\n             \"16:00\", \"17:00\", \"18:00\", \"19:00\", \"20:00\", \"21:00\", \"22:00\", \"23:00\"),\n    area = request_coords,\n    dataset_short_name = \"reanalysis-era5-single-levels\",\n    target = paste0(\"germany_weather\", i, \".nc\")\n  )\n  \n  ### Télécharger le fichier et le stocker dans le répertoire de travail actuel.\n  file <- wf_request(user = \"XXXXX\", # ID utilisateur (pour l'authentification)\n                     request = request, # la requête\n                     transfer = TRUE, # télécharger le fichier\n                     path = here::here(\"data\", \"Weather\")) ## chemin pour sauvegarder les données\n  }"},{"path":"time_series.html","id":"charger-les-données-climatiques","chapter":"23 Série temporelle et détection des épidémies","heading":"Charger les données climatiques","text":"Que vous ayez téléchargé les données climatiques via notre manuel ou que vous ayez utilisé le code ci-dessus, vous devriez maintenant avoir 10 ans de fichiers de données climatiques “.nc” stockés dans le même dossier sur votre ordinateur.Utilisez le code ci-dessous pour importer ces fichiers dans R avec le paquet stars.Une fois que ces fichiers ont été importés en tant qu’objet data, nous allons les convertir en un cadre de données.","code":"\n## définir le chemin vers le dossier météo \nfile_paths <- list.files(\n  here::here(\"data\", \"time_series\", \"weather\"), # remplacer par votre propre chemin de fichier \n  full.names = TRUE)\n\n## ne garder que ceux qui ont le nom courant d'intérêt \nfile_paths <- file_paths[str_detect(file_paths, \"germany\")]\n\n## lire tous les fichiers en tant qu'objet stars \ndata <- stars::read_stars(file_paths)## t2m, tp, \n## t2m, tp, \n## t2m, tp, \n## t2m, tp, \n## t2m, tp, \n## t2m, tp, \n## t2m, tp, \n## t2m, tp, \n## t2m, tp, \n## t2m, tp,\n## conversion en cadre de données \ntemp_data <- as_tibble(data) %>% \n  ## ajouter des variables et corriger les unités\n  mutate(\n    ## créer une variable de semaine calendaire \n    epiweek = tsibble::yearweek(time), \n    ## créer une variable de date (début de la semaine calendaire)\n    date = as.Date(epiweek),\n    ## changer la température de kelvin en celsius\n    t2m = set_units(t2m, celsius), \n    ## changer les précipitations de mètres en millimètres \n    tp = set_units(tp, mm)) %>% \n  ## regrouper par semaine (en gardant la date aussi)\n  group_by(epiweek, date) %>% \n  ## obtenir la moyenne par semaine\n  summarise(t2m = as.numeric(mean(t2m)), \n            tp = as.numeric(mean(tp)))"},{"path":"time_series.html","id":"données-de-séries-temporelles","chapter":"23 Série temporelle et détection des épidémies","heading":"23.3 Données de séries temporelles","text":"Il existe un certain nombre de paquets différents pour structurer et traiter les données de données de séries temporelles. Comme nous l’avons dit, nous nous concentrerons sur la famille de paquets tidyverts et nous utiliserons donc le paquet tsibble pour définir notre objet série temporelle. Avoir un ensemble de données défini comme un objet de série temporelle, il est beaucoup plus facile de structurer notre analyse.Pour ce faire, nous utilisons la fonction tsibble() et spécifions l’“index”, c’est-à-dire la variable spécifiant l’unité de temps qui nous intéresse. Dans notre cas, il s’agit de la variable epiweek.Si nous avions un ensemble de données avec des comptages hebdomadaires par province, par exemple, nous pourrions également spécifier la variable de regroupement en utilisant l’argument key =. Cela nous permettrait d’effectuer une analyse pour chaque groupe.En regardant class(counts), constate qu’en plus d’être un cadre de données ordonné (“tbl_df”, “tbl”, “data.frame”), il possède les propriétés supplémentaires d’un cadre de données de série temporelle (“tbl_ts”).Vous pouvez jeter un coup d’oil rapide à vos données en utilisant ggplot2. Nous voyons sur le graphique que qu’il existe un modèle saisonnier clair, et qu’il n’y pas de manques. Cependant, il semble y avoir un problème avec la déclaration au début de chaque année, dans la dernière semaine de l’année, puis augmentent pour la première semaine de l’année suivante.ATTENTION: La plupart des ensembles de données ne sont pas aussi propres que cet exemple. Vous devrez vérifier les doublons et les valuers qui manques comme ci-dessous. ","code":"\n## Définir un objet de série temporelle \ncounts <- tsibble(counts, index = epiweek)\n## tracer un graphique linéaire des cas par semaine\nggplot(counts, aes(x = epiweek, y = case)) + \n     geom_line()"},{"path":"time_series.html","id":"duplicates","chapter":"23 Série temporelle et détection des épidémies","heading":"Duplicates","text":"tsibble n’autorise pas les observations en double. Ainsi, chaque ligne devra être\nunique, ou unique au sein du groupe (variable key). Le paquet quelques fonctions qui aident à identifier les doublons. Celles-ci incluent are_duplicated() qui vous donne un vecteur VRAI/FAUX indiquant si la ligne est un dupliqué, et duplicates() qui vous donne un cadre de données des lignes dupliquées.Voir la page sur De-duplication pour plus de détails sur la façon de sélectionner les lignes que vous voulez.","code":"\n## obtient un vecteur de VRAI/FAUX si les lignes sont des doublons\nare_duplicated(counts, index = epiweek) \n\n## Obtenez un cadre de données pour les lignes dupliquées. \nduplicates(counts, index = epiweek) "},{"path":"time_series.html","id":"manques","chapter":"23 Série temporelle et détection des épidémies","heading":"Manques","text":"Nous avons vu lors de notre brève inspection ci-dessus qu’il n’y pas de manques, mais nous avons aussi vu qu’il semble y avoir un problème de retard de déclaration autour du nouvel . Une façon de résoudre ce problème pourrait être de définir ces valeurs comme manquantes, puis d’imputer les valeurs. La forme la plus simple d’imputation de séries chronologiques consiste à tracer une ligne droite entre les dernières valeurs non manquantes et les valeurs manquantes.\nPour ce faire, nous utiliserons la fonction na_interpolation() du package imputeTS.Consultez la page Données manquantes pour connaître les autres options d’imputation.Une autre solution consisterait à calculer une moyenne mobile, pour essayer de pour tenter d’aplanir ces problèmes de déclaration apparents (voir la section suivante et la page sur les Moyennes mobiles).","code":"\n## créez une variable avec les manques au lieu des semaines avec des problèmes de déclaration.\ncounts <- counts %>% \n     mutate(case_miss = if_else(\n          ## si epiweek contient 52, 53, 1 ou 2\n          str_detect(epiweek, \"W51|W52|W53|W01|W02\"), \n          ## alors définie comme manquante \n          NA_real_, \n          ## sinon, conservez la valeur dans le cas\n          case\n     ))\n\n## alternativement interpoler les manquants par une tendance linéaire \n## entre deux points adjacents les plus proches\ncounts <- counts %>% \n  mutate(case_int = imputeTS::na_interpolation(case_miss)\n         )\n\n## pour vérifier quelles valeurs ont été imputées par rapport à l'original.\nggplot_na_imputations(counts$case_miss, counts$case_int) + \n  ## faire un graphique traditionnel (avec des axes noirs et un fond blanc)\n  theme_classic()"},{"path":"time_series.html","id":"analyse-descriptive","chapter":"23 Série temporelle et détection des épidémies","heading":"23.4 Analyse descriptive","text":"","code":""},{"path":"time_series.html","id":"timeseries_moving","chapter":"23 Série temporelle et détection des épidémies","heading":"Moyennes mobiles","text":"Si les données sont très bruyantes (les comptes sautent en haut et en bas), alors il peut être utile de calculer une moyenne mobile. Dans l’exemple ci-dessous, pour chaque semaine, nous calculons le nombre moyen de cas des quatre semaines précédentes. Cela permet de lisser les données, pour les rendre plus interprétables. Dans notre cas, cela n’apporte pas grand-chose.\nNous nous en tiendrons aux données interpolées pour la suite de l’analyse. Voir la page Moyennes mobiles pour plus de détails.","code":"\n## créer une variable de moyenne mobile (traite les manques)\ncounts <- counts %>% \n     ## créer la variable ma_4w \n     ## glisser sur chaque ligne de la variable case\n     mutate(ma_4wk = slider::slide_dbl(case, \n                               ## pour chaque ligne, calculez le nom\n                               ~ mean(.x, na.rm = TRUE),\n                               ## utiliser les quatre semaines précédentes\n                               .before = 4))\n\n### faire une visualisation rapide de la différence \nggplot(counts, aes(x = epiweek)) + \n     geom_line(aes(y = case)) + \n     geom_line(aes(y = ma_4wk), colour = \"red\")"},{"path":"time_series.html","id":"périodicité","chapter":"23 Série temporelle et détection des épidémies","heading":"Périodicité","text":"Nous définissons ci-dessous une fonction personnalisée pour créer un périodogramme. Voir la page ecrire les fonctions pour des informations sur la façon d’écrire des fonctions dans R.Tout d’abord, la fonction est définie. Ses arguments incluent un jeu de données avec une colonne counts, start_week = qui est la première semaine du jeu de données, un nombre pour indiquer combien de périodes par (par exemple 52, 12), et enfin le style de sortie (voir les détails dans le code ci-dessous).ATTENTION: Il est possible d’utiliser les semaines ci-dessus pour les ajouter aux termes sin et cosinus, cependant nous utiliserons une fonction pour générer ces termes (voir la section régression ci-dessous) .","code":"\n## Arguments de la fonction\n#####################\n## x est un ensemble de données\n## counts est une variable avec des données de comptage ou des taux dans x \n## start_week est la première semaine de votre série de données\n## period est le nombre d'unités dans une année. \n## output indique si vous souhaitez renvoyer le périodogramme spectral ou les semaines de pointe.\n  ## \"périodogramme\" ou \"semaines\".\n\n# Définissez la fonction\nperiodogram <- function(x, \n                        counts, \n                        start_week = c(2002, 1), \n                        period = 52, \n                        output = \"weeks\") {\n  \n\n    ## s'assurer que ce n'est pas un tsibble, filtrer sur le projet et ne garder que les colonnes d'intérêt.\n    prepare_data <- dplyr::as_tibble(x)\n    \n    # prepare_data <- prepare_data[prepare_data[[strata]] == j, ]\n    prepare_data <- dplyr::select(prepare_data, {{counts}})\n    \n    ## créer une série temporelle \"zoo\" intermédiaire pour pouvoir l'utiliser avec spec.pgram\n    zoo_cases <- zoo::zooreg(prepare_data, \n                             start = start_week, frequency = period)\n    \n    ## obtenir un périodogramme spectral n'utilisant pas la transformée de fourier rapide. \n    periodo <- spec.pgram(zoo_cases, fast = FALSE, plot = FALSE)\n    \n    ## retourner les semaines de pointe \n    periodo_weeks <- 1 / periodo$freq[order(-periodo$spec)] * period\n    \n    if (output == \"weeks\") {\n      periodo_weeks\n    } else {\n      periodo\n    }\n    \n}\n\n## obtenir le périodogramme spectral pour extraire les semaines avec les fréquences les plus élevées \n## (vérification de la saisonnalité) \nperiodo <- periodogram(counts, \n                       case_int, \n                       start_week = c(2002, 1),\n                       output = \"periodogram\")\n\n## Tirez le spectre et la fréquence dans un cadre de données pour le tracé.\nperiodo <- data.frame(periodo$freq, periodo$spec)\n\n## Tracez un périodogramme montrant la périodicité la plus fréquente. \nggplot(data = periodo, \n                aes(x = 1/(periodo.freq/52), y = log(periodo.spec))) + \n  geom_line() + \n  labs(x = \"Period (weeks)\", y = \"Log(density)\")\n## obtenir un vecteur semaines dans l'ordre croissant \npeak_weeks <- periodogram(counts, \n                          case_int, \n                          start_week = c(2002, 1), \n                          output = \"weeks\")"},{"path":"time_series.html","id":"décomposition","chapter":"23 Série temporelle et détection des épidémies","heading":"Décomposition","text":"La décomposition classique est utilisée pour décomposer une série temporelle en plusieurs parties, qui lorsqu’elles sont prises ensemble constituent le modèle que vous voyez.Ces différentes parties sont :La tendance-cycle (la direction à long terme des données)La saisonnalité (motifs répétitifs)L’aléatoire (ce qui reste après avoir retiré la tendance et la saison).","code":"\n## Décomposition de l'ensemble de données counts \ncounts %>% \n  ## en utilisant un modèle additif de décomposition classique\n  model(classical_decomposition(case_int, type = \"additive\")) %>%\n  ## extraire les informations importantes du modèle\n  components() %>% \n  ## générer un graphique \n  autoplot()"},{"path":"time_series.html","id":"autocorrélation","chapter":"23 Série temporelle et détection des épidémies","heading":"Autocorrélation","text":"L’autocorrélation vous renseigne sur la relation entre les comptes de chaque semaine et les semaines qui la précèdent (appelées décalages).En utilisant la fonction ACF(), nous pouvons produire un graphique qui nous montre un certain nombre de lignes pour la relation à différents décalages. Si le décalage est de 0 (x = 0), cette ligne sera toujours égale à 1, car elle montre la relation entre les deux. La première ligne illustrée ici (x = 1) montre la relation entre chaque observation et l’observation qui la précède (décalage de 1), la seconde montre la relation entre chaque observation et l’avant-dernière (décalage de 2) et ainsi de suite jusqu’à un décalage de 52 qui montre la relation entre chaque observation et l’observation d’un (52 semaines avant).L’utilisation de la fonction PACF() (pour l’autocorrélation partielle) montre le même type de relation, mais ajustée pour toutes les autres semaines intermédiaires. Ceci est moins informatif pour déterminer la périodicité.Vous pouvez tester formellement l’hypothèse nulle d’indépendance d’une série temporelle (c’est à dire qu’elle n’est pas autocorrélée) en utilisant le test de Ljung-Box (dans le paquet stats). Une valeur p significative suggère qu’il existe une autocorrélation dans les données.","code":"\n## en utilisant l'ensemble de données counts\ncounts %>% \n  ## calculer l'autocorrélation en utilisant une année complète de lags\n  ACF(case_int, lag_max = 52) %>% \n  ## afficher un graphique\n  autoplot()\n## en utilisant l'ensemble de données counts \ncounts %>% \n  ## calculer l'autocorrélation partielle en utilisant une année complète de décalages\n  PACF(case_int, lag_max = 52) %>% \n  ## Afficher un graphique\n  autoplot()\n## Test d'indépendance \nBox.test(counts$case_int, type = \"Ljung-Box\")## \n##  Box-Ljung test\n## \n## data:  counts$case_int\n## X-squared = 462.65, df = 1, p-value < 2.2e-16"},{"path":"time_series.html","id":"ajustement-des-régressions","chapter":"23 Série temporelle et détection des épidémies","heading":"23.5 Ajustement des régressions","text":"Il est possible d’ajuster un grand nombre de régressions différentes à une série temporelle, Cependant, nous allons montrer ici comment ajuster une régression binomiale négative, c’est souvent la plus appropriée pour les données de comptage dans les maladies infectieuses.","code":""},{"path":"time_series.html","id":"termes-de-fourier","chapter":"23 Série temporelle et détection des épidémies","heading":"Termes de Fourier","text":"Les termes de Fourier sont l’équivalent des courbes sin et cosin. La différence est que ceux-ci sont ajustés en fonction de la recherche de la combinaison de courbes la plus appropriée pour expliquervos données.\nSi vous n’ajustez qu’un seul terme de Fourier, cela équivaudrait à ajuster une courbe sin et un cosin pour le décalage le plus fréquent de votre périodogramme (dans notre cas 52 semaines). Nous utilisons la fonction fourier() du paquet forecast.Dans le code ci-dessous, nous assignons en utilisant le $, car fourier() renvoie deux colonnes (une pour le sin et une pour le cosin) et celles-ci sont ajoutées à l’ensemble de données sous forme de liste, appelée “fourier”. Mais cette liste peut ensuite être utilisée comme une variable normale dans une régression.","code":"\n## ajout des termes de fourier en utilisant les variables epiweek et case_int\ncounts$fourier <- select(counts, epiweek, case_int) %>% \n  fourier(K = 1)"},{"path":"time_series.html","id":"binomiale-négative","chapter":"23 Série temporelle et détection des épidémies","heading":"Binomiale négative","text":"Il est possible d’ajuster des régressions en utilisant les fonctions stats ou MASS de base (par exemple, lm(), glm() et glm.nb()). Cependant, nous utiliserons celles du paquet trending, car cela permet de calculer les intervalles de confiance et de prédictionconfiance et les intervalles de prédiction appropriés (qui ne sont pas disponibles autrement). La syntaxe est la même, et vous spécifiez une variable de résultat puis un tilde (~) puis vous ajoutez vos diverses variables d’exposition d’intérêt séparées par un plus (+).L’autre différence est que nous définissons d’abord le modèle et ensuite fit() aux données. Ceci est utile car cela permet de comparer plusieurs modèles différents avec la même syntaxe.ATTENTION: Si vous vouliez utiliser des taux, plutôt que des comptes, vous pourriez inclure la variable population comme terme de décalage logarithmique, en ajoutant offset(log(population). Vous auriez alors besoin de définir la population à 1, avant d’utiliser predict() afin de produire un taux. ATTENTION: Pour l’ajustement de modèles plus complexes tels que les modèles comme ARIMA ou prophète, voir le paquet fable.","code":"\n## définissez le modèle que vous voulez ajuster (binomiale négative). \nmodel <- glm_nb_model(\n  ## définir le nombre de cas comme résultat d'intérêt\n  case_int ~\n    ## utiliser epiweek pour tenir compte de la tendance\n    epiweek +\n    ## utiliser les termes de fourier pour tenir compte de la saisonnalité\n    fourier)\n\n## ajustez votre modèle en utilisant le jeu de données de comptage\nfitted_model <- trending::fit(model, data.frame(counts))\n\n### calculer les intervalles de confiance et les intervalles de prédiction \nobserved <- predict(fitted_model, simulate_pi = FALSE)\n\nestimate_res <- data.frame(observed$result)\n\n## Tracez votre régression \nggplot(data = estimate_res, aes(x = epiweek)) + \n  ## ajouter une ligne pour l'estimation du modèle\n  geom_line(aes(y = estimate),\n            col = \"red\") + \n  ## ajouter une bande pour les intervalles de prédiction \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## ajouter une ligne pour le nombre de cas observés\n  geom_line(aes(y = case_int), \n            col = \"black\") + \n  ## faire un graphique traditionnel (avec des axes noirs et un fond blanc)\n  theme_classic()"},{"path":"time_series.html","id":"résidus","chapter":"23 Série temporelle et détection des épidémies","heading":"Résidus","text":"Pour voir si notre modèle s’adapte bien aux données observées, nous devons examiner les résidus. Les résidus sont la différence entre les comptes observés et les comptes estimés à partir du modèle. Nous pourrions calculer cela simplement en utilisant case_int - estimate, mais la fonction residuals() l’extrait directement de la régression pour nous.Ce que nous voyons ci-dessous, c’est que nous n’expliquons pas toutes les variations que nous pourrions expliquer avec le modèle. Il se peut que nous devions ajuster plus de termes de Fourier, et s’attaquer à l’amplitude. Cependant, pour cet exemple, nous allons laisser les choses telles quelles. Les graphiques montrent que notre modèle est moins bon dans les pics et les creux (lorsque les comptages sont les plus élevés et les plus bas) et qu’il est plus susceptible de sous-estimer les comptagees observés.","code":"\n## calculate the residuals \nestimate_res <- estimate_res %>% \n  mutate(resid = fitted_model$result[[1]]$residuals)\n\n## are the residuals fairly constant over time (if not: outbreaks? change in practice?)\nestimate_res %>%\n  ggplot(aes(x = epiweek, y = resid)) +\n  geom_line() +\n  geom_point() + \n  labs(x = \"epiweek\", y = \"Residuals\")\n## is there autocorelation in the residuals (is there a pattern to the error?)  \nestimate_res %>% \n  as_tsibble(index = epiweek) %>% \n  ACF(resid, lag_max = 52) %>% \n  autoplot()\n## are residuals normally distributed (are under or over estimating?)  \nestimate_res %>%\n  ggplot(aes(x = resid)) +\n  geom_histogram(binwidth = 0.01) +\n  geom_rug() +\n  labs(y = \"count\") \n## compare observed counts to their residuals \n  ## should also be no pattern \nestimate_res %>%\n  ggplot(aes(x = estimate, y = resid)) +\n  geom_point() +\n  labs(x = \"Fitted\", y = \"Residuals\")\n## formally test autocorrelation of the residuals\n## H0 is that residuals are from a white-noise series (i.e. random)\n## test for independence \n## if p value significant then non-random\nBox.test(estimate_res$resid, type = \"Ljung-Box\")## \n##  Box-Ljung test\n## \n## data:  estimate_res$resid\n## X-squared = 336.25, df = 1, p-value < 2.2e-16"},{"path":"time_series.html","id":"relation-entre-deux-séries-temporelles","chapter":"23 Série temporelle et détection des épidémies","heading":"23.6 Relation entre deux séries temporelles","text":"Nous examinons ici l’utilisation de données météorologiques (en particulier la température) pour expliquer le nombre de cas de campylobacter.","code":""},{"path":"time_series.html","id":"fusionner-des-ensembles-de-données","chapter":"23 Série temporelle et détection des épidémies","heading":"Fusionner des ensembles de données","text":"Nous pouvons fusionner nos ensembles de données à l’aide de la variable week. Pour plus d’informations sur la fusion, voir la section du manuel sur les joindres.","code":"\n## left join so that we only have the rows already existing in counts\n## drop the date variable from temp_data (otherwise is duplicated)\ncounts <- left_join(counts, \n                    select(temp_data, -date),\n                    by = \"epiweek\")\ncounts %>% \n  ## garder les variables qui nous intéressent \n  select(epiweek, case_int, t2m) %>% \n  ## Changez vos données en format long\n  pivot_longer(\n    ## utiliser epiweek comme clé\n    !epiweek,\n    ## déplacez les noms des colonnes vers la nouvelle colonne \"measure\".\n    names_to = \"measure\", \n    ## déplacez les valeurs des cellules vers la nouvelle colonne \"values\".\n    values_to = \"value\") %>% \n  ## créer un graphique avec l'ensemble de données ci-dessus\n  ## Tracez l'epiweek sur l'axe des x et les valeurs (nombres/celsius) sur l'axe des y. \n  ggplot(aes(x = epiweek, y = value)) + \n    ## créez un graphique séparé pour les comptages tempérés et les comptages de cas. \n    ## laissez-les définir leurs propres axes y\n    facet_grid(measure ~ ., scales = \"free_y\") +\n    ## Tracez les deux comme une ligne\n    geom_line()"},{"path":"time_series.html","id":"lags-et-corrélation-croisée","chapter":"23 Série temporelle et détection des épidémies","heading":"Lags et corrélation croisée","text":"Pour tester formellement quelles semaines sont les plus fortement liées entre les cas et la température. Nous pouvons utiliser la fonction de corrélation croisée (CCF()) du paquet feasts. Vous pouvez également visualiser (plutôt que d’utiliser arrange) en utilisant la fonction autoplot().Nous voyons qu’un décalage de 4 semaines est le plus fortement corrélé, donc nous créons une variable de température décalée à inclure dans notre régression.ATTENTION: Notez que les quatre premières semaines de nos données dans la variable de température décalée sont manquantes (NA) - car il n’y pas quatre\nsemaines précédentes pour obtenir des données. Afin d’utiliser cet ensemble de données avec la fonction predict() du paquet trending, nous devons utiliser l’argument simulate_pi = FALSE dans la fonction predict() plus bas. Si nous voulions utiliser l’option simulate, alors nous devons supprimer ces manques et les stocker comme un nouvel ensemble de données en ajoutant drop_na(t2m_lag4). au morceau de code ci-dessous.","code":"\ncounts %>% \n  ## calculer la corrélation croisée entre les comptages interpolés et la température\n  CCF(case_int, t2m,\n      ## fixer le délai maximum à 52 semaines\n      lag_max = 52, \n      ## retourne le coefficient de corrélation \n      type = \"correlation\") %>% \n  ## arange dans l'ordre décroissant du coefficient de corrélation \n  ## montre les décalages les plus associés\n  arrange(-ccf) %>% \n  ## montrer seulement les dix premiers \n  slice_head(n = 10)## # A tsibble: 10 x 2 [1W]\n##         lag   ccf\n##    <cf_lag> <dbl>\n##  1      -4W 0.749\n##  2      -5W 0.745\n##  3      -3W 0.735\n##  4      -6W 0.729\n##  5      -2W 0.727\n##  6      -7W 0.704\n##  7      -1W 0.695\n##  8      -8W 0.671\n##  9       0W 0.649\n## 10      47W 0.638\ncounts <- counts %>% \n  ## créer une nouvelle variable pour la température décalée de quatre semaines.\n  mutate(t2m_lag4 = lag(t2m, n = 4))"},{"path":"time_series.html","id":"binomiale-négative-avec-deux-variables","chapter":"23 Série temporelle et détection des épidémies","heading":"Binomiale négative avec deux variables","text":"Nous ajustons une régression binomiale négative comme nous l’avons fait précédemment. Cette fois, nous ajoutons la variable de température retardée de quatre semaines.ATTENTION: Notez l’utilisation de simulate_pi = FALSE\ndans l’argument predict(). Ceci est dû au fait que le comportement par défaut de trending\nest d’utiliser le paquet ciTools pour estimer un intervalle de prédiction. Cela ne fonctionne pas s’il y des comptes NA, et produit également des intervalles plus granulaires.\nVoir ?trending::predict.trending_model_fit pour plus de détails. Pour étudier les termes individuels, nous pouvons extraire la régression binomiale négative originale du paquet trending en utilisant get_fitted_model() et la passer au fonction tidy() du paquetage broom pour récupérer les estimations exponentielles et lesintervalles de confiance associés.Ce que cela nous montre est que la température décalée, après avoir contrôlé la tendance et la saisonnalité, est similaire au nombre de cas (estimation ~ 1) et significativement associée.\nCela suggère qu’il pourrait s’agir d’une bonne variable à utiliser pour prédire le nombre de cas futurs (les prévisions climatiques étant facilement accessibles).Une rapide inspection visuelle du modèle montre qu’il pourrait faire un meilleur travail pour d’estimer le nombre de cas observés.","code":"\n## définissez le modèle que vous voulez ajuster (binomial négatif). \nmodel <- glm_nb_model(\n  ## définir le nombre de cas comme résultat d'intérêt\n  case_int ~\n    ## utiliser epiweek pour tenir compte de la tendance\n    epiweek +\n    ## utiliser les termes de fourier pour tenir compte de la saisonnalité\n    fourier + \n    ## utiliser la température retardée de quatre semaines \n    t2m_lag4\n    )\n\n## ajustez votre modèle en utilisant l'ensemble de données de comptage\nfitted_model <- trending::fit(model, data.frame(counts))\n\n### calculer les intervalles de confiance et les intervalles de prédiction \nobserved <- predict(fitted_model, simulate_pi = FALSE)\nfitted_model %>% \n  ## extraire la régression binomiale négative originale\n  get_fitted_model() #%>% ## [[1]]\n## \n## Call:  glm.nb(formula = case_int ~ epiweek + fourier + t2m_lag4, data = data.frame(counts), \n##     init.theta = 32.80689607, link = log)\n## \n## Coefficients:\n##  (Intercept)       epiweek  fourierS1-52  fourierC1-52      t2m_lag4  \n##   5.82535083    0.00008464   -0.28502594   -0.19537827    0.00667157  \n## \n## Degrees of Freedom: 504 Total (i.e. Null);  500 Residual\n##   (4 observations deleted due to missingness)\n## Null Deviance:       2015 \n## Residual Deviance: 508.2     AIC: 6784\n  ## obtenir un cadre de données ordonné des résultats\n  #broom::tidy(exponentiate = TRUE, \n  #     conf.int = TRUE)\nestimate_res <- data.frame(observed$result)\n     \n## Tracez votre régression \nggplot(data = estimate_res, aes(x = epiweek)) + \n  ## ajouter une ligne pour l'estimation du modèle\n  geom_line(aes(y = estimate),\n            col = \"red\") + \n  ## ajouter une bande pour les intervalles de prédiction \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## ajouter une ligne pour le nombre de cas observés\n  geom_line(aes(y = case_int), \n            col = \"black\") + \n  ## faire un graphique traditionnel (avec des axes noirs et un fond blanc)\n  theme_classic()"},{"path":"time_series.html","id":"résidus-1","chapter":"23 Série temporelle et détection des épidémies","heading":"Résidus","text":"Nous examinons à nouveau les résidus pour voir si notre modèle s’adapte bien aux données observées. Les résultats et l’interprétation sont ici similaires à ceux de la régression précédente, donc il est peut-être plus judicieux de s’en tenir au modèle plus simple sans température.","code":"\n## calculer les résidus \nestimate_res <- estimate_res %>% \n  mutate(resid = case_int - estimate)\n\n## les résidus sont-ils assez constants dans le temps (si non : épidémies ? changement de pratique ?)\nestimate_res %>%\n  ggplot(aes(x = epiweek, y = resid)) +\n  geom_line() +\n  geom_point() + \n  labs(x = \"epiweek\", y = \"Residuals\")\n## Y a-t-il une autocorrélation dans les résidus (y a-t-il un modèle d'erreur ?) ?  \nestimate_res %>% \n  as_tsibble(index = epiweek) %>% \n  ACF(resid, lag_max = 52) %>% \n  autoplot()\n## les résidus sont-ils normalement distribués (y a-t-il sous-estimation ou surestimation ?)  \nestimate_res %>%\n  ggplot(aes(x = resid)) +\n  geom_histogram(binwidth = 100) +\n  geom_rug() +\n  labs(y = \"count\") \n## comparer les comptages observés à leurs résidus \n  ## il ne devrait pas y avoir de modèle \nestimate_res %>%\n  ggplot(aes(x = estimate, y = resid)) +\n  geom_point() +\n  labs(x = \"Fitted\", y = \"Residuals\")\n## tester formellement l'autocorrélation des résidus\n## H0 est que les résidus proviennent d'une série à bruit blanc (c'est-à-dire aléatoire)\n## Test d'indépendance \n### si la valeur p est significative alors non aléatoire\nBox.test(estimate_res$resid, type = \"Ljung-Box\")## \n##  Box-Ljung test\n## \n## data:  estimate_res$resid\n## X-squared = 339.52, df = 1, p-value < 2.2e-16"},{"path":"time_series.html","id":"détection-des-épidémies","chapter":"23 Série temporelle et détection des épidémies","heading":"23.7 Détection des épidémies","text":"Nous allons démontrer ici deux méthodes (similaires) de détection des épidémies.\nLa première s’appuie sur les sections précédentes. Nous utilisons le paquet trending pour ajuster les régressions aux années précédentes, et puisprédire ce que nous nous attendons à voir l’année suivante. Si les comptages observés sont supérieursce que nous attendons, cela pourrait suggérer qu’il y une épidémie. La deuxième méthode est basée sur des principes similaires mais utilise le paquet surveillance,qui possède un certain nombre d’algorithmes différents pour la détection des aberrations.ATTENTION: Normalement, vous vous intéressez à l’année en cours (où vous ne connaissez que les comptages jusqu’à la semaine actuelle). Donc, dans cet exemple, nous prétendons être dans la semaine 39 de 2011.","code":""},{"path":"time_series.html","id":"tendance-paquet","chapter":"23 Série temporelle et détection des épidémies","heading":"tendance paquet","text":"Pour cette méthode, nous définissons une ligne de base (qui devrait généralement être d’environ 5 ans de données). Nous ajustons une régression aux données de base, puis nous l’utilisons pour prédire les estimations pour l’année suivante.","code":""},{"path":"time_series.html","id":"date-limite","chapter":"23 Série temporelle et détection des épidémies","heading":"Date limite","text":"Il est plus facile de définir vos dates à un endroit, puis de les utiliser dans le reste de votre code.Ici nous définissons une date de début (quand nos observations ont commencé) et une date limite (la fin de notre période de référence - et le début de la période pour laquelle nous voulons prédire).Nous définissons également le nombre de semaines entre la date limite de la période de référence et la date de fin de la période pour laquelle nous sommes intéressés à prédire.ATTENTION: Dans cet exemple, nous prétendons être actuellement à la fin du mois de septembre 2011 (“2011 W39”).","code":"\n## définir la date de début (quand les observations ont commencé)\nstart_date <- min(counts$epiweek)\n\n## définir une semaine de coupure (fin de la ligne de base, début de la période de prédiction)\ncut_off <- yearweek(\"2010-12-31\")\n\n## définir la dernière date qui nous intéresse (c'est-à-dire la fin de la prédiction)\nend_date <- yearweek(\"2011-12-31\")\n\n## trouver combien de semaines dans la période (année) d'intérêt.\nnum_weeks <- as.numeric(end_date - cut_off)"},{"path":"time_series.html","id":"ajoutez-des-lignes-.unnumbered.","chapter":"23 Série temporelle et détection des épidémies","heading":"23.7.0.1 Ajoutez des lignes {.unnumbered}.","text":"Pour pouvoir faire des prévisions dans un format tidyverse, nous devons avoir le bon nombre de lignes dans notre jeu de données, c’est-à-dire une ligne pour chaque semaine jusqu’à la date de fin définie ci-dessus. Le code ci-dessous vous permet d’ajouter ces lignes par une variable de regroupement - par exemple, si nous avons plusieurs pays dans un même ensemble de données, nous pouvons ajouter des lignes pour chacun d’entre eux. La fonction group_by_key() de tsibble nous permet d’effectuer ce regroupement, et ensuite de passer les données groupées aux fonctions dplyr, group_modify() et add_row(). Ensuite, nous spécifions la séquence des semaines entre une après la semaine maximale actuellement disponible dans les données et la semaine de fin.","code":"\n## ajouter les semaines manquantes jusqu'à la fin de l'année \ncounts <- counts %>%\n  ## regrouper par région\n  group_by_key() %>%\n  ## pour chaque groupe, ajoutez les lignes à partir de la semaine d'épi la plus élevée jusqu'à la fin de l'année\n  group_modify(~add_row(.,\n                        epiweek = seq(max(.$epiweek) + 1, \n                                      end_date,\n                                      by = 1)))"},{"path":"time_series.html","id":"termes-de-fourier-1","chapter":"23 Série temporelle et détection des épidémies","heading":"Termes de Fourier","text":"Nous devons redéfinir nos termes de Fourier, car nous voulons les adapter à la date de base uniquement, puis prédire (extrapoler) ces termes pour l’annee suivante. Pour ce faire, nous devons combiner deux listes de sortie de la fonction fourier() ensemble ; la première est pour les données de base, et la seconde prédit pour l’année qui nous intéresse (en définissant le paramètre fourier()).N.b. pour lier les lignes, nous devons utiliser rbind() (plutôt que tidyverse bind_rows) carles colonnes de fourier sont une liste (et ne sont donc pas nommées individuellement).","code":"\n## définir les termes de fourier (sincos) \ncounts <- counts %>% \n  mutate(\n    ## combiner les termes de fourier pour les semaines avant et après la date limite de 2010\n    ## (nb. les termes de fourier de 2011 sont prédits)\n    fourier = rbind(\n      ## obtenir les termes de fourier pour les années précédentes\n      fourier(\n        ## garder uniquement les lignes avant 2011\n        filter(counts, \n               epiweek <= cut_off), \n        ## inclure un ensemble de termes sin cos \n        K = 1\n        ), \n      ## prédire les termes de fourier pour 2011 (en utilisant les données de base)\n      fourier(\n        ## garder uniquement les lignes avant 2011\n        filter(counts, \n               epiweek <= cut_off),\n        ## inclure un ensemble de termes sin cos \n        K = 1, \n        ## prédire 52 semaines à l'avance\n        h = num_weeks\n        )\n      )\n    )"},{"path":"time_series.html","id":"diviser-les-données-et-ajuster-la-régression","chapter":"23 Série temporelle et détection des épidémies","heading":"Diviser les données et ajuster la régression","text":"Nous devons maintenant diviser notre ensemble de données en deux périodes : la période de base et la période de prédiction. Ceci est fait en utilisant la fonction dplyr group_split() après group_by(), et créera une liste avec deux cadres de données, un pour la période avant la coupure et un pour la période après la coupure.Nous utilisons ensuite la fonction pluck() du paquet purrr pour extraire les ensembles de données de la liste (ce qui équivaut à utiliser des crochets, par exemple dat[[1]]), et nous pouvons alors ajuster notre modèle aux données de base, et ensuite utiliser la fonction predict() pour nos données d’intérêt après la coupure.Consultez la page sur l’itération, les boucles et les listes pour en savoir plus sur purrr.ATTENTION: Notez l’utilisation de simulate_pi = FALSE dans l’argument predict(). Ceci est dû au fait que le comportement par défaut de trending est d’utiliser le paquet ciTools pour estimer un intervalle de prédiction. Cela ne fonctionne pas s’il y des comptes NA, et produit également des intervalles plus granulaires. Voir ?trending::predict.trending_model_fit pour plus de détails. Comme précédemment, nous pouvons visualiser notre modèle avec ggplot. Nous mettons en évidence les alertes avecpoints rouges pour les comptes observés au-dessus de l’intervalle de prédiction de 95 %. Cette fois, nous ajoutons également une ligne verticale pour indiquer quand la prévision commence.","code":"\n# diviser les données pour l'ajustement et la prédiction\ndat <- counts %>% \n  group_by(epiweek <= cut_off) %>%\n  group_split()\n\n## définir le modèle que vous voulez ajuster (binomial négatif) \nmodel <- glm_nb_model(\n  ## définir le nombre de cas comme résultat d'intérêt\n  case_int ~\n    ## utiliser epiweek pour tenir compte de la tendance\n    epiweek +\n    ## utiliser les termes de fourier pour tenir compte de la saisonnalité\n    fourier\n)\n\n# définir les données à utiliser pour l'ajustement et celles pour la prédiction.\nfitting_data <- pluck(dat, 2)\npred_data <- pluck(dat, 1) %>% \n  select(case_int, epiweek, fourier)\n\n# ajustement du modèle \nfitted_model <- trending::fit(model, data.frame(fitting_data))\n\n# obtenir le confint et les estimations pour les données ajustées\nobserved <- fitted_model %>% \n  predict(simulate_pi = FALSE)\n\n# prévoir avec les données que l'on veut prévoir avec \nforecast <- fitted_model %>% \n  predict(data.frame(pred_data), simulate_pi = FALSE)\n\n## combiner les ensembles de données de base et prédits\nobserved <- bind_rows(observed$result, forecast$result)\n## Tracez votre régression \nggplot(data = observed, aes(x = epiweek)) + \n  ## ajoutez une ligne pour l'estimation du modèle\n  geom_line(aes(y = estimate),\n            col = \"grey\") + \n  ## ajouter une bande pour les intervalles de prédiction \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## ajouter une ligne pour le nombre de cas observés\n  geom_line(aes(y = case_int), \n            col = \"black\") + \n  ## Tracez des points pour les nombres observés supérieurs aux prévisions.\n  geom_point(\n    data = filter(observed, case_int > upper_pi), \n    aes(y = case_int), \n    color = \"red\", \n    size = 2) + \n  ## ajouter une ligne verticale et une étiquette pour montrer où la prévision a commencé\n  geom_vline(\n           xintercept = as.Date(cut_off), \n           linetype = \"dashed\") + \n  annotate(geom = \"text\", \n           label = \"Forecast\", \n           x = cut_off, \n           y = max(observed$upper_pi) - 250, \n           angle = 90, \n           vjust = 1\n           ) + \n  ## faire un graphique traditionnel (avec des axes noirs et un fond blanc)\n  theme_classic()## Warning: Removed 13 rows containing missing values (`geom_line()`)."},{"path":"time_series.html","id":"validation-de-la-prédiction","chapter":"23 Série temporelle et détection des épidémies","heading":"Validation de la prédiction","text":"Au-delà de l’inspection des résidus, il est important d’étudier la capacité de votre modèle à prédire les cas dans le futur. Cela vous donne une idée de la fiabilité de vos\nseuils d’alerte.La méthode traditionnelle de validation consiste à voir dans quelle mesure vous pouvez prédire l’année la plus récente avant l’année en cours (parce que vous ne pouvez pas prédire l’année en cours).Par exemple, dans notre ensemble de données, nous utiliserions les données de 2002 à 2009 pour prédire 2010, et ensuite voir si ces prédictions sont exactes. Ensuite, nous réajustons le modèle pour incluredonnées de 2010 et les utiliser pour prédire les comptages de 2011.Comme peut le voir dans la figure ci-dessous, réalisée par Hyndman et al dans “Forecasting principles practice”.figure reproduite avec l’autorisation des auteurs.L’inconvénient de cette méthode est que vous n’utilisez pas toutes les données dont vous disposez et que vous n’obtenez pas le modèle final que vous utilisez pour la prédiction.Une alternative consiste à utiliser une méthode appelée validation croisée. Dans ce scénario, vous passez en revue toutes les données disponibles pour ajuster plusieurs modèles afin de prédire un à l’avance. Vous utilisez de plus en plus de données dans chaque modèle, comme le montre la figure ci-dessous tirée de la même [Hyndman et al texte]((https://otexts.com/fpp3/). Par exemple, le premier modèle utilise 2002 pour prédire 2003, le second utilise 2002 et 2003 pour prédire 2004, et ainsi de suite.\nfigure reproduite avec l’autorisation des auteurs.Dans la figure ci-dessous, nous utilisons la fonction map() du paquet purrr pour boucler sur chaque ensemble de données. Nous mettons ensuite les estimations dans un seul ensemble de données et les fusionnons avec le nombre de cas original, pour utiliser le paquet yardstick pour calculer les mesures de précision. Nous calculons quatre mesures, notamment Erreur quadratique moyenne (RMSE), Erreur absolue moyenne (MAE) l’erreur absolue moyenne mise à l’échelle (MASE), l’erreur absolue moyenne en pourcentage (MAPE).CAUTION: Notez l’utilisation de simulate_pi = FALSE dans l’argument predict(). Ceci est dû au fait que le comportement par défaut de trending est d’utiliser le paquet ciTools pour estimer un intervalle de prédiction. Cela ne fonctionne pas s’il y des comptes NA, et produit également des intervalles plus granulaires. Voir ?trending::predict.trending_model_fit pour plus de détails. ","code":"\n## Validation croisée : prédire la ou les semaines à venir en fonction de la fenêtre glissante.\n\n## élargissez vos données en les faisant glisser dans des fenêtres de 52 semaines (avant + après). \n## pour prédire les 52 semaines à venir\n## (crée des chaînes d'observations de plus en plus longues - conserve les données plus anciennes)\n\n## définir la fenêtre que l'on veut faire glisser\nroll_window <- 52\n\n## Définir les semaines à venir à prévoir \nweeks_ahead <- 52\n\n## créer un ensemble de données répétitives, de plus en plus longues.\n## étiqueter chaque ensemble de données avec un identifiant unique.\n## utiliser seulement les cas avant l'année d'intérêt (i.e. 2011)\ncase_roll <- counts %>% \n  filter(epiweek < cut_off) %>% \n  ## Garder uniquement les variables de la semaine et du nombre de cas.\n  select(epiweek, case_int) %>% \n    ## laisser tomber les x dernières observations \n    ## en fonction du nombre de semaines d'anticipation de la prévision. \n    ## (sinon ce sera une prévision réelle à \"inconnu\")\n    slice(1 :(n() - weeks_ahead)) %>%\n    as_tsibble(index = epiweek) %>% \n    ## reconduire chaque semaine dans x après les fenêtres pour créer l'ID de regroupement \n    ## en fonction de la fenêtre de roulement spécifiée\n    stretch_tsibble(.init = roll_window, .step = 1) %>% \n  ## laisser tomber les deux premiers - car il n'y a pas de cas \"avant\".\n  filter(.id > roll_window)\n\n\n## pour chacun des ensembles de données uniques, exécutez le code ci-dessous\nforecasts <- purrr::map(unique(case_roll$.id), \n                        function(i) {\n  \n  ## garder uniquement le pli courant en cours d'ajustement \n  mini_data <- filter(case_roll, .id == i) %>% \n    as_tibble()\n  \n  ## créer un ensemble de données vides pour la prévision sur \n  forecast_data <- tibble(\n    epiweek = seq(max(mini_data$epiweek) + 1,\n                  max(mini_data$epiweek) + weeks_ahead,\n                  by = 1),\n    case_int = rep.int(NA, weeks_ahead),\n    .id = rep.int(i, weeks_ahead)\n  )\n  \n  ## ajouter les données de prévision à l'original \n  mini_data <- bind_rows(mini_data, forecast_data)\n  \n  ## définir le cut off basé sur les dernières données de comptage non manquantes. \n  cv_cut_off <- mini_data %>% \n    ## ne garder que les lignes non manquantes\n    drop_na(case_int) %>% \n    ## obtenir la dernière semaine\n    summarise(max(epiweek)) %>% \n    ## extraire ce qui n'est pas dans un dataframe\n    pull()\n  \n  ## Remettre mini_data dans un tsibble\n  mini_data <- tsibble(mini_data, index = epiweek)\n  \n  ## définir les termes de fourier (sincos) \n  mini_data <- mini_data %>% \n    mutate(\n    ## Combinez les termes de Fourier pour les semaines avant et après la date limite.\n    fourier = rbind(\n      ## obtenir les termes de fourier pour les années précédentes\n      forecast::fourier(\n        ### ne conserve que les lignes avant la date butoir\n        filter(mini_data, \n               epiweek <= cv_cut_off), \n        ## inclure un ensemble de termes sin cos \n        K = 1\n        ), \n      ## prédire les termes de fourier pour l'année suivante (en utilisant les données de base)\n      fourier(\n        ## conserver uniquement les lignes avant la coupure\n        filter(mini_data, \n               epiweek <= cv_cut_off),\n        ## inclure un ensemble de termes sin cos \n        K = 1, \n        ## prédire 52 semaines à l'avance\n        h = weeks_ahead\n        )\n      )\n    )\n  \n  \n  # diviser les données pour l'ajustement et la prédiction\n  dat <- mini_data %>% \n    group_by(epiweek <= cv_cut_off) %>%\n    group_split()\n\n  ## définir le modèle que vous voulez ajuster (binomiale négative) \n  model <- glm_nb_model(\n    ## définir le nombre de cas comme résultat d'intérêt\n    case_int ~\n      ## utiliser epiweek pour tenir compte de la tendance\n      epiweek +\n      ## utiliser les termes de fourier pour tenir compte de la saisonnalité\n      fourier\n  )\n\n  # définir les données à utiliser pour l'ajustement et celles pour la prédiction.\n  fitting_data <- pluck(dat, 2)\n  pred_data <- pluck(dat, 1)\n  \n  # ajuster le modèle \n  fitted_model <- trending::fit(model, data.frame(fitting_data))\n  \n  # prévoir avec les données que l'on veut prédire avec \n  forecasts <- fitted_model %>% \n    predict(data.frame(pred_data), simulate_pi = FALSE) \n forecasts <- data.frame(forecasts$result[[1]]) %>% \n      ## garder seulement la semaine et l'estimation de la prévision\n    select(epiweek, estimate)\n    \n  }\n  )\n\n## Transformer la liste en un cadre de données avec toutes les prévisions.\nforecasts <- bind_rows(forecasts)\n\n## joindre les prévisions aux données observées\nforecasts <- left_join(forecasts, \n                       select(counts, epiweek, case_int),\n                       by = \"epiweek\")\n\n## en utilisant {yardstick} calculer les métriques\n  ## RMSE : Root mean squared error (erreur quadratique moyenne)\n  ## MAE : Erreur absolue moyenne   \n  ## MASE : Mean absolute scaled error (erreur absolue moyenne mise à l'échelle)\n  ## MAPE : Erreur absolue moyenne en pourcentage\nmodel_metrics <- bind_rows(\n  ## dans votre ensemble de données forcées, comparez les données observées aux données prédites.\n  rmse(forecasts, case_int, estimate), \n  mae( forecasts, case_int, estimate),\n  mase(forecasts, case_int, estimate),\n  mape(forecasts, case_int, estimate),\n  ) %>% \n  ### ne conserve que le type de métrique et sa sortie\n  select(Metric = .metric, \n         Measure = .estimate) %>% \n  ## faire en sorte que le format soit large pour pouvoir lier les lignes ensuite\n  pivot_wider(names_from = Metric, values_from = Measure)\n\n## Retourner les métriques du modèle \nmodel_metrics## # A tibble: 1 × 4\n##    rmse   mae  mase  mape\n##   <dbl> <dbl> <dbl> <dbl>\n## 1  252.  199.  1.96  17.3"},{"path":"time_series.html","id":"surveillance-paquet","chapter":"23 Série temporelle et détection des épidémies","heading":"surveillance paquet","text":"Dans cette section, nous utilisons le paquet surveillance pour créer des seuils d’alerte basés sur des algorithmes de détection d’épidémies. Il existe plusieurs méthodes différentes disponibles dans le paquet, mais nous nous concentrerons ici sur deux options. Pour plus de détails, voir ces articles sur l’application et théorie\ndes alogirths utilisés.La première option utilise la méthode améliorée de Farrington. Celle-ci ajuste un glm binomial négatif (y compris la tendance) et pondère à la baisse les épidémies passées (valeurs aberrantes) pour créer un niveau de seuil.La deuxième option utilise la méthode glrnb. Celle-ci ajuste également un glm binomial négatif\nbinomiale négative, mais inclut la tendance et les termes de Fourier (elle est donc privilégiée ici). La régression est utilisée pour calculer la “moyenne de contrôle” (~valeurs ajustées) - elle utilise ensuite une statistique de rapport de vrai semblance généralisé calculé pour évaluer s’il y un changement de la moyenne pour chaque semaine. Notez que le seuil pour chaque semaine prend en compte les semaines précédentes, de sorte que s’il y un changement soutenu, une alarme sera déclenchée. (Notez également qu’après chaque alarme, l’algorithme est réinitialisé).Afin de travailler avec le paquet surveillance, nous devons d’abord définir un objet “série temporelle de surveillance” (en utilisant la fonction sts()) pour s’intégrer dans le cadre.","code":"\n## Définir un objet de série temporelle de surveillance\n## nb. vous pouvez inclure un dénominateur avec l'objet population (voir ?sts)\ncounts_sts <- sts(observed = counts$case_int[!is.na(counts$case_int)],\n                  start = c(\n                    ## sous-ensemble pour ne garder que l'année de start_date. \n                    as.numeric(str_sub(start_date, 1, 4)), \n                    ## sous-ensemble pour ne conserver que la semaine à partir de la date de départ\n                    as.numeric(str_sub(start_date, 7, 8))), \n                  ## définir le type de données (dans ce cas, hebdomadaire)\n                  freq = 52)\n\n## définir la plage de semaines que vous voulez inclure (c'est-à-dire la période de prédiction)\n## nb. l'objet sts ne compte que les observations sans leur attribuer un identifiant de semaine ou d'année. \n## d'année - nous utilisons donc nos données pour définir les observations appropriées.\nweekrange <- cut_off - start_date"},{"path":"time_series.html","id":"méthode-farrington","chapter":"23 Série temporelle et détection des épidémies","heading":"Méthode Farrington","text":"Nous définissons ensuite chacun de nos paramètres pour la méthode de Farrington dans une liste.\nEnsuite, nous exécutons l’algorithme en utilisant farringtonFlexible() et ensuite nous pouvons extraire le seuil d’une alerte en utilisant farringtonmethod@upperbound pour l’inclure dans notre données. Il est également possible d’extraire un VRAI/FAUX pour chaque semaine si elle déclenché une alerte (au-dessus du seuil) en utilisant farringtonmethod@alarm.Nous pouvons ensuite visualiser les résultats dans ggplot comme nous l’avons fait précédemment.","code":"\n## définir le contrôle\nctrl <- list(\n  ## définissez la période pour laquelle vous voulez un seuil (i.e. 2011)\n  range = which(counts_sts@epoch > weekrange),\n  b = 9, ## nombre d'années en arrière pour la ligne de base\n  w = 2, ## taille de la fenêtre de roulement en semaines\n  weightsThreshold = 2.58, ## repondération des épidémies passées (méthode noufaily améliorée - l'originale suggère 1)\n  ## pastWeeksNotIncluded = 3, ## utilisation de toutes les semaines disponibles (noufaily suggère d'en éliminer 26)\n  trend = TRUE,\n  pThresholdTrend = 1, ## 0.05 normalement, mais 1 est conseillé dans la méthode améliorée (c'est-à-dire toujours garder)\n  thresholdMethod = \"nbPlugin\",\n  populationOffset = TRUE\n  )\n\n## appliquer la méthode flexible de Farrington\nfarringtonmethod <- farringtonFlexible(counts_sts, ctrl)\n\n## créer une nouvelle variable dans le jeu de données original appelée threshold.\n## contenant la limite supérieure de Farrington. \n## nb. ceci est seulement pour les semaines de 2011 (donc besoin de sous-ensembler les lignes)\ncounts[which(counts$epiweek >= cut_off & \n               !is.na(counts$case_int)),\n              \"threshold\"] <- farringtonmethod@upperbound\nggplot(counts, aes(x = epiweek)) + \n  ## ajouter le nombre de cas observés sous forme de ligne\n  geom_line(aes(y = case_int, colour = \"Observed\")) + \n  ## ajout de la limite supérieure de l'algorithme d'aberration\n  geom_line(aes(y = threshold, colour = \"Alert threshold\"), \n            linetype = \"dashed\", \n            size = 1.5) +\n  ## définir les couleurs\n  scale_colour_manual(values = c(\"Observed\" = \"black\", \n                                 \"Alert threshold\" = \"red\")) + \n  ## faire un graphique traditionnel (avec des axes noirs et un fond blanc)\n  theme_classic() + \n  ## supprimer le titre de la légende \n  theme(legend.title = element_blank())"},{"path":"time_series.html","id":"méthode-glrnb","chapter":"23 Série temporelle et détection des épidémies","heading":"Méthode GLRNB","text":"De même pour la méthode GLRNB, nous définissons chacun de nos paramètres pour le dans une liste, puis nous ajustons l’algorithme et extrayons les limites supérieures.ATTENTION: Cette méthode utilise la “force brute” (similaire au bootstrapping) pour calculer les seuils, donc peut prendre beaucoup de temps!.Voir la vignette GLRNB pour plus de détails.Visualisez les sorties comme précédemment.","code":"\n## définir les options de contrôle\nctrl <- list(\n  ## définir la période pour laquelle on veut un seuil (i.e. 2011)\n  range = which(counts_sts@epoch > weekrange),\n  mu0 = list(S = 1, ## nombre de termes de fourier (harmoniques) à inclure\n  trend = TRUE, ## inclusion ou non de la tendance\n  refit = FALSE), ## si l'on refit le modèle après chaque alarme\n  ## cARL = seuil pour la statistique GLR (arbitraire)\n     ## 3 ~ seuil intermédiaire pour minimiser les faux positifs\n     ## 1 s'ajuste aux 99%PI de glm.nb - avec des changements après les pics (seuil abaissé pour l'alerte)\n   c.ARL = 2,\n   # thêta = log(1.5), ## équivaut à une augmentation de 50% des cas dans une épidémie\n   ret = \"cases\" ## retourne la limite supérieure du seuil sous forme de nombre de cas\n  )\n\n## appliquer la méthode glrnb\nglrnbmethod <- glrnb(counts_sts, control = ctrl, verbose = FALSE)\n\n## créer une nouvelle variable dans l'ensemble de données original appelée threshold\n## contenant la limite supérieure de glrnb. \n## nb. ceci est seulement pour les semaines de 2011 (donc besoin de sous-ensembler les lignes)\ncounts[which(counts$epiweek >= cut_off & \n               !is.na(counts$case_int)),\n              \"threshold_glrnb\"] <- glrnbmethod@upperbound\nggplot(counts, aes(x = epiweek)) + \n  ## ajouter le nombre de cas observés sous forme de ligne\n  geom_line(aes(y = case_int, colour = \"Observed\")) + \n  ## ajout de la limite supérieure de l'algorithme d'aberration\n  geom_line(aes(y = threshold_glrnb, color = \"Alert threshold\"), \n            linetype = \"dashed\", \n            size = 1.5) +\n  ## définir les couleurs\n  scale_colour_manual(values = c(\"Observed\" = \"black\", \n                                 \"Alert threshold\" = \"red\")) + \n  ## faire un graphique traditionnel (avec des axes noirs et un fond blanc)\n  theme_classic() + \n  ## supprimer le titre de la légende \n  theme(legend.title = element_blank())"},{"path":"time_series.html","id":"série-chronologique-interrompue","chapter":"23 Série temporelle et détection des épidémies","heading":"23.8 Série chronologique interrompue","text":"Les séries chronologiques interrompues (également appelées régression segmentée ou analyse d’intervention), est souvent utilisée pour évaluer l’impact des vaccins sur l’incidence des maladies. Mais elle peut être utilisée pour évaluer l’impact d’un large éventail d’interventions ou d’introductions. Par exemple, des changements dans les procédures hospitalières ou l’introduction d’une nouvelle souche de maladie dans une population. Dans cet exemple, nous supposerons qu’une nouvelle souche de Campylobacter été introduite en Allemagne fin 2008, et nous verrons si cela affecte le nombre de cas. Nous utiliserons à nouveau la régression binomiale négative. Cette fois-ci, la régression sera divisée en deux parties, l’une avant l’intervention (ou l’introduction de la nouvelle souche ici) et une autre après (les périodes pré et post). Cela nous permet de calculer un ratio de taux d’incidence comparant les deux périodes. Une explication de l’équation pourrait rendre les choses plus claires (sinon, ignorez-la !).La régression binomiale négative peut être définie comme suit :\\[\\log(Y_t)= Î²_0 + Î²_1 \\times t+ Î²_2 \\times Î´(t-t_0) + Î²_3\\times(t-t_0 )^+ + log(pop_t) + e_t\\]Où :\n\\(Y_t\\) est le nombre de cas observés au temps \\(t\\).\\(pop_t\\) est la taille de la population en 100 000 au moment \\(t\\) (non utilisé ici)\\(t_0\\) est la dernière année de la pré-période (y compris la période de transition, le cas échéant).\\(Î'(x\\) est la fonction indicatrice (elle vaut 0 si xâ¤0 et 1 si x>0)\\((x)^+\\) est l’opérateur de coupure (il vaut x si x>0 et 0 sinon)\\(e_t\\) désigne le résidu\nDes termes supplémentaires, tendance et saison, peuvent être ajoutés si nécessaire.\\(Î²_2 \\times Î'(t-t_0) + Î²_3\\times(t-t_0 )^+\\) est la partie linéaire généralisée de la post-période et est nulle dans la pré-période. Cela signifie que les estimations de \\(Î²_2\\) et \\(Î²_3\\) sont les effets de l’intervention.Nous devons recalculer les termes de fourier sans faire de prévision ici, car nous utiliserons toutes les données dont nous disposons (c’est-à-dire rétrospectivement). De plus, nous devons calculerles termes supplémentaires nécessaires à la régression.Nous utilisons ensuite ces termes pour ajuster une régression binomiale négative, et produisons un tableau avec le pourcentage de changement. Cet exemple montre qu’il n’y pas eu de changement significatif.ATTENTION: Notez l’utilisation de simulate_pi = FALSE dans l’argument predict(). Ceci est dû au fait que le comportement par défaut de trending est d’utiliser le paquet ciTools pour estimer un intervalle de prédiction. Cela ne fonctionne pas s’il y des comptes NA, et produit également des intervalles plus granulaires. Voir ?trending::predict.trending_model_fit pour plus de détails. Comme précédemment, nous pouvons visualiser les résultats de la régression.","code":"\n## ajouter les termes de fourier en utilisant les variabless epiweek et case_int\ncounts$fourier <- select(counts, epiweek, case_int) %>% \n  as_tsibble(index = epiweek) %>% \n  fourier(K = 1)\n\n## définir la semaine d'intervention \nintervention_week <- yearweek(\"2008-12-31\")\n\n## définir les variables pour la régression \ncounts <- counts %>% \n  mutate(\n    ## correspond à t dans la formule\n      ## nombre de semaines (on pourrait probablement aussi utiliser la variable epiweeks)\n    # linear = row_number(epiweek), \n    ## correspond au delta(t-t0) dans la formule\n      ## période de pré ou post intervention\n    intervention = as.numeric(epiweek >= intervention_week), \n    ## correspond à (t-t0)^+ dans la formule\n      ## nombre de semaines après l'intervention\n      ## (choisir le plus grand nombre entre 0 et ce qui ressort du calcul)\n    time_post = pmax(0, epiweek - intervention_week + 1))\n## définissez le modèle que vous voulez ajuster (binomial négatif). \nmodel <- glm_nb_model(\n  ## définir le nombre de cas comme résultat d'intérêt\n  case_int ~\n    ## utiliser epiweek pour tenir compte de la tendance\n    epiweek +\n    ## utiliser les termes fourier pour tenir compte de la saisonnalité\n    fourier + \n    ## ajouter si dans la pré ou post-période \n    intervention + \n    ## ajouter le temps après l'intervention \n    time_post\n    )\n\n## ajustez votre modèle en utilisant l'ensemble de données de comptage\nfitted_model <- trending::fit(model, data.frame(counts))\n\n### calculer les intervalles de confiance et les intervalles de prédiction \nobserved <- predict(fitted_model, simulate_pi = FALSE)\n## Afficher les estimations et le pourcentage de changement dans un tableau\nfitted_model %>% \n  ## extraire la régression binomiale négative originale\n  get_fitted_model() %>% \n  ## obtenir un cadre de données ordonné des résultats\n  tidy(exponentiate = TRUE, \n       conf.int = TRUE) %>% ### ne conserve que les valeurs d'intervention \n  ### ne conserve que la valeur d'intervention \n  filter(term == \"intervention\") %>% \n  ## changer le IRR en pourcentage de changement pour l'estimation et les ICs \n  mutate(\n    ## pour chacune des colonnes d'intérêt - créer une nouvelle colonne\n    across(\n      all_of(c(\"estimate\", \"conf.low\", \"conf.high\")), \n      ## appliquer la formule pour calculer le pourcentage de changement\n            .f = function(i) 100 * (i - 1), \n      ## ajouter un suffixe aux nouveaux noms de colonnes avec \"_perc\".\n      .names = \"{.col}_perc\")\n    ) %>% \n  ## ne garder (et renommer) que certaines colonnes \n  select( \"IRR\" = estimate, \n         \"95%CI low\" = conf.low, \n         \"95%CI high\" = conf.high,\n         \"Variation in percentag\" = estimate_perc, \n         \"95%CI low (perc)\" = conf.low_perc, \n         \"95%CI high (perc)\" = conf.high_perc,\n         \"p-value\" = p.value)\nestimate_res <- data.frame(observed$result)\n\nggplot(estimate_res, aes(x = epiweek)) + \n  ## ajouter le nombre de cas observés sous forme de ligne\n  geom_line(aes(y = case_int, colour = \"Observed\")) + \n  ## ajout d'une ligne pour l'estimation du modèle\n  geom_line(aes(y = estimate, col = \"Estimate\")) + \n  ## ajouter une bande pour les intervalles de prédiction \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## ajouter une ligne verticale et une étiquette pour montrer où la prévision a commencé\n  geom_vline(\n           xintercept = as.Date(intervention_week), \n           linetype = \"dashed\") + \n  annotate(geom = \"text\", \n           label = \"Intervention\", \n           x = intervention_week, \n           y = max(estimate_res$upper_pi), \n           angle = 90, \n           vjust = 1\n           ) + \n  ## définir les couleurs\n  scale_colour_manual(values = c(\"Observed\" = \"black\", \n                                 \"Estimate\" = \"red\")) + \n  ## faire un graphique traditionnel (avec des axes noirs et un fond blanc)\n  theme_classic()"},{"path":"time_series.html","id":"ressources-10","chapter":"23 Série temporelle et détection des épidémies","heading":"23.9 Ressources","text":"Prévision : principes et pratique - manuelÉtudes de cas d’analyse de séries temporelles EPIETCours de Penn State\nManuscrit du paquet de surveillance","code":""},{"path":"epidemic_models.html","id":"epidemic_models","chapter":"24 Modélisation des épidémies","heading":"24 Modélisation des épidémies","text":"","code":""},{"path":"epidemic_models.html","id":"overview","chapter":"24 Modélisation des épidémies","heading":"24.1 Overview","text":"Il existe un nombre croissant d’outils pour la modélisation des épidémies qui nous permettent de mener des analyses assez complexes avec un effort minimal.Cette section fournira une\naperçu sur la façon d’utiliser ces outils pour :estimer le nombre de reproduction effectif Rt et les statistiques connexes.\ntelles que le temps de doublementproduire des projections à court terme de l’incidence future.Il ne s’agit pas d’un aperçu des méthodologies et des méthodes statistiques qui sous-tendent ces outils. Veuillez donc vous référer à l’onglet Ressources pour des liens vers des\ndocuments traitant de ce sujet. Assurez-vous d’avoir une bonne compréhension des\nles méthodes avant d’utiliser ces outils ; cela vous permettra d’interpréter correctement\nleurs résultats.Voici un exemple de l’un des résultats que nous produirons dans cette section.","code":""},{"path":"epidemic_models.html","id":"préparation-7","chapter":"24 Modélisation des épidémies","heading":"24.2 Préparation","text":"Nous allons utiliser deux méthodes et packages différents pour l’estimation Rt,\nà savoir EpiNow et EpiEstim, ainsi que le package projections pour la prévision de l’incidence des cas.Ce fragment de code montre le chargement des paquets nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire et le charge pour l’utiliser. Vous pouvez également charger les paquets installés avec library() de base R. Voir la page sur R basics pour plus d’informations sur les paquets R.Nous utiliserons la linelist de cas nettoyée pour toutes les analyses de cette section. Si vous voulez suivre, cliquez pour télécharger la linelist “propre” (en tant que fichier .rds). Consultez la page Télécharger le manuel et les données pour télécharger tous les exemples de données utilisés dans ce manuel.","code":"\npacman::p_load(\n   rio, # Importation de fichiers\n   here, # Localisation de fichiers\n   tidyverse, # Gestion des données + graphiques ggplot2\n   epicontacts, # Analyse des réseaux de transmission\n   EpiNow2, # Estimation de Rt\n   EpiEstim, # Estimation Rt\n   projections, # Projections d'incidence\n   incidence2, # Traitement des données d'incidence\n   epitrix, # Fonctions epi utiles\n   distcrete # Distributions discrètes des délais\n)\n# Importez la liste de cas nettoyée\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"epidemic_models.html","id":"estimation-de-rt","chapter":"24 Modélisation des épidémies","heading":"24.3 Estimation de Rt","text":"","code":""},{"path":"epidemic_models.html","id":"epinow2-vs.-epiestim","chapter":"24 Modélisation des épidémies","heading":"EpiNow2 vs. EpiEstim","text":"Le taux de reproduction R est une mesure de la transmissibilité d’une maladie, et est défini comme le nombre attendu de cas secondaires par cas infecté. Dans une population totalement sensible, cette valeur représente le nombre de reproduction de base, R0. Cependant, comme le nombre d’individus sensibles dans une population évolue au cours d’une épidémie ou d’une pandémie, et que diverses mesures de réponse sont mises en œuvre, la mesure la plus couramment utilisée de la transmissibilité est le taux de reproduction effectif, Rt ; il est défini défini comme le nombre attendu de cas secondaires par cas infecté à un moment, t.Le paquet EpiNow2 fournit le cadre le plus sophistiqué pour l’estimation de Rt. Il présente deux avantages essentiels par rapport à l’autre paquet couramment utilisé, EpiEstim :Il tient compte des délais de déclaration et peut donc estimer Rt même lorsque les données récentes sont incomplètes.Il estime Rt sur les dates d’infection plutôt que sur les dates de début de déclaration, ce qui signifie que l’effet d’une intervention sera immédiatement reflété dans un changement de Rt, plutôt qu’avec un delai.Cependant, elle présente également deux inconvénients majeurs :Elle nécessite la connaissance de la distribution des temps de génération (c’est-à-dire la distribution des délais entre l’infection d’un cas primaire et d’un cas secondaire), la distribution de la période d’incubation (c’est-à-dire la distribution des délais entre l’infection et l’apparition des symptômes) et toute autre distribution de délai pertinente pour vos données (par exemple, si vous avez des dates de déclaration, vous avez besoin de la distribution des délais entre l’apparition des symptômes et la déclaration, ou la période d’incubation). Bien que cela permette une estimation plus précise de Rt, EpiEstim ne requiert que la distribution de l’intervalle sériel (c’est-à-dire la distribution des délais entre l’apparition des symptômes d’un cas primaire et d’un cas secondaire), qui peut être la seule distribution disponible pour vous.EpiNow2 est significativement plus lent que EpiEstim, de manière anecdotique par un facteur de 100 à 1000 ! Par exemple, l’estimation de Rt pour l’échantillon de foyers considéré dans cette section prend environ quatre heures (ceci été exécuté pour un grand d’itérations pour garantir une grande précision et pourrait probablement être réduite si nécessaire) mais il n’en reste pas moins que l’algorithme est lent en général. Cela peut être irréalisable si vous mettez régulièrement à jour votre base de données pour Rt.Le paquet que vous choisirez d’utiliser dépendra donc des données, du temps et des ressources informatiques dont vous disposez.","code":""},{"path":"epidemic_models.html","id":"epinow2","chapter":"24 Modélisation des épidémies","heading":"EpiNow2","text":"","code":""},{"path":"epidemic_models.html","id":"estimation-des-distributions-de-retard","chapter":"24 Modélisation des épidémies","heading":"24.3.0.1 Estimation des distributions de retard","text":"Les distributions de retard requises pour exécuter EpiNow2 dépendent des données dont vous disposez. Essentiellement, vous devez être en mesure de décrire le délai entre la date d’infection à la date de l’événement que vous voulez utiliser pour estimer Rt. Si\nvous utilisez les dates d’apparition, il s’agit simplement de la distribution de la période d’incubation. Si vous utilisez les dates de déclaration, vous avez besoin du\ndélai entre l’infection et la déclaration. Comme il est peu probable que cette distribution soit connue directement, EpiNow2 vous permet d’enchaîner plusieurs distributions de délai ; dans ce cas, le délai entre l’infection et la déclaration est le même.Comme nous disposons des dates d’apparition des symptômes pour tous nos cas dans la liste d’exemples, nous n’aurons besoin que de la distribution de la période d’incubation pour déterminer le délai d’apparition des symptômes.Nous pouvons soit estimer cette distribution\nà partir des données ou utiliser les valeurs de la littérature.Une estimation de la période d’incubation d’Ebola dans la littérature (tirée de cet article) avec une moyenne de 9,1, un écart-type de 7,3 et une valeur maximale de 30, serait spécifiée comme suit :Notez que EpiNow2 exige que ces distributions de délais soient fournies sur une échelle log d’où l’appel log autour de chaque valeur (sauf le paramètre max qui doit être fourni sur une échelle naturelle). Les paramètres mean_sd et sd_sd définissent l’écart type des estimations de la moyenne. Comme ceux-ci ne sont pas connus dans ce cas, nous choisissons la valeur assez arbitraire de 0.1.Dans cette analyse, nous estimons plutôt la distribution de la période d’incubation à partir de la linelist elle-même en utilisant la fonction bootstrapped_dist_fit, ce qui va\nune distribution lognormale aux délais observés entre l’infection et l’apparition de la maladie.L’autre distribution dont nous avons besoin est le temps de génération. Comme nous avons des données sur les temps d’infection et les liens de transmission, nous pouvons estimer cette\ndistribution à partir de la liste de liens en calculant le délai entre les temps d’infection\ndes paires infecteur-infecte. Pour ce faire, nous utilisons la fonction pratique get_pairwise du paquet epicontacts, qui nous permet de calculer les différences par paire des propriétés de la linelist entre les paires de transmission. Nous créons d’abord un objet epicontacts (voir la page Chaînes de transmission pour plus de détails) :Nous ajustons ensuite la différence de temps d’infection entre les paires de transmission,\ncalculée en utilisant get_pairwise, à une distribution gamma :","code":"\nincubation_period_lit <- list(\n  mean = log(9.1),\n  mean_sd = log(0.1),\n  sd = log(7.3),\n  sd_sd = log(0.1),\n  max = 30\n)\n## Estimation de la période d'incubation\nincubation_period <- bootstrapped_dist_fit(\n  linelist$date_onset - linelist$date_infection,\n  dist = \"lognormal\",\n  max_value = 100,\n  bootstraps = 1\n)\n## générer des contacts\ncontacts <- linelist %>%\n  transmute(\n    from = infector,\n    to = case_id\n  ) %>%\n  drop_na()\n\n## générer un objet epicontacts\nepic <- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts, \n  directed = TRUE\n)\n## estimation du temps de génération gamma\ngeneration_time <- bootstrapped_dist_fit(\n  get_pairwise(epic, \"date_infection\"),\n  dist = \"gamma\",\n  max_value = 20,\n  bootstraps = 1\n)"},{"path":"epidemic_models.html","id":"exécution-de-epinow2","chapter":"24 Modélisation des épidémies","heading":"Exécution de EpiNow2","text":"Maintenant, il ne nous reste plus qu’à calculer l’incidence journalière à partir de la liste linéaire, ce que nous pouvons faire facilement avec les fonctions dplyr group_by() et n(). Notez que EpiNow2 exige que les noms des colonnes soient date et confirm.Nous pouvons ensuite estimer Rt en utilisant la fonction epinow. Quelques remarques sur les entrées :Nous pouvons fournir n’importe quel nombre de distributions de délais “enchaînés” à l’argument delays.\nNous les insérons simplement à côté de l’objet incubation_period dans la fonction delay_opts.return_output permet de s’assurer que la sortie est retournée dans R et pas seulement\nun fichier.verbose spécifie que nous voulons une lecture de la progression.horizon indique pour combien de jours nous voulons projeter l’incidence future.Nous passons des options supplémentaires à l’argument stan pour spécifier combien de temps\nnous voulons exécuter l’inférence pour. L’augmentation de samples et de chains vous donnera une estimation plus précise qui caractérisera mieux l’incertitude.Cependant, l’exécution sera plus longue.","code":"\n## Obtenir l'incidence à partir des dates d'apparition\ncases <- linelist %>%\n  group_by(date = date_onset) %>%\n  summarise(confirm = n())\n## exécuter epinow\nepinow_res <- epinow(\n  reported_cases = cases,\n  generation_time = generation_time,\n  delays = delay_opts(incubation_period),\n  return_output = TRUE,\n  verbose = TRUE,\n  horizon = 21,\n  stan = stan_opts(samples = 750, chains = 4)\n)"},{"path":"epidemic_models.html","id":"analyser-les-sorties","chapter":"24 Modélisation des épidémies","heading":"Analyser les sorties","text":"Une fois l’exécution du code terminée, nous pouvons tracer un résumé très facilement comme suit. Faites défiler l’image pour voir l’étendue complète.Nous pouvons également examiner diverses statistiques sommaires :Pour des analyses plus approfondies et des tracés personnalisés, vous pouvez accéder aux estimations quotidiennes résumées via $estimates$summarised. Nous allons convertir le tableau par défaut data.table en un tibble pour faciliter l’utilisation avec dplyr.titre d’exemple, faisons un graphique du temps de doublement et de Rt. Nous n’examinerons que les premiers mois de l’épidémie, lorsque Rt est largement\nsupérieur à un, pour éviter de tracer des temps de doublement extrêmement élevés.Nous utilisons la formule log(2)/taux de croissance pour calculer le temps de doublement à partir du taux de croissance estimé.","code":"\n## Tracer la figure récapitulative\nplot(epinow_res)\n## tableau récapitulatif\nepinow_res$summary##                                  measure                  estimate  numeric_estimate\n## 1: New confirmed cases by infection date                4 (2 -- 6) <data.table[1x9]>\n## 2:        Expected change in daily cases                    Unsure              0.56\n## 3:            Effective reproduction no.        0.88 (0.73 -- 1.1) <data.table[1x9]>\n## 4:                        Rate of growth -0.012 (-0.028 -- 0.0052) <data.table[1x9]>\n## 5:          Doubling/halving time (days)          -60 (130 -- -25) <data.table[1x9]>\n## extraire le résumé et le convertir en tibble\nestimates <- as_tibble(epinow_res$estimates$summarised)\nestimates\n## faire des df larges pour le tracé de la médiane\ndf_wide <- estimates %>%\n  filter(\n    variable %in% c(\"growth_rate\", \"R\"),\n    date < as.Date(\"2014-09-01\")\n  ) %>%\n  ## convertir les taux de croissance en temps de doublement\n  mutate(\n    across(\n      c(median, lower_90:upper_90),\n      ~ case_when(\n        variable == \"growth_rate\" ~ log(2)/.x,\n        TRUE ~ .x\n      )\n    ),\n    ## renommer la variable pour refléter la transformation\n    variable = replace(variable, variable == \"growth_rate\", \"doubling_time\")\n  )\n\n## créer des df longs pour le tracé des quantiles\ndf_long <- df_wide %>%\n  ## ici, nous faisons correspondre les quantiles (par exemple, lower_90 à upper_90)\n  pivot_longer(\n    lower_90:upper_90,\n    names_to = c(\".value\", \"quantile\"),\n    names_pattern = \"(.+)_(.+)\"\n  )\n\n## créer un graphique\nggplot() +\n  geom_ribbon(\n    data = df_long,\n    aes(x = date, ymin = lower, ymax = upper, alpha = quantile),\n    color = NA\n  ) +\n  geom_line(\n    data = df_wide,\n    aes(x = date, y = median)\n  ) +\n  ## utiliser label_parsed pour permettre l'utilisation d'une étiquette en indice\n  facet_wrap(\n    ~ variable,\n    ncol = 1,\n    scales = \"free_y\",\n    labeller = as_labeller(c(R = \"R[t]\", doubling_time = \"Doubling~time\"), label_parsed),\n    strip.position = 'left'\n  ) +\n  ## définir manuellement la transparence des quantiles\n  scale_alpha_manual(\n    values = c(`20` = 0.7, `50` = 0.4, `90` = 0.2),\n    labels = function(x) paste0(x, \"%\")\n  ) +\n  labs(\n    x = NULL,\n    y = NULL,\n    alpha = \"Credible\\ninterval\"\n  ) +\n  scale_x_date(\n    date_breaks = \"1 month\",\n    date_labels = \"%b %d\\n%Y\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    strip.background = element_blank(),\n    strip.placement = 'outside'\n  )"},{"path":"epidemic_models.html","id":"epiestim","chapter":"24 Modélisation des épidémies","heading":"EpiEstim","text":"Pour exécuter EpiEstim, nous devons fournir des données sur l’incidence journalière et spécifier l’intervalle sériel (c’est-à-dire la distribution des délais entre l’apparition des symptômes des cas primaires et secondaires).Les données d’incidence peuvent être fournies à EpiEstim sous la forme d’un vecteur, d’un cadre de données ou d’un objet incidence provenant du paquetage original incidence. Vous pouvez même faire la distinction entre les importations et les infections acquises localement ; voir la documentation de ?estimate_R pour plus de détails.Nous allons créer l’entrée en utilisant incidence2. Voir la page sur Epidemic curves pour plus d’exemples avec le paquet incidence2. Comme il y eu des mises à jour du paquet incidence2 qui ne correspondent pas complètement à l’entrée attendue de estimateR(), quelques étapes supplémentaires mineures sont nécessaires. L’objet incidence consiste en un tibble avec des dates et leurs nombres de cas respectifs. Nous utilisons complete() de tidyr pour nous assurer que toutes les dates sont incluses (même celles sans cas), puis nous rename() les colonnes pour les aligner avec ce qui est attendu par estimate_R() dans une étape ultérieure.Le paquetage fournit plusieurs options pour spécifier l’intervalle sériel, dont les détails sont fournis dans la documentation de ?estimate_R.","code":"\n## Obtenir l'incidence à partir de la date d'apparition\ncases <- incidence2::incidence(linelist, date_index = \"date_onset\") %>% # obtient le nombre de cas par jour\n  tidyr::complete(date_index = seq.Date( # s'assurer que toutes les dates sont représentées\n    from = min(date_index, na.rm = T),\n    to = max(date_index, na.rm=T),\n    by = \"day\"),\n    fill = list(count = 0)) %>% # convertit les comptes NA en 0\n  rename(I = count, # renomme aux noms attendus par estimateR\n         dates = date_index)"},{"path":"epidemic_models.html","id":"utiliser-des-estimations-dintervalles-sériels-issues-de-la-littérature","chapter":"24 Modélisation des épidémies","heading":"Utiliser des estimations d’intervalles sériels issues de la littérature","text":"En utilisant l’option method = \"parametric_si\", nous pouvons spécifier manuellement la moyenne et l’écart type de l’intervalle sériel dans la littérature ou dans un objet config créé à l’aide de la fonction make_config. Nous utilisons une moyenne et un écart-type de 12.0 et 5.2, respectivement, définis dans cet article :Nous pouvons ensuite estimer Rt avec la fonction estimate_R :et tracer un résumé des résultats :","code":"\n## créer config\nconfig_lit <- make_config(\n  mean_si = 12.0,\n  std_si = 5.2\n)\ncases <- cases %>% \n     filter(!is.na(date))\n\n\n#créer un cadre de données pour la fonction estimate_R()\ncases_incidence <- data.frame(dates = seq.Date(from = min(cases$dates),\n                               to = max(cases$dates), \n                               by = 1))\n\ncases_incidence <- left_join(cases_incidence, cases) %>% \n     select(dates, I) %>% \n     mutate(I = ifelse(is.na(I), 0, I))## Joining with `by = join_by(dates)`\nepiestim_res_lit <- estimate_R(\n  incid = cases_incidence,\n  method = \"parametric_si\",\n  config = config_lit\n)## Default config will estimate R on weekly sliding windows.\n##     To change this change the t_start and t_end arguments.\nplot(epiestim_res_lit)"},{"path":"epidemic_models.html","id":"utilisation-destimations-dintervalles-en-série-à-partir-des-données","chapter":"24 Modélisation des épidémies","heading":"Utilisation d’estimations d’intervalles en série à partir des données","text":"Comme nous avons des données sur les dates d’apparition des symptômes et les liens de transmission, nous pouvons également estimer l’intervalle sériel à partir de la liste de liens en calculant le délai entre les dates d’apparition des symptômes des paires infecteur-infecté.\nComme nous l’avons fait dans la section EpiNow2 nous allons utiliser la fonction get_pairwise du paquet epicontacts qui nous permet de calculer les différences par paires des propriétés de la liste de liens entre les paires de transmission. Nous créons d’abord un objet epicontacts (voir la page Chaînes de transmission pour plus de détails) :Nous ajustons ensuite la différence de dates d’apparition entre les paires de transmissions, calculée en utilisant get_pairwise, à une distribution gamma. Nous utilisons l’outil pratique fit_disc_gamma du paquet epitrix pour cette procédure d’ajustement, car nous avons besoin d’une distribution discrète.Nous passons ensuite ces informations à l’objet config, exécutons EpiEstim et traçons les résultats :","code":"\n## générer des contacts\ncontacts <- linelist %>%\n  transmute(\n    from = infector,\n    to = case_id\n  ) %>%\n  drop_na()\n\n## générer un objet epicontacts\nepic <- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts, \n  directed = TRUE\n)\n## Estimation de l'intervalle sériel gamma\nserial_interval <- fit_disc_gamma(get_pairwise(epic, \"date_onset\"))\n## faire le config\nconfig_emp <- make_config(\n  mean_si = serial_interval$mu,\n  std_si = serial_interval$sd\n)\n\n## Exécuter epiestim\nepiestim_res_emp <- estimate_R(\n  incid = cases_incidence,\n  method = \"parametric_si\",\n  config = config_emp\n)## Default config will estimate R on weekly sliding windows.\n##     To change this change the t_start and t_end arguments.\n## tracer les résultats\nplot(epiestim_res_emp)"},{"path":"epidemic_models.html","id":"spécification-des-fenêtres-temporelles-destimation","chapter":"24 Modélisation des épidémies","heading":"Spécification des fenêtres temporelles d’estimation","text":"Ces options par défaut fournissent une estimation hebdomadaire glissante et peuvent servir d’avertissement si vous estimez Rt trop tôt dans l’épidémie pour une estimation précise.Vous pouvez changer cela en fixant une date de début ultérieure pour l’estimation de Rt, comme indiqué ci-dessous.Malheureusement, EpiEstim n’offre qu’une façon très maladroite de spécifier ces temps d’estimation, en ce sens que vous devez fournir un vecteur d’entiers __ se référant aux dates de début et de fin de chaque fenêtre temporelle.Maintenant, nous réexécutons EpiEstim et nous pouvons voir que les estimations ne commencent qu’à partir de juin :","code":"\n## définir un vecteur de dates commençant le 1er juin\nstart_dates <- seq.Date(\n  as.Date(\"2014-06-01\"),\n  max(cases$dates) - 7,\n  by = 1\n) %>%\n  ## soustraire la date de départ pour la convertir en numérique\n  `-`(min(cases$dates)) %>%\n  ## convertir en entier\n  as.integer()\n\n## ajouter six jours pour une fenêtre glissante d'une semaine\nend_dates <- start_dates + 6\n  \n## faire la configuration\nconfig_partial <- make_config(\n  mean_si = 12.0,\n  std_si = 5.2,\n  t_start = start_dates,\n  t_end = end_dates\n)\n## exécuter epiestim\nepiestim_res_partial <- estimate_R(\n  incid = cases_incidence,\n  method = \"parametric_si\",\n  config = config_partial\n)\n\n## tracer les résultats\nplot(epiestim_res_partial)"},{"path":"epidemic_models.html","id":"analyser-les-sorties-1","chapter":"24 Modélisation des épidémies","heading":"Analyser les sorties","text":"Les principales sorties sont accessibles via $R. titre d’exemple, nous allons créer un graphe de Rt et une mesure de “potentiel de transmission” donnée par le produit de\nRt et du nombre de cas signalés ce jour-là ; cela représente le\nnombre attendu de cas dans la prochaine génération d’infection.","code":"\n## créer un cadre de données large pour la médiane\ndf_wide <- epiestim_res_lit$R %>%\n  rename_all(clean_labels) %>%\n  rename(\n    lower_95_r = quantile_0_025_r,\n    lower_90_r = quantile_0_05_r,\n    lower_50_r = quantile_0_25_r,\n    upper_50_r = quantile_0_75_r,\n    upper_90_r = quantile_0_95_r,\n    upper_95_r = quantile_0_975_r,\n    ) %>%\n  mutate(\n    ## extraire la date médiane de t_start et t_end\n    dates = epiestim_res_emp$dates[round(map2_dbl(t_start, t_end, median))],\n    var = \"R[t]\"\n  ) %>%\n  ## fusionner les données d'incidence quotidienne\n  left_join(cases, \"dates\") %>%\n  ## calculer le risque pour toutes les estimations r\n  mutate(\n    across(\n      lower_95_r:upper_95_r,\n      ~ .x*I,\n      .names = \"{str_replace(.col, '_r', '_risk')}\"\n    )\n  ) %>%\n  ## séparer les estimations de r et les estimations de risque\n  pivot_longer(\n    contains(\"median\"),\n    names_to = c(\".value\", \"variable\"),\n    names_pattern = \"(.+)_(.+)\"\n  ) %>%\n  ## Assigner des niveaux de facteurs\n  mutate(variable = factor(variable, c(\"risk\", \"r\")))\n\n## créer un cadre de données long à partir des quantiles\ndf_long <- df_wide %>%\n  select(-variable, -median) %>%\n  ## séparer les estimations de r/risque et les niveaux de quantile\n  pivot_longer(\n    contains(c(\"lower\", \"upper\")),\n    names_to = c(\".value\", \"quantile\", \"variable\"),\n    names_pattern = \"(.+)_(.+)_(.+)\"\n  ) %>%\n  mutate(variable = factor(variable, c(\"risk\", \"r\")))\n\n## créer un graphique\nggplot() +\n  geom_ribbon(\n    data = df_long,\n    aes(x = dates, ymin = lower, ymax = upper, alpha = quantile),\n    color = NA\n  ) +\n  geom_line(\n    data = df_wide,\n    aes(x = dates, y = median),\n    alpha = 0.2\n  ) +\n  ## utiliser label_parsed pour permettre l'utilisation d'une étiquette en indice\n  facet_wrap(\n    ~ variable,\n    ncol = 1,\n    scales = \"free_y\",\n    labeller = as_labeller(c(r = \"R[t]\", risk = \"Transmission~potential\"), label_parsed),\n    strip.position = 'left' \n  ) +\n  ## définir manuellement la transparence des quantiles\n  scale_alpha_manual(\n    values = c(`50` = 0.7, `90` = 0.4, `95` = 0.2),\n    labels = function(x) paste0(x, \"%\")\n  ) +\n  labs(\n    x = NULL,\n    y = NULL,\n    alpha = \"Credible\\ninterval\"\n  ) +\n  scale_x_date(\n    date_breaks = \"1 month\",\n    date_labels = \"%b %d\\n%Y\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    strip.background = element_blank(),\n    strip.placement = 'outside' \n  )"},{"path":"epidemic_models.html","id":"projection-de-lincidence","chapter":"24 Modélisation des épidémies","heading":"24.4 Projection de l’incidence","text":"","code":""},{"path":"epidemic_models.html","id":"epinow2-1","chapter":"24 Modélisation des épidémies","heading":"EpiNow2","text":"En plus de l’estimation de Rt, EpiNow2 permet également la prévision de\nRt et les projections du nombre de cas par l’intégration avec le paquet EpiSoon sous le capot. Tout ce que vous avez à faire est de spécifier l’argument horizon dans votre appel de fonction epinow, indiquant le nombre de jours que vous voulez projeter dans le futur ; voir la section EpiNow2 sous la rubrique “Estimation\nRt” pour plus de détails sur la façon de mettre en place EpiNow2. Dans cette\nsection, nous allons simplement tracer les sorties de cette analyse, stockées dans le fichier\nl’objet epinow_res.","code":"\n## définir la date minimale pour le tracé\nmin_date <- as.Date(\"2015-03-01\")\n\n## extraire les estimations résumées\nestimates <- as_tibble(epinow_res$estimates$summarised)\n\n## extraire les données brutes sur l'incidence des cas\nobservations <- as_tibble(epinow_res$estimates$observations) %>%\n  filter(date > min_date)\n\n## extraire les estimations prévisionnelles du nombre de cas\ndf_wide <- estimates %>%\n  filter(\n    variable == \"reported_cases\",\n    type == \"forecast\",\n    date > min_date\n  )\n\n## convertir en un format encore plus long pour le tracé des quantiles\ndf_long <- df_wide %>%\n  ## ici nous faisons correspondre les quantiles (par exemple, lower_90 à upper_90)\n  pivot_longer(\n    lower_90:upper_90,\n    names_to = c(\".value\", \"quantile\"),\n    names_pattern = \"(.+)_(.+)\"\n  )\n\n## créer un graphique\nggplot() +\n  geom_histogram(\n    data = observations,\n    aes(x = date, y = confirm),\n    stat = 'identity',\n    binwidth = 1\n  ) +\n  geom_ribbon(\n    data = df_long,\n    aes(x = date, ymin = lower, ymax = upper, alpha = quantile),\n    color = NA\n  ) +\n  geom_line(\n    data = df_wide,\n    aes(x = date, y = median)\n  ) +\n  geom_vline(xintercept = min(df_long$date), linetype = 2) +\n  ## Définir manuellement la transparence des quantiles\n  scale_alpha_manual(\n    values = c(`20` = 0.7, `50` = 0.4, `90` = 0.2),\n    labels = function(x) paste0(x, \"%\")\n  ) +\n  labs(\n    x = NULL,\n    y = \"Daily reported cases\",\n    alpha = \"Credible\\ninterval\"\n  ) +\n  scale_x_date(\n    date_breaks = \"1 month\",\n    date_labels = \"%b %d\\n%Y\"\n  ) +\n    theme_minimal(base_size = 14)"},{"path":"epidemic_models.html","id":"projections","chapter":"24 Modélisation des épidémies","heading":"projections","text":"Le paquet projections développé par RECON permet de faire très facilement des prévisions d’incidence à court terme, ne nécessitant que la connaissance du nombre de reproduction effectif de reproduction Rt et de l’intervalle de série. Nous verrons ici comment utiliser des estimations d’intervalle sériel de la littérature et comment utiliser nos propres estimations de la liste de diffusion.","code":""},{"path":"epidemic_models.html","id":"utiliser-les-estimations-dintervalles-sériels-de-la-littérature","chapter":"24 Modélisation des épidémies","heading":"Utiliser les estimations d’intervalles sériels de la littérature","text":"projections nécessite une distribution d’intervalle série discrétisée de la classe distcrete du paquet distcrete. Nous utiliserons une distribution gamma avec une moyenne de 12,0 et un écart-type de 5,2 définie dans cet article. Pour convertir ces valeurs en paramètres de forme et d’échelle requis pour une distribution gamma. nous utiliserons la fonction gamma_mucv2shapescale du paquet epitrix.Voici une vérification rapide pour s’assurer que l’intervalle de série est correct. Nous accédons à la densité de la distribution gamma que nous venons de définir par $d, ce qui revient à appeler dgamma :","code":"\n## obtenir les paramètres de forme et d'échelle à partir du mu moyen et du coefficient de\n## variation (par exemple, le rapport entre l'écart type et la moyenne).\nshapescale <- epitrix::gamma_mucv2shapescale(mu = 12.0, cv = 5.2/12)\n\n## fabriquer un objet distcrete\nserial_interval_lit <- distcrete::distcrete(\n  name = \"gamma\",\n  interval = 1,\n  shape = shapescale$shape,\n  scale = shapescale$scale\n)\n## vérifiez que l'intervalle série est correct\nqplot(\n  x = 0:50, y = serial_interval_lit$d(0:50), geom = \"area\",\n  xlab = \"Serial interval\", ylab = \"Density\"\n)"},{"path":"epidemic_models.html","id":"utilisation-des-estimations-dintervalles-sériels-à-partir-des-données","chapter":"24 Modélisation des épidémies","heading":"Utilisation des estimations d’intervalles sériels à partir des données","text":"Comme nous avons des données sur les dates d’apparition des symptômes et les liens de transmission, nous pouvons également estimer l’intervalle sériel à partir de la liste de liens en calculant le délai entre les dates d’apparition des symptômes des paires infecteur-infecté. Comme nous l’avons fait dans la section EpiNow2, nous allons utiliser la fonction get_pairwise du paquet epicontacts qui nous permet de calculer les différences par paires des propriétés de la liste de liens entre les paires de transmission. Nous créons d’abord un objet epicontacts (voir la page Chaînes de transmission pour plus de détails) :Nous ajustons ensuite la différence de dates d’apparition entre les paires de transmissions, calculée avec get_pairwise, à une distribution gamma. Nous utilisons l’outil pratique fit_disc_gamma du paquet epitrix pour cette procédure d’ajustement, car nous avons besoin d’une distribution discrète.","code":"\n## générer des contacts\ncontacts <- linelist %>%\n  transmute(\n    from = infector,\n    to = case_id\n  ) %>%\n  drop_na()\n\n## générer un objet epicontacts\nepic <- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts, \n  directed = TRUE\n)\n## Estimation de l'intervalle sériel gamma\nserial_interval <- fit_disc_gamma(get_pairwise(epic, \"date_onset\"))\n\n## inspecter l'estimation\nserial_interval[c(\"mu\", \"sd\")]## $mu\n## [1] 11.51047\n## \n## $sd\n## [1] 7.696056"},{"path":"epidemic_models.html","id":"projection-de-lincidence-1","chapter":"24 Modélisation des épidémies","heading":"Projection de l’incidence","text":"Pour projeter l’incidence future, nous devons fournir l’incidence historique sous la forme d’un objet incidence, ainsi qu’un échantillon de valeurs Rt plausibles. Nous générerons ces valeurs en utilisant les estimations Rt générées par EpiEstim dans la section précédente (sous “Estimation de la valeur de Rt”) et stockées dans l’objet epiestim_res_emp. Dans le code ci-dessous nous extrayons les estimations de la moyenne et de l’écart type de Rt pour la dernière fenêtre de temps de l’épidémie (en utilisant la fonction tail pour accéder au dernier élément d’un vecteur), et nous simulons 1000 valeurs à partir d’une distribution gamma en utilisant rgamma. Vous pouvez également fournir votre propre vecteur de valeurs Rt que vous souhaitez utiliser pour les projections.Nous utilisons ensuite la fonction project() pour effectuer la prévision réelle. Nous spécifions le nombre de jours pour lesquels nous voulons faire une projection via les arguments n_days, et nous spécifions le nombre de simulations en utilisant les arguments n_sim.Nous pouvons alors facilement tracer l’incidence et les projections en utilisant les fonctions plot() et add_projections(). peut facilement sous-évaluer l’objet incidence pour ne montrer que les cas les plus récents en utilisant l’opérateur de crochets.Vous pouvez également extraire facilement les estimations brutes du nombre de cas quotidiens en convertissant la sortie en un cadre de données.","code":"\n## créer un objet d'incidence à partir des dates d'apparition des symptômes\ninc <- incidence::incidence(linelist$date_onset)## 256 missing observations were removed.\n## extraire les valeurs r plausibles de l'estimation la plus récente\nmean_r <- tail(epiestim_res_emp$R$`Mean(R)`, 1)\nsd_r <- tail(epiestim_res_emp$R$`Std(R)`, 1)\nshapescale <- gamma_mucv2shapescale(mu = mean_r, cv = sd_r/mean_r)\nplausible_r <- rgamma(1000, shape = shapescale$shape, scale = shapescale$scale)\n\n## vérifier la distribution\nqplot(x = plausible_r, geom = \"histogram\", xlab = expression(R[t]), ylab = \"Counts\")## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n## faire une projection\nproj <- project(\n  x = inc,\n  R = plausible_r,\n  si = serial_interval$distribution,\n  n_days = 21,\n  n_sim = 1000\n)\n## Tracer l'incidence et les projections\nplot(inc[inc$dates > as.Date(\"2015-03-01\")]) %>%\n  add_projections(proj)\n## convertir en cadre de données pour les données brutes\nproj_df <- as.data.frame(proj)\nproj_df"},{"path":"epidemic_models.html","id":"ressources-11","chapter":"24 Modélisation des épidémies","heading":"24.5 Ressources","text":"Voici un article qui décrit la méthodologie mise en œuvre dans EpiEstim.\nVoici un article décrivant la méthodologie mise en œuvre dans EpiNow.\nVoici un article décrivant diverses considérations méthodologiques et pratiques pour l’estimation de Rt.","code":""},{"path":"contact_tracing.html","id":"contact_tracing","chapter":"25 Suivi des contacts","heading":"25 Suivi des contacts","text":"Cette page présente une analyse descriptive de données de recherche de contacts, en ajoutant quelques considérations et approches clés uniques à ce type de données.Cette page fait référence à un grand nombre des compétences de base en matière de gestion et de visualisation des données R abordées dans d’autres pages (par exemple, le nettoyage des données, le pivotement, les tableaux, les analyses de séries chronologiques), mais nous mettrons en évidence des exemples spécifiques au suivi des contacts qui ont été utiles pour la prise de décision opérationnelle. Il s’agit par exemple de la visualisation des données de suivi de la recherche de contacts dans le temps ou dans des zones géographiques, ou de la production de tableaux d’indicateurs de performance clés (KPI) propres pour les superviseurs de la recherche de contacts.Pour la démonstration, nous utiliserons un échantillon de données de suivi des contacts provenant de la plateforme Go.Data. Les principes abordés ici s’appliquent aux données de suivi des contacts provenant d’autres plates-formes. Il se peut que vous deviez simplement suivre différentes étapes de pré-traitement des données en fonction de la structure de vos données.Vous pouvez en savoir plus sur le projet Go.Data sur le site de documentation Github ou la communauté de pratique.","code":""},{"path":"contact_tracing.html","id":"préparation-8","chapter":"25 Suivi des contacts","heading":"25.1 Préparation","text":"","code":""},{"path":"contact_tracing.html","id":"chargement-de-packages","chapter":"25 Suivi des contacts","heading":"Chargement de packages","text":"Ce bout de code montre le chargement des packages nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le package si nécessaire et le charger pour l’utiliser. Vous pouvez aussi charger les packages installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les packages R.","code":"\npacman::p_load(\n  rio,          # importation de données \n  here,         # chemins d'accès relatifs aux fichiers \n  janitor,      # nettoyage des données et tableaux\n  lubridate,    # travailler avec des dates\n  epikit,       # fonction age_categories()\n  apyramid,     # age pyramids\n  tidyverse,    # manipulation et visualisation des données\n  RColorBrewer, # colour palettes\n  formattable,  # fancy tables\n  kableExtra    # formatage des tableaux\n)"},{"path":"contact_tracing.html","id":"importation-de-données-2","chapter":"25 Suivi des contacts","heading":"Importation de données","text":"Nous allons importer des jeux de données exemple de contacts, et de leur”suivi”. Ces données ont été récupérées et non imbriquées à partir de l’API Go.Data et stockées dans des fichiers “.rds”.Vous pouvez télécharger tous les exemples de données pour ce manuel à partir de la page Télécharger le manuel et les données.Si vous souhaitez télécharger les exemples de données de suivi des contacts spécifiques à cette page, utilisez les trois liens de téléchargement ci-dessous : Cliquer pour télécharger données sur les investigations des cas (.rds file)  Cliquer pour télécharger les données d’enregistrement de contacts (.rds file)  Cliquer pour télécharger les données de suivi des contacts (.rds file) Dans leur forme originale dans les fichiers téléchargeables, les données reflètent les données fournies par l’API Go.Data (en savoir plus sur APIs ). À titre d’exemple, nous allons nettoyer les données pour les rendre plus faciles à lire sur cette page. Si vous utilisez une instance Go.Data, vous pouvez consulter les instructions complètes sur la façon de récupérer vos données .Ci-dessous, les jeux de données sont importés à l’aide de la fonction import() du package rio. Voir la page Importation et exportation pour les différentes manières d’importer des données. Nous utilisons () pour spécifier le chemin du fichier - vous devez fournir le chemin du fichier spécifique à votre ordinateur. Nous utilisons ensuite select() pour sélectionner seulement certaines colonnes des données, afin de simplifier pour les besoins de la démonstration.","code":""},{"path":"contact_tracing.html","id":"données-des-cas","chapter":"25 Suivi des contacts","heading":"Données des cas","text":"Ces données sont un tableau des cas, et des informations les concernant.Voici les nrow(cases) cas :","code":"\ncases <- import(here(\"data\", \"godata\", \"cases_clean.rds\")) %>% \n  select(case_id, firstName, lastName, gender, age, age_class,\n         occupation, classification, was_contact, hospitalization_typeid)"},{"path":"contact_tracing.html","id":"données-sur-les-contacts","chapter":"25 Suivi des contacts","heading":"Données sur les contacts","text":"Ces données sont un tableau de tous les contacts et des informations les concernant. Là encore, vous pouvez fournir votre propre chemin de fichier. Après l’importation, nous effectuons quelques étapes préliminaires de nettoyage des données, notamment :Définir age_class comme facteur et inverser l’ordre des niveaux pour que les plus jeunes soient les premiers.Sélectionner seulement certaines colonnes, en renommant l’une d’entre elles.Attribuer artificiellement les lignes dont le 2 niveau d’administration est manquant à “Djembe”, pour améliorer la clarté de certains exemples de visualisation.Voici les nrow(contacts) lignes de le contacts dataframe:","code":"\ncontacts <- import(here(\"data\", \"godata\", \"contacts_clean.rds\")) %>% \n  mutate(age_class = forcats::fct_rev(age_class)) %>% \n  select(contact_id, contact_status, firstName, lastName, gender, age,\n         age_class, occupation, date_of_reporting, date_of_data_entry,\n         date_of_last_exposure = date_of_last_contact,\n         date_of_followup_start, date_of_followup_end, risk_level, was_case, admin_2_name) %>% \n  mutate(admin_2_name = replace_na(admin_2_name, \"Djembe\"))"},{"path":"contact_tracing.html","id":"données-de-suivi","chapter":"25 Suivi des contacts","heading":"Données de suivi","text":"Ces données sont des enregistrements des interactions de “suivi” avec les contacts. Chaque contact est censé avoir une rencontre chaque jour pendant 14 jours après son exposition.Nous importons et effectuons quelques étapes de nettoyage. Nous sélectionnons certaines colonnes, et convertissons également une colonne de caractères en toutes les valeurs minuscules.Voici les 50 premières lignes de la base de données nrow(followups)-row followups (chaque ligne est une interaction de suivi, avec le statut du suivi dans la colonne followup_status) :","code":"\nfollowups <- rio::import(here::here(\"data\", \"godata\", \"followups_clean.rds\")) %>% \n  select(contact_id, followup_status, followup_number,\n         date_of_followup, admin_2_name, admin_1_name) %>% \n  mutate(followup_status = str_to_lower(followup_status))"},{"path":"contact_tracing.html","id":"données-de-relations","chapter":"25 Suivi des contacts","heading":"Données de relations","text":"Ici, nous importons des données montrant la relation entre les cas et les contacts. Nous sélectionnons certaines colonnes à afficher.Vous trouverez ci-dessous les 50 premières lignes du jeu de données relations, qui enregistre toutes les relations entre les cas et les contacts.","code":"\nrelationships <- rio::import(here::here(\"data\", \"godata\", \"relationships_clean.rds\")) %>% \n  select(source_visualid, source_gender, source_age, date_of_last_contact,\n         date_of_data_entry, target_visualid, target_gender,\n         target_age, exposure_type)"},{"path":"contact_tracing.html","id":"analyses-descriptives","chapter":"25 Suivi des contacts","heading":"25.2 Analyses descriptives","text":"Vous pouvez utiliser les techniques abordées dans d’autres pages de ce manuel pour effectuer des analyses descriptives de vos cas, de vos contacts et de leurs relations. Vous trouverez ci-dessous quelques exemples","code":""},{"path":"contact_tracing.html","id":"démographie","chapter":"25 Suivi des contacts","heading":"Démographie","text":"Comme le montre la page consacrée aux Pyramides démographiques, vous pouvez visualiser la répartition par âge et par sexe (nous utilisons ici le package apyramide).","code":""},{"path":"contact_tracing.html","id":"age-et-sexe-des-contacts","chapter":"25 Suivi des contacts","heading":"Age et sexe des contacts","text":"La pyramide ci-dessous compare la répartition par âge des contacts, par sexe. Notez que les contacts dont l’âge est manquant sont inclus dans leur propre barre en haut. Vous pouvez modifier ce comportement par défaut, mais envisagez alors d’indiquer le nombre de contacts manquants dans une légende.Avec la structure de données Go.Data, le jeu de données relations contient les âges des cas et des contacts, vous pourriez donc utiliser ce jeu de données et créer une pyramide des âges montrant les différences entre ces deux groupes de personnes. Le tableau de données relations sera modifié pour transformer les colonnes d’âge numériques en catégories (voir la page Nettoyage des données et fonctions de base). Nous faisons également pivoter le tableau de données pour faciliter le traçage avec ggplot2 (voir Pivoter les données).Maintenant nous pouvons tracer cet ensemble de données transformées avec age_pyramid() comme avant, mais en remplaçant gender par category (contact, ou cas).Nous pouvons également visualiser d’autres caractéristiques telles que la répartition par profession (par exemple, sous la forme d’un diagramme circulaire).","code":"\napyramid::age_pyramid(\n  data = contacts,                                   # utiliser la base de données des contacts\n  age_group = \"age_class\",                           # colonne d'âge catégorielle\n  split_by = \"gender\") +                             # genre pour les moitiés de la pyramide\n  labs(\n    fill = \"Gender\",                                 # titre de la légende\n    title = \"Age/Sex Pyramid of COVID-19 contacts\")+ # titre du graphique\n  theme_minimal()                                    # un fond simple\nrelation_age <- relationships %>% \n  select(source_age, target_age) %>% \n  transmute(        # transmute est comme mutate() mais supprime toutes les autres colonnes non mentionnées\n    source_age_class = epikit::age_categories(source_age, breakers = seq(0, 80, 5)),\n    target_age_class = epikit::age_categories(target_age, breakers = seq(0, 80, 5)),\n    ) %>% \n  pivot_longer(cols = contains(\"class\"), names_to = \"category\", values_to = \"age_class\")  # pivotement plus long\n\n\nrelation_age## # A tibble: 200 × 2\n##    category         age_class\n##    <chr>            <fct>    \n##  1 source_age_class 80+      \n##  2 target_age_class 15-19    \n##  3 source_age_class <NA>     \n##  4 target_age_class 50-54    \n##  5 source_age_class <NA>     \n##  6 target_age_class 20-24    \n##  7 source_age_class 30-34    \n##  8 target_age_class 45-49    \n##  9 source_age_class 40-44    \n## 10 target_age_class 30-34    \n## # ℹ 190 more rows\napyramid::age_pyramid(\n  data = relation_age,                               # utiliser un ensemble de données de relations modifiées\n  age_group = \"age_class\",                           # colonne d'âge catégorielle\n  split_by = \"category\") +                           # par cas et contacts\n  scale_fill_manual(\n    values = c(\"orange\", \"purple\"),                  # pour spécifier les couleurs ET les étiquettes\n    labels = c(\"Case\", \"Contact\"))+\n  labs(\n    fill = \"Legend\",                                           # titre de la légende\n    title = \"Pyramides demographiques de cas et contacts de COVID-19\")+ # titre du graph\n  theme_minimal()                                              # fond simple\n# Clean dataset and get counts by occupation\nocc_plot_data <- cases %>% \n  mutate(occupation = forcats::fct_explicit_na(occupation),  # faire des valeurs manquantes NA une catégorie\n         occupation = forcats::fct_infreq(occupation)) %>% # ordonner les niveaux de facteurs par ordre de fréquence\n  count(occupation)                                          # obtenir des chiffres par profession\n  \n# Make pie chart\nggplot(data = occ_plot_data, mapping = aes(x = \"\", y = n, fill = occupation))+\n  geom_bar(width = 1, stat = \"identity\") +\n  coord_polar(\"y\", start = 0) +\n  labs(\n    fill = \"Occupation\",\n    title = \"Occupation connue des cas de covid-19\")+\n  theme_minimal() +                    \n  theme(axis.line = element_blank(),\n        axis.title = element_blank(),\n        axis.text = element_blank())"},{"path":"contact_tracing.html","id":"contacts-par-cas","chapter":"25 Suivi des contacts","heading":"Contacts par cas","text":"Le nombre de contacts par cas peut être une unité de mesure importante pour évaluer la qualité du dénombrement des contacts et la conformité de la population à la réponse de santé publique.En fonction de votre structure de données, cela peut être évalué avec un ensemble de données qui contient tous les cas et les contacts. Dans les ensembles de données de Go.Data, les liens entre les cas (“sources”) et les contacts (“cibles”) sont stockés dans le jeu de données relationships.Dans cet ensemble de données, chaque ligne est un contact, et le cas source est listé dans la ligne. Aucun contact n’de relations avec plusieurs affaires. multiples, mais si c’est le cas, vous devrez peut-être en tenir compte avant de faire le graphique (et de les explorer aussi !).Nous commençons par compter le nombre de lignes (contacts) par cas source. Ceci est enregistré comme un tableau de données.Nous utilisons geom_histogram() pour représenter ces données sous forme d’histogramme.","code":"\ncontacts_per_case <- relationships %>% \n  count(source_visualid)\n\ncontacts_per_case## # A tibble: 23 × 2\n##    source_visualid     n\n##    <chr>           <int>\n##  1 CASE-2020-0001     13\n##  2 CASE-2020-0002      5\n##  3 CASE-2020-0003      2\n##  4 CASE-2020-0004      4\n##  5 CASE-2020-0005      5\n##  6 CASE-2020-0006      3\n##  7 CASE-2020-0008      3\n##  8 CASE-2020-0009      3\n##  9 CASE-2020-0010      3\n## 10 CASE-2020-0012      3\n## # ℹ 13 more rows\nggplot(data = contacts_per_case)+        # commencer avec le tableau de données créé ci-dessus\n  geom_histogram(mapping = aes(x = n))+  # afficher l'histogramme du nombre de contacts par cas\n  scale_y_continuous(expand = c(0,0))+   # supprimer l'espace excédentaire en dessous de 0 sur l'axe des ordonnées\n  theme_light()+                         # simplifier le fond\n  labs(\n    title = \"Number of contacts per case\",\n    y = \"Cases\",\n    x = \"Contacts per case\"\n  )"},{"path":"contact_tracing.html","id":"suivi-de-contacts","chapter":"25 Suivi des contacts","heading":"25.3 Suivi de contacts","text":"Les données de recherche des contacts contiennent souvent des données de “suivi”, qui enregistrent les résultats des contrôles quotidiens des symptômes des personnes en quarantaine. L’analyse de ces données permet d’orienter la stratégie de réponse, d’identifier les contacts susceptibles d’être perdus pour le suivi ou de développer la maladie.","code":""},{"path":"contact_tracing.html","id":"nettoyage-de-données","chapter":"25 Suivi des contacts","heading":"Nettoyage de données","text":"Ces données peuvent exister sous différents formats. Elles peuvent exister sous la forme d’une large avec une ligne par contact et une colonne par “jour” de suivi. jour” de suivi. Voir Pivoter les données pour obtenir des descriptions des données “longues” et données “larges” et comment faire pivoter des données plus larges ou plus longues.Dans notre exemple Go.Data, ces données sont stockées dans le tableau followups, qui est dans un format “long” avec une ligne par interaction de suivi. Les 50 premières lignes ressemblent à ceci :ATTENTION: Méfiez-vous des doublons lorsque vous traitez des données de suivi, car il peut y avoir plusieurs suivis erronés le même jour pour un contact donné. Cela peut sembler être une erreur mais reflète la réalité - par exemple, un agent de recherche de contacts pourrait soumettre un formulaire de suivi en début de journée alors qu’il n’pas pu joindre le contact, et soumettre un second formulaire lorsqu’il été joint par la suite. La façon dont vous souhaitez traiter les doublons dépend du contexte opérationnel. - veillez simplement à documenter clairement votre approche.Voyons combien d’instances de lignes “en double” nous avons :Dans notre exemple de données, les seuls enregistrements auxquels cela s’applique sont ceux auxquels il manque un ID ! Nous pouvons les supprimer. Mais, pour les besoins de la démonstration, nous allons montrer les étapes de la déduplication afin qu’il n’y ait qu’un seul encoutrement de suivi par personne et par jour. Voir la page sur déduplication pour plus de détails. Nous supposerons que l’enregistrement de rencontre le plus récent est le bon. Nous profitons également de l’occasion pour nettoyer la colonne followup_number (le “jour” du suivi qui devrait qui devrait être compris entre 1 et 14).Pour chaque rencontre de suivi, nous avons un statut de suivi (tel que si la rencontre eu lieu et, le cas échéant, si le contact eu des symptômes ou non). Pour voir toutes les valeurs, nous pouvons exécuter un rapide tabyl() (de janitor) ou table() (de base R) (voir Tableaux descriptifs) par followup_status pour voir la fréquence de chacun des résultats.Dans cet ensemble de données, “vu_not_ok” signifie “vu avec des symptômes”, et “vu_ok” signifie “vu sans symptômes”.","code":"\nfollowups %>% \n  count(contact_id, date_of_followup) %>%   # obtenir des jours de suivi uniques\n  filter(n > 1)                             # afficher les enregistrements où le nombre est supérieur à 1 ## # A tibble: 3 × 3\n##   contact_id date_of_followup     n\n##   <chr>      <date>           <int>\n## 1 <NA>       2020-09-03           2\n## 2 <NA>       2020-09-04           2\n## 3 <NA>       2020-09-05           2\nfollowups_clean <- followups %>%\n  \n  # Enlever les doublons\n  group_by(contact_id, date_of_followup) %>%        # grouper les lignes par jour de suivi\n  arrange(contact_id, desc(date_of_followup)) %>%   # organiser les lignes, par jour de suivi, par date de suivi (le plus récent en haut)\n  slice_head() %>%                                  # ne conserver que la première ligne par id contact\n  ungroup() %>% \n  \n  # Autres nettoyages\n  mutate(followup_number = replace(followup_number, followup_number > 14, NA)) %>% # nettoyer des données erronées\n  drop_na(contact_id)                               # supprimer les id_contact dont les données sont manquantes\nfollowups_clean %>% \n  tabyl(followup_status)##  followup_status   n    percent\n##           missed  10 0.02325581\n##    not_attempted   5 0.01162791\n##    not_performed 319 0.74186047\n##      seen_not_ok   6 0.01395349\n##          seen_ok  90 0.20930233"},{"path":"contact_tracing.html","id":"graphe-dans-le-temps","chapter":"25 Suivi des contacts","heading":"Graphe dans le temps","text":"Comme les données de dates sont continues, nous utiliserons un histogramme pour les représenter avec date_du_suivi assigné à l’axe des abscisses. Nous pouvons obtenir un histogramme “empilé” en spécifiant un argument fill = dans aes(), que nous assignons à la colonne followup_status. Par conséquent, vous pouvez définir le titre de la légende en utilisant l’argument fill = de labs().constate que les contacts ont été identifiés par vagues (correspondant vraisemblablement aux vagues épidémiques de cas), et que vl’achèvement du suivi ne semble pas s’être amélioré au cours de l’épidémie.ATTENTION: Si vous préparez de nombreux graphiques (par exemple pour plusieurs juridictions), vous voudrez que les légendes apparaissent de manière identique, même si les données sont plus ou moins complètes ou composées. Il peut y avoir des graphiques pour lesquels tous les statuts de suivi ne sont pas présents dans les données, mais vous voulez quand même que ces catégories apparaissent dans les légendes. Dans les ggplots (comme ci-dessus), vous pouvez spécifier l’argument drop = FALSE de la fonction scale_fill_discrete(). Dans les tableaux, utilisez tabyl() qui montre les comptes pour tous les niveaux de facteurs, ou si vous utilisez count() de dplyr ajoutez l’argument .drop = FALSE pour inclure les comptes pour tous les niveaux de facteurs.","code":"\nggplot(data = followups_clean)+\n  geom_histogram(mapping = aes(x = date_of_followup, fill = followup_status)) +\n  scale_fill_discrete(drop = FALSE)+   # Afficher tous les niveaux de facteurs (followup_status) dans la légende, même ceux qui ne sont pas utilisés.\n  theme_classic() +\n  labs(\n    x = \"\",\n    y = \"Number of contacts\",\n    title = \"Daily Contact Followup Status\",\n    fill = \"Followup Status\",\n    subtitle = str_glue(\"Data as of {max(followups$date_of_followup, na.rm=T)}\"))   # sous-titres dynamiques"},{"path":"contact_tracing.html","id":"suivi-quotidien-individuel","chapter":"25 Suivi des contacts","heading":"Suivi quotidien individuel","text":"Si votre épidémie est suffisamment petite, vous voudrez peut-être voir chaque contact individuellement et voir son statut au cours de son suivi. Heureusement, cet tableau de données followups contient déjà une colonne avec le le “numéro” du jour du suivi (1-14). Si cette colonne n’existe pas dans vos données, vous pouvez la créer en calculant la différence entre la date de la dernière rencontre et la date à laquelle le suivi devait commencer pour le contact.Un mécanisme de visualisation pratique (si le nombre de cas n’est pas trop important) peut être un diagramme de dispersion, réalisé avec geom_tile(). Voir plus de détails dans la page heat plot.","code":"\nggplot(data = followups_clean)+\n  geom_tile(mapping = aes(x = followup_number, y = contact_id, fill = followup_status),\n            color = \"grey\")+       # lignes grises\n  scale_fill_manual( values = c(\"yellow\", \"grey\", \"orange\", \"darkred\", \"darkgreen\"))+\n  theme_minimal()+\n  scale_x_continuous(breaks = seq(from = 1, to = 14, by = 1))"},{"path":"contact_tracing.html","id":"analyse-par-groupe","chapter":"25 Suivi des contacts","heading":"Analyse par groupe","text":"Ces données de suivi sont peut-être consultées journellement ou hebdomadairement pour la prise de décision opérationnelle. Vous souhaitez peut-être des désagrégations plus significatives par zone géographique ou par équipe de suivi des contacts. Nous pouvons le faire en ajustant les colonnes fournies à group_by().","code":"\nplot_by_region <- followups_clean %>%                                        # commencer par l'ensemble de données de suivi\n  count(admin_1_name, admin_2_name, followup_status) %>%   # obtenir les chiffres par région-statut unique (crée la colonne 'n' avec les chiffres)\n  \n  # begin ggplot()\n  ggplot(                                         # commencer le ggplot\n    mapping = aes(x = reorder(admin_2_name, n),     # réorganiser les facteurs administratifs en fonction des valeurs numériques de la colonne 'n'.\n                  y = n,                            # hauteur de la barre de la colonne 'n'.\n                  fill = followup_status,           # colorer les barres empilées en fonction de leur statut\n                  label = n))+                      # passer à geom_label()              \n  geom_col()+                                     # barres empilées, cartographie obtenue au-dessus\n  geom_text(                                      # ajouter du texte, cartographie obtenue à partir de la version précédente\n    size = 3,                                         \n    position = position_stack(vjust = 0.5), \n    color = \"white\",           \n    check_overlap = TRUE,\n    fontface = \"bold\")+\n  coord_flip()+\n  labs(\n    x = \"\",\n    y = \"Number of contacts\",\n    title = \"Contact Followup Status, by Region\",\n    fill = \"Followup Status\",\n    subtitle = str_glue(\"Data as of {max(followups_clean$date_of_followup, na.rm=T)}\")) +\n  theme_classic()+                                                                      # Simplifier le fond\n  facet_wrap(~admin_1_name, strip.position = \"right\", scales = \"free_y\", ncol = 1)      # introduire les facettes \n\nplot_by_region"},{"path":"contact_tracing.html","id":"tableaux-kpi","chapter":"25 Suivi des contacts","heading":"25.4 Tableaux KPI","text":"Il existe un certain nombre d’indicateurs clés de performance ( KPI) qui peuvent être calculés et suivis à différents niveaux de désagrégation et sur différentes périodes de temps afin de contrôler les performances de la recherche de contacts. Une fois que vous maîtrisez les calculs et le format de base du tableau, il est assez facile d’intervertir les différents KPI.Il existe de nombreuses sources de KPI pour le suivi des contacts, comme celle de ResolveToSaveLives.org. La majeure partie du travail consistera à parcourir votre structure de données et à réfléchir à tous les critères d’inclusion/exclusion. Nous présentons quelques exemples ci-dessous, en utilisant la structure de métadonnées de Go.Data :Nous vous proposons ci-dessous un exemple de création d’un tableau visuel pour afficher le suivi des contacts dans les différentes zones d’administration. À la fin, nous le convertirons en tableau de présentation avec le package formattable (mais vous pouvez utiliser d’autres packages comme flextable - voir Tableaux de présentation).La manière de créer un tel tableau dépend de la structure de vos données de suivi des contacts. Utilisez la page Tableaux descriptifs pour apprendre à résumer les données à l’aide des fonctions dplyr.Nous allons créer une table qui sera dynamique et changera au fur et à mesure que les données changeront. Pour rendre les résultats intéressants, nous allons définir une “date de rapport” pour nous permettre de simuler l’exécution du tableau à un certain jour (nous choisissons le 10 juin 2020). Les données sont filtrées à cette date.Maintenant, sur la base de notre structure de données, nous allons faire ce qui suit :Commencez par les données followups et résumez-les pour inclure, pour chaque contact unique :La date du dernier enregistrement (quel que soit le statut du suivi).La date de la dernière suivi où le contact été “vu”le statut du suivi lors de cette dernière suivi (par exemple, avec des symptômes, sans symptômes)Joignez ces données aux données des contacts, qui contiennent d’autres informations telles que le statut général du contact, la date de la dernière exposition à un cas, etc. Nous allons également calculer des indicateurs intéressants pour chaque contact, comme le nombre de jours depuis la dernière exposition.Nous regroupons les données de contact élargies par région géographique (admin_2_name) et calculons des statistiques sommaires par régionEnfin, nous mettons en forme le tableau pour qu’il soit bien présenté.Tout d’abord, nous résumons les données de suivi pour obtenir les informations qui nous intéressent :Voici à quoi ressemblent ces données :Maintenant, nous allons ajouter ces informations à l’ensemble de données contacts, et calculer quelques colonnes supplémentaires.Voici à quoi ressemblent ces données. Il faut noter la colonne contacts à droite, et la nouvelle colonne calculée à l’extrême droite.Ensuite, nous résumons les données sur les contacts par région, afin d’obtenir un tableaux de synthèse des colonnes de statistiques.Et maintenant, nous appliquons le style des paquets formattable et knitr. y compris une note de pied de page qui indique la date “en date du”.","code":"\n# Définissez \"Date du rapport\" pour simuler l'exécution du rapport avec des données \"à partir de\" cette date.\nreport_date <- as.Date(\"2020-06-10\")\n\n# Créez des données de suivi pour refléter la date du rapport.\ntable_data <- followups_clean %>% \n  filter(date_of_followup <= report_date)\nfollowup_info <- table_data %>% \n  group_by(contact_id) %>% \n  summarise(\n    date_last_record   = max(date_of_followup, na.rm=T),\n    date_last_seen     = max(date_of_followup[followup_status %in% c(\"seen_ok\", \"seen_not_ok\")], na.rm=T),\n    status_last_record = followup_status[which(date_of_followup == date_last_record)]) %>% \n  ungroup()\ncontacts_info <- followup_info %>% \n  right_join(contacts, by = \"contact_id\") %>% \n  mutate(\n    database_date       = max(date_last_record, na.rm=T),\n    days_since_seen     = database_date - date_last_seen,\n    days_since_exposure = database_date - date_of_last_exposure\n    )\ncontacts_table <- contacts_info %>% \n  \n  group_by(`Admin 2` = admin_2_name) %>%\n  \n  summarise(\n    `Registered contacts` = n(),\n    `Active contacts`     = sum(contact_status == \"UNDER_FOLLOW_UP\", na.rm=T),\n    `In first week`       = sum(days_since_exposure < 8, na.rm=T),\n    `In second week`      = sum(days_since_exposure >= 8 & days_since_exposure < 15, na.rm=T),\n    `Became case`         = sum(contact_status == \"BECAME_CASE\", na.rm=T),\n    `Lost to follow up`   = sum(days_since_seen >= 3, na.rm=T),\n    `Never seen`          = sum(is.na(date_last_seen)),\n    `Followed up - signs` = sum(status_last_record == \"Seen_not_ok\" & date_last_record == database_date, na.rm=T),\n    `Followed up - no signs` = sum(status_last_record == \"Seen_ok\" & date_last_record == database_date, na.rm=T),\n    `Not Followed up`     = sum(\n      (status_last_record == \"NOT_ATTEMPTED\" | status_last_record == \"NOT_PERFORMED\") &\n        date_last_record == database_date, na.rm=T)) %>% \n    \n  arrange(desc(`Registered contacts`))\ncontacts_table %>%\n  mutate(\n    `Admin 2` = formatter(\"span\", style = ~ formattable::style(\n      color = ifelse(`Admin 2` == NA, \"red\", \"grey\"),\n      font.weight = \"bold\",font.style = \"italic\"))(`Admin 2`),\n    `Followed up - signs`= color_tile(\"white\", \"orange\")(`Followed up - signs`),\n    `Followed up - no signs`= color_tile(\"white\", \"#A0E2BD\")(`Followed up - no signs`),\n    `Became case`= color_tile(\"white\", \"grey\")(`Became case`),\n    `Lost to follow up`= color_tile(\"white\", \"grey\")(`Lost to follow up`), \n    `Never seen`= color_tile(\"white\", \"red\")(`Never seen`),\n    `Active contacts` = color_tile(\"white\", \"#81A4CE\")(`Active contacts`)\n  ) %>%\n  kable(\"html\", escape = F, align =c(\"l\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\")) %>%\n  kable_styling(\"hover\", full_width = FALSE) %>%\n  add_header_above(c(\" \" = 3, \n                     \"Of contacts currently under follow up\" = 5,\n                     \"Status of last visit\" = 3)) %>% \n  kableExtra::footnote(general = str_glue(\"Data are current to {format(report_date, '%b %d %Y')}\"))"},{"path":"contact_tracing.html","id":"matrices-de-transmission","chapter":"25 Suivi des contacts","heading":"25.5 Matrices de transmission","text":"Comme indiqué sur la page Heat plots, vous pouvez créer une matrice de “qui infecté qui” en utilisant geom_tile().Lorsque de nouveaux contacts sont créés, Go.Data stocke ces informations de liens dans le lien relationships de l’API ; et nous pouvons voir les 50 premières lignes de cet ensemble de données ci-dessous. Cela signifie que nous pouvons créer un diagramme de chaleur avec relativement peu d’étapes étant donné que chaque contact est déjà joint à son cas source.Comme nous l’avons fait ci-dessus pour la pyramide des âges comparant les cas et les contacts, nous pouvons sélectionner les quelques variables dont nous avons besoin et créer des colonnes avec des groupes d’âge catégoriques pour les sources (cas) et les cibles (contacts).Comme décrit précédemment, nous créons des tableaux croisés ;convertir en format long avec des proportions ;et créer une carte géographique pour l’âge.","code":"\nheatmap_ages <- relationships %>% \n  select(source_age, target_age) %>% \n  mutate(                              # transmute est comme mutate() mais supprime toutes les autres colonnes\n    source_age_class = epikit::age_categories(source_age, breakers = seq(0, 80, 5)),\n    target_age_class = epikit::age_categories(target_age, breakers = seq(0, 80, 5))) \ncross_tab <- table(\n  source_cases = heatmap_ages$source_age_class,\n  target_cases = heatmap_ages$target_age_class)\n\ncross_tab##             target_cases\n## source_cases 0-4 5-9 10-14 15-19 20-24 25-29 30-34 35-39 40-44 45-49 50-54 55-59 60-64\n##        0-4     0   0     0     0     0     0     0     0     0     1     0     1     0\n##        5-9     0   0     1     0     0     0     0     1     0     0     0     1     0\n##        10-14   0   0     0     0     0     0     0     0     0     0     0     0     0\n##        15-19   0   0     0     0     0     0     0     0     0     0     0     0     0\n##        20-24   1   1     0     1     2     0     2     1     0     0     0     1     0\n##        25-29   1   2     0     0     0     0     0     0     0     0     0     0     0\n##        30-34   0   0     0     0     0     0     0     0     1     1     0     1     0\n##        35-39   0   2     0     0     0     0     0     0     0     1     0     0     0\n##        40-44   0   0     0     0     1     0     2     1     0     3     1     1     0\n##        45-49   1   2     2     0     0     0     3     0     1     0     3     2     1\n##        50-54   1   2     1     2     0     0     1     0     0     3     4     1     0\n##        55-59   0   1     0     0     1     1     2     0     0     0     0     0     0\n##        60-64   0   0     0     0     0     0     0     0     0     0     0     0     0\n##        65-69   0   0     0     0     0     0     0     0     0     0     0     0     0\n##        70-74   0   0     0     0     0     0     0     0     0     0     0     0     0\n##        75-79   0   0     0     0     0     0     0     0     0     0     0     0     0\n##        80+     1   0     0     2     1     0     0     0     1     0     0     0     0\n##             target_cases\n## source_cases 65-69 70-74 75-79 80+\n##        0-4       0     0     0   0\n##        5-9       0     0     0   0\n##        10-14     0     0     0   0\n##        15-19     0     0     0   0\n##        20-24     0     0     0   1\n##        25-29     0     0     0   0\n##        30-34     0     0     0   0\n##        35-39     0     0     0   0\n##        40-44     0     0     1   1\n##        45-49     0     0     0   1\n##        50-54     1     0     0   1\n##        55-59     0     0     0   0\n##        60-64     0     0     0   0\n##        65-69     0     0     0   0\n##        70-74     0     0     0   0\n##        75-79     0     0     0   0\n##        80+       0     0     0   0\nlong_prop <- data.frame(prop.table(cross_tab))\nggplot(data = long_prop)+       # utiliser des données longues, avec des proportions comme Freq\n  geom_tile(                    # visualisez-le en tuiles\n    aes(\n      x = target_cases,         # l'axe des x est l'âge du cas\n      y = source_cases,     # l'axe y est l'âge de l'infecteur\n      fill = Freq))+            # La couleur de la tuile est la colonne Freq dans les données\n  scale_fill_gradient(          # ajuster la couleur de remplissage des tuiles\n    low = \"blue\",\n    high = \"orange\")+\n  theme(axis.text.x = element_text(angle = 90))+\n  labs(                         # labels\n    x = \"Target case age\",\n    y = \"Source case age\",\n    title = \"Who infected whom\",\n    subtitle = \"Frequency matrix of transmission events\",\n    fill = \"Proportion of all\\ntranmsission events\"     # legend title\n  )"},{"path":"contact_tracing.html","id":"resources-6","chapter":"25 Suivi des contacts","heading":"25.6 Resources","text":"https://github.com/WorldHealthOrganization/godata/tree/master/analytics/r-reportinghttps://worldhealthorganization.github.io/godata/https://community-godata..int/","code":""},{"path":"survey_analysis.html","id":"survey_analysis","chapter":"26 Analyse d’enquête","heading":"26 Analyse d’enquête","text":"","code":""},{"path":"survey_analysis.html","id":"aperçu-2","chapter":"26 Analyse d’enquête","heading":"26.1 Aperçu","text":"Cette page démontre l’utilisation de plusieurs packages pour l’analyse d’enquêtes.La plupart des paquets R d’enquête reposent sur le paquet survey pour effectuer des analyses pondérées.\nNous utiliserons survey ainsi que srvyr (une enveloppe pour survey permettant un codage de type tidyverse) et gtsummary (une enveloppe pour survey permettant de créer des tableaux prêts à être publiés).Bien que le paquet original survey ne permette pas le codage de style tidyverse, tidyverse, il présente l’avantage supplémentaire d’autoriser les modèles linéaires généralisés pondérés par les pondérés par les enquêtes (qui seront ajoutés à cette page à une date ultérieure). Nous allons également démontrer l’utilisation d’une fonction du paquet sitrep pour créer des poids d’échantillonnage (n.b ce paquet n’est pas encore sur CRAN, mais peut être installé à partir de github).La plupart de cette page est basée sur le travail effectué pour le projet “R4Epis” ; pour le code détaillé et les modèles R-markdown, voir la page github [“R4Epis”] (https://github.com/R4EPI/sitrep). Une partie du code basé sur le paquet survey est basé sur les premières versions de Études de cas EPIET.Pour l’instant, cette page ne traite pas du calcul de la taille des échantillons ou de l’échantillonnage. Pour un calculateur de taille d’échantillon simple à utiliser, voir OpenEpi. La page GIS basics du manuel comportera éventuellement une section sur l’échantillonnage aléatoire spatial, et cette page comportera éventuellement une section sur les cadres d’échantillonnage. Cette page contiendra également une section sur les bases de sondage ainsi que sur le calcul de la taille des échantillons.Données d’enquêteTemps d’observationPondérationObjets de la conception de l’enquêteAnalyse descriptiveProportions pondéréesTaux pondérés","code":""},{"path":"survey_analysis.html","id":"préparation-9","chapter":"26 Analyse d’enquête","heading":"26.2 Préparation","text":"","code":""},{"path":"survey_analysis.html","id":"paquets-1","chapter":"26 Analyse d’enquête","heading":"Paquets","text":"Ce morceau de code montre le chargement des paquets nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire et le charge pour l’utiliser. Vous pouvez également charger des paquets avec library() depuis base R. Voir la page sur [R basics] pour plus d’informations sur les paquets R.\nIci, nous démontrons également l’utilisation de la fonction p_load_gh() de pacman pour installer et charger un paquet de github qui n’pas encore été publié sur CRAN.","code":"\n## charger des paquets depuis CRAN\npacman::p_load(rio, # Importation du fichier\n               here, # Localisation de fichiers\n               tidyverse, # gestion des données + graphiques ggplot2\n               tsibble, # gère les ensembles de données de séries temporelles\n               survey, # pour les fonctions d'enquête\n               srvyr, # wrapper dplyr pour le paquet d'enquête\n               gtsummary, # wrapper pour le paquet d'enquête pour produire des tableaux\n               apyramid, # un paquet dédié à la création de pyramides des âges\n               patchwork, # pour combiner des ggplots\n               ggforce # pour les tracés alluviaux/sankey\n               ) \n\n## charger les paquets de github pour le temps d'observation / fonctions de pondération\nif(!require(sitrep)){\n   remotes::install_github(\"r4epi/sitrep\")\n   library(sitrep)\n}"},{"path":"survey_analysis.html","id":"charger-les-données","chapter":"26 Analyse d’enquête","heading":"Charger les données","text":"L’ensemble de données d’exemple utilisé dans cette section :des données fictives d’enquête de mortalité.comptes de population fictifs pour la zone d’enquête.Dictionnaire de données pour les données fictives de l’enquête sur la mortalité.Ceci est basé sur l’enquête pré-approuvée par le comité d’examen éthique de MSF OCA. Le site données fictives ont été produites dans le cadre du projet “R4Epis”.\nTout ceci est basé sur les données collectées à l’aide de KoboToolbox, qui est un logiciel de collecte de données basé sur Open Data Kit.Kobo vous permet d’exporter à la fois les données collectées et le dictionnaire de données pour cet ensemble de données. Nous vous recommandons vivement de le faire, car cela simplifie le nettoyage des données et est utile pour rechercher des variables/questions.TIP: Le dictionnaire de données de Kobo comporte des noms de variables dans la colonne “nom” de la feuille d’enquête. Les valeurs possibles pour chaque variable sont spécifiées dans la feuille de choix. Dans la feuille de choix, “name” la valeur abrégée et les colonnes “label::english” et “label::french” ont les versions longues appropriées. L’utilisation de la fonction msf_dict_survey() du paquet epidict pour importer un fichier Excel du dictionnaire Kobo sera reformaté pour vous afin de pouvoir l’utiliser facilement pour le recodage. CAUTION: Le jeu de données d’exemple n’est pas le même comme un export (comme dans Kobo vous exportez différents niveaux de questionnaire individuellement).\n- voir la section sur les données d’enquête ci-dessous pour fusionner les différents niveaux.Le jeu de données est importé à l’aide de la fonction import() du paquet rio. Consultez la page Importation et exportation pour connaître les différentes façons d’importer des données.Les 10 premières lignes de l’enquête sont affichées ci-dessous.Nous voulons également importer les données sur la population d’échantillonnage afin de pouvoir produire des pondérations appropriées. Ces données peuvent se présenter sous différents formats. Cependant, nous vous suggérons de les présenter comme suit (vous pouvez simplement les saisir dans un excel).Les 10 premières lignes de l’enquête sont affichées ci-dessous.Pour les enquêtes en grappes, vous pouvez souhaiter ajouter des poids d’enquête au niveau de la grappe. Vous pouvez lire ces données comme ci-dessus.\nAlternativement, s’il n’y que quelques comptages, ils peuvent être entrés comme suit dans un tibble. Dans tous les cas, vous aurez besoin d’avoir une colonne avec un identifiant de grappe qui correspondant à vos données d’enquête, et une autre colonne avec le nombre de ménages dans chaque grappe.","code":"\n# Importez les données d'enquête\nsurvey_data <- rio::import(\"survey_data.xlsx\")\n\n# Importez le dictionnaire dans R\nsurvey_dict <- rio::import(\"survey_dict.xlsx\") \n# Importez les données de la population\npopulation <- rio::import(\"population.xlsx\")\n## définir le nombre de ménages dans chaque cluster\ncluster_counts <- tibble(cluster = c(\"village_1\", \"village_2\", \"village_3\", \"village_4\", \n                                     \"village_5\", \"village_6\", \"village_7\", \"village_8\",\n                                     \"village_9\", \"village_10\"), \n                         households = c(700, 400, 600, 500, 300, \n                                        800, 700, 400, 500, 500))"},{"path":"survey_analysis.html","id":"nettoyer-les-données-2","chapter":"26 Analyse d’enquête","heading":"Nettoyer les données","text":"L’exemple ci-dessous permet de s’assurer que la colonne date est au bon format. Il existe plusieurs autres façons de procéder (voir la page Travailler avec des dates pour plus de détails), mais l’utilisation du dictionnaire pour définir les dates est rapide et facile.Nous créons également une variable de groupe d’âge en utilisant la fonction age_categories() de epikit - voir la section Nettoyage de données et fonctions essentielles pour plus de détails. De plus, nous créons une variable de caractère définissant dans quel district se trouvent les différents clusters.Enfin, nous recodons toutes les variables oui/non en variables VRAI/FAUX, sinon elles ne peuvent pas être utilisées par les fonctions de proportion survey.","code":"\n## sélectionne les noms de variables de date dans le dictionnaire \nDATEVARS <- survey_dict %>% \n  filter(type == \"date\") %>% \n  filter(name %in% names(survey_data)) %>% \n  ## filtre pour correspondre aux noms des colonnes de vos données\n  pull(name) # sélectionne les variables de date\n  \n## changer en dates \nsurvey_data <- survey_data %>%\n  mutate(across(all_of(DATEVARS), as.Date))\n\n\n## ajouter ceux dont l'âge est uniquement en mois à la variable année (diviser par douze).\nsurvey_data <- survey_data %>% \n  mutate(age_years = if_else(is.na(age_years), \n                             age_months / 12, \n                             age_years))\n\n## définir la variable groupe d'âge\nsurvey_data <- survey_data %>% \n     mutate(age_group = age_categories(age_years, \n                                    breakers = c(0, 3, 15, 30, 45)\n                                    ))\n\n\n## créer une variable caractère basée sur les groupes d'une autre variable \nsurvey_data <- survey_data %>% \n  mutate(health_district = case_when(\n    cluster_number %in% c(1:5) ~ \"district_a\", \n    TRUE ~ \"district_b\"\n  ))\n\n\n## sélectionner les noms de variables oui/non dans le dictionnaire \nYNVARS <- survey_dict %>% \n  filter(type == \"yn\") %>% \n  filter(name %in% names(survey_data)) %>% \n  ## filtre pour correspondre aux noms des colonnes de vos données\n  pull(name) # select yn vars\n  \n## changer en dates \nsurvey_data <- survey_data %>%\n  mutate(across(all_of(YNVARS), \n                str_detect, \n                pattern = \"yes\"))"},{"path":"survey_analysis.html","id":"données-denquête","chapter":"26 Analyse d’enquête","heading":"26.3 Données d’enquête","text":"Il existe de nombreux plans d’échantillonnage différents qui peuvent être utilisés pour les enquêtes. Ici, nous allons démontrer le code pour :\n- Stratifié\n- en grappes\n- Stratifié et grappeComme décrit ci-dessus (en fonction de la façon dont vous concevez votre questionnaire), les données de chaque niveau seront exportées comme un ensemble de données séparé de Kobo. Dans notre exemple, il y \nun niveau pour les ménages et un niveau pour les individus au sein de ces ménages.Ces deux niveaux sont liés par un identifiant unique. Pour un ensemble de données Kobo, cette variable est “_index” au niveau du ménage, qui correspond à “_parent_index” au niveau de l’individu.\nCela créera de nouvelles lignes pour le ménage avec chaque individu correspondant, voir la section du manuel sur Joindre des données pour plus de détails.","code":"\n## Joignez les données des individus et des ménages pour former un ensemble de données complet.\nsurvey_data <- left_join(survey_data_hh, \n                         survey_data_indiv,\n                         by = c(\"_index\" = \"_parent_index\"))\n\n\n## créer un identifiant unique en combinant les index des deux niveaux \nsurvey_data <- survey_data %>% \n     mutate(uid = str_glue(\"{index}_{index_y}\"))"},{"path":"survey_analysis.html","id":"temps-dobservation","chapter":"26 Analyse d’enquête","heading":"26.4 Temps d’observation","text":"Pour les enquêtes de mortalité, nous voulons maintenant savoir combien de temps chaque individu été présent dans l’emplacement afin de pouvoir calculer un taux de mortalité approprié pour notre période d’intérêt. Ceci n’est pas pertinent pour toutes les enquêtes, mais particulièrement pour les enquêtes de mortalité, car elles sont fréquemment menées auprès de populations mobiles ou déplacées.Pour ce faire, nous définissons d’abord notre période d’intérêt, également connue sous le nom de période de rappel (c’est-à-dire le moment où l’enquête est menée). Nous pouvons ensuite utiliser cette période pour définir des dates inappropriées comme manquantes, c’est-à-dire que si des décès sont signalés en dehors de la période d’intérêt.Nous pouvons ensuite utiliser nos variables de date pour définir les dates de début et de fin pour chaque individu. Nous pouvons utiliser la fonction find_start_date() de sitrep pour affiner les causes des les dates et ensuite utiliser cela pour calculer la différence entre les jours (personne-temps).Date de début :\nL’événement d’arrivée approprié le plus tôt dans votre période de rappel. Soit le début de votre période de rappel (que vous définissez à l’avance), soit une date après le début de la période de rappel, le cas échéant (par exemple, les arrivées ou les naissances).Date de fin :\nSoit la fin de votre période de rappel, soit une date antérieure à la fin du rappel.","code":"\n## Définit le début/la fin de la période de rappel.\n## peut être changé en variables de date provenant de l'ensemble de données \n## (par exemple, date d'arrivée et date du questionnaire)\nsurvey_data <- survey_data %>% \n  mutate(recall_start = as.Date(\"2018-01-01\"), \n         recall_end = as.Date(\"2018-05-01\")\n  )\n\n\n# Définir les dates inappropriées à NA sur la base de règles \n## par exemple, arrivées avant le début, départs après la fin.\nsurvey_data <- survey_data %>%\n      mutate(\n           arrived_date = if_else(arrived_date < recall_start, \n                                 as.Date(NA),\n                                  arrived_date),\n           birthday_date = if_else(birthday_date < recall_start,\n                                  as.Date(NA),\n                                  birthday_date),\n           left_date = if_else(left_date > recall_end,\n                              as.Date(NA),\n                               left_date),\n           death_date = if_else(death_date > recall_end,\n                               as.Date(NA),\n                               death_date)\n           )\n## Créer de nouvelles variables pour les dates/causes de début et de fin.\nsurvey_data <- survey_data %>% \n     ## choisir la date la plus ancienne saisie dans l'enquête.\n     ## à partir des naissances, des arrivées dans les ménages et des arrivées dans les camps. \n     find_start_date(\"birthday_date\",\n                  \"arrived_date\",\n                  period_start = \"recall_start\",\n                  period_end = \"recall_end\",\n                  datecol = \"startdate\",\n                  datereason = \"startcause\"\n                 ) %>%\n     ## choisir la date la plus ancienne saisie dans l'enquête\n     ## à partir des départs du camp, des décès et de la fin de l'étude\n     find_end_date(\"left_date\",\n                \"death_date\",\n                period_start = \"recall_start\",\n                period_end = \"recall_end\",\n                datecol = \"enddate\",\n                datereason = \"endcause\" \n               )\n\n\n## étiqueter ceux qui étaient présents au début/à la fin (sauf les naissances/décès)\nsurvey_data <- survey_data %>% \n     mutate(\n       ## remplir la date de début pour qu'elle corresponde au début de la période de rappel (pour ceux qui sont vides) \n       startdate = if_else(is.na(startdate), recall_start, startdate), \n       ## définir la cause de début comme présente au début si elle est égale à la période de rappel \n       ## sauf si elle est égale à la date de naissance \n       startcause = if_else(startdate == recall_start & startcause != \"birthday_date\",\n                              \"Present at start\", startcause), \n       ## remplir la date de fin pour qu'elle corresponde à la fin de la période de rappel (pour ceux qui sont vides) \n       enddate = if_else(is.na(enddate), recall_end, enddate), \n       ## définir la cause de fin comme étant présente à la fin si égale à la fin de rappel \n       ## sauf si elle est égale à la date de décès\n       endcause = if_else(enddate == recall_end & endcause != \"death_date\", \n                            \"Present at end\", endcause))\n\n\n## Définir la durée d'observation en jours\nsurvey_data <- survey_data %>% \n  mutate(obstime = as.numeric(enddate - startdate))"},{"path":"survey_analysis.html","id":"pondération","chapter":"26 Analyse d’enquête","heading":"26.5 Pondération","text":"Il est important d’éliminer les observations erronées avant d’ajouter les poids de l’enquête. Par exemple, si vous avez des observations avec un temps d’observation négatif, vous devrez les vérifier (vous pouvez le faire avec la fonction assert_positive_timespan() de sitrep. Une autre chose est si vous voulez supprimer les lignes vides (par exemple avec drop_na(uid)) ou supprimer les doublons (voir la section du manuel sur la déduplication pour plus de détails). Ceux qui n’ont pas de consentement doivent aussi être supprimés.Dans cet exemple, nous filtrons les cas que nous voulons supprimer et les stockons dans un cadre de données séparé - de cette façon, nous pouvons décrire ceux qui ont été exclus de l’enquête. Nous utilisons ensuite la fonction anti_join() de dplyr pour supprimer ces cas exclus de nos données d’enquête.DANGER: Vous ne pouvez pas avoir de valeurs manquantes dans votre variable de poids, ni dans aucune des variables pertinentes pour le plan de sondage (par exemple, les variables d’âge, de sexe, de strates ou de grappes).Comme mentionné ci-dessus, nous montrons comment ajouter des poids pour trois plans d’étude différents (stratifié, en grappe et en grappe stratifié). Ceux-ci nécessitent des informations sur la population source et/ou les grappes enquêtées. Nous utiliserons le code de la grappe stratifiée pour cet exemple, mais utilisez celui qui est le plus approprié à votre plan d’étude.","code":"\n## stockez les cas que vous abandonnez afin de pouvoir les décrire (par exemple, non-consentant. \n## ou mauvais village/cluster)\ndropped <- survey_data %>% \n  filter(!consent | is.na(startdate) | is.na(enddate) | village_name == \"other\")\n\n## utiliser les cas abandonnés pour supprimer les lignes inutilisées de l'ensemble des données de l'enquête.  \nsurvey_data <- anti_join(survey_data, dropped, by = names(dropped))\n# stratified ------------------------------------------------------------------\n# Créez une variable appelée \"surv_weight_strata\".\n# contient les poids pour chaque individu - par groupe d'âge, sexe et district sanitaire.\nsurvey_data <- add_weights_strata(x = survey_data,\n                                         p = population,\n                                         surv_weight = \"surv_weight_strata\",\n                                         surv_weight_ID = \"surv_weight_ID_strata\",\n                                         age_group, sex, health_district)\n\n## cluster ---------------------------------------------------------------------\n\n# obtient le nombre de personnes d'individus interrogés par ménage\n# ajoute une variable avec les comptes de la variable index du ménage (parent)\nsurvey_data <- survey_data %>%\n  add_count(index, name = \"interviewed\")\n\n\n## crée des poids de cluster\nsurvey_data <- add_weights_cluster(x = survey_data,\n                                          cl = cluster_counts,\n                                          eligible = member_number,\n                                          interviewed = interviewed,\n                                          cluster_x = village_name,\n                                          cluster_cl = cluster,\n                                          household_x = index,\n                                          household_cl = households,\n                                          surv_weight = \"surv_weight_cluster\",\n                                          surv_weight_ID = \"surv_weight_ID_cluster\",\n                                          ignore_cluster = FALSE,\n                                          ignore_household = FALSE)\n\n\n# stratifié et cluster ------------------------------------------------------\n# créer un poids d'enquête pour la grappe et les strates\nsurvey_data <- survey_data %>%\n  mutate(surv_weight_cluster_strata = surv_weight_strata * surv_weight_cluster)"},{"path":"survey_analysis.html","id":"objets-de-conception-denquête","chapter":"26 Analyse d’enquête","heading":"26.6 Objets de conception d’enquête","text":"Créez un objet d’enquête en fonction de la conception de votre étude. Utilisé de la même manière que les cadres de données pour calculer les proportions de poids, etc. Assurez-vous que toutes les variables nécessaires sont créées avant cela.Il y quatre options, commentez celles que vous n’utilisez pas :\n- aléatoire simple\n- Stratifié\n- en grappe\n- Grappe stratifiéePour ce modèle, nous supposerons que nous regroupons les enquêtes dans deux strates distinctes (districts sanitaires et B). Pour obtenir des estimations globales, nous devons donc combiner les poids des grappes et des strates.Comme nous l’avons mentionné précédemment, il existe deux paquets disponibles pour ce faire. Le classique est survey et il existe un paquetage appelé srvyr qui crée des objets et des fonctions adaptés à tidyverse. Nous ferons la démonstration des deux, mais notez que la plupart du code de ce chapitre utilisera des objets basés sur srvyr. La seule exception est que le paquet gtsummary n’accepte que les objets survey.","code":""},{"path":"survey_analysis.html","id":"paquet-survey","chapter":"26 Analyse d’enquête","heading":"26.6.1 Paquet **Survey","text":"Le paquet survey utilise effectivement le codage base R, et il n’est donc pas possible d’utiliser les pipes (%>%) ou d’autres syntaxes dplyr. Avec le paquetage survey, nous utilisons la fonction svydesign() pour définir un objet d’enquête avec les clusters, les poids et les strates appropriés.NOTE: nous devons utiliser le tilde (~) devant les variables, ceci parce que le package utilise la syntaxe base R d’affectation des variables basée sur des formules. ","code":"\n# aléatoire simple ---------------------------------------------------------------\nbase_survey_design_simple <- svydesign(ids = ~1, # 1 pour aucun id de grappe\n                   weights = NULL, # aucun poids ajouté\n                   strata = NULL, # l'échantillonnage est simple (pas de strates)\n                   data = survey_data # doit spécifier l'ensemble de données\n                  )\n\n## stratified ------------------------------------------------------------------\nbase_survey_design_strata <- svydesign(ids = ~1, # 1 pour aucun id de cluster\n                   weights = ~surv_weight_strata, # variable de poids créée ci-dessus\n                   strata = ~health_district, # l'échantillonnage a été stratifié par district\n                   data = survey_data # il faut spécifier l'ensemble de données\n                  )\n\n# cluster ---------------------------------------------------------------------\nbase_survey_design_cluster <- svydesign(ids = ~village_name, # ids de cluster\n                   weights = ~surv_weight_cluster, # variable de poids créée ci-dessus\n                   strata = NULL, # l'échantillonnage était simple (pas de strates)\n                   data = survey_data # il faut spécifier l'ensemble de données\n                  )\n\n# cluster stratifié ----------------------------------------------------------\nbase_survey_design <- svydesign(ids = ~village_name, # ids de cluster\n                   weights = ~surv_weight_cluster_strata, # variable de poids créée ci-dessus\n                   strata = ~health_district, # l'échantillonnage a été stratifié par district\n                   data = survey_data # doit spécifier l'ensemble de données\n                  )"},{"path":"survey_analysis.html","id":"paquet-srvyr","chapter":"26 Analyse d’enquête","heading":"26.6.2 Paquet **Srvyr","text":"Avec le paquet srvyr, nous pouvons utiliser la fonction as_survey_design(), qui les mêmes arguments que ci-dessus, mais autorise les tubes (%>%), et nous n’avons donc pas besoin d’utiliser le tilde (%>%).","code":"\n## aléatoire simple ---------------------------------------------------------------\nsurvey_design_simple <- survey_data %>% \n  as_survey_design(ids = 1, # 1 pour aucun id de grappe \n                   weights = NULL, # Aucun poids ajouté\n                   strata = NULL # l'échantillonnage était simple (pas de strates)\n                  )\n## stratified ------------------------------------------------------------------\nsurvey_design_strata <- survey_data %>%\n  as_survey_design(ids = 1, # 1 pour aucun id de cluster\n                   weights = surv_weight_strata, # variable de poids créée ci-dessus\n                   strata = health_district # l'échantillonnage a été stratifié par district\n                  )\n## cluster ---------------------------------------------------------------------\nsurvey_design_cluster <- survey_data %>%\n  as_survey_design(ids = village_name, # ids de la grappe\n                   weights = surv_weight_cluster, # variable de poids créée ci-dessus\n                   strata = NULL # l'échantillonnage était simple (pas de strates)\n                  )\n\n## cluster stratifié ----------------------------------------------------------\nsurvey_design <- survey_data %>%\n  as_survey_design(ids = village_name, # ids de la grappe\n                   weights = surv_weight_cluster_strata, # variable de poids créée ci-dessus\n                   strata = health_district # l'échantillonnage a été stratifié par district\n                  )"},{"path":"survey_analysis.html","id":"analyse-descriptive-1","chapter":"26 Analyse d’enquête","heading":"26.7 Analyse descriptive","text":"L’analyse descriptive et la visualisation de base sont traitées en détail dans d’autres chapitres du manuel, nous ne nous y attarderons donc pas ici. Pour plus de détails, voir les chapitres sur les tableaux descriptifs, les tests statistiques, les tableaux de présentation, [les bases du ggplot] (#ggplot_basics) et rapports R markdown.Dans cette section, nous allons nous concentrer sur la manière d’étudier le biais dans votre échantillon et de le visualiser. Nous nous pencherons également sur la visualisation du flux de population dans le cadre d’une enquête à l’aide de diagrammes alluviaux/sankey.En général, vous devriez envisager d’inclure les analyses descriptives suivantes :Le nombre final de grappes, de ménages et d’individus inclus.Nombre d’individus exclus et les raisons de cette exclusionNombre médian (fourchette) de ménages par grappe et d’individus par ménage.","code":""},{"path":"survey_analysis.html","id":"biais-déchantillonnage","chapter":"26 Analyse d’enquête","heading":"26.7.1 Biais d’échantillonnage","text":"Comparez les proportions dans chaque groupe d’âge entre votre échantillon et la population source. Ceci est important pour pouvoir mettre en évidence un éventuel biais d’échantillonnage. Vous pouvez également répéter cette opération en examinant les distributions par sexe.Notez que ces p-values ne sont qu’indicatives, et qu’une discussion descriptive (ou une visualisation avec les pyramides d’âge ci-dessous) des distributions dans votre échantillon d’étude par rapport à la population source est plus importante que le test binomial lui-même. Cela est dû au fait que l’augmentation de la taille de l’échantillon conduira le plus souvent à des différences qui peuvent ne pas être pertinentes après la pondération de vos données.","code":"\n## dénombrements et saillies de la population étudiée.\nag <- survey_data %>% \n  group_by(age_group) %>% \n  drop_na(age_group) %>% \n  tally() %>% \n  mutate(proportion = n / sum(n), \n         n_total = sum(n))\n\n## comptes et props de la population source\npropcount <- population %>% \n  group_by(age_group) %>%\n    tally(population) %>%\n    mutate(proportion = n / sum(n))\n\n## lier ensemble les colonnes de deux tables, regrouper par âge, et effectuer un \n## un test binomial pour voir si n/total est significativement différent de la population\n## proportion.\n  ## Le suffixe ajoute ici du texte à la fin des colonnes dans chacun des deux ensembles de données.\nleft_join(ag, propcount, by = \"age_group\", suffix = c(\"\", \"_pop\")) %>%\n  group_by(age_group) %>%\n  ## broom::tidy(binom.test()) crée une trame de données à partir du test binomial et ## ajoutera les variables p.p. à la trame de données.\n  ## ajoutera les variables p.value, parameter, conf.low, conf.high, method, and\n  ## alternative. Nous n'utiliserons que p.value ici. Vous pouvez inclure d'autres\n  ## d'autres colonnes si vous souhaitez faire état des intervalles de confiance.\n  mutate(binom = list(broom::tidy(binom.test(n, n_total, proportion_pop)))) %>%\n  unnest(cols = c(binom)) %>% # important pour l'expansion du cadre de données binom.test\n  mutate(proportion_pop = proportion_pop * 100) %>%\n  ## Ajustement des valeurs de p pour corriger les faux positifs. \n  ## (parce que l'on teste plusieurs groupes d'âge). Cela ne fera une \n  ## une différence que si vous avez plusieurs catégories d'âge\n  mutate(p.value = p.adjust(p.value, method = \"holm\")) %>%\n                      \n  ## N'affichez que les valeurs de p supérieures à 0,001 (celles qui sont inférieures sont signalées comme <0,001)\n  mutate(p.value = ifelse(p.value < 0.001, \n                          \"<0.001\", \n                          as.character(round(p.value, 3)))) %>% \n  \n  ## renommez les colonnes de manière appropriée\n  select(\n    \"Groupe d'âge\" = age_group,\n    \"Population étudiée (n)\" = n,\n    \"Population étudiée (%)\" = proportion,\n    \"Population source (n)\" = n_pop,\n    \"Population source (%)\" = proportion_pop,\n    \"P-value\" = p.value\n  )## # A tibble: 5 × 6\n## # Groups:   Groupe d'âge [5]\n##   `Groupe d'âge` `Population étudiée (n)` Population étudiée (%…¹ Population source (n…²\n##   <chr>                             <int>                   <dbl>                  <dbl>\n## 1 0-2                                  12                  0.0256                   1360\n## 2 3-14                                 42                  0.0896                   7244\n## 3 15-29                                64                  0.136                    5520\n## 4 30-44                                52                  0.111                    3232\n## 5 45+                                 299                  0.638                    2644\n## # ℹ abbreviated names: ¹​`Population étudiée (%)`, ²​`Population source (n)`\n## # ℹ 2 more variables: `Population source (%)` <dbl>, `P-value` <chr>"},{"path":"survey_analysis.html","id":"pyramides-démographiques","chapter":"26 Analyse d’enquête","heading":"26.7.2 Pyramides démographiques","text":"Les pyramides démographiques (ou âge-sexe) sont un moyen facile de visualiser la distribution dans la population de votre enquête. Il est également intéressant de créer des tableaux descriptifs et le sexe par strates d’enquête. Nous allons démontrer l’utilisation du paquet apyramide car il permet de pondérées en utilisant notre objet de conception d’enquête créé ci-dessus. Autres options pour créer pyramides démographiques sont traitées en détail dans ce chapitre du manuel. Nous utiliserons également une fonction wrapper de apyramid appelée age_pyramid() qui permet de gagner quelque lignes de code pour produire un graphique avec des proportions.Comme pour le test binomial formel de différence, vu plus haut dans la section sur le biais d’échantillonnage, nous sommes intéressés ici à visualiser si notre population échantillonnée est sensiblement différente de la population source et si la pondération corrige cette différence. Pour ce faire, nous allons utiliser le paquet patchwork pour montrer nos visualisations ggplot côte à côte ; pour plus de détails, voir la section sur la combinaison de tracés dans le chapitre du manuel Astuces de ggplot du manuel. Nous allons visualiser notre population source, notre population d’enquête non pondérée et notre population d’enquête pondérée. Vous pouvez également envisager de visualiser chaque strate de votre enquête, pars exemple ici, en utilisant l’argument stack_by = \"health_district\" (voir ?plot_age_pyramid pour plus de détails).NOTE: Les axes x et y sont inversés dans les pyramides .","code":"\n## définir les limites et les étiquettes de l'axe des x ---------------------------------------------\n## (mettez à jour ces chiffres pour qu'ils correspondent aux valeurs de votre graphique)\nmax_prop <- 35 ## choisissez la plus haute proportion que vous voulez montrer \nstep <- 5 # choisissez l'espace que vous voulez entre les étiquettes. \n\n## cette partie définit le vecteur en utilisant les nombres ci-dessus avec des ruptures d'axe.\nbreaks <- c(\n    seq(max_prop/100 * -1, 0 - step/100, step/100), \n    0, \n    seq(0 + step / 100, max_prop/100, step/100)\n    )\n\n## cette partie définit le vecteur en utilisant les nombres ci-dessus avec les limites de l'axe\nlimits <- c(max_prop/100 * -1, max_prop/100)\n\n## Cette partie définit le vecteur en utilisant les nombres ci-dessus avec les étiquettes d'axe.\nlabels <- c(\n      seq(max_prop, step, -step), \n      0, \n      seq(step, max_prop, step)\n    )\n\n\n## créer des graphiques individuellement --------------------------------------------------\n\n## tracer la population source \n## nb : cette population doit être réduite à la population globale (c'est-à-dire en enlevant les districts de santé).\nsource_population <- population %>%\n  ## s'assurer que l'âge et le sexe sont des facteurs\n  mutate(age_group = factor(age_group, \n                            levels = c(\"0-2\", \n                                       \"3-14\", \n                                       \"15-29\",\n                                       \"30-44\", \n                                       \"45+\")), \n         sex = factor(sex)) %>% \n  group_by(age_group, sex) %>% \n  ## additionner les comptes pour chaque district de santé \n  summarise(population = sum(population)) %>% \n  ## supprimer le regroupement pour pouvoir calculer la proportion globale\n  ungroup() %>% \n  mutate(proportion = population / sum(population)) %>% \n  ## tracer la pyramide \n  age_pyramid(\n            age_group = age_group, \n            split_by = sex, \n            count = proportion, \n            proportional = TRUE) +\n  ## Afficher uniquement le libellé de l'axe des y (sinon répété dans les trois graphiques)\n  labs(title = \"Population source\", \n       y = \"\", \n       x = \"Groupe d'âge (années)\") + \n  ## rendre l'axe des x identique pour tous les graphiques \n  scale_y_continuous(breaks = breaks, \n    limits = limits, \n    labels = labels)\n  \n  \n## Tracez l'échantillon de population non pondéré \nsample_population <- age_pyramid(survey_data, \n                 age_group = \"age_group\", \n                 split_by = \"sex\",\n                 proportion = TRUE) + \n  ## Afficher uniquement le libellé de l'axe des x (sinon répété dans les trois graphiques)\n  labs(title = \"Population échantillon non pondérée\", \n       y = \"Proportion (%)\", \n       x = \"\") + \n  ## rendre l'axe des x identique pour tous les graphiques \n  scale_y_continuous(breaks = breaks, \n    limits = limits, \n    labels = labels)\n\n\n## tracer la population de l'échantillon pondéré \nweighted_population <- survey_design %>% \n  ## S'assurer que les variables sont des facteurs\n  mutate(age_group = factor(age_group), \n         sex = factor(sex)) %>%\n  age_pyramid(\n    age_group = \"age_group\",\n    split_by = \"sex\", \n    proportion = TRUE) +\n  ## Afficher uniquement le libellé de l'axe des x (sinon répété dans les trois graphiques)\n  labs(title = \"Echantillon de population pondéré\", \n       y = \"\", \n       x = \"\") + \n  ## rendre l'axe des x identique pour tous les graphiques \n  scale_y_continuous(breaks = breaks, \n    limits = limits, \n    labels = labels)\n\n## combine les trois tracés ----------------------------------------------------\n## Combinez trois tracés côte à côte en utilisant + \nsource_population + sample_population + weighted_population + \n  ## ne montrer qu'une seule légende et définir le thème \n  ## notez l'utilisation de & pour combiner le thème avec plot_layout()\n  plot_layout(guides = \"collect\") & \n  theme(legend.position = \"bottom\", # déplace la légende vers le bas\n        legend.title = element_blank(), # supprimer le titre\n        text = element_text(size = 18), # change la taille du texte\n        axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1) # tourner le texte de l'axe x\n       )"},{"path":"survey_analysis.html","id":"diagramme-alluvialsankey","chapter":"26 Analyse d’enquête","heading":"26.7.3 Diagramme alluvial/sankey","text":"La visualisation des points de départ et des résultats pour les individus peut être très utile pour obtenir une vue d’ensemble. L’application est évidente pour les populations mobiles, mais il existe de nombreuses autres applications telles que les cohortes ou toute autre situation\noù il y des transitions d’états pour les individus. Ces diagrammes ont plusieurs noms différents, y compris alluvial, sankey et ensembles parallèles - les détails sont dans le chapitre du manuel consacré aux diagrammes et graphiques.","code":"\n## résumer les données\nflow_table <- survey_data %>%\n  count(startcause, endcause, sex) %>% # obtenir des comptages \n  gather_set_data(x = c(\"startcause\", \"endcause\")) # changer de format pour le tracé\n\n\n\n## Tracez votre ensemble de données \n  ## sur l'axe des x, les causes de début et de fin.\n  ## gather_set_data génère un ID pour chaque combinaison possible.\n  ## La division par y donne les combinaisons possibles de début et de fin.\n  ## la valeur n donne les comptes (peut aussi être changée en proportion).\nggplot(flow_table, aes(x, id = id, split = y, value = n)) +\n  ## colorer les lignes par sexe \n  geom_parallel_sets(aes(fill = sex), alpha = 0.5, axis.width = 0.2) + ### remplir les cases d'étiquettes en gris.\n  ## remplir les cases d'étiquettes en gris\n  geom_parallel_sets_axes(axis.width = 0.15, fill = \"grey80\", color = \"grey80\") + ## changer la couleur du texte et l'angle de l'étiquette.\n  ## changer la couleur et l'angle du texte (doit être ajusté)\n  geom_parallel_sets_labels(color = \"black\", angle = 0, size = 5) + ## ajuster la couleur et l'angle du texte (doit être ajusté)\n  ## suppression des étiquettes d'axe\n  theme_void()+\n  theme(legend.position = \"bottom\")"},{"path":"survey_analysis.html","id":"proportions-pondérées","chapter":"26 Analyse d’enquête","heading":"26.8 Proportions pondérées","text":"Cette section détaillera comment produire des tableaux pour les effectifs et les proportions pondérés, avec les intervalles de confiance associés et l’effet de plan. Il existe quatre options différentes utilisant les fonctions des paquets suivants : survey, srvyr, sitrep et gtsummary. Pour un codage minimal permettant de produire un tableau standard de style épidémiologique, nous recommandons la fonction sitrep - qui est un wrapper pour le code srvyr ; notez cependant que ce n’est pas encore sur CRAN et que cela peut changer dans le futur. Autrement, le code survey est susceptible d’être le plus stable à long terme, alors que srvyr s’intégrera le mieux dans les flux de travail de tidyverse. Bien que les fonctions gtsummary ont beaucoup de potentiel, elles semblent expérimentales et incomplètes au moment de la rédaction.","code":""},{"path":"survey_analysis.html","id":"paquet-survey-1","chapter":"26 Analyse d’enquête","heading":"26.8.1 Paquet **Survey","text":"Nous pouvons utiliser la fonction svyciprop() de survey pour obtenir des proportions pondérées et les intervalles de confiance à 95% qui les accompagnent. Il est intéressant de noter que svyprop() ne semble accepter que les variables comprises entre 0 et 1 (ou VRAI/FAUX), donc les variables catégorielles ne fonctionneront pas.NOTE: Les fonctions de survey acceptent également les objets de conception srvyr, mais ici nous avons utilisé l’objet de conception survey juste pour la cohérence .Nous pouvons combiner les fonctions de survey présentées ci-dessus en une fonction que nous définissons nous-mêmes ci-dessous, appelée svy_prop ; et nous pouvons alors utiliser cette fonction avec map() du paquetage purrr pour itérer sur plusieurs variables et créer un tableau. Voir le chapitre du manuel itération pour plus de détails sur purrr.","code":"\n## produire des comptes pondérés \nsvytable(~died, base_survey_design)## died\n##      FALSE       TRUE \n## 1406244.43   76213.01\n## produit des proportions pondérées\nsvyciprop(~died, base_survey_design, na.rm = T)##               2.5% 97.5%\n## died 0.0514 0.0208  0.12\n## obtenir l'effet du plan de sondage \nsvymean(~died, base_survey_design, na.rm = T, deff = T) %>% \n  deff()## diedFALSE  diedTRUE \n##  3.755508  3.755508\n# Définissez la fonction permettant de calculer les effectifs pondérés, les proportions, l'IC et l'effet de plan.\n# x est la variable entre guillemets \n# design est votre objet de conception d'enquête\n\nsvy_prop <- function(design, x) {\n  \n  ## mettre la variable d'intérêt dans une formule \n  form <- as.formula(paste0( \"~\" , x))\n  ## garder seulement la colonne VRAIE des comptes de svytable\n  weighted_counts <- svytable(form, design)[[2]]\n  ## calculer les proportions (multiplier par 100 pour obtenir des pourcentages).\n  weighted_props <- svyciprop(form, design, na.rm = TRUE) * 100\n  ## extraire les intervalles de confiance et les multiplier pour obtenir des pourcentages.\n  weighted_confint <- confint(weighted_props) * 100\n  ## utiliser svymean pour calculer l'effet de plan et ne garder que la colonne TRUE.\n  design_eff <- deff(svymean(form, design, na.rm = TRUE, deff = TRUE))[[TRUE]]\n  \n  ## combiner en un seul cadre de données\n  full_table <- cbind(\n    \"Variable\" = x,\n    \"Count\" = weighted_counts,\n    \"Proportion\" = weighted_props,\n    weighted_confint, \n    \"Design effect\" = design_eff\n    )\n  \n  ## Retourner le tableau sous forme de cadre de données\n  full_table <- data.frame(full_table, \n             ## supprimer les noms de variables des lignes (c'est une colonne séparée maintenant)\n             row.names = NULL)\n  \n  ## Remplacer les valeurs numériques par des valeurs numériques\n  full_table[ , 2:6] <- as.numeric(full_table[ , 2:6])\n  \n  ## Retourner le cadre de données\n  full_table\n}\n\n## itérer sur plusieurs variables pour créer un tableau \npurrr::map(\n  ## définir les variables d'intérêt\n  c(\"left\", \"died\", \"arrived\"), \n  ## déclarer la fonction utilisée et les arguments pour cette fonction (design)\n  svy_prop, design = base_survey_design) %>% \n  ## réduire la liste à un seul cadre de données\n  bind_rows() %>% \n  ## round \n  mutate(across(where(is.numeric), round, digits = 1))##   Variable    Count Proportion X2.5. X97.5. Design.effect\n## 1     left 701199.1       47.3  39.2   55.5           2.4\n## 2     died  76213.0        5.1   2.1   12.1           3.8\n## 3  arrived 761799.0       51.4  40.9   61.7           3.9"},{"path":"survey_analysis.html","id":"paquet-srvyr-1","chapter":"26 Analyse d’enquête","heading":"26.8.2 Paquet **Srvyr","text":"Avec srvyr, nous pouvons utiliser la syntaxe dplyr pour créer une table. Notez que la méthode fonction survey_mean() est utilisée et que l’argument de proportion est spécifié, ainsi que également que la même fonction est utilisée pour calculer l’effet de plan. Ceci est dû au fait que srvyr englobe les deux fonctions du paquetage survey, svyciprop() et svymean(), qui sont utilisées dans la section ci-dessus.NOTE: Il ne semble pas non plus possible d’obtenir des proportions à partir de variables catégorielles en utilisant srvyr, si vous en avez besoin, consultez la section ci-dessous utilisant sitrep .Là encore, nous pourrions écrire une fonction pour itérer sur plusieurs variables en utilisant le paquet purrr. Voir le chapitre du manuel itération pour plus de détails sur purrr.","code":"\n## utiliser l'objet de conception srvyr\nsurvey_design %>% \n  summarise(\n    ## produire les comptes pondérés \n    counts = survey_total(died), \n    ## produire les proportions pondérées et les intervalles de confiance \n    ## multiplier par 100 pour obtenir un pourcentage \n    props = survey_mean(died, \n                        proportion = TRUE, \n                        vartype = \"ci\") * 100, \n    ## produire l'effet de plan \n    deff = survey_mean(died, deff = TRUE)) %>% \n  ## conserver uniquement les lignes d'intérêt\n  ## (supprimez les erreurs standard et répétez le calcul des proportions)\n  select(counts, props, props_low, props_upp, deff_deff)## # A tibble: 1 × 5\n##   counts props props_low props_upp deff_deff\n##    <dbl> <dbl>     <dbl>     <dbl>     <dbl>\n## 1 76213.  5.14      2.08      12.1      3.76\n# Définit la fonction permettant de calculer les effectifs pondérés, les proportions, l'IC et l'effet du plan de sondage.\n# design est l'objet de votre plan de sondage\n# x est la variable entre guillemets \n\n\nsrvyr_prop <- function(design, x) {\n  \n  summarise(\n    ## utiliser l'objet du plan de sondage\n    design, \n    ## produire les comptes pondérés \n    counts = survey_total(.data[[x]]), \n    ## produire les proportions pondérées et les intervalles de confiance \n    ## multiplier par 100 pour obtenir un pourcentage \n    props = survey_mean(.data[[x]], \n                        proportion = TRUE, \n                        vartype = \"ci\") * 100, \n    ## produire l'effet de plan \n    deff = survey_mean(.data[[x]], deff = TRUE)) %>% \n  ## ajouter le nom de la variable\n  mutate(variable = x) %>% \n  ## ne conserve que les lignes d'intérêt\n  ## (supprimez les erreurs standard et répétez le calcul des proportions)\n  select(variable, counts, props, props_low, props_upp, deff_deff)\n  \n}\n  \n\n## itérer sur plusieurs variables pour créer un tableau \npurrr::map(\n  ## définir les variables d'intérêt\n  c(\"left\", \"died\", \"arrived\"), \n  ## déclarer la fonction utilisée et les arguments pour cette fonction (design)\n  ~srvyr_prop(.x, design = survey_design)) %>% \n  ## réduire la liste à un seul cadre de données\n  bind_rows()## # A tibble: 3 × 6\n##   variable  counts props props_low props_upp deff_deff\n##   <chr>      <dbl> <dbl>     <dbl>     <dbl>     <dbl>\n## 1 left     701199. 47.3      39.2       55.5      2.38\n## 2 died      76213.  5.14      2.08      12.1      3.76\n## 3 arrived  761799. 51.4      40.9       61.7      3.93"},{"path":"survey_analysis.html","id":"paquet-sitrep","chapter":"26 Analyse d’enquête","heading":"26.8.3 Paquet **Sitrep","text":"La fonction tab_survey() de sitrep est une enveloppe pour srvyr, vous permettant de créer des tableaux pondérés avec un codage minimal. Elle vous permet également de calculer proportions pondérées pour les variables catégorielles.","code":"\n## utilisation de l'objet survey design\nsurvey_design %>% \n  ## passe les noms des variables d'intérêt sans les citer\n  tab_survey(arrived, left, died, education_level,\n             deff = TRUE, # calculer l'effet du plan de sondage\n             pretty = TRUE # fusionner la proportion et le 95%CI\n             )## Warning: removing 257 missing value(s) from `education_level`## # A tibble: 9 × 5\n##   variable        value            n  deff ci               \n##   <chr>           <chr>        <dbl> <dbl> <chr>            \n## 1 arrived         TRUE       761799.  3.93 51.4% (40.9-61.7)\n## 2 arrived         FALSE      720658.  3.93 48.6% (38.3-59.1)\n## 3 left            TRUE       701199.  2.38 47.3% (39.2-55.5)\n## 4 left            FALSE      781258.  2.38 52.7% (44.5-60.8)\n## 5 died            TRUE        76213.  3.76 5.1% (2.1-12.1)  \n## 6 died            FALSE     1406244.  3.76 94.9% (87.9-97.9)\n## 7 education_level higher     171644.  4.70 42.4% (26.9-59.7)\n## 8 education_level primary    102609.  2.37 25.4% (16.2-37.3)\n## 9 education_level secondary  130201.  6.68 32.2% (16.5-53.3)"},{"path":"survey_analysis.html","id":"paquet-gtsummary","chapter":"26 Analyse d’enquête","heading":"26.8.4 Paquet **Gtsummary","text":"Avec gtsummary, il ne semble pas y avoir de fonctions intégrées pour ajouter des intervalles de confiance ou l’effet de plan. Ici nous montrons comment définir une fonction pour ajouter des intervalles de confiance et ensuite ajouter des intervalles de confiance à une table gtsummary créée en utilisant la fonction tbl_svysummary().","code":"\nconfidence_intervals <- function(data, variable, by, ...) {\n  \n  ## extraire les intervalles de confiance et les multiplier pour obtenir des pourcentages.\n  props <- svyciprop(as.formula(paste0( \"~\" , variable)),\n              data, na.rm = TRUE)\n  \n  ## Extraire les intervalles de confiance \n  as.numeric(confint(props) * 100) %>% ### rendre numérique et multiplier pour le pourcentage\n    round(., digits = 1) %>% ## arrondir à un chiffre\n    c(.) %>% ## extraire les chiffres de la matrice\n    paste0(., collapse = \"-\") ## combine en un seul caractère\n}\n\n## utiliser l'objet de conception du paquet d'enquêtes\ntbl_svysummary(base_survey_design, \n               include = c(arrived, left, died), ## définir les variables à inclure\n               statistic = list(everything() ~ c(\"{n} ({p}%)\"))) %>% ## définir les statistiques d'intérêt\n  add_n() %>% ## ajoute le total pondéré \n  add_stat(fns = everything() ~ confidence_intervals) %>% ## ajouter les ICs\n  ## modifier les en-têtes de colonnes\n  modify_header(\n    list(\n      n ~ \"**Total pondéré (N)**\",\n      stat_0 ~ \"**Compte pondéré**\",\n      add_stat_1 ~ \"**95%CI**\"\n    )\n    )"},{"path":"survey_analysis.html","id":"ratios-pondérés","chapter":"26 Analyse d’enquête","heading":"26.9 Ratios pondérés","text":"De même, pour les ratios pondérés (comme pour les ratios de mortalité), vous pouvez utiliser le paquetage survey ou le paquet srvyr. Vous pouvez également écrire des fonctions (similaires à celles ci-dessus) pour itérer sur plusieurs variables. Vous pourriez également créer une fonction pour gtsummary comme ci-dessus mais actuellement, elle n’pas de fonctionnalité intégrée.","code":""},{"path":"survey_analysis.html","id":"paquet-survey-2","chapter":"26 Analyse d’enquête","heading":"26.9.1 Paquet **Survey","text":"","code":"\nratio <- svyratio(~died, \n         denominator = ~obstime, \n         design = base_survey_design)\n\nci <- confint(ratio)\n\ncbind(\n  ratio$ratio * 10000, \n  ci * 10000\n)##       obstime    2.5 %   97.5 %\n## died 5.981922 1.194294 10.76955"},{"path":"survey_analysis.html","id":"paquet-srvyr-paquet","chapter":"26 Analyse d’enquête","heading":"26.9.2 Paquet SRVYR (paquet)","text":"","code":"\nsurvey_design %>% \n  ### ratio d'enquête utilisé pour tenir compte du temps d'observation \n  summarise(\n    mortality = survey_ratio(\n      as.numeric(died) * 10000, \n      obstime, \n      vartype = \"ci\")\n    )## # A tibble: 1 × 3\n##   mortality mortality_low mortality_upp\n##       <dbl>         <dbl>         <dbl>\n## 1      5.98         0.349          11.6"},{"path":"survey_analysis.html","id":"ressources-12","chapter":"26 Analyse d’enquête","heading":"26.10 Ressources","text":"Page des statistiques de l’UCLAAnalyse des données d’enquête gratuitepaquet srvyrpaquet gtsummaryÉtudes de cas de l’enquête EPIET","code":""},{"path":"survival_analysis.html","id":"survival_analysis","chapter":"27 Analyse de survie","heading":"27 Analyse de survie","text":"","code":""},{"path":"survival_analysis.html","id":"aperçu-3","chapter":"27 Analyse de survie","heading":"27.1 Aperçu","text":"L’analyse de survie s’attache à décrire pour un individu ou un groupe d’individus donné, un point d’événement défini appelé l’échec (apparition d’une maladie, guérison d’une maladie, décès, rechute après réponse à un traitement…) qui survient après une période de temps appelée le temps d’échec (ou le temps de suivi dans les études de cohorte/population) pendant laquelle les individus sont observés. Pour déterminer le temps d’échec, il est alors nécessaire de définir un temps d’origine (qui peut être la date d’inclusion, la date du diagnostic…).La cible d’inférence de l’analyse de survie est alors le temps entre une origine et un événement. Dans la recherche médicale actuelle, elle est largement utilisée dans les études cliniques pour évaluer l’effet d’un traitement par exemple, ou en épidémiologie du cancer pour évaluer une grande variété de mesures de survie au cancer.Elle s’exprime généralement par la probabilité de survie qui est la probabilité que l’événement d’intérêt ne se soit pas produit avant une durée t.Censure : La censure se produit lorsqu’à la fin du suivi, certains des individus n’ont pas eu l’événement d’intérêt, et donc leur temps réel jusqu’à l’événement est inconnu. Nous nous concentrerons principalement sur la censure à droite ici, mais pour plus de détails sur la censure et l’analyse de survie en général, vous pouvez consulter les références.","code":""},{"path":"survival_analysis.html","id":"préparation-10","chapter":"27 Analyse de survie","heading":"27.2 Préparation","text":"","code":""},{"path":"survival_analysis.html","id":"chargement-des-paquets-5","chapter":"27 Analyse de survie","heading":"Chargement des paquets","text":"Pour effectuer des analyses de survie dans R, un des paquets les plus utilisés est le paquet survival. Nous l’installons d’abord et le chargeons ensuite, ainsi que les autres paquets qui seront utilisés dans cette section :Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire et le charge pour l’utiliser. Vous pouvez aussi charger les paquets installés avec library() de base R. Voir la page sur [R basics] pour plus d’informations sur les paquets R.Cette page explore les analyses de survie en utilisant la linelist utilisée dans la plupart des pages précédentes et sur laquelle nous appliquons quelques changements pour avoir des données de survie correctes.","code":""},{"path":"survival_analysis.html","id":"importation-du-jeu-de-données","chapter":"27 Analyse de survie","heading":"Importation du jeu de données","text":"Nous importons le jeu de données des cas d’une épidémie d’Ebola simulée. Si vous voulez suivre le mouvement, cliquez pour télécharger la linelist “propre” (en tant que fichier .rds). Importez des données avec la fonction import() du paquet rio (elle gère de nombreux types de fichiers comme .xlsx, .csv, .rds - voir la page Importation et exportation pour plus de détails).","code":"\n# importation de linelist\nlinelist_case_data <- rio::import(\"linelist_cleaned.rds\")"},{"path":"survival_analysis.html","id":"gestion-et-transformation-des-données","chapter":"27 Analyse de survie","heading":"Gestion et transformation des données","text":"En bref, les données de survie peuvent être décrites comme ayant les trois caractéristiques suivantes :la variable dépendante ou réponse est le temps d’attente jusqu’à l’occurrence d’un événement bien défini,les observations sont censurées, en ce sens que pour certaines unités, l’événement d’intérêt ne s’est pas produit au moment où les données sont analysées, etil existe des prédicteurs ou des variables explicatives dont nous souhaitons évaluer ou contrôler l’effet sur le temps d’attente.Ainsi, nous allons créer les différentes variables nécessaires pour respecter cette structure et effectuer l’analyse de survie.Nous définissonsun nouveau cadre de données linelist_surv pour cette analysenotre événement d’intérêt comme étant le “décès” (donc notre probabilité de survie sera la probabilité d’être en vie après un certain temps après le moment d’origine),le temps de suivi (futime) comme le temps entre le moment de l’apparition et le moment du résultat en jours,les patients censurés comme ceux qui se sont rétablis ou pour lesquels le résultat final n’est pas connu, c’est-à-dire que l’événement “décès” n’pas été observé (event=0).CAUTION: Puisque dans une étude de cohorte réelle, l’information sur le moment de l’origine et la fin du suivi est connue étant donné que les individus sont observés, nous éliminerons les observations où la date d’apparition ou la date de l’issue est inconnue. De même, les cas où la date d’apparition est postérieure à la date de l’issue seront supprimés car ils sont considérés comme erronés.TIP: Étant donné que le filtrage sur une date supérieure à (>) ou inférieure à (<) peut supprimer les lignes avec des valeurs manquantes, l’application du filtre sur les mauvaises dates supprimera également les lignes avec des dates manquantes.Nous utilisons ensuite case_when() pour créer une colonne age_cat_small dans laquelle il n’y que 3 catégories d’âge.TIP: Nous pouvons vérifier les nouvelles colonnes que nous avons créées en faisant un résumé sur le futime et un tableau croisé entre event et outcome à partir duquel il été créé. Outre cette vérification, c’est une bonne habitude de communiquer la durée médiane de suivi lors de l’interprétation des résultats de l’analyse de survie.Maintenant, nous croisons la nouvelle var age_cat_small et l’ancienne col age_cat pour nous assurer que les affectations sont correctes.Maintenant, nous examinons les 10 premières observations des données linelist_surv en regardant des variables spécifiques (y compris celles nouvellement créées).Nous pouvons aussi croiser les colonnes age_cat_small et gender pour avoir plus de détails sur la distribution de cette nouvelle colonne par sexe. Nous utilisons tabyl() et les fonctions adorn de janitor comme décrit dans la page [Descriptive tables].","code":"\n#Créer une nouvelle donnée appelée linelist_surv à partir de la donnée linelist_case_data.\n\nlinelist_surv <- linelist_case_data %>% \n     \n  dplyr::filter(\n       # supprimez les observations dont la date d'apparition ou la date d'issue est erronée ou manquante.\n       date_outcome > date_onset) %>% \n  \n  dplyr::mutate(\n       # créer la var événement qui vaut 1 si le patient est décédé et 0 s'il a été censuré à droite\n       event = ifelse(is.na(outcome) | outcome == \"Recover\", 0, 1), \n    \n       # créer la var sur le temps de suivi en jours\n       futime = as.double(date_outcome - date_onset), \n    \n       # créer une nouvelle variable de catégorie d'âge avec seulement 3 niveaux de strates\n       age_cat_small = dplyr::case_when( \n            age_years < 5 ~ \"0-4\",\n            age_years >= 5 & age_years < 20 ~ \"5-19\",\n            age_years >= 20 ~ \"20+\"),\n       \n       # l'étape précédente a créé la var age_cat_small en tant que caractère.\n       # maintenant le convertir en facteur et spécifier les niveaux.\n       # Notez que les valeurs NA restent des NA et ne sont pas mises dans un niveau \"inconnu\" par exemple,\n       # puisque dans les prochaines analyses, elles devront être supprimées.\n       age_cat_small = fct_relevel(age_cat_small, \"0-4\", \"5-19\", \"20+\")\n       )\nsummary(linelist_surv$futime)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##    1.00    6.00   10.00   11.98   16.00   64.00\n# croiser les tableaux de la nouvelle var événement et de la var résultat à partir de laquelle elle a été créée.\n# pour s'assurer que le code a fait ce qu'il était censé faire.\nlinelist_surv %>% \n  tabyl(outcome, event)##  outcome    0    1\n##    Death    0 1952\n##  Recover 1547    0\n##     <NA> 1040    0\nlinelist_surv %>% \n  tabyl(age_cat_small, age_cat)##  age_cat_small 0-4 5-9 10-14 15-19 20-29 30-49 50-69 70+ NA_\n##            0-4 834   0     0     0     0     0     0   0   0\n##           5-19   0 852   717   575     0     0     0   0   0\n##            20+   0   0     0     0   862   554    69   5   0\n##           <NA>   0   0     0     0     0     0     0   0  71\nlinelist_surv %>% \n  select(case_id, age_cat_small, date_onset, date_outcome, outcome, event, futime) %>% \n  head(10)##    case_id age_cat_small date_onset date_outcome outcome event futime\n## 1   8689b7           0-4 2014-05-13   2014-05-18 Recover     0      5\n## 2   11f8ea           20+ 2014-05-16   2014-05-30 Recover     0     14\n## 3   893f25           0-4 2014-05-21   2014-05-29 Recover     0      8\n## 4   be99c8          5-19 2014-05-22   2014-05-24 Recover     0      2\n## 5   07e3e8          5-19 2014-05-27   2014-06-01 Recover     0      5\n## 6   369449           0-4 2014-06-02   2014-06-07   Death     1      5\n## 7   f393b4           20+ 2014-06-05   2014-06-18 Recover     0     13\n## 8   1389ca           20+ 2014-06-05   2014-06-09   Death     1      4\n## 9   2978ac          5-19 2014-06-06   2014-06-15   Death     1      9\n## 10  fc15ef          5-19 2014-06-16   2014-07-09 Recover     0     23\nlinelist_surv %>% \n  tabyl(gender, age_cat_small, show_na = F) %>% \n  adorn_totals(where = \"both\") %>% \n  adorn_percentages() %>% \n  adorn_pct_formatting() %>% \n  adorn_ns(position = \"front\")##  gender         0-4          5-19           20+          Total\n##       f 482 (22.4%) 1,184 (54.9%)   490 (22.7%) 2,156 (100.0%)\n##       m 325 (15.0%)   880 (40.6%)   960 (44.3%) 2,165 (100.0%)\n##   Total 807 (18.7%) 2,064 (47.8%) 1,450 (33.6%) 4,321 (100.0%)"},{"path":"survival_analysis.html","id":"bases-de-lanalyse-de-survie","chapter":"27 Analyse de survie","heading":"27.3 Bases de l’analyse de survie","text":"","code":""},{"path":"survival_analysis.html","id":"construction-dun-objet-de-type-surv","chapter":"27 Analyse de survie","heading":"Construction d’un objet de type surv","text":"Nous allons d’abord utiliser Surv() de survival pour construire un objet de type survie à partir des colonnes de temps de suivi et d’événement.Le résultat d’une telle étape est de produire un objet de type Surv qui condense les informations de temps et si l’événement d’intérêt (le décès) été observé. Cet objet sera finalement utilisé dans le côté droit des formules de modèle suivantes (voir documentation).Pour revoir, voici les 10 premières lignes des données linelist_surv, en ne visualisant que certaines colonnes importantes.Et voici les 10 premiers éléments de survobj. Il s’imprime essentiellement comme un vecteur de temps de suivi, avec “+” pour représenter si une observation été censurée à droite. Voyez comment les chiffres s’alignent au-dessus et en dessous.","code":"\n# Utilisez la syntaxe Suv() pour les données censurées à droite\nsurvobj <- Surv(time = linelist_surv$futime,\n                event = linelist_surv$event)\nlinelist_surv %>% \n  select(case_id, date_onset, date_outcome, futime, outcome, event) %>% \n  head(10)##    case_id date_onset date_outcome futime outcome event\n## 1   8689b7 2014-05-13   2014-05-18      5 Recover     0\n## 2   11f8ea 2014-05-16   2014-05-30     14 Recover     0\n## 3   893f25 2014-05-21   2014-05-29      8 Recover     0\n## 4   be99c8 2014-05-22   2014-05-24      2 Recover     0\n## 5   07e3e8 2014-05-27   2014-06-01      5 Recover     0\n## 6   369449 2014-06-02   2014-06-07      5   Death     1\n## 7   f393b4 2014-06-05   2014-06-18     13 Recover     0\n## 8   1389ca 2014-06-05   2014-06-09      4   Death     1\n## 9   2978ac 2014-06-06   2014-06-15      9   Death     1\n## 10  fc15ef 2014-06-16   2014-07-09     23 Recover     0\n#imprimez les 50 premiers éléments du vecteur pour voir comment il se présente\nhead(survobj, 10)##  [1]  5+ 14+  8+  2+  5+  5  13+  4   9  23+"},{"path":"survival_analysis.html","id":"exécution-des-analyses-initiales","chapter":"27 Analyse de survie","heading":"Exécution des analyses initiales","text":"Nous commençons ensuite notre analyse en utilisant la fonction survfit() pour produire un objet survfit, qui s’adapte aux calculs par défaut pour les estimations Kaplan Meier (KM) de la courbe de survie globale (marginale), qui sont en fait une fonction échelon avec des sauts aux moments des événements observés. L’objet final survfit contient une ou plusieurs courbes de survie et est créé en utilisant l’objet Surv comme variable de réponse dans la formule du modèle.NOTE: L’estimation de Kaplan-Meier est une estimation non paramétrique du maximum de vraisemblance (MLE) de la fonction de survie. (voir les ressources pour plus d’informations).Le résumé de cet objet survfit donnera ce que l’appelle une table de survie. Pour chaque pas de temps du suivi (temps) où un événement s’est produit (par ordre croissant) :le nombre de personnes qui étaient à risque de développer l’événement (les personnes qui n’ont pas encore eu l’événement ou qui ont été censurées : n.risk)ceux qui ont développé l’événement (n.event)et à partir de ce qui précède : la probabilité de ne pas développer l’événement (probabilité de ne pas mourir, ou de survivre au-delà de ce moment spécifique).enfin, l’erreur standard et l’intervalle de confiance pour cette probabilité sont dérivés et affichés.Nous ajustons les estimations de la GC en utilisant la formule où l’objet “survobj” précédemment survécu est la variable de réponse. “~ 1” précise que nous exécutons le modèle pour la survie globale.En utilisant summary(), nous pouvons ajouter l’option times et spécifier certaines heures auxquelles nous voulons voir les informations de survie.Nous pouvons également utiliser la fonction print(). L’argument print.rmean = TRUE permet d’obtenir le temps de survie moyen et son erreur standard (se).NOTE: La durée moyenne de survie restreinte (RMST) est une mesure de survie spécifique de plus en plus utilisée dans l’analyse de survie des cancers et qui est souvent définie comme l’aire sous la courbe de survie, étant donné que nous observons les patients jusqu’au temps restreint T (plus de détails dans la section Ressources).TIP: Nous pouvons créer l’objet surv directement dans la fonction survfit() et économiser une ligne de code. Cela ressemblera alors à : linelistsurv_quick <- survfit(Surv(futime, event) ~ 1, data=linelist_surv).","code":"\n# ajuster les estimations KM en utilisant une formule où l'objet Surv \"survobj\" est la variable de réponse.\n# \"~ 1\" signifie que nous exécutons le modèle pour la survie globale.  \nlinelistsurv_fit <- survival::survfit(survobj ~ 1)\n\n#imprimez son résumé pour plus de détails\nsummary(linelistsurv_fit)## Call: survfit(formula = survobj ~ 1)\n## \n##  time n.risk n.event survival std.err lower 95% CI upper 95% CI\n##     1   4539      30    0.993 0.00120        0.991        0.996\n##     2   4500      69    0.978 0.00217        0.974        0.982\n##     3   4394     149    0.945 0.00340        0.938        0.952\n##     4   4176     194    0.901 0.00447        0.892        0.910\n##     5   3899     214    0.852 0.00535        0.841        0.862\n##     6   3592     210    0.802 0.00604        0.790        0.814\n##     7   3223     179    0.757 0.00656        0.745        0.770\n##     8   2899     167    0.714 0.00700        0.700        0.728\n##     9   2593     145    0.674 0.00735        0.660        0.688\n##    10   2311     109    0.642 0.00761        0.627        0.657\n##    11   2081     119    0.605 0.00788        0.590        0.621\n##    12   1843      89    0.576 0.00809        0.560        0.592\n##    13   1608      55    0.556 0.00823        0.540        0.573\n##    14   1448      43    0.540 0.00837        0.524        0.556\n##    15   1296      31    0.527 0.00848        0.511        0.544\n##    16   1152      48    0.505 0.00870        0.488        0.522\n##    17   1002      29    0.490 0.00886        0.473        0.508\n##    18    898      21    0.479 0.00900        0.462        0.497\n##    19    798       7    0.475 0.00906        0.457        0.493\n##    20    705       4    0.472 0.00911        0.454        0.490\n##    21    626      13    0.462 0.00932        0.444        0.481\n##    22    546       8    0.455 0.00948        0.437        0.474\n##    23    481       5    0.451 0.00962        0.432        0.470\n##    24    436       4    0.447 0.00975        0.428        0.466\n##    25    378       4    0.442 0.00993        0.423        0.462\n##    26    336       3    0.438 0.01010        0.419        0.458\n##    27    297       1    0.436 0.01017        0.417        0.457\n##    29    235       1    0.435 0.01030        0.415        0.455\n##    38     73       1    0.429 0.01175        0.406        0.452\n#imprime son résumé à des moments précis\nsummary(linelistsurv_fit, times = c(5,10,20,30,60))## Call: survfit(formula = survobj ~ 1)\n## \n##  time n.risk n.event survival std.err lower 95% CI upper 95% CI\n##     5   3899     656    0.852 0.00535        0.841        0.862\n##    10   2311     810    0.642 0.00761        0.627        0.657\n##    20    705     446    0.472 0.00911        0.454        0.490\n##    30    210      39    0.435 0.01030        0.415        0.455\n##    60      2       1    0.429 0.01175        0.406        0.452\n# Imprimez l'objet linelistsurv_fit avec le temps de survie moyen et son se. \nprint(linelistsurv_fit, print.rmean = TRUE)## Call: survfit(formula = survobj ~ 1)\n## \n##         n events rmean* se(rmean) median 0.95LCL 0.95UCL\n## [1,] 4539   1952   33.1     0.539     17      16      18\n##     * restricted mean with upper limit =  64"},{"path":"survival_analysis.html","id":"risque-cumulé","chapter":"27 Analyse de survie","heading":"Risque cumulé","text":"Outre la fonction summary(), nous pouvons également utiliser la fonction str() qui donne plus de détails sur la structure de l’objet survfit(). Il s’agit d’une liste de 16 éléments.Parmi ces éléments, il y en un important : cumhaz, qui est un vecteur numérique. Il pourrait être tracé pour permettre de montrer le danger cumulatif, le danger étant le taux instantané d’occurrence de l’événement (voir références).","code":"\nstr(linelistsurv_fit)## List of 16\n##  $ n        : int 4539\n##  $ time     : num [1:59] 1 2 3 4 5 6 7 8 9 10 ...\n##  $ n.risk   : num [1:59] 4539 4500 4394 4176 3899 ...\n##  $ n.event  : num [1:59] 30 69 149 194 214 210 179 167 145 109 ...\n##  $ n.censor : num [1:59] 9 37 69 83 93 159 145 139 137 121 ...\n##  $ surv     : num [1:59] 0.993 0.978 0.945 0.901 0.852 ...\n##  $ std.err  : num [1:59] 0.00121 0.00222 0.00359 0.00496 0.00628 ...\n##  $ cumhaz   : num [1:59] 0.00661 0.02194 0.05585 0.10231 0.15719 ...\n##  $ std.chaz : num [1:59] 0.00121 0.00221 0.00355 0.00487 0.00615 ...\n##  $ type     : chr \"right\"\n##  $ logse    : logi TRUE\n##  $ conf.int : num 0.95\n##  $ conf.type: chr \"log\"\n##  $ lower    : num [1:59] 0.991 0.974 0.938 0.892 0.841 ...\n##  $ upper    : num [1:59] 0.996 0.982 0.952 0.91 0.862 ...\n##  $ call     : language survfit(formula = survobj ~ 1)\n##  - attr(*, \"class\")= chr \"survfit\""},{"path":"survival_analysis.html","id":"tracer-les-courbes-de-kaplan-meir","chapter":"27 Analyse de survie","heading":"Tracer les courbes de Kaplan-Meir","text":"Une fois les estimations KM ajustées, nous pouvons visualiser la probabilité d’être en vie à un moment donné en utilisant la fonction de base plot() qui dessine la “courbe de Kaplan-Meier”. En d’autres termes, la courbe ci-dessous est une illustration classique de l’expérience de survie dans l’ensemble du groupe de patients.Nous pouvons rapidement vérifier le temps de suivi min et max sur la courbe.Une manière simple d’interpréter est de dire qu’au temps zéro, tous les participants sont encore en vie et que la probabilité de survie est alors de 100%. Cette probabilité diminue au fil du temps, à mesure que les patients meurent. La proportion de participants survivant après 60 jours de suivi est d’environ 40 %.L’intervalle de confiance des estimations de survie KM est également tracé par défaut et peut être écarté en ajoutant l’option conf.int = FALSE à la commande plot().Puisque l’événement d’intérêt est la “mort”, dessiner une courbe décrivant les compléments des proportions de survie conduira à dessiner les proportions de mortalité cumulées. Ceci peut être fait avec lines(), qui ajoute des informations à un graphique existant.","code":"\nplot(linelistsurv_fit, \n     xlab = \"Days of follow-up\", # étiquette de l'axe des x\n     ylab=\"Probabilité de survie\", # étiquette de l'axe des y\n     main= \"Courbe de survie globale\" # titre de la figure\n     )\n# tracé original\nplot(\n  linelistsurv_fit,\n  xlab = \"Jours de suivi\",       \n  ylab = \"Probabilité de survie\",       \n  mark.time = TRUE, # marque les événements sur la courbe : un \"+\" est imprimé à chaque événement\n  conf.int = FALSE, # ne pas tracer l'intervalle de confiance\n  main = \"Courbe de survie globale et mortalité cumulée\"\n  )\n\n# Dessinez une courbe supplémentaire au tracé précédent\nlines(\n  linelistsurv_fit,\n  lty = 3, # utiliser un type de ligne différent pour plus de clarté\n  fun = \"event\", # dessine les événements cumulés au lieu de la survie \n  mark.time = FALSE,\n  conf.int = FALSE\n  )\n\n# Ajoutez une légende au graphique\nlegend(\n  \"topright\", # position de la légende\n  legend = c(\"Survival\", \"Cum. Mortality\"), # texte de la légende \n  lty = c(1, 3), # types de lignes à utiliser dans la légende\n  cex = .85, # paramètres qui définissent la taille du texte de la légende\n  bty = \"n\", # aucun type de boîte à dessiner pour la légende\n  )"},{"path":"survival_analysis.html","id":"comparaison-des-courbes-de-survie","chapter":"27 Analyse de survie","heading":"27.4 Comparaison des courbes de survie","text":"Pour comparer la survie au sein de différents groupes de nos participants ou patients observés, nous pourrions avoir besoin de regarder d’abord leurs courbes de survie respectives, puis d’effectuer des tests pour évaluer la différence entre les groupes indépendants. Cette comparaison peut concerner des groupes basés sur le sexe, l’âge, le traitement, la comorbidité…","code":""},{"path":"survival_analysis.html","id":"test-du-log-rank","chapter":"27 Analyse de survie","heading":"Test du log rank","text":"Le test du log rank est un test populaire qui compare l’ensemble de l’expérience de survie entre deux ou plusieurs groupes indépendants et peut être considéré comme un test permettant de savoir si les courbes de survie sont identiques (se chevauchent) ou non (hypothèse nulle d’aucune différence de survie entre les groupes). La fonction survdiff() du paquet survie permet d’exécuter le test log-rank lorsque l’spécifie rho = 0 (ce qui est le cas par défaut). Le résultat du test donne une statistique de chi-deux ainsi qu’une valeur p puisque la statistique de log-rang est approximativement distribuée comme une statistique de test de chi-deux.Nous essayons d’abord de comparer les courbes de survie par groupe de sexe. Pour cela, nous essayons d’abord de les visualiser (vérifier si les deux courbes de survie se chevauchent). Un nouvel objet survfit sera créé avec une formule légèrement différente. Ensuite, l’objet survdiff sera créé.En fournissant ~ gender comme partie droite de la formule, nous ne traçons plus la survie globale mais plutôt par sexe.Maintenant, nous pouvons tracer les courbes de survie par sexe. Jetez un oeil à l’ordre des niveaux de strates dans la colonne sexe avant de définir vos couleurs et votre légende.Et maintenant nous pouvons calculer le test de la différence entre les courbes de survie en utilisant `survdiff()``Nous constatons que la courbe de survie des femmes et celle des hommes se chevauchent et que le test log-rank ne met pas en évidence de différence de survie entre les femmes et les hommes.Certains autres packages R permettent d’illustrer les courbes de survie de différents groupes et de tester la différence en une seule fois. En utilisant la fonction ggsurvplot() du paquet survminer, nous pouvons également inclure dans notre courbe les tableaux de risque imprimés pour chaque groupe, ainsi que la p-value du test log-rank.CAUTION: Les fonctions survminer exigent que vous spécifiiez l’objet de survie et que vous spécifiiez à nouveau les données utilisées pour ajuster l’objet de survie. N’oubliez pas de le faire pour éviter les messages d’erreur non spécifiques. Nous pouvons également vouloir tester les différences de survie en fonction de la source d’infection (source de contamination).Dans ce cas, le test Log rank donne suffisamment de preuves d’une différence dans les probabilités de survie à alpha= 0.005. Les probabilités de survie des patients qui ont été infectés lors de funérailles sont plus élevées que les probabilités de survie des patients qui ont été infectés dans d’autres lieux, ce qui suggère un bénéfice de survie.","code":"\n# créez le nouvel objet survfit basé sur le sexe\nlinelistsurv_fit_sex <- survfit(Surv(futime, event) ~ gender, data = linelist_surv)\n# définissez les couleurs\ncol_sex <- c(\"light green\", \"dark green\")\n\n# Créez le graphique\nplot(\n  linelistsurv_fit_sex,\n  col = col_sex,\n  xlab = \"Jours de suivi\",\n  ylab = \"Probabilité de survie\")\n\n# ajouter une légende\nlegend(\n  \"topright\",\n  legend = c(\"Female\", \"Male\"),\n  col = col_sex,\n  lty = 1,\n  cex = .9,\n  bty = \"n\")\n#Test de la différence entre les courbes de survie\nsurvival::survdiff(\n  Surv(futime, event) ~ gender, \n  data = linelist_surv\n  )## Call:\n## survival::survdiff(formula = Surv(futime, event) ~ gender, data = linelist_surv)\n## \n## n=4321, 218 observations deleted due to missingness.\n## \n##             N Observed Expected (O-E)^2/E (O-E)^2/V\n## gender=f 2156      924      909     0.255     0.524\n## gender=m 2165      929      944     0.245     0.524\n## \n##  Chisq= 0.5  on 1 degrees of freedom, p= 0.5\nsurvminer::ggsurvplot(\n    linelistsurv_fit_sex, \n    data = linelist_surv, # spécifiez à nouveau les données utilisées pour ajuster linelistsurv_fit_sex \n    conf.int = FALSE, # ne pas montrer l'intervalle de confiance des estimations KM\n    surv.scale = \"percent\", # présente les probabilités sur l'axe des ordonnées en %.\n    break.time.by = 10, # présente l'axe du temps avec un incrément de 10 jours\n    xlab = \"Jours de suivi\",\n    ylab = \"Probabilité de survie\",\n    pval = T, # imprimer la valeur p du test de Log-rank \n    pval.coord = c(40,.91), # imprimer la valeur p à ces coordonnées de tracé\n    risk.table = T, # imprime le tableau des risques en bas de page \n    legend.title = \"Gender\", # légende des caractéristiques\n    legend.labs = c(\"Female\", \"Male\"),\n    font.legend = 10, \n    palette = \"Dark2\", # spécifier la palette de couleurs \n    surv.median.line = \"hv\", # dessine des lignes horizontales et verticales sur les médianes de survie\n    ggtheme = theme_light() # simplifie le fond du graphique\n)\nlinelistsurv_fit_source <- survfit(\n  Surv(futime, event) ~ source,\n  data = linelist_surv\n  )\n\n# plot\nggsurvplot( \n  linelistsurv_fit_source,\n  data = linelist_surv,\n  size = 1, linetype = \"strata\", # types de lignes\n  conf.int = T,\n  surv.scale = \"percent\",  \n  break.time.by = 10, \n  xlab = \"Jours de suivi\",\n  ylab= \"Probabilité de survie\",\n  pval = T,\n  pval.coord = c(40, .91),\n  risk.table = T,\n  legend.title = \"Source d'infection\",\n  legend.labs = c(\"Funéraire\", \"Autre\"),\n  font.legend = 10,\n  palette = c(\"#E7B800\", \"#3E606F\"),\n  surv.median.line = \"hv\", \n  ggtheme = theme_light()\n)"},{"path":"survival_analysis.html","id":"analyse-de-régression-de-cox","chapter":"27 Analyse de survie","heading":"27.5 Analyse de régression de Cox","text":"La régression des risques proportionnels de Cox est l’une des techniques de régression les plus populaires pour l’analyse de survie. D’autres modèles peuvent également être utilisés puisque le modèle de Cox requiert des hypothèses importantes qui doivent être vérifiées pour une utilisation appropriée, comme l’hypothèse des risques proportionnels : voir les références.Dans un modèle de régression à risques proportionnels de Cox, la mesure de l’effet est le taux de risque (HR), qui est le risque d’échec (ou le risque de décès dans notre exemple), étant donné que le participant survécu jusqu’à un moment spécifique. Habituellement, nous sommes intéressés par la comparaison de groupes indépendants en ce qui concerne leurs risques, et nous utilisons un rapport de risque, qui est analogue à un rapport de cotes dans le cadre d’une analyse de régression logistique multiple. La fonction cox.ph() du paquet survival est utilisée pour ajuster le modèle. La fonction cox.zph() du paquet survival peut être utilisée pour tester l’hypothèse de risques proportionnels pour un ajustement du modèle de régression de Cox.NOTE: Une probabilité doit être comprise entre 0 et 1. Cependant, le hasard représente le nombre attendu d’événements par unité de temps.Si le rapport de risque d’un prédicteur est proche de 1, alors ce prédicteur n’affecte pas la survie,si le HR est inférieur à 1, alors le prédicteur est protecteur (c’est-à-dire associé à une meilleure survie),et si le HR est supérieur à 1, alors le prédicteur est associé à un risque accru (ou à une diminution de la survie).","code":""},{"path":"survival_analysis.html","id":"ajustement-dun-modèle-de-cox","chapter":"27 Analyse de survie","heading":"Ajustement d’un modèle de Cox","text":"Nous pouvons d’abord ajuster un modèle pour évaluer l’effet de l’âge et du sexe sur la survie. En imprimant simplement le modèle, nous avons les informations sur :les coefficients de régression estimés coef qui quantifient l’association entre les prédicteurs et le résultat,leur exponentielle (pour faciliter l’interprétation, exp(coef)) qui produit le rapport de risque,leur erreur standard se(coef),le z-score : combien d’erreurs standard le coefficient estimé est-il éloigné de 0,et la valeur p : la probabilité que le coefficient estimé puisse être 0.La fonction summary() appliquée à l’objet modèle de cox donne plus d’informations, comme l’intervalle de confiance du HR estimé et les différents résultats du test.L’effet de la première covariable gender est présenté dans la première ligne. genderm (masculin) est imprimé, ce qui implique que le premier niveau de strate (“f”), c’est-à-dire le groupe féminin, est le groupe de référence pour le sexe. Ainsi, l’interprétation du paramètre de test est celle des hommes par rapport aux femmes. La valeur p indique qu’il n’y pas suffisamment de preuves d’un effet du sexe sur le risque attendu ou d’une association entre le sexe et la mortalité toutes causes confondues.Le même manque de preuves est noté concernant le groupe d’âge.Il était intéressant d’exécuter le modèle et de regarder les résultats, mais un premier coup d’oeil pour vérifier si les hypothèses de risques proportionnels sont respectées pourrait aider à gagner du temps.NOTE: Un deuxième argument appelé méthode peut être spécifié lors du calcul du modèle de cox, qui détermine comment les liens sont traités. Le défaut est “efron”, et les autres options sont “breslow” et “exact”.Dans un autre modèle, nous ajoutons d’autres facteurs de risque tels que la source de l’infection et le nombre de jours entre la date d’apparition et l’admission. Cette fois, nous vérifions d’abord l’hypothèse des risques proportionnels avant de poursuivre.Dans ce modèle, nous avons inclus un prédicteur continu (days_onset_hosp). Dans ce cas, nous interprétons les estimations des paramètres comme l’augmentation du logarithme attendu du risque relatif pour chaque augmentation d’une unité du prédicteur, les autres prédicteurs restant constants. Nous vérifions d’abord l’hypothèse de risques proportionnels.La vérification graphique de cette hypothèse peut être effectuée avec la fonction ggcoxzph() du paquet survminer.Les résultats du modèle indiquent qu’il existe une association négative entre la durée entre le début de la maladie et l’admission et la mortalité toutes causes confondues. Le risque attendu est 0,9 fois plus faible chez une personne qui est admise un jour plus tard qu’une autre, le sexe restant constant. Ou, de manière plus directe, une augmentation d’une unité de la durée entre le début de la maladie et l’admission est associée à une diminution de 10,7 % (coef *100) du risque de décès.Les résultats montrent également une association positive entre la source d’infection et la mortalité toutes causes confondues. C’est-à-dire qu’il y un risque accru de décès (1,21x) pour les patients qui ont eu une source d’infection autre que les funérailles.Nous pouvons vérifier cette relation avec une table :Nous devrions examiner et étudier pourquoi cette association existe dans les données. Une explication possible serait que les patients qui vivent assez longtemps pour être admis plus tard avaient une maladie moins grave au départ. Une autre explication peut-être plus probable est que, puisque nous avons utilisé un faux ensemble de données simulées, ce schéma ne reflète pas la réalité !","code":"\n#ajustement du modèle de cox\nlinelistsurv_cox_sexage <- survival::coxph(\n              Surv(futime, event) ~ gender + age_cat_small, \n              data = linelist_surv\n              )\n\n\n#imprimer le modèle ajusté\nlinelistsurv_cox_sexage## Call:\n## survival::coxph(formula = Surv(futime, event) ~ gender + age_cat_small, \n##     data = linelist_surv)\n## \n##                       coef exp(coef) se(coef)      z     p\n## genderm           -0.03149   0.96900  0.04767 -0.661 0.509\n## age_cat_small5-19  0.09400   1.09856  0.06454  1.456 0.145\n## age_cat_small20+   0.05032   1.05161  0.06953  0.724 0.469\n## \n## Likelihood ratio test=2.8  on 3 df, p=0.4243\n## n= 4321, number of events= 1853 \n##    (218 observations deleted due to missingness)\n#sommaire du modèle\nsummary(linelistsurv_cox_sexage)## Call:\n## survival::coxph(formula = Surv(futime, event) ~ gender + age_cat_small, \n##     data = linelist_surv)\n## \n##   n= 4321, number of events= 1853 \n##    (218 observations deleted due to missingness)\n## \n##                       coef exp(coef) se(coef)      z Pr(>|z|)\n## genderm           -0.03149   0.96900  0.04767 -0.661    0.509\n## age_cat_small5-19  0.09400   1.09856  0.06454  1.456    0.145\n## age_cat_small20+   0.05032   1.05161  0.06953  0.724    0.469\n## \n##                   exp(coef) exp(-coef) lower .95 upper .95\n## genderm               0.969     1.0320    0.8826     1.064\n## age_cat_small5-19     1.099     0.9103    0.9680     1.247\n## age_cat_small20+      1.052     0.9509    0.9176     1.205\n## \n## Concordance= 0.514  (se = 0.007 )\n## Likelihood ratio test= 2.8  on 3 df,   p=0.4\n## Wald test            = 2.78  on 3 df,   p=0.4\n## Score (logrank) test = 2.78  on 3 df,   p=0.4\ntest_ph_sexage <- survival::cox.zph(linelistsurv_cox_sexage)\ntest_ph_sexage##               chisq df    p\n## gender        0.454  1 0.50\n## age_cat_small 0.838  2 0.66\n## GLOBAL        1.399  3 0.71\n#fit le modèle\nlinelistsurv_cox <- coxph(\n                        Surv(futime, event) ~ gender + age_years+ source + days_onset_hosp,\n                        data = linelist_surv\n                        )\n\n\n#Tester le modèle de risque proportionnel\nlinelistsurv_ph_test <- cox.zph(linelistsurv_cox)\nlinelistsurv_ph_test##                    chisq df       p\n## gender           0.45062  1    0.50\n## age_years        0.00199  1    0.96\n## source           1.79622  1    0.18\n## days_onset_hosp 31.66167  1 1.8e-08\n## GLOBAL          34.08502  4 7.2e-07\nsurvminer::ggcoxzph(linelistsurv_ph_test)\n#imprimez le résumé du modèle\nsummary(linelistsurv_cox)## Call:\n## coxph(formula = Surv(futime, event) ~ gender + age_years + source + \n##     days_onset_hosp, data = linelist_surv)\n## \n##   n= 2772, number of events= 1180 \n##    (1767 observations deleted due to missingness)\n## \n##                      coef exp(coef)  se(coef)      z Pr(>|z|)    \n## genderm          0.004710  1.004721  0.060827  0.077   0.9383    \n## age_years       -0.002249  0.997753  0.002421 -0.929   0.3528    \n## sourceother      0.178393  1.195295  0.084291  2.116   0.0343 *  \n## days_onset_hosp -0.104063  0.901169  0.014245 -7.305 2.77e-13 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n##                 exp(coef) exp(-coef) lower .95 upper .95\n## genderm            1.0047     0.9953    0.8918    1.1319\n## age_years          0.9978     1.0023    0.9930    1.0025\n## sourceother        1.1953     0.8366    1.0133    1.4100\n## days_onset_hosp    0.9012     1.1097    0.8764    0.9267\n## \n## Concordance= 0.566  (se = 0.009 )\n## Likelihood ratio test= 71.31  on 4 df,   p=1e-14\n## Wald test            = 59.22  on 4 df,   p=4e-12\n## Score (logrank) test = 59.54  on 4 df,   p=4e-12\nlinelist_case_data %>% \n  tabyl(days_onset_hosp, outcome) %>% \n  adorn_percentages() %>%  \n  adorn_pct_formatting()##  days_onset_hosp Death Recover   NA_\n##                0 44.3%   31.4% 24.3%\n##                1 46.6%   32.2% 21.2%\n##                2 43.0%   32.8% 24.2%\n##                3 45.0%   32.3% 22.7%\n##                4 41.5%   38.3% 20.2%\n##                5 40.0%   36.2% 23.8%\n##                6 32.2%   48.7% 19.1%\n##                7 31.8%   38.6% 29.5%\n##                8 29.8%   38.6% 31.6%\n##                9 30.3%   51.5% 18.2%\n##               10 16.7%   58.3% 25.0%\n##               11 36.4%   45.5% 18.2%\n##               12 18.8%   62.5% 18.8%\n##               13 10.0%   60.0% 30.0%\n##               14 10.0%   50.0% 40.0%\n##               15 28.6%   42.9% 28.6%\n##               16 20.0%   80.0%  0.0%\n##               17  0.0%  100.0%  0.0%\n##               18  0.0%  100.0%  0.0%\n##               22  0.0%  100.0%  0.0%\n##               NA 52.7%   31.2% 16.0%"},{"path":"survival_analysis.html","id":"forest-plots","chapter":"27 Analyse de survie","heading":"Forest plots","text":"Nous pouvons ensuite visualiser les résultats du modèle de cox en utilisant les parcelles forestières pratiques avec la fonction ggforest() du paquet survminer.","code":"\nggforest(linelistsurv_cox, data = linelist_surv)"},{"path":"survival_analysis.html","id":"covariables-dépendantes-du-temps-dans-les-modèles-de-survie","chapter":"27 Analyse de survie","heading":"27.6 Covariables dépendantes du temps dans les modèles de survie","text":"Certaines des sections suivantes ont été adaptées avec la permission d’une excellente introduction à l’analyse de survie dans R par le Dr Emily Zabor.Dans la dernière section, nous avons abordé l’utilisation de la régression de Cox pour examiner les associations entre les covariables d’intérêt et les résultats de survie, mais ces analyses reposent sur la mesure de la covariable au départ, c’est-à-dire avant le début du suivi de l’événement.Que se passe-t-il si vous vous intéressez à une covariable qui est mesurée après le début du suivi ? Ou, que se passe-t-il si vous avez une covariable qui peut changer dans le temps ?Par exemple, vous travaillez peut-être avec des données cliniques où vous avez répété les mesures des valeurs de laboratoire de l’hôpital qui peuvent changer dans le temps. C’est un exemple de Covariable Dépendante du Temps. Pour résoudre ce problème, vous avez besoin d’une configuration spéciale, mais heureusement, le modèle cox est très flexible et ce type de données peut également être modélisé avec les outils du paquet survival.","code":""},{"path":"survival_analysis.html","id":"configuration-des-covariables-dépendantes-du-temps","chapter":"27 Analyse de survie","heading":"Configuration des covariables dépendantes du temps","text":"L’analyse des covariables dépendantes du temps dans R nécessite la configuration d’un ensemble de données spécial. Si cela vous intéresse, consultez l’article plus détaillé de l’auteur du paquet survival Utilisation de covariables dépendantes du temps et de coefficients dépendants du temps dans le modèle de Cox.Pour cela, nous allons utiliser un nouvel ensemble de données du package SemiCompRisks nommé BMT, qui comprend des données sur 137 patients ayant subi une greffe de moelle osseuse. Les variables sur lesquelles nous allons nous concentrer sont :T1 - temps (en jours) jusqu’au décès ou au dernier suivi.delta1 - indicateur de décès ; 1-Dead, 0-AliveTA - temps (en jours) jusqu’à la maladie aiguë du greffon contre l’hôte.deltaA - indicateur de la maladie aiguë du greffon contre l’hôte ;\n1 - Développement d’une réaction aiguë du greffon contre l’hôte.\n0 - N’jamais développé de maladie aiguë du greffon contre l’hôte.\n1 - Développement d’une réaction aiguë du greffon contre l’hôte.0 - N’jamais développé de maladie aiguë du greffon contre l’hôte.Nous allons charger cet ensemble de données à partir du paquet survival en utilisant la commande base R data(), qui peut être utilisée pour charger des données qui sont déjà incluses dans un paquet R qui est chargé. Le cadre de données BMT apparaîtra dans votre environnement R.","code":"\ndata(BMT, package = \"SemiCompRisks\")"},{"path":"survival_analysis.html","id":"ajouter-lidentifiant-unique-du-patient","chapter":"27 Analyse de survie","heading":"Ajouter l’identifiant unique du patient","text":"Il n’y pas de colonne d’identifiant unique dans les données BMT, ce qui est nécessaire pour créer le type de jeu de données que nous voulons. Nous utilisons donc la fonction rowid_to_column() du paquet tidyverse tibble pour créer une nouvelle colonne d’identification appelée my_id (ajoute une colonne au début du cadre de données avec des identifiants de ligne séquentiels, en commençant par 1). Nous nommons le cadre de données bmt.L’ensemble de données ressemble maintenant à ceci :","code":"\nbmt <- rowid_to_column(BMT, \"my_id\")"},{"path":"survival_analysis.html","id":"développer-les-lignes-de-patients","chapter":"27 Analyse de survie","heading":"Développer les lignes de patients","text":"Ensuite, nous allons utiliser la fonction tmerge() avec les fonctions d’aide event() et tdc() pour créer le jeu de données restructuré. Notre est de restructurer l’ensemble de données pour créer une ligne séparée pour chaque patient pour chaque intervalle de temps où ils ont une valeur différente pour deltaA. Dans ce cas, chaque patient peut avoir au maximum deux lignes selon qu’il développé ou non une maladie aiguë du greffon contre l’hôte pendant la période de collecte des données. Nous appellerons notre nouvel indicateur de développement de la maladie aiguë du greffon contre l’hôte agvhd.tmerge() crée un long jeu de données avec plusieurs intervalles de temps pour les différentes valeurs de covariables pour chaque patient.event() crée le nouvel indicateur d’événement pour aller avec les intervalles de temps nouvellement créés.tdc() crée la colonne de covariable dépendante du temps, agvhd, pour aller avec les intervalles de temps nouvellement créés.Pour voir ce que cela donne, examinons les données des 5 premiers patients individuels.Les variables d’intérêt dans les données originales ressemblaient à ceci :Le nouvel ensemble de données pour ces mêmes patients ressemble à ceci :Maintenant, certains de nos patients ont deux lignes dans l’ensemble de données correspondant aux intervalles où ils ont une valeur différente de notre nouvelle variable, agvhd. Par exemple, le patient 1 maintenant deux lignes avec une valeur agvhd de zéro du temps 0 au temps 67, et une valeur de 1 du temps 67 au temps 2081.","code":"\ntd_dat <- \n  tmerge(\n    data1 = bmt %>% select(my_id, T1, delta1), \n    data2 = bmt %>% select(my_id, T1, delta1, TA, deltaA), \n    id = my_id, \n    death = event(T1, delta1),\n    agvhd = tdc(TA)\n    )\nbmt %>% \n  select(my_id, T1, delta1, TA, deltaA) %>% \n  filter(my_id %in% seq(1, 5))##   my_id   T1 delta1   TA deltaA\n## 1     1 2081      0   67      1\n## 2     2 1602      0 1602      0\n## 3     3 1496      0 1496      0\n## 4     4 1462      0   70      1\n## 5     5 1433      0 1433      0\ntd_dat %>% \n  filter(my_id %in% seq(1, 5))##   my_id   T1 delta1 tstart tstop death agvhd\n## 1     1 2081      0      0    67     0     0\n## 2     1 2081      0     67  2081     0     1\n## 3     2 1602      0      0  1602     0     0\n## 4     3 1496      0      0  1496     0     0\n## 5     4 1462      0      0    70     0     0\n## 6     4 1462      0     70  1462     0     1\n## 7     5 1433      0      0  1433     0     0"},{"path":"survival_analysis.html","id":"régression-de-cox-avec-covariables-dépendantes-du-temps","chapter":"27 Analyse de survie","heading":"Régression de Cox avec covariables dépendantes du temps","text":"Maintenant que nous avons remodelé nos données et ajouté la nouvelle variable aghvd dépendante du temps, ajustons un simple modèle de régression de Cox à variable unique. Nous pouvons utiliser la même fonction coxph() que précédemment, nous devons juste changer notre fonction Surv() pour spécifier à la fois le temps de début et de fin pour chaque intervalle en utilisant les arguments time1 = et time2 =.Encore une fois, nous allons visualiser les résultats de notre modèle cox en utilisant la fonction ggforest() du paquet survminer :Comme vous pouvez le constater à partir du diagramme forestier, de l’intervalle de confiance et de la valeur p, il ne semble pas y avoir de forte association entre le décès et la maladie aiguë du greffon contre l’hôte dans le contexte de notre modèle simple.","code":"\nbmt_td_model = coxph(\n  Surv(time = tstart, time2 = tstop, event = death) ~ agvhd, \n  data = td_dat\n  )\n\nsummary(bmt_td_model)## Call:\n## coxph(formula = Surv(time = tstart, time2 = tstop, event = death) ~ \n##     agvhd, data = td_dat)\n## \n##   n= 163, number of events= 80 \n## \n##         coef exp(coef) se(coef)    z Pr(>|z|)\n## agvhd 0.3351    1.3980   0.2815 1.19    0.234\n## \n##       exp(coef) exp(-coef) lower .95 upper .95\n## agvhd     1.398     0.7153    0.8052     2.427\n## \n## Concordance= 0.535  (se = 0.024 )\n## Likelihood ratio test= 1.33  on 1 df,   p=0.2\n## Wald test            = 1.42  on 1 df,   p=0.2\n## Score (logrank) test = 1.43  on 1 df,   p=0.2\nggforest(bmt_td_model, data = td_dat)"},{"path":"survival_analysis.html","id":"ressources-13","chapter":"27 Analyse de survie","heading":"27.7 Ressources","text":"Analyse de survie partie : concepts de base et premières analysesAnalyse de survie en RAnalyse de survie dans la recherche sur les maladies infectieuses : décrire les événements dans le tempsChapitre sur les modèles de survie avancés PrincetonUtilisation de covariables et de coefficients dépendant du temps dans le modèle de CoxAide-mémoire pour l’analyse de survie RFeuille de calcul SurvminerArticle sur les différentes mesures de survie pour les données des registres du cancer avec le code R fourni comme matériel supplémentaire","code":""},{"path":"gis.html","id":"gis","chapter":"28 GIS basics","heading":"28 GIS basics","text":"","code":""},{"path":"gis.html","id":"présentation","chapter":"28 GIS basics","heading":"28.1 Présentation","text":"Les caracteristiques geospatiales de vos données peuvent fournir des informations capitales en situation de pandemie.En effet, ils permettent de repondent à des questions tels que:Ou se trouve les zones à risques de la maladieOu se trouve les zones à risques de la maladieComment les zones à risques evoluent dans le tempsComment les zones à risques evoluent dans le tempsL’accessibilité du plateau medical et la nécessité d’apporter des améliorationsL’accessibilité du plateau medical et la nécessité d’apporter des améliorationsL’accent mis sur le SIG à travers ces pages rend accessible toutes les compétences pertinentes pouvant être utilisées en cas de reponse pandemique.va voir les methodes simples pour visualiser les donnees spatiales grace aux packages tmap et ggplot.Nous allons aussi passer en revue le package sf qui permet une manipulation des donnees de types vecteurs. Enfin va aborder brievement les statistiques spatiales à travers les notions de dependance spatiale, l’autocorrelation spatiale et la regression spatiale en utilisant le package spdep","code":""},{"path":"gis.html","id":"mots-clés","chapter":"28 GIS basics","heading":"28.2 Mots clés","text":"Quelques mots clés sont definis en bas.Pour une bonne initiation au SIG nous suggérons de suivre l’un des tutoriels proposés dans les références.Systeme d’Information Geographique(SIG) - Un SIG est un outil informatique ou un environnement qui permet de regrouper, de manipuler, d’analyser et de visualiser les données spatiales","code":""},{"path":"gis.html","id":"logiciels-sig","chapter":"28 GIS basics","heading":"Logiciels SIG","text":"Les logiciels populaires de SIG qui existent, fonctionnent sur la base d’une interface graphique qui interagit apres un clic de l’utlisateur.Ces outils peuvent etre utlisés sans aucun prerequis en programmation et ont comme avantage de pouvoir selectionner et placer des icones et des elements sur une carte manuellement.Les logiciels de SIG les plus connus sont :ARCGIS - un logiciel commercial developpé par la compagnie ESRI.ce jour il reste le logiciel de SIG le plus populaire.QGIS - un logiciel de SIG libre d’utilisation qui fait pratiquement la meme choses que ARCGIS. peut Telecharger QGIS par iciFaire du SIG en utilisant R peut sembler frustant pour les premiers pas parce qu’à la place de pointer et cliquer , il faut maintenant ecrire des lignes de commande dans une interface (besoin de coder pour obtenir un resultat ).Mais ce changement de paradigme présente des avantages tels que l’automatisation et la reproductibilité dans la conception des carte et les analyses realisées.","code":""},{"path":"gis.html","id":"données-spatiales","chapter":"28 GIS basics","heading":"Données spatiales","text":"Les types de données utilisées en SIG sont de deux natures: les rasters et les vecteursDonnées vecteurs - Les données vecteurs dont l’utilisation est la plus courante dans l’environnement SIG sont dotés de proprietes géometriques par les sommets et les lignes reliant les sommets. Les données vecteurs largement utilisées peuvent être divisées en trois :Points - le point est constitué d’un pair de coordonnnées (x,y) qui marque un lieu précis dans l’espace à travers le systeme de coordonnées. Il est la forme simple de représentation des donnees spatiales et peuvent etre utilisé pour situer le lieu d’apparition d’une maladie lors d’une pandémie (la maison du patient) ou un endroit (exemple : hôpital) sur une carte .Points - le point est constitué d’un pair de coordonnnées (x,y) qui marque un lieu précis dans l’espace à travers le systeme de coordonnées. Il est la forme simple de représentation des donnees spatiales et peuvent etre utilisé pour situer le lieu d’apparition d’une maladie lors d’une pandémie (la maison du patient) ou un endroit (exemple : hôpital) sur une carte .Lignes - Une ligne est composée de deux points reliés.Elle une longueur et peut etre utilisée pour representer les routes ou les cours d’eauxLignes - Une ligne est composée de deux points reliés.Elle une longueur et peut etre utilisée pour representer les routes ou les cours d’eauxPolygones - Un polygones est une association minimum de 3 points reliés les uns aux autres .Les caractéristiques d’un polygone sont : le périmètre et l’aire.En pratique ils sont utilisés pour delmiter les contours d’une zone (village) ou une infractructures(hopital)Polygones - Un polygones est une association minimum de 3 points reliés les uns aux autres .Les caractéristiques d’un polygone sont : le périmètre et l’aire.En pratique ils sont utilisés pour delmiter les contours d’une zone (village) ou une infractructures(hopital)Données Rasters - coté des données vecteurs des rasters qui sont des matrix constitués par des cellules contenant chacunes des informations par exemple l’altitude, la temperature, la pente, la couverture forestière etc. les rasters peuvent servir de fond de carte pour les donnees vecteurs","code":""},{"path":"gis.html","id":"visualisation-des-données-spatiales","chapter":"28 GIS basics","heading":"Visualisation des données spatiales","text":"Pour afficher sur une carte des donnnées spatiales à partir d’un logiciel de SIG il est nécessaire de la part de l’utilisateur de connaitre l’emplacement des donnees .Lors qu’il nous arrive de manipuler des données vecteurs ce qui est d’ailleurs le plus frequents, les données sont stocker dans des fichiers shapefilesShapefiles - Un shapefile est un format de données vecteurs tres repandus dans le monde du SIG et il permet de stocker des donnees pouvant etre des points des lignes et des polygones.C’est en realite une collection ou un ensemnble de fichiers se terminant avec les extensions .shp,.shx et .dbf.Tout ces fichiers doivent etre presents dans un et unique dossiers pour obtenir une donnée shapefile fiable.\nL’ensemble de ces fichiers shapefile peuvent être comprimer en format zip pour un envoi à travers un mail ou un telechargement à partir d’un site webLe shapefile contient des information sur un objet de la surface terreste modelisé et sa localisation géographique .Cela est important parce que bien que la terre est une geoide le système de coordonnées bidimentionnel au niveau des shapefiles permet de situer un objet sur la surface de la terreSystéme de réference de coordonnées  - Un CRS est un système de coordonnées utilisé pour localiser géographiquement un objet sur la surface de la terre .Il quelques composantes clés:Systeme de Coordonnées - Plusieurs systèmes de coordonnées existent mais il est important de savoir les coodonnées géographiques utilisées sont adossées à quel système.Les degres pour le longitude/latitude sont fréquents mais note aussi l’usage des coordonnées UTMSysteme de Coordonnées - Plusieurs systèmes de coordonnées existent mais il est important de savoir les coodonnées géographiques utilisées sont adossées à quel système.Les degres pour le longitude/latitude sont fréquents mais note aussi l’usage des coordonnées UTMUnités - Connaitre l’unité du système de coordonnées(degres ou decimal) est primordiale pour faire certaines analyses spatialesUnités - Connaitre l’unité du système de coordonnées(degres ou decimal) est primordiale pour faire certaines analyses spatialesDatum - C’est une modélisation de la terre revue au fil des annees, il est important de vérifier que les cartes utilisées ont le meme datum ou systeme geodesiqueDatum - C’est une modélisation de la terre revue au fil des annees, il est important de vérifier que les cartes utilisées ont le meme datum ou systeme geodesiqueProjection - C’est l’utilisation d’équation mathematique pour projeter la forme geoide de la terre sur une surface planeProjection - C’est l’utilisation d’équation mathematique pour projeter la forme geoide de la terre sur une surface planeRappellons que les données spatiales peuvent être manipulées sans avoir recours aux outils cartographiques ci-dessous","code":""},{"path":"gis.html","id":"débuter-avec-le-sig","chapter":"28 GIS basics","heading":"28.3 Débuter avec le SIG","text":"Il y quelques éléments clés que vous devrez avoir et auxquels vous devrez penser pour faire une carte. Ces éléments sont les suivants :Un jeu de données - il peut s’agir d’un format de données spatiales (comme les shapefiles, comme indiqué ci-dessus) ou d’un format non spatial (par exemple, un simple csv).Un jeu de données - il peut s’agir d’un format de données spatiales (comme les shapefiles, comme indiqué ci-dessus) ou d’un format non spatial (par exemple, un simple csv).Si votre ensemble de données n’est pas dans un format spatial, vous aurez également besoin d’un jeu données de référence. Les données de référence sont constituées de la représentation spatiale des données et des attributs associés, qui peuvent inclure des éléments contenant les informations relatives à l’emplacement et à l’adresse d’entités spécifiques.\nSi vous travaillez avec des limites géographiques prédéfinies (par exemple, des régions administratives), les fichiers de forme de référence peuvent souvent être téléchargés gratuitement depuis une agence gouvernementale ou une organisation de partage de données. En cas de doute, un bon point de départ est de rechercher sur Google ” [régions] shapefile “.\nSi vous avez des informations d’adresse, mais pas de latitude et de longitude, vous devrez peut-être utiliser un moteur de géocodage pour obtenir les données de référence spatiale pour vos enregistrements.\nSi votre ensemble de données n’est pas dans un format spatial, vous aurez également besoin d’un jeu données de référence. Les données de référence sont constituées de la représentation spatiale des données et des attributs associés, qui peuvent inclure des éléments contenant les informations relatives à l’emplacement et à l’adresse d’entités spécifiques.Si vous travaillez avec des limites géographiques prédéfinies (par exemple, des régions administratives), les fichiers de forme de référence peuvent souvent être téléchargés gratuitement depuis une agence gouvernementale ou une organisation de partage de données. En cas de doute, un bon point de départ est de rechercher sur Google ” [régions] shapefile “.Si vous travaillez avec des limites géographiques prédéfinies (par exemple, des régions administratives), les fichiers de forme de référence peuvent souvent être téléchargés gratuitement depuis une agence gouvernementale ou une organisation de partage de données. En cas de doute, un bon point de départ est de rechercher sur Google ” [régions] shapefile “.Si vous avez des informations d’adresse, mais pas de latitude et de longitude, vous devrez peut-être utiliser un moteur de géocodage pour obtenir les données de référence spatiale pour vos enregistrements.Si vous avez des informations d’adresse, mais pas de latitude et de longitude, vous devrez peut-être utiliser un moteur de géocodage pour obtenir les données de référence spatiale pour vos enregistrements.Une idée de la manière dont vous voulez présenter les informations de vos ensembles de données à votre public cible. Il existe de nombreux types de cartes, et il est important de réfléchir au type de carte qui correspond le mieux à vos besoins.Une idée de la manière dont vous voulez présenter les informations de vos ensembles de données à votre public cible. Il existe de nombreux types de cartes, et il est important de réfléchir au type de carte qui correspond le mieux à vos besoins.","code":""},{"path":"gis.html","id":"types-of-maps-for-visualizing-your-data","chapter":"28 GIS basics","heading":"Types of maps for visualizing your data","text":"","code":""},{"path":"gis.html","id":"les-types-de-cartes-pour-visualiser-vos-données","chapter":"28 GIS basics","heading":"Les types de cartes pour visualiser vos données","text":"Carte chloroplethe - ce sont des cartes thematiques ou les couleurs l’ombrage et les motifs sont utilisés pour representer les valeurs des variables présentes dans les attributs en fonction des unités geograpphiques.Par exemple, une valeur plus grande peut être indiquée par une couleur plus foncée qu’une valeur plus petite. Ce type de carte est particulièrement utile pour visualiser une variable et son évolution dans des régions ou des zones géopolitiques définies.carte de fréquentation de la densite des cas - C’est Un type de carte thematique ou l’intensité des couleurs est proportionnelle à la valeur de l’observation cela ne fait pas intervenir des zones ou des limites geographiques et adminitratives. Ce genre de carte est utilisé pour montrerles zones à risques ou les lieux à forte concentration de variables observéesCarte de densité de points - Une carte thematique qui utilise des points pour représenter la valeur du variable dans les données.Ce type de carte permet de visualiser les données avec un nuage de point afin d’identifier la presence de clusters ou foyersCarte à symboles proportionnels (carte à symboles gradués) - une carte thématique similaire à une carte choroplèthe, mais au lieu d’utiliser une couleur pour indiquer la valeur d’un attribut, elle utilise un symbole (généralement un cercle) en relation avec la valeur. Par exemple, une valeur plus grande peut être indiquée par un symbole plus grand qu’une valeur plus petite. Ce type de carte est idéal lorsque vous souhaitez visualiser la taille ou la quantité de vos données dans des régions géographiques.Vous pouvez également combiner plusieurs types de visualisations différentes pour montrer des schémas géographiques complexes. Par exemple, les cas (points) de la carte ci-dessous sont colorés en fonction de l’établissement de santé le plus proche (voir la légende). Les grands cercles rouges montrent les zones de couverture des établissements de santé d’un certain rayon, et les points rouges brillants les cas qui étaient en dehors de toute zone de desserte :\nRemarque : L’objectif principal de cette page SIG est basé sur le contexte de la réponse aux épidémies sur le terrain. Par conséquent, le contenu de la page couvrira les manipulations, visualisations et analyses de données spatiales de base.","code":""},{"path":"gis.html","id":"preparation-3","chapter":"28 GIS basics","heading":"28.4 Preparation","text":"","code":""},{"path":"gis.html","id":"chargement-packages","chapter":"28 GIS basics","heading":"Chargement packages","text":"Ce morceau de code montre le chargement des paquets nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire et le charge pour l’utiliser. Vous pouvez également charger les paquets installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les paquets R.Vous pouvez consulter une vue d’ensemble de tous les paquets R qui traitent des données spatiales sur le site CRAN “Spatial Task View”.","code":"\npacman::p_load(\n  rio,           # Pour importer les données\n  here,          # Pour situer l'emplacement des donnes\n  tidyverse,     # nettoyer manipuler et visualiser les données( inclure le package ggplot2)\n  sf,            # manipuler les donnees spatiales avec le package sf\n  tmap,          # pour produire des cartes simples, fonctionne pour les cartes interactives et statiques\n  janitor,       # pour nettoyer les noms de colonnes\n  OpenStreetMap, # pour ajouter la  carte de base OSM sur la carte ggplot\n  spdep          # statistiques spatiales\n  ) "},{"path":"gis.html","id":"exemple-de-données-de-cas","chapter":"28 GIS basics","heading":"Exemple de données de cas","text":"À des fins de démonstration, nous travaillerons avec un échantillon aléatoire de 1000 cas provenant du dataframe linelist de l’épidémie d’Ebola simulée (d’un point de vue computationnel, travailler avec moins de cas est plus facile à afficher dans ce manuel). Si vous souhaitez suivre le processus, cliquez pour télécharger la linelist “propre” (en tant que fichier .rds).Comme nous prenons un échantillon aléatoire de cas, vos résultats peuvent être légèrement différents de ce qui est démontré ici lorsque vous exécutez les codes par vous-même.Importez les données avec la fonction import() du paquet rio (elle gère de nombreux types de fichiers comme .xlsx, .csv, .rds - voir la page Importation et exportation pour plus de détails).Ensuite, nous sélectionnons un échantillon aléatoire de 1000 lignes en utilisant sample() de base R.Maintenant nous voulons convertir cette linelist qui est de classe dataframe, en un objet de classe “sf” (caractéristiques spatiales). Étant donné que la linelist deux colonnes “lon” et “lat” représentant la longitude et la latitude de la résidence de chaque cas, cela sera facile.Nous utilisons le package sf (caractéristiques spatiales) et sa fonction st_as_sf() pour créer le nouvel objet que nous appelons linelist_sf. Ce nouvel objet ressemble essentiellement à la linelist, mais les colonnes lon et lat ont été désignées comme des colonnes de coordonnées, et un système de référence de coordonnées (CRS) été attribué pour l’affichage des points. 4326 identifie nos coordonnées comme étant basées sur le Système géodésique mondial 1984 (WGS84) - qui est la norme pour les coordonnées GPS.Voici à quoi ressemble le dataframe original linelist. Dans cette démonstration, nous n’utiliserons que la colonne date_onset et geometry (qui été construite à partir des champs de longitude et de latitude ci-dessus et qui est la dernière colonne du dataframe).","code":"\n# importer le jeu de données linelist nettoyé\nlinelist <- import(\"linelist_cleaned.rds\")  \n# générer 1000 numéros de ligne aléatoires, à partir du nombre de lignes de la linelist\nsample_rows <- sample(nrow(linelist), 1000)\n\n#  creons un sous-ensembles de linelist   pour ne garder que les lignes de l'échantillon, et toutes les colonnes\nlinelist <- linelist[sample_rows,]\n# Creons un objet  sf \nlinelist_sf <- linelist %>%\n     sf::st_as_sf(coords = c(\"lon\", \"lat\"), crs = 4326)\nDT::datatable(head(linelist_sf, 10), rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )"},{"path":"gis.html","id":"shapefiles-des-limites-administratives","chapter":"28 GIS basics","heading":"shapefiles des limites administratives","text":"Sierra Leone: shapefiles des limites administrativesPar avance, nous avons téléchargé toutes les limites administratives de la Sierra Leone à partir du Humanitarian Data Exchange (HDX) site Web ici. Alternativement, vous pouvez télécharger ces données et toutes les autres données d’exemple pour ce manuel via notre package R, comme expliqué dans la page Télécharger le manuel et les données.Nous allons maintenant procéder comme suit pour enregistrer le shapefile Admin Level 3 dans R :Importer les shapefilesNettoyer les noms des colonnesFiltrer les lignes pour ne garder que les zones d’intérêt.Pour importer un fichier shapefile, nous utilisons la fonction read_sf() de sf. Le chemin du fichier est fourni via (). - Dans notre cas, le fichier se trouve dans notre projet R dans les sous-dossiers “data”, “gis” et “shp”, avec le nom de fichier “sle_adm3.shp” (voir les pages sur Importation et exportation et Projets R pour plus d’informations). Vous devrez fournir votre propre chemin de fichier.Ensuite, nous utilisons clean_names() du package janitor pour normaliser les noms de colonnes du fichier shapefile. Nous utilisons également filter() pour ne conserver que les lignes dont le nom d’administrateur est “Western Area Urban” ou “Western Area Rural”.Vous pouvez voir ci-dessous à quoi ressemble le fichier shapefile après importation et nettoyage. Faites défiler vers la droite pour voir s’il y des colonnes avec le niveau d’administration 0 (pays), le niveau d’administration 1, le niveau d’administration 2, et enfin le niveau d’administration 3. Chaque niveau un nom de caractère et un identifiant unique “pcode”. Le pcode se développe avec chaque niveau d’administration croissant, par exemple SL (Sierra Leone) -> SL04 (Western) -> SL0410 (Western Area Rural) -> SL040101 (Koya Rural).","code":"\n# ADM3 level clean\nsle_adm3 <- sle_adm3_raw %>%\n  janitor::clean_names() %>% # normaliser les noms de colonnes\n  filter(admin2name %in% c(\"Western Area Urban\", \"Western Area Rural\")) # filtre pour garder certaines zones"},{"path":"gis.html","id":"population-data","chapter":"28 GIS basics","heading":"Population data","text":"Sierra Leone : Population par ADM3Ces données peuvent être téléchargées sur HDX (lien ici) ou via notre package R epirhandbook comme expliqué dans la page Télécharger le manuel et les données. Nous utilisons import() pour charger le fichier .csv. Nous passons également le fichier importé à clean_names() pour standardiser la syntaxe des noms de colonnes.Voici à quoi ressemble le fichier de la population. Faites défiler vers la droite pour voir comment chaque juridiction des colonnes avec la population “masculine”, la population “féminine”, la population “totale”, et la répartition de la population en colonnes par groupe d’âge.","code":"\n# Population par ADM3\nsle_adm3_pop <- import(here(\"data\", \"gis\", \"population\", \"sle_admpop_adm3_2020.csv\")) %>%\n  janitor::clean_names()"},{"path":"gis.html","id":"infractructures-sanitaires","chapter":"28 GIS basics","heading":"Infractructures sanitaires","text":"Sierra Leone : Données sur les établissements de santé provenant d’OpenStreetMap.Encore une fois, nous avons téléchargé les emplacements des établissements de santé à partir de HDX ici ou via les instructions dans la page Télécharger le manuel et les données(#download_book_data.Nous importons le shapefile des points des établissements avec read_sf(), nettoyons à nouveau les noms des colonnes, et filtrons ensuite pour ne garder que les points étiquetés comme “hôpital”, “clinique”, ou “médecins”.Voici le dataframe obtenu defile jusqu’en bas pour voir le nom de l’infrastructures sanitaires et les coordonnées geographiques à travers la colonne geometry.","code":"\n#  Les donnees shapefiles de OSM sur  les infractuctures sanitaires \nsle_hf <- sf::read_sf(here(\"data\", \"gis\", \"shp\", \"sle_hf.shp\")) %>% \n  janitor::clean_names() %>%\n  filter(amenity %in% c(\"hospital\", \"clinic\", \"doctors\"))"},{"path":"gis.html","id":"visualiser-les-coordonnées","chapter":"28 GIS basics","heading":"28.5 Visualiser les coordonnées","text":"La manière la plus simple de visualiser des coordonnées X-Y (longitude/latitude, points), dans ce cas de figure, est de les dessiner sous forme de points directement à partir de l’objet linelist_sf que nous avons créé dans la section de préparation.Le package tmap offre des capacités de cartographie simples à la fois pour le mode statique (mode “plot”) et interactif (mode “view”) avec seulement quelques lignes de code. La syntaxe de tmap est similaire à celle de ggplot2, de sorte que les commandes sont ajoutées les unes aux autres avec +. Vous trouverez plus de détails dans cette vignette.Définir le mode tmap. Dans ce cas, nous utiliserons le mode “plot”, qui produit des sorties statiques.Ci-dessous, seulement les points sont affichés. tm_shape() prend comme argument : l’objet linelist_sf. Ensuite , Nous ajoutons des points via tm_dots(), en spécifiant la taille et la couleur. Comme linelist_sf est un objet sf, nous avons déjà désigné les deux colonnes qui contiennent les coordonnées lat/long et le système de référence des coordonnées (CRS) :les points seulement ne sont pas assez informatifs. Nous devons donc également cartographier les limites administratives :Apres cela, nous utilisons tm_shape() (voir documentation) mais au lieu de fournir le shapefile des points ou les cas sont localisés, nous fournissons le shapefile des limites administratives (polygones).Avec l’argument bbox = (bbox signifie “bounding box”) nous pouvons spécifier l’emprise des coordonnées. Nous allons d’abord visualiser la carte sans l’emprise bbox, et ensuite avec l’emprise de l’objet.Et maintenant les points et les polygones ensemble :Pour lire une bonne comparaison des options de mappage dans R, consultez cet article de blog.","code":"\ntmap_mode(\"plot\") # choisir soit  \"view\" ou \"plot\"\n# Juste les cas (points)\ntm_shape(linelist_sf) + tm_dots(size=0.08, col='blue')\n# Uniquement les frontieres administratives (polygones)\ntm_shape(sle_adm3) +               # Shapefiles des limites administratives\n  tm_polygons(col = \"#F7F7F7\")+    # afficher les polygones en gris clairs\n  tm_borders(col = \"#000000\",      # parametrer la couleur des bordures   et l'epaisseur des lignes\n             lwd = 2) +\n  tm_text(\"admin3name\")            # le texte de la colonne à afficher pour chaque polygone\n\n\n#Comme ci-dessus, mais avec un zoom à partir de l'emprise\ntm_shape(sle_adm3,\n         bbox = c(-13.3, 8.43,    # sommet\n                  -13.2, 8.5)) +  # sommet\n  tm_polygons(col = \"#F7F7F7\") +\n  tm_borders(col = \"#000000\", lwd = 2) +\n  tm_text(\"admin3name\")\n# tous ensemble\ntm_shape(sle_adm3, bbox = c(-13.3, 8.43, -13.2, 8.5)) +     #\n  tm_polygons(col = \"#F7F7F7\") +\n  tm_borders(col = \"#000000\", lwd = 2) +\n  tm_text(\"admin3name\")+\ntm_shape(linelist_sf) +\n  tm_dots(size=0.08, col='blue', alpha = 0.5) +\n  tm_layout(title = \"Distribution of Ebola cases\")   # donner un titre à la carte"},{"path":"gis.html","id":"jointures-spatiales","chapter":"28 GIS basics","heading":"28.6 Jointures spatiales","text":"Vous êtes peut-être familier avec la jonction de données d’un jeu de données à un autre. Plusieurs méthodes sont présentées à la page Joindre des données de ce manuel. Une jointure spatiale un objectif similaire mais exploite les relations spatiales. Au lieu de compter sur des valeurs communes dans les colonnes pour faire correspondre correctement les observations, vous pouvez utiliser leurs relations spatiales, comme le fait qu’une observation soit dans une autre, ou le plus proche voisin d’une autre, ou dans un buffer d’un certain rayon d’une autre, etc.Le package sf offre diverses méthodes de jointures spatiales. Vous trouverez plus de documentation sur la méthode st_join et les types de jointures spatiales dans cette référence.","code":""},{"path":"gis.html","id":"points-dans-le-polygone","chapter":"28 GIS basics","heading":"Points dans le polygone","text":"Attribuer spatialement des unités administratives aux casVoici une question intéressante : la liste de cas ne contient aucune information sur les unités administratives des cas. Bien qu’il soit idéal de collecter ces informations au cours de la phase initiale de collecte des données, nous pouvons également attribuer des unités administratives aux cas individuels sur la base de leurs relations spatiales (c’est-à-dire l’intersection d’un point avec un polygone).Ci-dessous, nous allons croiser spatialement les emplacements de nos cas (points) avec les limites d’ADM3 (polygones) :Commencer par l’objet linelist (points)Jointure spatiale aux limites, en définissant le type de jointure comme etant “st_intersects”.Utilisez select() pour ne garder que certaines des colonnes de la nouvelle limite administrative.Toutes les colonnes de sle_adms ont été ajoutées à la linelist ! Chaque cas maintenant des colonnes détaillant les niveaux administratifs dont il fait partie. Dans cet exemple, nous voulons seulement garder deux des nouvelles colonnes (niveau administratif 3), donc nous sélectionnons() les anciens noms de colonnes et seulement les deux supplémentaires d’intérêt :Ci-dessous, à des fins d’affichage, vous pouvez voir les dix premiers cas et les limites administratives de niveau 3(ADM3) qui y ont été rattachées, en fonction de l’endroit où le point croisé les formes polygonales.Nous pouvons maintenant décrire nos cas par unité administrative - ce que nous ne pouvions pas faire avant la jointure spatiale !Nous pouvons également créer un diagramme en barres du nombre de cas par unité administrative.Dans cet exemple, nous commençons le ggplot() avec la linelist_adm, afin de pouvoir appliquer des fonctions de facteurs comme fct_infreq() qui ordonne les barres par fréquence (voir la page sur les Facteurs pour des conseils).","code":"\nlinelist_adm <- linelist_sf %>%\n  \n  # joindre le fichier des limites administratives à  linelist sur la base de l'intersection spatiale.\n  sf::st_join(sle_adm3, join = st_intersects)\nlinelist_adm <- linelist_sf %>%\n  \n  # joindre le fichier des limites administratives au fichier linelist, sur la base de l'intersection spatiale.\n  sf::st_join(sle_adm3, join = st_intersects) %>% \n  \n  # Conservez les anciens noms de colonnes et deux nouveaux noms admin d'intérêt\n  select(names(linelist_sf), admin3name, admin3pcod)\n# Vous verrez maintenant les noms ADM3 attachés à chaque cas.\nlinelist_adm %>% select(case_id, admin3name, admin3pcod)## Simple feature collection with 1000 features and 3 fields\n## Geometry type: POINT\n## Dimension:     XY\n## Bounding box:  xmin: -13.27125 ymin: 8.448376 xmax: -13.20613 ymax: 8.490898\n## Geodetic CRS:  WGS 84\n## First 10 features:\n##      case_id     admin3name admin3pcod                   geometry\n## 2298  33f478        West II   SL040207 POINT (-13.22454 8.461931)\n## 595   973c48      Central I   SL040201   POINT (-13.232 8.473367)\n## 5140  db38e1        East II   SL040204 POINT (-13.20976 8.476097)\n## 4938  d73b9d      Central I   SL040201 POINT (-13.22483 8.473492)\n## 4807  332efa         East I   SL040203 POINT (-13.21599 8.487442)\n## 5055  f1a689 Mountain Rural   SL040102  POINT (-13.21071 8.45948)\n## 356   195a2f       East III   SL040205 POINT (-13.20946 8.477543)\n## 5870  dab0c9 Mountain Rural   SL040102 POINT (-13.21533 8.454846)\n## 5883  29af75       West III   SL040208 POINT (-13.26932 8.479565)\n## 2282  05067a Mountain Rural   SL040102 POINT (-13.21619 8.451049)\n# Créer un nouveau dataframe contenant le nombre de cas par unité administrative.\ncase_adm3 <- linelist_adm %>%          # commencer avec linelist avec de nouveaux admin colonnes\n  as_tibble() %>%                      # convert en format  tibble pour un meilleur affichage\n  group_by(admin3pcod, admin3name) %>% # regrouper par   unite admin, à la fois  par le nom   et le  pcode \n  summarise(cases = n()) %>%           # utilisons la fonction summarize et  comptons les lignes\n  arrange(desc(cases))                     # arrangement par ordre decroissant\n\ncase_adm3## # A tibble: 10 × 3\n## # Groups:   admin3pcod [10]\n##    admin3pcod admin3name     cases\n##    <chr>      <chr>          <int>\n##  1 SL040102   Mountain Rural   298\n##  2 SL040208   West III         242\n##  3 SL040207   West II          151\n##  4 SL040204   East II          105\n##  5 SL040203   East I            59\n##  6 SL040201   Central I         58\n##  7 SL040206   West I            37\n##  8 SL040205   East III          26\n##  9 SL040202   Central II        14\n## 10 <NA>       <NA>              10\nggplot(\n    data = linelist_adm,                       # Debuter  avec linelist qui contient les infos sur les unites admin \n    mapping = aes(\n      x = fct_rev(fct_infreq(admin3name))))+ # L'axe des x est constitué d'unités administratives, classées par fréquence (inversée).\n  geom_bar()+                                # créer des barres, la hauteur est le nombre de lignes\n  coord_flip()+                              # retournement des axes X et Y pour une lecture plus aisée des unités d'admin\n  theme_classic()+                           # simplifier le fond\n  labs(                                      # titres et les  labels\n    x = \"Admin Niveau 3\",\n    y = \"Number of cases\",\n    title = \"Nombre de cas par unité adminstrative\",\n    caption = \"Tel que déterminé par une jointure spatiale, à partir de 1000 cas échantillonnés de façon aléatoire dans linelist.\"\n  )"},{"path":"gis.html","id":"le-voisin-le-plus-proche","chapter":"28 GIS basics","heading":"Le voisin le plus proche","text":"Trouver l’établissement de santé le plus proche / la zone de captageIl peut être utile de savoir où sont situés les établissements de santé par rapport aux foyers de maladies.Nous pouvons utiliser la méthode de jointure st_nearest_feature de la fonction st_join() (package sf) pour visualiser l’établissement de santé le plus proche des cas individuels.Nous commençons avec le fichier de forme linelist linelist_sf.Nous joignons spatialement avec sle_hf, qui est les emplacements des établissements de santé et des cliniques (points)Nous pouvons voir ci-dessous (les 50 premières lignes) que chaque cas maintenant des données sur la clinique/hôpital le plus proche.Nous pouvons voir que “Den Clinic” est l’établissement de santé le plus proche pour environ 30 % des cas.Pour visualiser les résultats, nous pouvons utiliser tmap - cette fois-ci en mode interactif pour une visualisation plus facile.","code":"\n# Établissement de santé le plus proche de chaque cas\nlinelist_sf_hf <- linelist_sf %>%                  # commencons avec linelist shapefile  \n  st_join(sle_hf, join = st_nearest_feature) %>%   # données de la clinique la plus proche jointes aux données du cas \n  select(case_id, osm_id, name, amenity) %>%       # conserver les colonnes d'intérêt, notamment l'identifiant, le nom, le type et la géométrie de l'établissement de santé\n  rename(\"nearest_clinic\" = \"name\")                # renommer pour plus de clarté\n# Nombre de cas par établissement de santé\nhf_catchment <- linelist_sf_hf %>%   # commencer par linelist comprenant les données de la clinique la plus proche\n  as.data.frame() %>%                # convertir de shapefile à dataframe\n  count(nearest_clinic,              # compter les lignes par \"nom\" (de la clinique)\n        name = \"case_n\") %>%         # assign new counts column as \"case_n\"\n  arrange(desc(case_n))              # classer par ordre décroissant\n\nhf_catchment                         # Afficher sur  la console##                          nearest_clinic case_n\n## 1                            Den Clinic    357\n## 2       Shriners Hospitals for Children    330\n## 3         GINER HALL COMMUNITY HOSPITAL    168\n## 4                             panasonic     46\n## 5 Princess Christian Maternity Hospital     32\n## 6                                  <NA>     26\n## 7                     ARAB EGYPT CLINIC     25\n## 8                  MABELL HEALTH CENTER     16\ntmap_mode(\"view\")   # Utiliser tmap en  mode  interactive  \n\n# Visualiser les points ou sont localisés les cas et cliniques\ntm_shape(linelist_sf_hf) +            # visualiser les cas\n  tm_dots(size=0.08,                  # cas colorés par la clinique la plus proche\n          col='nearest_clinic') +    \ntm_shape(sle_hf) +                    # tracer les  cliniques en gros points noirs\n  tm_dots(size=0.3, col='black', alpha = 0.4) +      \n  tm_text(\"name\") +                   # superposition du nom de l'installation\ntm_view(set.view = c(-13.2284, 8.4699, 13), # ajuster le zoom (coordonnées du centre, zoom)\n        set.zoom.limits = c(13,14))+\ntm_layout(title = \"Cas, colorés par la clinique la plus proche\")"},{"path":"gis.html","id":"buffer","chapter":"28 GIS basics","heading":"Buffer","text":"Nous pouvons également explorer combien de cas sont situés à moins de 2,5 km (~30 minutes) de distance de marche de l’établissement de santé le plus proche.Remarque : pour des calculs de distance plus précis, il est préférable de reprojeter votre objet sf dans le système de projection de la carte locale, tel que l’UTM (Terre projetée sur une surface plane). Dans cet exemple, pour des raisons de simplicité, nous nous en tiendrons au système de coordonnées géograhpiques World Geodetic System (WGS84) (la Terre est représentée par une surface sphérique / ronde, les unités sont donc en degrés décimaux). Nous utiliserons une conversion générale de : 1 degré décimal = ~111km.Pour plus d’informations sur les projections cartographiques et les systèmes de coordonnées, consultez cet article esri. Ce blog traite des différents types de projection cartographique et de la manière de choisir une projection appropriée en fonction de la zone d’intérêt et du contexte de votre carte / analyse.Tout d’abord, créez un tampon circulaire d’un rayon de ~2,5 km autour de chaque établissement de santé. Ceci est fait avec la fonction st_buffer() de tmap. Parce que l’unité de la carte est en degrés décimaux lat/long, c’est ainsi que “0,02” est interprété. Si le système de coordonnées de votre carte est en mètres, le nombre doit être fourni en mètres.Ci-dessous, nous traçons les zones tampons elles-mêmes, avec les valeurs de :Ensuite, nous intersectons ces tampons avec les cas (points) en utilisant st_join() et le type de jointure de st_intersects. C’est-à-dire que les données de la zone tampon sont jointes aux points qu’ils croisent.Maintenant, nous pouvons compter les résultats : nrow(linelist_sf_hf_2k[.na(linelist_sf_hf_2k$osm_id.y),]) sur 1000 cas ne recoupent aucun tampon (cette valeur est manquante), et vivent donc à plus de 30 minutes de marche de l’établissement de santé le plus proche.Nous pouvons visualiser les résultats de telle sorte que les cas qui n’ont intersecté aucun tampon apparaissent en rouge.","code":"\nsle_hf_2k <- sle_hf %>%\n  st_buffer(dist=0.02)       # degrés décimaux se traduisant par environ 2,5 km \ntmap_mode(\"plot\")\n# Creons une zone tampon circulaire\ntm_shape(sle_hf_2k) +\n  tm_borders(col = \"black\", lwd = 2)+\ntm_shape(sle_hf) +                    # materialiser les installations cliniques avec  de gros points rouges\n  tm_dots(size=0.3, col='black')      \n# Intersecter les cas observés  avec la zone tampon\nlinelist_sf_hf_2k <- linelist_sf_hf %>%\n  st_join(sle_hf_2k, join = st_intersects, left = TRUE) %>%\n  filter(osm_id.x==osm_id.y | is.na(osm_id.y)) %>%\n  select(case_id, osm_id.x, nearest_clinic, amenity.x, osm_id.y)\n# Cas qui n'ont pas été croisés avec l'un des tampons de l'établissement de santé\nlinelist_sf_hf_2k %>% \n  filter(is.na(osm_id.y)) %>%\n  nrow()## [1] 1000\ntmap_mode(\"view\")\n\n# Affichez  d'abord les cas en points\ntm_shape(linelist_sf_hf) +\n  tm_dots(size=0.08, col='nearest_clinic') +\n\n# tracer les installations cliniques en gros points noirs\ntm_shape(sle_hf) +                    \n  tm_dots(size=0.3, col='black')+   \n\n# Superposez ensuite les zones tampons des établissements de santé sous forme de polylignes.\ntm_shape(sle_hf_2k) +\n  tm_borders(col = \"black\", lwd = 2) +\n\n# Highlight cases that are not part of any health facility buffers\n# en points noirs  \ntm_shape(linelist_sf_hf_2k %>%  filter(is.na(osm_id.y))) +\n  tm_dots(size=0.1, col='red') +\ntm_view(set.view = c(-13.2284,8.4699, 13), set.zoom.limits = c(13,14))+\n\n# ajouter le titre\ntm_layout(title = \"Nombre de Cas par zone couverture des cliniques \")"},{"path":"gis.html","id":"les-autres-jointures-spatiales","chapter":"28 GIS basics","heading":"les autres jointures spatiales","text":"Les valeurs alternatives pour l’argument join comprennent (de la documentation)st_contains_properlyst_containsst_covered_byst_coversst_crossesst_disjointst_equals_exactst_equalsst_is_within_distancest_nearest_featurest_overlapsst_touchesst_within","code":""},{"path":"gis.html","id":"choropleth-maps","chapter":"28 GIS basics","heading":"28.7 Choropleth maps","text":"Les cartes choroplèthes peuvent être utiles pour visualiser vos données par zone prédéfinie, généralement une unité administrative ou une zone de santé. Dans le cadre de la réponse aux épidémies, cela peut aider à cibler l’allocation des ressources pour des zones spécifiques présentant des taux d’incidence élevés, par exemple.Maintenant que nous avons les noms des unités administratives attribués à tous les cas (voir la section sur les jointures spatiales, ci-dessus), nous pouvons commencer à cartographier le nombre de cas par zone (cartes choroplèthes).Puisque nous disposons également des données de population par ADM3, nous pouvons ajouter ces informations à la table case_adm3 créée précédemment.Nous commençons avec le cadre de données créé à l’étape précédente case_adm3, qui est un tableau récapitulatif de chaque unité administrative et de son nombre de cas.Les données de population sle_adm3_pop sont jointes à l’aide d’un left_join() de dplyr sur la base des valeurs communes à la colonne admin3pcod dans le dataframe case_adm3, et à la colonne adm_pcode dans le dataframe sle_adm3_pop. Voir la page Joindre des données).select() est appliqué au nouveau dataframe, pour ne garder que les colonnes utiles - total est la population totale.Les cas pour 10.000 habitants sont calculés comme une nouvelle colonne avec mutate().faire une Jointure cette table au shapefile ADM3 polygones pour la cartographie.Cartographier le resultatNous pouvons cartographier le taux d’incidence","code":"\n# Ajouter les données de la population et calculer les cas pour 10K de population\ncase_adm3 <- case_adm3 %>% \n     left_join(sle_adm3_pop,                             #ajouter des colonnes à partir du jeu données pop\n               by = c(\"admin3pcod\" = \"adm3_pcode\")) %>%  # jointure basee sur les valeurs communes à ces deux colonnes\n     select(names(case_adm3), total) %>%                 # ne conserver que les colonnes importantes, notamment la population totale\n     mutate(case_10kpop = round(cases/total * 10000, 3)) # créer une nouvelle colonne avec le taux de cas pour 10000, arrondi à 3 décimales\n\ncase_adm3                                                # imprimer sur la console pour l'affichage## # A tibble: 10 × 5\n## # Groups:   admin3pcod [10]\n##    admin3pcod admin3name     cases  total case_10kpop\n##    <chr>      <chr>          <int>  <int>       <dbl>\n##  1 SL040102   Mountain Rural   298  33993       87.7 \n##  2 SL040208   West III         242 210252       11.5 \n##  3 SL040207   West II          151 145109       10.4 \n##  4 SL040204   East II          105  99821       10.5 \n##  5 SL040203   East I            59  68284        8.64\n##  6 SL040201   Central I         58  69683        8.32\n##  7 SL040206   West I            37  60186        6.15\n##  8 SL040205   East III          26 500134        0.52\n##  9 SL040202   Central II        14  23874        5.86\n## 10 <NA>       <NA>              10     NA       NA\ncase_adm3_sf <- case_adm3 %>%                 # Commencer par les cas et classer par unité administrative\n  left_join(sle_adm3, by=\"admin3pcod\") %>%    # jointure aux données shapefile par colonne commune\n  select(objectid, admin3pcod,                # ne conserver que certaines colonnes d'intérêt\n         admin3name = admin3name.x,           # nettoyer le nom de   ce  column\n         admin2name, admin1name,\n         cases, total, case_10kpop,\n         geometry) %>%                        # conserver la géométrie pour que les polygones puissent être cartographier\n  drop_na(objectid) %>%                       # supprimer les lignes vides\n  st_as_sf()                                  # convertir en  shapefile\n# tmap mode\ntmap_mode(\"plot\")               # carte statique\n\n# visualiser les polygones\ntm_shape(case_adm3_sf) + \n        tm_polygons(\"cases\") +  # colorier en fonction  du nombre de cas \n        tm_text(\"admin3name\")   # afficher les noms\n# Cases per 10K population\ntmap_mode(\"plot\")             # mode affiche statique\n\n# plot\ntm_shape(case_adm3_sf) +                # visualiser lespolygons\n  tm_polygons(\"case_10kpop\",            # colorier en fonction du colonnes contenant le pourcentages des cas\n              breaks=c(0, 10, 50, 100), # définir des points de rupture pour les couleurs\n              palette = \"Purples\"       # utiliser une palette de couleurs violettes\n              ) +\n  tm_text(\"admin3name\")                 # afficher le texte"},{"path":"gis.html","id":"cartographie-avec-ggplot2","chapter":"28 GIS basics","heading":"28.8 Cartographie avec ggplot2","text":"Si vous êtes déjà familiarisé avec l’utilisation de ggplot2, vous pouvez utiliser ce package pour créer des cartes statiques de vos données. La fonction geom_sf() dessinera différents objets en fonction des caractéristiques (points, lignes ou polygones) présentes dans vos données. Par exemple, vous pouvez utiliser geom_sf() dans un ggplot() utilisant des données sf avec une géométrie polygonale pour créer une carte choroplèthe.Pour illustrer comment cela fonctionne, nous pouvons commencer avec le fichier de forme ADM3 polygones que nous avons utilisé plus tôt. Rappelez-vous qu’il s’agit des régions de niveau administratif 3 de la Sierra Leone :Nous pouvons utiliser la fonction left_join() de dplyr pour ajouter les données que nous souhaitons mapper à l’objet shapefile. Dans ce cas, nous allons utiliser le cadre de données case_adm3 que nous avons créé plus tôt pour résumer le nombre de cas par région administrative ; cependant, nous pouvons utiliser cette même approche pour mapper n’importe quelle donnée stockée dans un cadre de données.Pour réaliser un graphique en colonnes du nombre de cas par région, en utilisant ggplot2, nous pourrions alors appeler geom_col() comme suit :Si nous voulons utiliser ggplot2 pour réaliser une carte choroplèthe du nombre de cas, nous pouvons utiliser une syntaxe similaire pour appeler la fonction geom_sf() :Nous pouvons ensuite personnaliser l’apparence de notre carte en utilisant une grammaire cohérente dans ggplot2, par exemple :Pour les utilisateurs de R qui sont à l’aise avec ggplot2, geom_sf() offre une implémentation simple et directe qui convient aux visualisations cartographiques de base. Pour en savoir plus, lisez la vignette geom_sf() ou le livre ggplot2.","code":"\nsle_adm3## Simple feature collection with 12 features and 19 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -13.29894 ymin: 8.094272 xmax: -12.91333 ymax: 8.499809\n## Geodetic CRS:  WGS 84\n## # A tibble: 12 × 20\n##    objectid admin3name     admin3pcod admin3ref_n    admin2name    admin2pcod admin1name\n##  *    <dbl> <chr>          <chr>      <chr>          <chr>         <chr>      <chr>     \n##  1      155 Koya Rural     SL040101   Koya Rural     Western Area… SL0401     Western   \n##  2      156 Mountain Rural SL040102   Mountain Rural Western Area… SL0401     Western   \n##  3      157 Waterloo Rural SL040103   Waterloo Rural Western Area… SL0401     Western   \n##  4      158 York Rural     SL040104   York Rural     Western Area… SL0401     Western   \n##  5      159 Central I      SL040201   Central I      Western Area… SL0402     Western   \n##  6      160 East I         SL040203   East I         Western Area… SL0402     Western   \n##  7      161 East II        SL040204   East II        Western Area… SL0402     Western   \n##  8      162 Central II     SL040202   Central II     Western Area… SL0402     Western   \n##  9      163 West III       SL040208   West III       Western Area… SL0402     Western   \n## 10      164 West I         SL040206   West I         Western Area… SL0402     Western   \n## 11      165 West II        SL040207   West II        Western Area… SL0402     Western   \n## 12      167 East III       SL040205   East III       Western Area… SL0402     Western   \n## # ℹ 13 more variables: admin1pcod <chr>, admin0name <chr>, admin0pcod <chr>,\n## #   date <date>, valid_on <date>, valid_to <date>, shape_leng <dbl>, shape_area <dbl>,\n## #   rowcacode0 <chr>, rowcacode1 <chr>, rowcacode2 <chr>, rowcacode3 <chr>,\n## #   geometry <MULTIPOLYGON [°]>\nsle_adm3_dat <- sle_adm3 %>% \n  inner_join(case_adm3, by = \"admin3pcod\") # inner join =  retenir seulement si dans les deux objets de données\n\nselect(sle_adm3_dat, admin3name.x, cases) # affiche les variables sélectionnées sur la console## Simple feature collection with 9 features and 2 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -13.29894 ymin: 8.384533 xmax: -13.12612 ymax: 8.499809\n## Geodetic CRS:  WGS 84\n## # A tibble: 9 × 3\n##   admin3name.x   cases                                                          geometry\n##   <chr>          <int>                                                <MULTIPOLYGON [°]>\n## 1 Mountain Rural   298 (((-13.21496 8.474341, -13.21479 8.474289, -13.21465 8.474296, -…\n## 2 Central I         58 (((-13.22646 8.489716, -13.22648 8.48955, -13.22644 8.489513, -1…\n## 3 East I            59 (((-13.2129 8.494033, -13.21076 8.494026, -13.21013 8.494041, -1…\n## 4 East II          105 (((-13.22653 8.491883, -13.22647 8.491853, -13.22642 8.49186, -1…\n## 5 Central II        14 (((-13.23154 8.491768, -13.23141 8.491566, -13.23144 8.49146, -1…\n## 6 West III         242 (((-13.28529 8.497354, -13.28456 8.496497, -13.28403 8.49621, -1…\n## 7 West I            37 (((-13.24677 8.493453, -13.24669 8.493285, -13.2464 8.493132, -1…\n## 8 West II          151 (((-13.25698 8.485518, -13.25685 8.485501, -13.25668 8.485505, -…\n## 9 East III          26 (((-13.20465 8.485758, -13.20461 8.485698, -13.20449 8.485757, -…\nggplot(data=sle_adm3_dat) +\n  geom_col(aes(x=fct_reorder(admin3name.x, cases, .desc=T),   # réorganiser l'axe des x par ordre décroissant 'cases'\n               y=cases)) +                                  # l'axe des y est le nombre de cas par région\n  theme_bw() +\n  labs(                                                     # définir le texte de la figure\n    title=\"Number of cases, by administrative unit\",\n    x=\"Admin level 3\",\n    y=\"Number of cases\"\n  ) + \n  guides(x=guide_axis(angle=45))                            # angle des étiquettes de l'axe des x de 45 degrés pour un meilleur ajustement\nggplot(data=sle_adm3_dat) + \n  geom_sf(aes(fill=cases))    # donnons une variable d'entrée  à fill pour varier selon le nombre de cas\nggplot(data=sle_adm3_dat) +                           \n  geom_sf(aes(fill=cases)) +                        \n  scale_fill_continuous(high=\"#54278f\", low=\"#f2f0f7\") +    # changeons le gradient de couleur\n  theme_bw() +\n  labs(title = \"Number of cases, by administrative unit\",   # mettre du texte dans le graphe\n       subtitle = \"Admin level 3\"\n  )"},{"path":"gis.html","id":"basemaps","chapter":"28 GIS basics","heading":"28.8.1 Basemaps","text":"","code":""},{"path":"gis.html","id":"openstreetmap","chapter":"28 GIS basics","heading":"OpenStreetMap","text":"Nous décrivons ci-dessous comment obtenir un plan de base pour une carte ggplot2 en utilisant les fonctionnalités d’OpenStreetMap. Les méthodes alternatives incluent l’utilisation de ggmap qui nécessite un enregistrement gratuit auprès de Google (détails).OpenStreetMap est un projet collaboratif visant à créer une carte du monde librement modifiable. Les données de géolocalisation sous-jacentes (par exemple, l’emplacement des villes, des routes, des caractéristiques naturelles, des aéroports, des écoles, des hôpitaux, des routes, etc.) sont considérées comme le principal résultat du projet.Tout d’abord, nous chargeons le paquet OpenStreetMap, à partir duquel nous allons obtenir notre carte de base.Ensuite, nous créons l’objet map, que nous définissons en utilisant la fonction openmap() du paquet OpenStreetMap (documentation). Nous fournissons les éléments suivants :upperLeft et lowerRight Deux paires de coordonnées spécifiant les limites du carreau de la carte de base.Dans ce cas, nous avons mis les valeurs max et min des lignes de la linelist, afin que la carte réponde dynamiquement aux données.zoom = (si null il est déterminé automatiquement)type = quel type de carte de base - nous avons listé plusieurs possibilités ici et le code utilise actuellement la première ([1]) “osm”.mergeTiles = nous avons choisi TRUE pour que les tuiles de base soient toutes fusionnées en une seule.Si nous traçons cette carte de base maintenant, en utilisant autoplot.OpenStreetMap() du paquet OpenStreetMap, vous voyez que les unités sur les axes ne sont pas des coordonnées de latitude/longitude. Il utilise un système de coordonnées différent. Pour afficher correctement les résidences du cas (qui sont stockées en lat/long), cela doit être changé.\nAinsi, nous voulons convertir la carte en latitude/longitude avec la fonction openproj() du paquet OpenStreetMap. Nous fournissons la carte de base map et nous fournissons également le système de référence de coordonnées (CRS) que nous voulons. Nous le faisons en fournissant la chaîne de caractères “proj.4” pour la projection WGS 1984, mais vous pouvez également fournir le CRS d’autres manières. (voir cette page pour mieux comprendre ce qu’est une chaîne proj.4)Maintenant, lorsque nous créons le tracé, nous voyons que les axes contiennent des coordonnées de latitude et de longitude. Le système de coordonnées été converti. Maintenant, nos cas seront tracés correctement s’ils sont superposés !Consultez les tutoriels ici et ici pour plus d’informations.","code":"\n# charger  package\npacman::p_load(OpenStreetMap)\n\n# Ajustez la carte de base par le couple de coordonnées lat/long. Choisir le type de tuile\nmap <- openmap(\n  upperLeft = c(max(linelist$lat, na.rm=T), max(linelist$lon, na.rm=T)),   # limits of basemap tile\n  lowerRight = c(min(linelist$lat, na.rm=T), min(linelist$lon, na.rm=T)),\n  zoom = NULL,\n  type = c(\"osm\", \"stamen-toner\", \"stamen-terrain\", \"stamen-watercolor\", \"esri\",\"esri-topo\")[1])\nautoplot.OpenStreetMap(map)\n# Projection WGS84\nmap_latlon <- openproj(map, projection = \"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\")\n# la representation graphique d'une carte doit se faire en  utilisant \"autoplot\" afin de pouvoir travailler avec ggplot.\nautoplot.OpenStreetMap(map_latlon)"},{"path":"gis.html","id":"cartes-thermiques-de-densité-avec-contours","chapter":"28 GIS basics","heading":"28.9 Cartes thermiques de densité avec contours","text":"Nous décrivons ci-dessous comment réaliser une carte thermique de densité des cas, sur une carte de base, en commençant par une liste de lignes (une ligne par cas).Créer une tuile basemap à partir d’OpenStreetMap, comme décrit ci-dessus.Tracez les cas de linelist en utilisant les colonnes de latitude et de longitude.Convertir les points en une carte thermique de densité avec stat_density_2d() de ggplot2,Lorsque nous avons une carte de base avec des coordonnées de latitude et de longitude, nous pouvons tracer nos cas par-dessus en utilisant les coordonnées de latitude et de longitude de leur résidence.En s’appuyant sur la fonction autoplot.OpenStreetMap() pour créer la carte de base, les fonctions de ggplot2 s’ajouteront facilement par-dessus, comme le montre geom_point() ci-dessous :\nLa carte ci-dessus peut être difficile à interpréter, surtout si les points se chevauchent. Vous pouvez donc tracer une carte de densité en 2d en utilisant la fonction ggplot2 stat_density_2d(). Vous utilisez toujours les coordonnées lat/lon de la linelist, mais une estimation de densité à noyau 2D est effectuée et les résultats sont affichés avec des lignes de contour - comme une carte topographique. Lisez la documentation complète ici.","code":"\n## la representation graphique d'une carte doit se faire en  utilisant \"autoplot\" afin de pouvoir travailler avec ggplot\nautoplot.OpenStreetMap(map_latlon)+                 # commercer avec basemap\n  geom_point(                                       # ajouter des points xy à partir des colonnes lon et lat de la linelist \n    data = linelist,                                \n    aes(x = lon, y = lat),\n    size = 1, \n    alpha = 0.5,\n    show.legend = FALSE) +                          # abandonner entièrement la légende\n  labs(x = \"Longitude\",                             # titres et etiquettes\n       y = \"Latitude\",\n       title = \"Cumulative cases\")\n# commencer par la carte de base\nautoplot.OpenStreetMap(map_latlon)+\n  \n  # ajouter le graphique de densité\n  ggplot2::stat_density_2d(\n        data = linelist,\n        aes(\n          x = lon,\n          y = lat,\n          fill = ..level..,\n          alpha = ..level..),\n        bins = 10,\n        geom = \"polygon\",\n        contour_var = \"count\",\n        show.legend = F) +                          \n  \n  # spécifier l'échelle de couleurs\n  scale_fill_gradient(low = \"black\", high = \"red\")+\n  \n  # etiquettes\n  labs(x = \"Longitude\",\n       y = \"Latitude\",\n       title = \"Distribution of cumulative cases\")"},{"path":"gis.html","id":"carte-thermique-des-séries-chronologiques","chapter":"28 GIS basics","heading":"Carte thermique des séries chronologiques","text":"La carte thermique de densité ci-dessus montre les cas cumulés. Nous pouvons examiner l’épidémie dans le temps et l’espace en facettant la carte de chaleur en fonction du mois d’apparition des symptômes, tel qu’il est dérivé de la liste des lignes.Nous commençons dans la linelist, en créant une nouvelle colonne avec l’année et le mois d’apparition des symptômes. La fonction format() de base R change la façon dont une date est affichée. Dans ce cas, nous voulons “YYYY-MM”.Maintenant, nous introduisons simplement le facettage via ggplot2 à la carte thermique de densité. facet_wrap() est appliqué, en utilisant les nouvelles colonnes comme lignes. Nous avons fixé le nombre de colonnes de facettes à 3 pour plus de clarté.","code":"\n# Extrait mois de l'apparition\nlinelist <- linelist %>% \n  mutate(date_onset_ym = format(date_onset, \"%Y-%m\"))\n\n# Examiner les valeurs \ntable(linelist$date_onset_ym, useNA = \"always\")## \n## 2014-04 2014-05 2014-06 2014-07 2014-08 2014-09 2014-10 2014-11 2014-12 2015-01 2015-02 \n##       2      11      17      48      98     205     170     134      72      70      63 \n## 2015-03 2015-04    <NA> \n##      46      28      36\n# packages\npacman::p_load(OpenStreetMap, tidyverse)\n\n# commencer avec  basemap\nautoplot.OpenStreetMap(map_latlon)+\n  \n  # ajouter le graphique de densité\n  ggplot2::stat_density_2d(\n        data = linelist,\n        aes(\n          x = lon,\n          y = lat,\n          fill = ..level..,\n          alpha = ..level..),\n        bins = 10,\n        geom = \"polygon\",\n        contour_var = \"count\",\n        show.legend = F) +                          \n  \n  # spécifier l'échelle de couleurs\n  scale_fill_gradient(low = \"black\", high = \"red\")+\n  \n  # etiquettes\n  labs(x = \"Longitude\",\n       y = \"Latitude\",\n       title = \"Distribution of cumulative cases over time\")+\n  \n  # facetter le graphique par mois-année de début d'activité\n  facet_wrap(~ date_onset_ym, ncol = 4)               "},{"path":"gis.html","id":"statistiques-spatiales","chapter":"28 GIS basics","heading":"28.10 Statistiques spatiales","text":"Jusqu’à présent, la plupart de nos discussions ont porté sur la visualisation des données spatiales. Dans certains cas, vous pouvez également être intéressé par l’utilisation des statistiques spatiales pour mesurer la force des relations spatiales des attributs dans vos données. Cette section donne un bref aperçu de certains concepts clés des statistiques spatiales et suggère quelques ressources utiles à explorer si vous souhaitez effectuer des analyses spatiales plus poussées.","code":""},{"path":"gis.html","id":"les-relations-spatiales","chapter":"28 GIS basics","heading":"Les relations spatiales","text":"Avant de pouvoir calculer toute statistique spatiale, nous devons spécifier les relations entre les objets de nos données. Il existe de nombreuses façons de conceptualiser les relations spatiales, mais un modèle simple et couramment appliqué est celui de la adjacence - plus précisément, nous nous attendons à une relation géographique entre les zones qui partagent une frontière ou qui sont “voisines” les unes des autres.Nous pouvons quantifier les relations d’adjencence entre les polygones des régions administratives dans les données sle_adm3 que nous avons utilisées avec le package spdep. Nous allons spécifier une contiguïté queen, ce qui signifie que les voisins possèdent au moins un segment de frontière commune.les voisins possèdent au moins un segment de frontière commune Dans notre cas, avec des polygones irréguliers, la distinction est triviale, mais dans certains cas, le choix entre la reine et la tour peut ne pas etre evidentLa matrice affiché ci-dessus montre les relations entre les 9 régions de nos données sle_adm3. Un score de 0 indique que deux régions ne sont pas voisines, tandis que toute valeur différente de 0 indique une relation de voisinage. Les valeurs de la matrice sont normalisées afin que chaque région ait un poids total par ligne egale à 1.Une meilleure façon de faire ressortir ces relations de voisinage est de les reprensenter graphiquement :Nous avons utilisé une approche d’adjacence pour identifier les polygones voisins ; les voisins que nous avons identifiés sont aussi parfois appelés voisins basés sur la contiguïté. Mais ce n’est qu’une façon de choisir les régions qui sont censées avoir une relation géographique. Les approches alternatives les plus courantes pour identifier les relations géographiques génèrent des voisins basés sur la distance ; brièvement, il s’agit de :K-plus proches voisins - Sur la base de la distance entre les centroïdes (le centre géographiquement pondéré de chaque région polygonale), sélectionnez les n régions les plus proches comme voisines. Un seuil de proximité de distance maximale peut également être fixé. Dans spdep, vous pouvez utiliser knearneigh() (voir documentation).K-plus proches voisins - Sur la base de la distance entre les centroïdes (le centre géographiquement pondéré de chaque région polygonale), sélectionnez les n régions les plus proches comme voisines. Un seuil de proximité de distance maximale peut également être fixé. Dans spdep, vous pouvez utiliser knearneigh() (voir documentation).Distance threshold neighbors - Sélectionne les voisins sur la base d’une un seuil de distance definie. Dans spdep, ces relations de voisinage peuvent être identifiées en utilisant dnearneigh() (voir documentation).Distance threshold neighbors - Sélectionne les voisins sur la base d’une un seuil de distance definie. Dans spdep, ces relations de voisinage peuvent être identifiées en utilisant dnearneigh() (voir documentation).","code":"\nsle_nb <- spdep::poly2nb(sle_adm3_dat, queen=T) #Extraction de la liste des voisins \nsle_adjmat <- spdep::nb2mat(sle_nb)    # créer une matrice résumant les relations entre voisins\nsle_listw <- spdep::nb2listw(sle_nb)   # créer l'objet listw (liste de poids) -- nous en aurons besoin plus tard\n\nsle_nb## Neighbour list object:\n## Number of regions: 9 \n## Number of nonzero links: 30 \n## Percentage nonzero weights: 37.03704 \n## Average number of links: 3.333333\nround(sle_adjmat, digits = 2)##   [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]\n## 1 0.00 0.20 0.00 0.20 0.00  0.2 0.00 0.20 0.20\n## 2 0.25 0.00 0.00 0.25 0.25  0.0 0.00 0.25 0.00\n## 3 0.00 0.00 0.00 0.50 0.00  0.0 0.00 0.00 0.50\n## 4 0.25 0.25 0.25 0.00 0.00  0.0 0.00 0.00 0.25\n## 5 0.00 0.33 0.00 0.00 0.00  0.0 0.33 0.33 0.00\n## 6 0.50 0.00 0.00 0.00 0.00  0.0 0.00 0.50 0.00\n## 7 0.00 0.00 0.00 0.00 0.50  0.0 0.00 0.50 0.00\n## 8 0.20 0.20 0.00 0.00 0.20  0.2 0.20 0.00 0.00\n## 9 0.33 0.00 0.33 0.33 0.00  0.0 0.00 0.00 0.00\n## attr(,\"call\")\n## spdep::nb2mat(neighbours = sle_nb)\nplot(sle_adm3_dat$geometry) +                                           # visualiser les limites de la region\n  spdep::plot.nb(sle_nb,as(sle_adm3_dat, 'Spatial'), col='grey', add=T) # ajout des relation de voisinage"},{"path":"gis.html","id":"autocorrélation-spatiale","chapter":"28 GIS basics","heading":"Autocorrélation spatiale","text":"La première loi de la géographie de Tobler, souvent citée, stipule que “Tout interagit avec tout, mais deux objets proches ont plus de\nchance de le faire que deux objets éloignés”. En épidémiologie, cela signifie souvent que la probabilité d’obtenir un résultat sanitaire particulier dans une région donnée est plus liée au resultats des régions voisines qu’à celui des régions éloignées. Ce concept été formalisé sous le nom d’autocorrélation spatiale - la propriété statistique selon laquelle les objets spatiaux ayant des valeurs similaires sont localisées dans l’espace. Les mesures statistiques de l’autocorrélation spatiale peuvent être utilisées pour quantifier la dépendance spatiale dans vos données, localiser l’endroit où ont trouve des patterns, et identifier les patterns d’autocorrélation spatiale entre des variables distinctes dans vos données. Cette section donne un aperçu de certaines mesures courantes d’autocorrélation spatiale et de la façon de les calculer dans R.de Moran - Il s’agit d’une statistique globale de synthèse de la corrélation entre la valeur d’une variable dans une région et les valeurs de cette même variable dans les régions voisines. La statistique de Moran est généralement comprise entre -1 et 1. Une valeur de 0 n’indique aucun modèle de corrélation spatiale, tandis que des valeurs plus proches de 1 ou de -1 indiquent une autocorrélation spatiale plus forte (valeurs similaires proches) ou une dispersion spatiale (valeurs dissemblables proches), respectivement.Par exemple, nous allons calculer une statistique de Moran pour quantifier l’autocorrélation spatiale dans les cas d’Ebola que nous avons cartographiés plus tôt (rappelez-vous, il s’agit d’un sous-ensemble de cas provenant du cadre de données de la linelist épidémique simulée). Le paquet spdep possède une fonction, moran.test, qui peut faire ce calcul pour nous :La sortie de la fonction moran.test() nous montre une statistique de Moran de round(moran_i$estimate[1],2). Cela indique la présence d’une autocorrélation spatiale dans nos données - plus précisément, que les régions présentant un nombre similaire de cas d’Ebola sont susceptibles d’être proches les unes des autres. La valeur p fournie par moran.test() est générée par comparaison avec l’espérance sous l’hypothèse nulle d’absence d’autocorrélation spatiale, et peut être utilisée si vous avez besoin de rapporter les résultats d’un test d’hypothèse formel.Local Moran’s - Nous pouvons décomposer la statistique (globale) de Moran calculée ci-dessus pour identifier l’autocorrélation spatiale localisée, c’est-à-dire pour identifier des groupes spécifiques dans nos données. Cette statistique, qui est parfois appelée Indicateur local d’association spatiale (LISA), résume l’étendue de l’autocorrélation spatiale autour de chaque région individuelle. Elle peut être utile pour trouver les points “chauds” et “froids” sur la carte.Pour montrer un exemple, nous pouvons calculer et cartographier le de Moran local pour les comptes de cas d’Ebola utilisés ci-dessus, avec la fonction local_moran() de spdep :Getis-Ord Gi* - Il s’agit d’une autre statistique couramment utilisée pour l’analyse des points chauds ; en grande partie, la popularité de cette statistique est liée à son utilisation dans l’outil d’analyse des points chauds d’ArcGIS. Elle est basée sur l’hypothèse que, généralement, la différence de valeur d’une variable entre des régions voisines devrait suivre une distribution normale. Elle utilise une approche de type z-score pour identifier les régions qui ont des valeurs significativement plus élevées (point chaud) ou significativement plus basses (point froid) d’une variable spécifiée, par rapport à leurs voisins.Nous pouvons calculer et cartographier la statistique Gi* en utilisant la fonction localG() de spdep :Comme vous pouvez le constater, la carte des Getis-Ord Gi* est légèrement différente de la carte des Moran locaux que j’ai produite précédemment. Cela reflète le fait que la méthode utilisée pour calculer ces deux statistiques est légèrement différente ; celle que vous devez utiliser dépend de votre cas d’utilisation spécifique et de la question de recherche qui vous intéresse.Test L de Lee - Il s’agit d’un test statistique de corrélation spatiale bivariée. Il vous permet de vérifier si la configuration spatiale d’une variable donnée x est similaire à la configuration spatiale d’une autre variable, y, dont suppose qu’elle est liée spatialement à x.Pour donner un exemple, testons si la configuration spatiale des cas d’Ebola de l’épidémie simulée est corrélée à la configuration spatiale de la population. Pour commencer, nous devons avoir une variable population dans nos données sle_adm3. Nous pouvons utiliser la variable total du dataframe sle_adm3_pop que nous avons chargé précédemment.Nous pouvons rapidement visualiser les configurations spatiales des deux variables côte à côte, pour voir si elles se ressemblent :Visuellement, les modèles semblent dissemblables. Nous pouvons utiliser la fonction lee.test() de spdep pour tester statistiquement si le modèle d’autocorrélation spatiale des deux variables est lié. La statistique L sera proche de 0 s’il n’y pas de corrélation entre les modèles, proche de 1 s’il y une forte corrélation positive (c’est-à-dire que les modèles sont similaires), et proche de -1 s’il y une forte corrélation négative (c’est-à-dire que les modèles sont inverses).Le résultat ci-dessus montre que la statistique L de Lee pour nos deux variables était round(lee_test$estimate[1],2), ce qui indique une faible corrélation négative. Cela confirme notre évaluation visuelle selon laquelle le schéma des cas et la population ne sont pas liés l’un à l’autre, et fournit la preuve que le schéma spatial des cas n’est pas strictement le résultat de la densité de population dans les zones à haut risque.La statistique de Lee L peut être utile pour faire ce genre d’inférences sur la relation entre des variables distribuées dans l’espace ; cependant, pour décrire la nature de la relation entre deux variables de manière plus détaillée, ou pour ajuster les facteurs de confusion, des techniques de régression spatiale seront nécessaires. Celles-ci sont décrites brièvement dans la section suivante.","code":"\nmoran_i <-spdep::moran.test(sle_adm3_dat$cases,    # vecteur numérique avec la variable d'intérêt\n                            listw=sle_listw)       # listw object résumant les relations de voisinage\n\nmoran_i                                            # print les résultats du test I de Moran## \n##  Moran I test under randomisation\n## \n## data:  sle_adm3_dat$cases  \n## weights: sle_listw    \n## \n## Moran I statistic standard deviate = 1.7557, p-value = 0.03957\n## alternative hypothesis: greater\n## sample estimates:\n## Moran I statistic       Expectation          Variance \n##        0.23018862       -0.12500000        0.04092847\n# calculer le I de Moran local\nlocal_moran <- spdep::localmoran(                  \n  sle_adm3_dat$cases,                              # variable d'interet \n  listw=sle_listw                                  # listw object avec la ponderation de voisinage\n)\n\n# joindre les results  à un jeu de données sf \nsle_adm3_dat<- cbind(sle_adm3_dat, local_moran)    \n\n# cartographier\nggplot(data=sle_adm3_dat) +\n  geom_sf(aes(fill=Ii)) +\n  theme_bw() +\n  scale_fill_gradient2(low=\"#2c7bb6\", mid=\"#ffffbf\", high=\"#d7191c\",\n                       name=\"Local Moran's I\") +\n  labs(title=\"Local Moran's I statistic for Ebola cases\",\n       subtitle=\"Admin level 3 regions, Sierra Leone\")\n# Effectuer une analyse G locale\ngetis_ord <- spdep::localG(\n  sle_adm3_dat$cases,\n  sle_listw\n)\n\n# joindre les résultats aux données SF\nsle_adm3_dat$getis_ord <- as.numeric(getis_ord)\n\n# afficher la carte\nggplot(data=sle_adm3_dat) +\n  geom_sf(aes(fill=getis_ord)) +\n  theme_bw() +\n  scale_fill_gradient2(low=\"#2c7bb6\", mid=\"#ffffbf\", high=\"#d7191c\",\n                       name=\"Gi*\") +\n  labs(title=\"Getis-Ord Gi* statistic for Ebola cases\",\n       subtitle=\"Admin level 3 regions, Sierra Leone\")\nsle_adm3_dat <- sle_adm3_dat %>% \n  rename(population = total)                          # renommer 'total' en  'population'\ntmap_mode(\"plot\")\n\ncases_map <- tm_shape(sle_adm3_dat) + tm_polygons(\"cases\") + tm_layout(main.title=\"Cases\")\npop_map <- tm_shape(sle_adm3_dat) + tm_polygons(\"population\") + tm_layout(main.title=\"Population\")\n\ntmap_arrange(cases_map, pop_map, ncol=2)   # arranger en facettes 2x1\nlee_test <- spdep::lee.test(\n  x=sle_adm3_dat$cases,          # variable 1 à comparer\n  y=sle_adm3_dat$population,     # variable 2 à comparer\n  listw=sle_listw                # listw objet avec les poids des voisins\n)\n\nlee_test## \n##  Lee's L statistic randomisation\n## \n## data:  sle_adm3_dat$cases ,  sle_adm3_dat$population \n## weights: sle_listw  \n## \n## Lee's L statistic standard deviate = -0.84171, p-value = 0.8\n## alternative hypothesis: greater\n## sample estimates:\n## Lee's L statistic       Expectation          Variance \n##       -0.12832478       -0.03486929        0.01232771"},{"path":"gis.html","id":"régression-spatiale","chapter":"28 GIS basics","heading":"Régression spatiale","text":"Vous pouvez souhaiter faire des inférences statistiques sur les relations entre les variables de vos données spatiales. Dans ce cas, il est utile d’envisager des techniques de régression spatiale, c’est-à-dire des approches de la régression qui prennent explicitement en compte l’organisation spatiale des unités dans vos données. Voici quelques raisons pour lesquelles vous pouvez avoir besoin d’envisager des modèles de régression spatiale, plutôt que des modèles de régression standard tels que les GLM :Les modèles de régression standard supposent que les résidus sont indépendants les uns des autres. En présence d’une forte autocorrélation spatiale, les résidus d’un modèle de régression standard sont susceptibles d’être également autocorrélés dans l’espace, violant ainsi cette hypothèse. Cela peut entraîner des problèmes d’interprétation des résultats du modèle, auquel cas un modèle spatial serait préférable.Les modèles de régression standard supposent que les résidus sont indépendants les uns des autres. En présence d’une forte autocorrélation spatiale, les résidus d’un modèle de régression standard sont susceptibles d’être également autocorrélés dans l’espace, violant ainsi cette hypothèse. Cela peut entraîner des problèmes d’interprétation des résultats du modèle, auquel cas un modèle spatial serait préférable.Les modèles de régression supposent aussi généralement que l’effet d’une variable x est constant sur toutes les observations. Dans le cas d’une hétérogénéité spatiale, les effets que nous souhaitons estimer peuvent varier dans l’espace, et nous pouvons être intéressés par la quantification de ces différences. Dans ce cas, les modèles de régression spatiale offrent plus de flexibilité pour estimer et interpréter les effets.Les modèles de régression supposent aussi généralement que l’effet d’une variable x est constant sur toutes les observations. Dans le cas d’une hétérogénéité spatiale, les effets que nous souhaitons estimer peuvent varier dans l’espace, et nous pouvons être intéressés par la quantification de ces différences. Dans ce cas, les modèles de régression spatiale offrent plus de flexibilité pour estimer et interpréter les effets.Les détails des approches de régression spatiale dépassent le cadre de ce manuel. Cette section donnera plutôt un aperçu des modèles de régression spatiale les plus courants et de leurs utilisations, et vous renverra à des références qui pourront vous être utiles si vous souhaitez approfondir ce domaine.Modèles d’erreurs spatiales - Ces modèles supposent que les termes d’erreur entre les unités spatiales sont corrélés, auquel cas les données violeraient les hypothèses d’un modèle MCO standard. Les modèles d’erreur spatiaux sont aussi parfois appelés modèles autorégressifs simultanés (SAR). Ils peuvent être ajustés en utilisant la fonction errorsarlm() du paquet spatialreg (fonctions de régression spatiale qui faisaient autrefois partie de spdep).Modèles de décalage spatial - Ces modèles supposent que la variable dépendante pour une région est influencée non seulement par la valeur des variables indépendantes dans , mais aussi par les valeurs de ces variables dans les régions voisines de . Comme les modèles à erreurs spatiales, les modèles à décalage spatial sont aussi parfois décrits comme des modèles autorégressifs simultanés (SAR). Ils peuvent être ajustés en utilisant la fonction lagsarlm() du paquet spatialreg.Le paquet spdep contient plusieurs tests de diagnostic utiles pour décider entre les modèles MCO standard, les modèles à décalage spatial et les modèles à erreur spatiale. Ces tests, appelés Diagnostics du multiplicateur de Lagrange, peuvent être utilisés pour identifier le type de dépendance spatiale de vos données et choisir le modèle le plus approprié. La fonction lm.LMtests() peut être utilisée pour calculer tous les tests du multiplicateur de Lagrange. Anselin (1988) fournit également un diagramme de flux utile pour décider du modèle de régression spatiale à utiliser en fonction des résultats des tests du multiplicateur de Lagrange :Modèles hiérarchiques bayésiens - Les approches bayésiennes sont couramment utilisées pour certaines applications de l’analyse spatiale, le plus souvent pour la cartographie des maladies. Elles sont préférables dans les cas où les données de cas sont peu distribuées (par exemple, dans le cas d’un résultat rare) ou statistiquement “bruyantes”, car elles peuvent être utilisées pour générer des estimations “lissées” du risque de maladie en tenant compte du processus spatial latent sous-jacent. Cela peut améliorer la qualité des estimations. Elles permettent également à l’enquêteur de préspécifier (via le choix de l’antériorité) les modèles de corrélation spatiale complexes qui peuvent exister dans les données, ce qui peut rendre compte de la variation spatialement dépendante et indépendante des variables indépendantes et dépendantes. Dans R, les modèles hiérarchiques bayésiens peuvent être ajustés à l’aide du paquet CARbayes (voir vignette) ou de R-INLA (voir site web et manuel). R peut également être utilisé pour appeler un logiciel externe qui effectue des estimations bayésiennes, comme JAGS ou WinBUGS.","code":""},{"path":"gis.html","id":"resources-7","chapter":"28 GIS basics","heading":"28.11 Resources","text":"R Simple Features sf package vignetteR Simple Features sf package vignetteR tmap package vignetteR tmap package vignetteggmap: Spatial Visualization ggplot2ggmap: Spatial Visualization ggplot2Intro making maps R, overview different packagesIntro making maps R, overview different packagesSpatial Data R (EarthLab course)Spatial Data R (EarthLab course)Applied Spatial Data Analysis R textbookApplied Spatial Data Analysis R textbookSpatialEpiApp - Shiny app downloadable R package, allowing provide data conduct mapping, cluster analysis, spatial statistics.SpatialEpiApp - Shiny app downloadable R package, allowing provide data conduct mapping, cluster analysis, spatial statistics.Introduction Spatial Econometrics R workshopAn Introduction Spatial Econometrics R workshop","code":""},{"path":"tables_presentation.html","id":"tables_presentation","chapter":"29 Présenter avec des tables","heading":"29 Présenter avec des tables","text":"HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22Cette page montre comment synthétiser les données d’un tableau ou d’un fichier dans des tables prêtes à être présentées en utilisant le package flextable (appelera ces tables les tables finales à présenter). Ces tables peuvent être insérées dans des diapositives Powerpoint, des pages HTML, des documents PDF ou Word, etc.Comprenez qu’avant d’utiliser flextable, vous devez créer la table finale sous forme de tableau de données. Utilisez les méthodes décrites dans les pages Tables descriptives et Restructurer des données telles que les tabulations, les tableaux croisés, les pivots et le calcul de statistiques descriptives pour cela. Le tableau de données résultant peut ensuite être fourni à flextable pour le formatage de l’aspect de la table finale à présenter.Il existe de nombreuses autres extensions (“packages”) R qui peuvent être utilisées pour créer des tables pour les présentations- nous avons choisi de mettre en avant flextable dans cette page. Un exemple d’utilisation du package knitr et de sa fonction kable() se trouve à la page Suivi de contacts. De même, le package DT est mis en avant dans la page Tableaux de bord avec Shiny. D’autres, comme GT et huxtable, sont mentionnés dans la page Packages suggérés.","code":""},{"path":"tables_presentation.html","id":"préparation-11","chapter":"29 Présenter avec des tables","heading":"29.1 Préparation","text":"","code":""},{"path":"tables_presentation.html","id":"charger-les-packages-1","chapter":"29 Présenter avec des tables","heading":"Charger les packages","text":"Installer et charger flextable. Dans ce manuel, nous mettons l’accent sur la fonction p_load() du “package” pacman, qui installe le (ou une liste de) “package (s)” que si nécessaire (uniquement si le package n’est pas déjà installé) et le charge pour l’utiliser . Vous pouvez également charger des “packages” avec library() à partir de R base. Voir la page sur Bases de R pour plus d’informations sur les “packages” R.","code":"\npacman::p_load(\n  rio,            # importer/exporter\n  here,           # chemin vers les fichiers\n  flextable,      # creer des tables HTML  \n  officer,        # fonctions d'aide pour les tables\n  tidyverse)      # data management, resume, et visualisation"},{"path":"tables_presentation.html","id":"importer-des-données-3","chapter":"29 Présenter avec des tables","heading":"Importer des données","text":"Pour commencer, nous importons la liste linéaire (“linelist”) nettoyée des cas d’une épidémie d’Ebola qui été simulée. Si vous voulez suivre en travaillant sur la base, cliquez pour télécharger la version “clean”  (en fichier .rds). Importez les données avec la fonction import() du “package” rio (elle gère de nombreux types de fichiers comme .xlsx, .csv, .rds - voir la page Importation et exportation pour plus de détails).Les 50 premières lignes de la liste linéaire sont affichées ci-dessous.","code":"\n# importer la liste lineaire\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"tables_presentation.html","id":"préparer-la-table","chapter":"29 Présenter avec des tables","heading":"Préparer la table","text":"Comme expliqué plus haut, avant de commencer à utiliser flextable, vous devez d’abord créer la table que vous voulez présenter sous forme de tableau de données. Consultez la page sur les Tables descriptives et les Données pivotantes pour apprendre à créer un tableau de données à l’aide de “packages” tels que janitor et dplyr. Vous devez disposer le contenu en lignes et en colonnes comme vous voulez qu’il soit affiché. C’est à dire part de notre base de données principales, lui applique les modifications et opérations nécessaires pour synthétiser l’information que l’veut présenter dans notre table finale et ce résultat sera enregistré dans un tableu de données. Ensuite, ce tableau de données sera soumis à flextable pour l’afficher avec la mise en forme voulue ajoutant des couleurs, des en-têtes, des polices, etc.Voici un exemple tiré de la page Tables descriptives sur la conversion de la “liste linéaire des cas” en un tableau de données qui résume/synthétise l’issue finale des patients et les valeurs CT (seuil de cycle dans un test de détection du virus par PCR) par hôpital, avec une ligne de totaux en bas. Le résultat est enregistré sous le nom de table.","code":"\ntable <- linelist %>% \n  \n  # Obtenez les valeurs résumees par hôpital et issue finale\n  ###############################################\n  group_by(hospital, outcome) %>%                      # Grouper les donnees selon ces deux variables\n  summarise(                                           # Creer un nouveau résumé des variables d'intérêt \n    N = n(),                                            # Nombre de lignes par  groupe \"hospital-outcome\"     \n    ct_value = median(ct_blood, na.rm=T)) %>%           # Valeur CT mediane  par groupe\n  \n  # ajouter le total\n  ############\n  bind_rows(                                           # Liez le tableau précédent avec ce mini-tableau de totaux\n    linelist %>% \n      filter(!is.na(outcome) & hospital != \"Missing\") %>%\n      group_by(outcome) %>%                            # Grouper avec var \"outcome\" uniquement et non par  \"hospital\"    \n      summarise(\n        N = n(),                                       # Nombre de lignes pour l'ensemble des données    \n        ct_value = median(ct_blood, na.rm=T))) %>%     # Valeur CT mediane pour l'ensemble des données    \n  \n  # Modifier en format long-large\n  ########################\n  mutate(hospital = replace_na(hospital, \"Total\")) %>% \n  pivot_wider(                                         # Pivoter du format long au format large\n    values_from = c(ct_value, N),                       # nouvelles valeurs sont crees depuis les vars \"ct\" et \"count\"\n    names_from = outcome) %>%                           # nouveaux noms de colonne crees depuis var \"outcomes\"\n  mutate(                                              # Creer de nouvelles colonnes\n    N_Known = N_Death + N_Recover,                               # nombre de cas avec l'issue finale connue\n    Pct_Death = scales::percent(N_Death / N_Known, 0.1),         # pourcentage de cas decedes (1 decimale)\n    Pct_Recover = scales::percent(N_Recover / N_Known, 0.1)) %>% # pourcentage de cas gueris (1 decimale)\n  select(                                              # Re-ordonner l'apparition des colonnes\n    hospital, N_Known,                                   # Colonnes d'Intro\n    N_Recover, Pct_Recover, ct_value_Recover,            # Colonnes concernant les gueris\n    N_Death, Pct_Death, ct_value_Death)  %>%             # Colonnes concernant les deces\n  arrange(N_Known)                                    # Trier les lignes de façon croissante (Total de la ligne en dernier)\n\ntable  # afficher la table## # A tibble: 7 × 8\n## # Groups:   hospital [7]\n##   hospital              N_Known N_Recover Pct_Recover ct_value_Recover N_Death Pct_Death\n##   <chr>                   <int>     <int> <chr>                  <dbl>   <int> <chr>    \n## 1 St. Mark's Maternity…     325       126 38.8%                     22     199 61.2%    \n## 2 Central Hospital          358       165 46.1%                     22     193 53.9%    \n## 3 Other                     685       290 42.3%                     21     395 57.7%    \n## 4 Military Hospital         708       309 43.6%                     22     399 56.4%    \n## 5 Missing                  1125       514 45.7%                     21     611 54.3%    \n## 6 Port Hospital            1364       579 42.4%                     21     785 57.6%    \n## 7 Total                    3440      1469 42.7%                     22    1971 57.3%    \n## # ℹ 1 more variable: ct_value_Death <dbl>"},{"path":"tables_presentation.html","id":"premiers-pas-avec-flextable","chapter":"29 Présenter avec des tables","heading":"29.2 Premiers pas avec flextable","text":"","code":""},{"path":"tables_presentation.html","id":"créer-un-objet-flextable","chapter":"29 Présenter avec des tables","heading":"Créer un objet flextable","text":"Pour créer et gérer les objets flextable, nous passons d’abord le tableau de données avec les informqtions que nous voulons présenter par la fonction flextable() et nous enregistrons le résultat sous le nom de my_table.hospitalN_KnownN_RecoverPct_Recoverct_value_RecoverN_DeathPct_Deathct_value_DeathSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22Après avoir fait cela, nous pouvons progressivement faire passer l’objet my_table par plus de fonctions de formatage flextable.Dans cette page, pour des raisons de clarté, nous sauvegarderons la table à des étapes intermédiaires sous le nom de my_table, en ajoutant des fonctions flextable étape par étape. Si vous voulez voir tout le code du début à la fin écrit en un seul bloc, visitez la section Tout le code ensemble ci-dessous.La syntaxe générale de chaque ligne de code flextable est la suivante :function(table, = X, j = X, part = \"X\"), :\nLa “fonction” peut être l’une des nombreuses fonctions différentes, telles que width() pour déterminer la largeur des colonnes, bg() pour définir les couleurs d’arrière-plan, align() pour définir si le texte est aligné au centre/à droite/à gauche, et ainsi de suite.\ntable = est le nom du tableau de données, mais il n’est pas nécessaire de l’indiquer si le tableau de données est intégré à la fonction.\npart = indique la partie de la table à laquelle la fonction appelée sera appliqué. Par ex: “header” pour l’entête de la table, “body” pour le corps de la table ou “” pour toutes les parties de la table.\n= spécifie la ligne à laquelle appliquer la fonction, où ‘X’ est le numéro de la ligne. S’il s’agit de plusieurs lignes, par exemple de la première à la troisième ligne, peut spécifier : = c(1:3). Notez que si ‘body’ est sélectionné, la première ligne commence sous la section d’en-tête.\nj = spécifie la colonne à laquelle appliquer la fonction, où ‘x’ est le numéro ou le nom de la colonne. Si plusieurs colonnes, par exemple la cinquième et la sixième, peut spécifier : `j = c(5,6).\nfunction(table, = X, j = X, part = \"X\"), :La “fonction” peut être l’une des nombreuses fonctions différentes, telles que width() pour déterminer la largeur des colonnes, bg() pour définir les couleurs d’arrière-plan, align() pour définir si le texte est aligné au centre/à droite/à gauche, et ainsi de suite.table = est le nom du tableau de données, mais il n’est pas nécessaire de l’indiquer si le tableau de données est intégré à la fonction.part = indique la partie de la table à laquelle la fonction appelée sera appliqué. Par ex: “header” pour l’entête de la table, “body” pour le corps de la table ou “” pour toutes les parties de la table.= spécifie la ligne à laquelle appliquer la fonction, où ‘X’ est le numéro de la ligne. S’il s’agit de plusieurs lignes, par exemple de la première à la troisième ligne, peut spécifier : = c(1:3). Notez que si ‘body’ est sélectionné, la première ligne commence sous la section d’en-tête.j = spécifie la colonne à laquelle appliquer la fonction, où ‘x’ est le numéro ou le nom de la colonne. Si plusieurs colonnes, par exemple la cinquième et la sixième, peut spécifier : `j = c(5,6).Vous pouvez trouver la liste complète des fonctions de formatage flextable ici ou consulter la documentation en tapant ?flextable.","code":"\nmy_table <- flextable(table) \nmy_table"},{"path":"tables_presentation.html","id":"largeur-de-la-colonne","chapter":"29 Présenter avec des tables","heading":"Largeur de la colonne","text":"Nous pouvons utiliser la fonction autofit(), qui permet d’étirer et de réajuster la table de façon esthétique de sorte que chaque cellule ne comporte qu’une seule ligne de texte. La fonction qflextable() est un raccourci pratique pour flextable() et autofit().hospitalN_KnownN_RecoverPct_Recoverct_value_RecoverN_DeathPct_Deathct_value_DeathSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22Cependant, cela n’est pas toujours approprié, surtout si les cellules contiennent des valeurs très longues, ce qui signifie que le tableau risque de ne pas tenir sur la page.À la place, nous pouvons spécifier des largeurs avec la fonction width(). Il faut parfois essayer plusieurs valeurs pour savoir laquelle correspond le mieux. Dans l’exemple ci-dessous, nous spécifions des largeurs différentes pour la colonne 1, la colonne 2 et les colonnes 4 à 8.hospitalN_KnownN_RecoverPct_Recoverct_value_RecoverN_DeathPct_Deathct_value_DeathSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\nmy_table %>% autofit()\nmy_table <- my_table %>% \n  width(j=1, width = 2.7) %>% \n  width(j=2, width = 1.5) %>% \n  width(j=c(4,5,7,8), width = 1)\n\nmy_table"},{"path":"tables_presentation.html","id":"en-têtes-de-colonnes","chapter":"29 Présenter avec des tables","heading":"En-têtes de colonnes","text":"Nous voulons des en-têtes plus clairs pour faciliter l’interprétation du contenu du tableau.Pour cette table, nous voudrons ajouter une deuxième couche d’en-tête afin que les colonnes couvrant les mêmes sous-groupes puissent être regroupées. Nous faisons cela avec la fonction add_header_row() avec top = TRUE. Nous précisons le nouveau nom de chaque colonne avec l’option values =, en laissant des valeurs vides \"\" pour les colonnes que nous savons que nous fusionnerons plus tard.Nous renommons également les noms des en-têtes dans le désormais deuxième en-tête dans une commande séparée en utilisant set_header_labels().Enfin, pour “regrouper” certains en-têtes de colonnes dans l’en-tête supérieur, nous utilisons merge_at() pour fusionner les en-têtes de colonnes dans la ligne d’en-tête supérieure.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\nmy_table <- my_table %>% \n  \n  add_header_row(\n    top = TRUE,                # Nouvel en-tête placé au-dessus de la rangée d'en-tête existante\n    values = c(\"Hospital\",     # Valeurs d'en-tête pour chaque colonne ci-dessous\n               \"Total cases with known outcome\", \n               \"Recovered\",    # Celui ci servira d'en-tête de niveau supérieur pour cette colonne et les deux suivantes\n               \"\",\n               \"\",\n               \"Died\",         # Celui ci servira d'en-tête de niveau supérieur pour cette colonne et les deux suivantes\n               \"\",             # Laisser vide comme ce sera fusionné avec \"Died\".\n               \"\")) %>% \n    \n  set_header_labels(         # Renommer les colonnes de la ligne d'en-tête originale\n      hospital = \"\", \n      N_Known = \"\",                  \n      N_Recover = \"Total\",\n      Pct_Recover = \"% of cases\",\n      ct_value_Recover = \"Median CT values\",\n      N_Death = \"Total\",\n      Pct_Death = \"% of cases\",\n      ct_value_Death = \"Median CT values\")  %>% \n  \n  merge_at(i = 1, j = 3:5, part = \"header\") %>% # Fusionner horizontalement les colonnes 3 à 5 dans une nouvelle ligne d'en-tête\n  merge_at(i = 1, j = 6:8, part = \"header\")     # Fusionnez horizontalement les colonnes 6 à 8 dans une nouvelle ligne d'en-tête.\n\nmy_table  # afficher la table résultante"},{"path":"tables_presentation.html","id":"bordures-et-arrière-plan","chapter":"29 Présenter avec des tables","heading":"Bordures et arrière-plan","text":"Vous pouvez ajuster les bordures, les lignes internes, etc. avec diverses fonctions flextable. Il est souvent plus facile de commencer par supprimer toutes les bordures existantes avec border_remove().Ensuite, vous pouvez appliquer des thèmes de bordure par défaut en passant la table à theme_box(), theme_booktabs(), ou theme_alafoli().Vous pouvez ajouter des lignes verticales et horizontales avec une variété de fonctions. hline() et vline() ajoutent des lignes à une ligne ou une colonne spécifiée, respectivement. Dans chacune d’elles, vous devez spécifier dans quelle partie de la table vous voulez le rajouter en précisant part = comme étant soit “”,“body” ou “header”. Pour les lignes verticales, spécifiez la colonne à l’argument j =, et pour les lignes horizontales la ligne à =. D’autres fonctions comme vline_right(), vline_left(), hline_top(), et hline_bottom() ajoutent des lignes aux bords externes de la table seulement.Dans toutes ces fonctions, le style de ligne lui-même doit être spécifié par border = et doit être le résultat d’une commande séparée utilisant la fonction fp_border() du “package” officer. Cette fonction vous aide à définir la largeur et la couleur de la ligne. Vous pouvez la définir avant d’appeler les commandes de table, comme indiqué ci-dessous.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\n# définir le style de la ligne de bordure\nborder_style = officer::fp_border(color=\"black\", width=1)\n\n# ajouter des lignes de bordure au tableau\nmy_table <- my_table %>% \n\n  # Enlever toutes les bordures existantes\n  border_remove() %>%  \n  \n  # ajouter des lignes horizontales via un thème prédéterminé\n  theme_booktabs() %>% \n  \n  # ajouter des lignes verticales pour séparer les sections \"Recovered\" et \"Died\"\n  vline(part = \"all\", j = 2, border = border_style) %>%   # a la colonne 2 \n  vline(part = \"all\", j = 5, border = border_style)       # a la colonne 5\n\nmy_table"},{"path":"tables_presentation.html","id":"police-et-alignement","chapter":"29 Présenter avec des tables","heading":"Police et alignement","text":"Nous alignons au centre toutes les colonnes, sauf la colonne la plus à gauche, avec les noms des hôpitaux, en utilisant la fonction align() de flextable.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22De plus, nous pouvons augmenter la taille de la police de l’en-tête et la mettre en gras. Nous pouvons également mettre en gras la ligne du total.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22Pour aérer la table, nous pouvons nous assurer que les colonnes de proportion n’affichent qu’une seule décimale en utilisant la fonction colformat_num(). Notez que cela aurait également pu être fait au stade de la gestion des données dans le tableau de données créé et fourni à flextable() avec la fonction round().HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\nmy_table <- my_table %>% \n   flextable::align(align = \"center\", j = c(2:8), part = \"all\") \nmy_table\nmy_table <-  my_table %>%  \n  fontsize(i = 1, size = 12, part = \"header\") %>%   # ajuster la taille de la police de l'en-tête\n  bold(i = 1, bold = TRUE, part = \"header\") %>%     # ajuster le caractère en gras de l'en-tête\n  bold(i = 7, bold = TRUE, part = \"body\")           # ajuster les caractères en gras de la ligne totale (ligne 7 du corps de la table)\n\nmy_table\nmy_table <- colformat_num(my_table, j = c(4,7), digits = 1)\nmy_table"},{"path":"tables_presentation.html","id":"fusionner-des-cellules","chapter":"29 Présenter avec des tables","heading":"Fusionner des cellules","text":"Tout comme nous fusionnons les cellules horizontalement dans la ligne d’en-tête, nous pouvons également fusionner les cellules verticalement en utilisant merge_at() et en spécifiant les lignes () et les colonnes (j). Ici, nous fusionnons les valeurs “Hospital” et “Total cases known outcome” verticalement pour leur donner plus d’espace.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\nmy_table <- my_table %>% \n  merge_at(i = 1:2, j = 1, part = \"header\") %>% \n  merge_at(i = 1:2, j = 2, part = \"header\")\n\nmy_table"},{"path":"tables_presentation.html","id":"couleur-darrière-plan","chapter":"29 Présenter avec des tables","heading":"Couleur d’arrière-plan","text":"Pour distinguer le contenu du corps de la table des en-têtes, nous pouvons ajouter une mise en forme supplémentaire, par exemple en modifiant la couleur de l’arrière-plan. Dans cet exemple, nous changeons le corps du tableau en gris.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\nmy_table <- my_table %>% \n    bg(part = \"body\", bg = \"gray95\")  \n\nmy_table "},{"path":"tables_presentation.html","id":"mise-en-forme-conditionnelle","chapter":"29 Présenter avec des tables","heading":"29.3 Mise en forme conditionnelle","text":"L’un des points forts de flextable est qu’il nous permet de faire des mises en forme de notre table finale selon des conditions que nous aurons fixées selon l’information que nous voulons souligner. Nous pouvons ainsi donc mettre en évidence toutes les valeurs d’une colonne qui répondent à une certaine condition. Par exemple nous voulons mettre l’accent sur les cas où plus de 55 % des cas sont décédés. Il suffit de mettre les critères dans l’argument = ou j =, précédé d’un tilde ~. Attention: la condition doit être précisée en utilisant le nom de la colonne (variable) dans le tableau de donnée fourni à flextable() non en utilisant le nom de la colonne qui s’affiche dans l’en-tête de la table finale.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22Ou bien, nous pouvons mettre en évidence la ligne entière répondant à un certain critère, tel qu’un hôpital d’intérêt. Pour ce faire, il suffit de supprimer la spécification de la colonne (j) afin que les critères s’appliquent à toutes les colonnes.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\nmy_table %>% \n  bg(j = 7, i = ~ Pct_Death >= 55, part = \"body\", bg = \"red\") \nmy_table %>% \n  bg(., i= ~ hospital == \"Military Hospital\", part = \"body\", bg = \"#91c293\") "},{"path":"tables_presentation.html","id":"tbl_pres_all","chapter":"29 Présenter avec des tables","heading":"29.4 L’ensemble du code","text":"Ci-dessous, nous regroupons tout le code des sections précédentes en un seul bloc comme vous serez amené à le faire.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\nborder_style = officer::fp_border(color=\"black\", width=1)\n\npacman::p_load(\n  rio,            # importer/exporter\n  here,           # chemin vers les fichiers\n  flextable,      # creer des tables HTML \n  officer,        # fonctions d'aide pour les tables\n  tidyverse)      # data management, resume, et visualisation\n\ntable <- linelist %>% \n\n  # Obtenez les valeurs résumees par hôpital et issue finale\n  ###############################################\n  group_by(hospital, outcome) %>%                      # Grouper les donnees selon ces deux variables\n  summarise(                                           # Creer un nouveau résumé des variables d'intérêt\n    N = n(),                                            # Nombre de lignes par  groupe \"hospital-outcome\"\n    ct_value = median(ct_blood, na.rm=T)) %>%           # Valeur CT mediane  par groupe\n  \n  # add totals\n  ############\n  bind_rows(                                           # Liez le tableau précédent avec ce mini-tableau de totaux\n    linelist %>% \n      filter(!is.na(outcome) & hospital != \"Missing\") %>%\n      group_by(outcome) %>%                            # # Grouper avec var \"outcome\" uniquement et non par  \"hospital\"    \n      summarise(\n        N = n(),                                       # Nombre de lignes pour l'ensemble des données      \n        ct_value = median(ct_blood, na.rm=T))) %>%     # Valeur CT mediane pour l'ensemble des données\n  \n  # Passer du format long de la table au format large\n  ########################\n  mutate(hospital = replace_na(hospital, \"Total\")) %>% \n  pivot_wider(                                         # Pivoter du format long au format large\n    values_from = c(ct_value, N),                       # nouvelles valeurs sont crees depuis les vars \"ct\" et \"count\"\n    names_from = outcome) %>%                           # nouveaux noms de colonne crees depuis var \"outcomes\"\n  mutate(                                              # Creer de nouvelles colonnes\n    N_Known = N_Death + N_Recover,                               # nombre de cas avec l'issue finale connue\n    Pct_Death = scales::percent(N_Death / N_Known, 0.1),         # pourcentage de cas decedes (1 decimale)\n    Pct_Recover = scales::percent(N_Recover / N_Known, 0.1)) %>% # pourcentage de cas gueris (1 decimale)\n  select(                                              # Re-ordonner l'apparition des colonnes\n    hospital, N_Known,                                   # Colonnes d'Intro\n    N_Recover, Pct_Recover, ct_value_Recover,            # Colonnes concernant les gueris\n    N_Death, Pct_Death, ct_value_Death)  %>%             # Colonnes concernant les deces\n  arrange(N_Known) %>%                                 # Trier les lignes de façon croissante (Total de la ligne en dernier)\n\n  # formatting\n  ############\n  flextable() %>%              # la table est pippee depuis les codes ci-dessus\n  add_header_row(\n    top = TRUE,                # Nouvel en-tête placé au-dessus de la rangée d'en-tête existante\n    values = c(\"Hospital\",     # Valeurs d'en-tête pour chaque colonne ci-dessous\n               \"Total cases with known outcome\", \n               \"Recovered\",    # Celui ci servira d'en-tête de niveau supérieur pour cette colonne\n               \"\",\n               \"\",\n               \"Died\",         # Celui ci servira d'en-tête de niveau supérieur pour cette colonne\n               \"\",             # Laisser vide comme ce sera fusionné avec \"Died\"\n               \"\")) %>% \n    set_header_labels(         # Renommer les colonnes de la ligne d'en-tête originale\n      hospital = \"\", \n      N_Known = \"\",                  \n      N_Recover = \"Total\",\n      Pct_Recover = \"% of cases\",\n      ct_value_Recover = \"Median CT values\",\n      N_Death = \"Total\",\n      Pct_Death = \"% of cases\",\n      ct_value_Death = \"Median CT values\")  %>% \n  merge_at(i = 1, j = 3:5, part = \"header\") %>% # Fusionner horizontalement les colonnes 3 à 5 dans une nouvelle ligne d'en-tête\n  merge_at(i = 1, j = 6:8, part = \"header\") %>%  \n  border_remove() %>%  \n  theme_booktabs() %>% \n  vline(part = \"all\", j = 2, border = border_style) %>%   # at column 2 \n  vline(part = \"all\", j = 5, border = border_style) %>%   # at column 5\n  merge_at(i = 1:2, j = 1, part = \"header\") %>% \n  merge_at(i = 1:2, j = 2, part = \"header\") %>% \n  width(j=1, width = 2.7) %>% \n  width(j=2, width = 1.5) %>% \n  width(j=c(4,5,7,8), width = 1) %>% \n  flextable::align(., align = \"center\", j = c(2:8), part = \"all\") %>% \n  bg(., part = \"body\", bg = \"gray95\")  %>% \n  bg(., j=c(1:8), i= ~ hospital == \"Military Hospital\", part = \"body\", bg = \"#91c293\") %>% \n  colformat_num(., j = c(4,7), digits = 1) %>%\n  bold(i = 1, bold = TRUE, part = \"header\") %>% \n  bold(i = 7, bold = TRUE, part = \"body\")## `summarise()` has grouped output by 'hospital'. You can override using the `.groups`\n## argument.\ntable"},{"path":"tables_presentation.html","id":"sauvegarder-votre-table","chapter":"29 Présenter avec des tables","heading":"29.5 Sauvegarder votre table","text":"Il existe différentes façons d’intégrer la table finale dans votre production.","code":""},{"path":"tables_presentation.html","id":"sauvegarder-une-seule-table","chapter":"29 Présenter avec des tables","heading":"Sauvegarder une seule table","text":"Vous pouvez exporter les tableaux vers des fichiers Word, PowerPoint ou HTML ou sous format image (PNG). Pour ce faire, utilisez l’une des fonctions suivantes :save_as_docx()save_as_pptx()save_as_image()save_as_html()Par exemple, ci-dessous, nous enregistrons notre table comme un document Word. Notez la syntaxe du premier argument - vous pouvez simplement fournir le nom de votre objet flextable, par exemple my_table, ou vous pouvez lui donner un “nom” comme indiqué ci-dessous (le nom est “table”). Si vous lui donnez un nom, celui-ci apparaîtra comme le titre de la table dans le document Word. Nous fournissons également le code pour sauvegarder la table sous format image PNG.Notez que les “packages” webshot ou webshot2 sont nécessaires pour sauvegarder un flextable comme une image. Les images peuvent sortir avec des arrière-plans transparents.Si vous voulez voir une version “en direct” de la sortie du flextable dans le format de document prévu, utilisez print() et spécifiez un des éléments ci-dessous pour preview =. Le document s’ouvrira “en direct” sur votre ordinateur dans le logiciel spécifié, mais ne sera pas sauvegardé. Cela peut être utile pour vérifier si le tableau tient dans une page/diapositive ou pour le copier rapidement dans un autre document. Vous pouvez utiliser la méthode d’impression avec l’argument preview défini à “pptx” ou “docx”.","code":"\n# Modifiez le tableau \"my table\" en fonction des besoins pour le titre du tableau.  \nsave_as_docx(\"my table\" = my_table, path = \"file.docx\")\n\nsave_as_image(my_table, path = \"file.png\")\nprint(my_table, preview = \"docx\") # Exemple de document Word\nprint(my_table, preview = \"pptx\") # Exemple de document Powerpoint"},{"path":"tables_presentation.html","id":"intégrer-la-table-dans-r-markdown","chapter":"29 Présenter avec des tables","heading":"Intégrer la table dans R markdown","text":"Cette table peut être intégrée dans un document automatisé, une sortie R markdown, si l’objet table est appelé dans le chunk R markdown. Cela signifie que la table peut être mise à jour dans le cadre d’un rapport où les données sont susceptibles de changer, de sorte que les chiffres peuvent être actualisés.Voir les détails dans la page Rapports avec R Markdown de ce manuel.","code":""},{"path":"tables_presentation.html","id":"ressources-14","chapter":"29 Présenter avec des tables","heading":"29.6 Ressources","text":"La documentation compléte sur flextable est ici: https://ardata-fr.github.io/flextable-book/ Le lien Github est ici\nUn guide sur toutes les fonctions flextable peût être trouvée iciVous pouvez accéder à une galerie de beaux exemples de tables flextable avec code ici","code":""},{"path":"ggplot_basics.html","id":"ggplot_basics","chapter":"30 Les bases de ggplot","heading":"30 Les bases de ggplot","text":"ggplot2 est le “package” R de visualisation de données le plus populaire. Sa fonction ggplot() est au cœur de ce “package”, et toute cette approche est familièrement connue sous le nom de “ggplot” avec les figures qui en résultent parfois affectueusement appelées “ggplots”. Le préfixe “gg” dans ce jargon reflète la “gramar graphics” (la grammaire des graphiques) utilisée pour construire les figures. ggplot2 bénéficie d’une grande variété de “packages” R supplémentaires qui améliorent encore ses fonctionnalités.La syntaxe est très différente de celle de la visualiation avec R base, et une courbe d’apprentissage y est associée. L’utilisation de ggplot2 exige généralement de l’utilisateur qu’il formate ses données d’une manière hautement compatible avec tidyverse, ce qui rend finalement l’utilisation conjointe de ces packages très efficace.Dans cette page, nous allons couvrir les principes fondamentaux de la visualisation avec ggplot2. Voir la page Astuces de ggplot pour des suggestions et des techniques avancées pour que vos graphiques soient vraiment esthétiques.Plusieurs tutoriels ggplot2 détaillés sont disponibles dans la section des ressources. Vous pouvez également télécharger cette fiche d’aide à la visualisation de données avec ggplot sur le site Web de RStudio. Si vous souhaitez trouver de l’inspiration pour visualiser vos données de manière créative, nous vous suggérons de consulter des sites Web tels que R graph gallery et Data--viz.","code":""},{"path":"ggplot_basics.html","id":"préparation-12","chapter":"30 Les bases de ggplot","heading":"30.1 Préparation","text":"","code":""},{"path":"ggplot_basics.html","id":"charger-les-extensions-packages","chapter":"30 Les bases de ggplot","heading":"Charger les extensions (“packages”)","text":"Ce chunk de code montre le chargement des “packages” nécessaires aux analyses. Dans ce manuel, nous souligons la fonction p_load() du “package” pacman, qui installe le (ou une liste de) “package (s)” que si nécessaire (uniquement si le package n’est pas déjà installé) et le charge pour l’utiliser. peut également charger des “packages” avec library() à partir de R base. Voir la page sur Bases de R pour plus d’informations sur les “packages” R.","code":"\npacman::p_load(\n  rio,            # importer/exporter \n  here,           # localiser des fichiers\n  stringr,         # travailler avec des caractères \n  janitor,\n  tidyverse,      # inclut ggplot2 et d'autres extensions de data management\n  ggforce\n)"},{"path":"ggplot_basics.html","id":"importer-des-données-4","chapter":"30 Les bases de ggplot","heading":"Importer des données","text":"Pour commencer, nous importons le jeu de données des cas d’une épidémie d’Ebola simulée. Si vous voulez suivre en travaillant sur le jeu de données, cliquez pour télécharger la version “clean”  (en fichier .rds). Importez les données avec la fonction import() du “package” rio (elle gère de nombreux types de fichiers comme .xlsx, .csv, .rds - voir la page Importation et exportation pour plus de détails).Les 50 premières lignes de la liste linéaire sont affichées ci-dessous.\nNous allons nous concentrer sur les variables continues age, wt_kg (le poids en kilos), ct_blood (valeurs CT), et days_onset_hosp (différence entre la date de début de symptômes et l’hospitalisation).","code":"\nlinelist <- rio::import(\"linelist_cleaned.rds\")"},{"path":"ggplot_basics.html","id":"nettoyage-général","chapter":"30 Les bases de ggplot","heading":"Nettoyage général","text":"Lorsque nous préparons des données pour les visualiser, il est préférable de faire en sorte qu’elles respectent autant que possible les normes pour des données bien rangées. Les pages de ce manuel consacrées à la gestion des données, telles que Nettoyage des données et fonctions de base, expliquent comment y parvenir.En préparant les données pour la visualisation, nous pouvons avoir recours à certaines pratiques simples qui pourraient améliorer le contenu des données pour faciliter et rendre pratique leur représentation. Toutefois cela n’équivaut pas nécessairement à une meilleure manipulation des données. Par exemple :Remplacer les valeurs manquantes NA dans une colonne de caractères par la chaîne de caractères “Inconnu”.Envisager de convertir une colonne en classe facteur pour que leurs valeurs aient des niveaux ordinaux prescrits.Nettoyer certaines colonnes de manière à ce que leurs valeurs (qui étaient codées de façon à être maniables) avec des caractères spéciaux comme des “underscores” (tirets bas), etc. soient transformées en texte normal ou en majuscules (voir Caractères et chaînes de caractères).Voici quelques exemples concrets de ce genre de pratiques :","code":"\n#creer une version d'affichage des colonnes avec des noms plus pratiques/maniables\nlinelist <- linelist %>%\n  mutate(\n    gender_disp = case_when(gender == \"m\" ~ \"Male\",        # m à Male \n                            gender == \"f\" ~ \"Female\",      # f à Female,\n                            is.na(gender) ~ \"Unknown\"),    # NA à Unknown\n    \n    outcome_disp = replace_na(outcome, \"Unknown\")          # remplacer les valeurs NA de la variable \"outcome\" par \"Unknown\" (\"Inconnu\").\n  )"},{"path":"ggplot_basics.html","id":"transformation-large-long","chapter":"30 Les bases de ggplot","heading":"Transformation large-long","text":"En ce qui concerne la structure des données, pour ggplot2, nous voulons souvent faire pivoter nos données dans des formats longs. Pour en savoir plus, consultez la page Pivoter les données.Par exemple, supposons que nous voulons visualiser des données qui sont dans un format “large”, comme pour chaque cas dans la linelist et leurs symptômes. Ci-dessous, nous créons une mini-linelist appelée symptoms_data qui ne contient que les colonnes case_id et les différentes variables des symptômes.Voici à quoi ressemblent les 50 premières lignes de cette mini-linelist - voyez comment elles sont présentées en format “large” avec chaque symptôme en tant que colonne :Si nous voulions représenter graphiquement le nombre de cas présentant des symptômes spécifiques, nous sommes limités par le fait que chaque symptôme est une colonne spécifique. Cependant, nous pouvons restructurer (“pivoter”) les colonnes de symptômes dans un format plus long comme ceci :Voici les 50 premières lignes. Notez que chaque cas désormais 5 lignes - une pour chaque symptôme possible. Les nouvelles colonnes symptom_name et symptom_is_present sont le résultat de la restructuration (ou “pivot”). Il faut cependant retenir que ce format peut ne pas être très utile pour d’autres opérations, mais qu’il est utile pour la représentation des données.","code":"\nsymptoms_data <- linelist %>% \n  select(c(case_id, fever, chills, cough, aches, vomit))\nsymptoms_data_long <- symptoms_data %>%    # commencer avec la mini-linelist appelée symptoms_data\n  \n  pivot_longer(\n    cols = -case_id,                       # pivoter toutes les colonnes à l'exception de case_id (on veut regrouper les colonnes avec les symptômes)\n    names_to = \"symptom_name\",             # assigner un nom à la nouvelle colonne qui va contenir les différents symptômes regroupés \n    values_to = \"symptom_is_present\") %>%  # assigner un nom à la nouvelle colonne qui va contenir les valeurs des différents symptômes regroupés (yes/no)\n  \n  mutate(symptom_is_present = replace_na(symptom_is_present, \"unknown\")) # convertir les valeurs NA en \"unknown\" (inconnu)"},{"path":"ggplot_basics.html","id":"bases-de-ggplot","chapter":"30 Les bases de ggplot","heading":"30.2 Bases de ggplot","text":"“Grammaire des graphiques” - ggplot2Constuire/générer des graphiques avec ggplot2 est basé sur “l’ajout” de couches de graphique et d’éléments de conception/représentation les uns sur les autres, chaque commande étant ajoutée aux précédentes avec un symbole “plus” (+). Le résultat est un ensemble d’objets graphiques multicouche qui peut être enregistré, modifié, imprimé, exporté, etc.Les objets ggplot peuvent être très complexes, mais l’ordre de base des couches ressemble généralement à ceci :Commencez par la commande de base ggplot() - cela “ouvre” le ggplot et permet d’ajouter les fonctions suivantes avec +. Généralement, le jeu de données à partir duquel veut générer des graphiques est également spécifié comme argument dans cette commande.Ajouter des couches “geom” - ces fonctions sont des éléments de représentation graphique qui permettent de visualiser les données comme des formes géométriques (geoms), par exemple comme un graphique à barres, un graphique linéaire, un nuage de points, un histogramme (ou une combinaison des différentes formes!). Ces fonctions commencent toutes par le préfixe geom_.Ajoutez des éléments de conception au graphique tels que les noms des axes, le titre, les polices, les tailles, les schémas de couleurs, les légendes ou la rotation des axes.Un exemple simple de code fictif permettant de dessiner un graphique avec ggplot2 est le suivant. Nous allons expliquer chaque composante dans les sections ci-dessous.","code":"\n# représenter les données dans my_data comme des points coloriés en rouge\nggplot(data = my_data)+                   # utiliser le jeu de données \"my_data\"\n  geom_point(                             # ajouter une couche de points (dots)\n    mapping = aes(x = col1, y = col2),    # préciser quelles données de my_data nous voulons représenter sous forme de points en donnant les coordonnées précises des points pour chaque axe\n    color = \"red\")+                       # autres spécifications pour le geom\n  labs()+                                 # ici on ajoute les titres, noms des axes, etc.\n  theme()                                 # ici on ajuste les couleurs, les polices, les tailles, etc. pour les éléments du graphique qui ne dépende pas des données (axes, titres, etc.) "},{"path":"ggplot_basics.html","id":"ggplot","chapter":"30 Les bases de ggplot","heading":"30.3 ggplot()","text":"La commande initiale de tout graphique ggplot2 est ggplot(). Cette commande crée simplement un cadre blanc qui représente la base de l’objet graphique et sur lequel peut ajouter des couches. Elle “ouvre” la voie à l’ajout de couches supplémentaires avec le symbole +.Généralement, la commande ggplot() inclut l’argument data = pour le graphique. Ceci permet de définir le jeu de données qui sera utilisé par défaut pour les couches suivantes du graphique.Cette commande se terminera par un + après la fermeture des parenthèses. Cela laisse la commande “ouverte”. Les fonctions ne s’exécuteront et le graphique n’apparaîtra que si la commande complète inclut une couche finale sans un + à la fin. Cela indique qu’ne veut plus rajouter d’éléments de représentation graphique et que le graphique final peut être affiché.","code":"\n# Ceci dessine juste un cadre blanc qui est la base de l'objet graphique\nggplot(data = linelist)"},{"path":"ggplot_basics.html","id":"geoms","chapter":"30 Les bases de ggplot","heading":"30.4 Geoms","text":"Un cadre blanc (la base de l’objet graphique) n’est certainement pas suffisant - nous devons créer des premiers éléments du graphique qui définissent les formes géométriques du graphique à partir de nos données (par exemple, des diagrammes en barres, des histogrammes, des nuages de points, des diagrammes en boîte).Ceci est fait en ajoutant des couches “geoms” à la commande initiale ggplot(). Il existe de nombreuses fonctions ggplot2 qui créent des “geoms”. Chacune de ces fonctions commence par “geom_”, nous les appellerons donc génériquement geom_XXXX(). Il y plus de 40 “geoms” dans ggplot2 et beaucoup d’autres créés par des utilisateurs. Vous pouvez les voir sur la galerie ggplot2. Certains parmi les “geoms” les plus utilisés sont listés ci-dessous :Histogrammes - geom_histogram()Diagrammes en barres - geom_bar() ou geom_col() (voir la section “Diagrammes en barres”)Les diagrammes en boîte - geom_boxplot().Les nuages de points (par exemple les diagrammes de dispersion) - geom_point().Graphiques linéaires - geom_line() ou geom_path().Lignes de tendance - geom_smooth().Dans un graphique, peut afficher un ou plusieurs “geom”. Chacun d’entre eux est ajouté aux commandes ggplot2 précédentes avec un +, et ils sont représentés séquentiellement de sorte que les “geom” les plus récents soient tracés au-dessus des précédents.","code":""},{"path":"ggplot_basics.html","id":"ggplot_basics_mapping","chapter":"30 Les bases de ggplot","heading":"30.5 “Mappage” ou comment faire correspondre les données au graphique","text":"La plupart des fonctions “geom” doivent savoir les variables précises du jeu de données qu’elles doivent utiliser pour créer leurs formes. Nous devons donc leur indiquer comment mapper (assigner) ces variables aux attributs du graphique tels que les axes (quelle variable sera représentée sur quel axe), les couleurs des formes (quelle modalité de quelle variable représenter en telle ou telle couleur), les tailles des formes, etc. Pour la plupart des “geom”, les composantes essentielles qui doivent être mises en correspondance avec les colonnes des données sont l’axe des x et (si nécessaire) celui des y.parle ainsi de “mappage” qui n’est dans ce cadre rien d’autre qu’une mise en relation entre un attribut graphique du “geom” et une variable du jeu de données utilisée pour faire la représentation graphique.Ce “mappage” (correspondance/assignation) se fait avec l’argument mapping =. Les “mappages” que nous fournissons à l’argument mapping doivent être enveloppés dans la fonction aes(), donc nous écririons quelque chose comme mapping = aes(x = col1, y = col2), comme montré ci-dessous.Ci-dessous, dans la commande ggplot(), les données sont définies comme la liste des cas linelist. Dans l’argument mapping = aes(), la colonne age est mise en correspondance avec l’axe des x, et la colonne wt_kg est mise en correspondance avec l’axe des y.Après un +, les commandes de représentation graphique continuent. Une forme est créée avec la fonction “geom” geom_point(). Ce “geom” hérite des “mappages” de la commande ggplot() ci-dessus - il connaît les affectations axe-colonne et procède à la visualisation de ces relations sous forme de points sur la base du graphique (le cadre blanc dessiné avec la première fonction).Comme autre exemple, les commandes suivantes utilisent les mêmes données, un “mappage” légèrement différent, et un “geom” différent. La fonction geom_histogram() ne nécessite qu’une colonne mappée sur l’axe des x, puisque l’axe des y est généré automatiquement (représente le comptage de chaque modalité fait automatiquement par la fonction).","code":"\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+\n  geom_point()\nggplot(data = linelist, mapping = aes(x = age))+\n  geom_histogram()"},{"path":"ggplot_basics.html","id":"attributs-esthétiques-du-graphique","chapter":"30 Les bases de ggplot","heading":"Attributs (esthétiques) du graphique","text":"Dans le jargon de ggplot, “l’esthétique” d’un graphique une signification assez spécifique. Il s’agit d’une propriété visuelle des données représentées. Notons que le terme “esthétique” fait ici référence aux données de variables “mappées” dans les “geoms”/formes - et non à l’affichage des éléments environnants du graphique qui ne dépendent pas des données tel que les titres, les noms des axes, la couleur de fond (qu’pourrait associer au mot “esthétique” en français courant). Dans ggplot, ces éléments d’affichage non reliés aux données sont appelés “thèmes” et sont déterminés par une commande theme() (voir cette section).Par conséquent, les caractéristiques esthétiques/attributs du graphique peuvent concerner les couleurs, les tailles, la transparence, le placement, etc. des données représentées. Tous les “geoms” n’auront pas les mêmes options esthétiques, mais beaucoup parmi ces options peuvent être utilisées par la plupart des “geoms”. Voici quelques exemples :shape = Afficher un point avec geom_point() comme un point, une étoile, un triangle, ou un carré…fill = La couleur intérieure (par exemple d’une barre ou d’un diagramme en boîte)color = La ligne extérieure d’une barre, d’un diagramme en boîte, etc., ou la couleur du point si utilise geom_point()size = Taille (par exemple, l’épaisseur de la ligne, la taille du point)alpha = La transparence (1 = opaque, 0 = invisible)binwidth = La largeur des cases de l’histogrammewidth = La largeur des colonnes du diagramme en barrelinetype = Le type de ligne (par exemple, solide, en pointillés …)Il est possible d’affecter des valeurs à ces attributs de deux manières :Affecter une valeur fixe/statique (par exemple, color = \"blue\") qui sera donc appliquée à toutes les observations représentéesRelier l’attribut à une variable de données (par exemple, color = hospital) de telle sorte que l’affichage de chaque observation dépende de sa valeur dans cette variable.\n","code":""},{"path":"ggplot_basics.html","id":"affecter-un-attribut-à-une-valeur-fixe","chapter":"30 Les bases de ggplot","heading":"Affecter un attribut à une valeur fixe","text":"Si nous souhaitions que l’attribut de l’objet graphique soit statique, c’est-à-dire qu’elle soit la même pour chaque observation des données, nous écrivons son affectation dans le “geom” mais en dehors de toute instruction mapping = aes(). Ces affectations peuvent ressembler à size = 1 ou color = \"blue\". Voici deux exemples :Dans le premier exemple, l’instruction mapping = aes() se trouve dans la commande ggplot() et les axes sont associés aux variables d’âge et de poids dans notre jeu de données. Les attributs du graphique, color =, size =, et alpha = (pour déterminer la transparence) sont assignées à des valeurs statiques. Pour plus de clarté, ceci est fait dans la fonction geom_point(), car vous pouvez ajouter d’autres “geoms” par la suite qui prendraient des valeurs différentes pour leur esthétique d’affichage.Dans le deuxième exemple, l’histogramme ne nécessite que la mise en relation de la variable d’intérêt à l’axe des x . Les valeurs statiques de l’histogramme binwidth =, color =, fill = (couleur de l’intérieur des barres) et alpha = sont à nouveau définies dans le “geom”.","code":"\n# Diagramme de dispersion\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  # définir les données et le mappage des axes\n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)         # définir l'esthétique du point statique\n\n# histogramme\nggplot(data = linelist, mapping = aes(x = age))+       # définir les données et les axes\n  geom_histogram(              # afficher l'histogramme\n    binwidth = 7,                # largeur des barres\n    color = \"red\",               # couleur de la ligne de la barre\n    fill = \"blue\",               # couleur intérieure de la barre\n    alpha = 0.1)                 # transparence de la barre"},{"path":"ggplot_basics.html","id":"relier-un-attribut-aux-valeurs-dune-variable","chapter":"30 Les bases de ggplot","heading":"Relier un attribut aux valeurs d’une variable","text":"L’alternative consiste à relier l’attribut de l’objet graphique aux valeurs d’une variable. Dans cette approche, l’affichage de cet attribut dépendra des valeurs prises dans cette variable. Si les valeurs de la variable sont continues, l’échelle d’affichage (légende) de cet attribut sera continue. Si les valeurs de la variable sont discrètes, la légende affichera chaque valeur et les données représentées apparaîtront comme “groupées” de manière distincte (pour en savoir plus, consultez la section groupage de cette page).Pour ce faire, nous devons associer l’attribut du graphique à un nom de variable de notre jeu de données (sans guillemets) ie le “mapper”. Ceci doit donc être fait dans une fonction mapping = aes() (note : il y plusieurs endroits dans le code où nous pouvons faire ces assignations (de mappage), comme discuté ci-dessous).Deux exemples sont présentés ci-dessous.Dans le premier exemple, l’attribut color = (de chaque point) est mappé à la variable age - et une échelle est apparue dans la légende ! Pour l’instant, notons simplement que l’échelle existe - nous montrerons comment la modifier dans les sections suivantes.Dans le deuxième exemple, deux nouveaux attributs sont également associés à des variables (color = et size =), tandis que les attributs shape = et alpha = sont associés à des valeurs fixes en dehors de toute fonction mapping = aes().Note : Les axes sont toujours assignées à des variables dans les données (pas à des valeurs statiques), et sont donc toujours mappées dans mapping = aes().Il devient important de garder la trace des différentes couches du graphique et les attributs lorsque vous créez des graphiques plus complexes - par exemple des graphiques avec plusieurs “geoms”. Dans l’exemple ci-dessous, l’attribut size = est assigné deux fois - une fois pour geom_point() et une fois pour geom_smooth() - et les deux fois comme une valeur statique.","code":"\n# Diagramme de dispersion\nggplot(data = linelist,   # définir les données\n       mapping = aes(     # mapper l'attribut aux valeurs de la colonne\n         x = age,         # mapper l'axe des x à la variable des âges           \n         y = wt_kg,       # mapper l'axe des y à la variable des poids\n         color = age)     # mapper l'attribut color à la variable des âges\n       )+     \n  geom_point()         # afficher les données comme des points \n\n#  Diagramme de dispersion\nggplot(data = linelist,   # définir les données\n       mapping = aes(     # mapper les attributs aux variables\n         x = age,           # mapper l'axe des x à la variable des âges           \n         y = wt_kg,         # mapper l'axe des y à la variable des poids\n         color = age,       #mapper l'attribut color à la variable des âges\n         size = age))+      # mapper l'attribut size (taille des points) à la variable des âges\n  geom_point(             # afficher les données comme des points\n    shape = \"diamond\",      # preciser la forme des points comme des diamants\n    alpha = 0.3)            # transparence des points à 30%.\nggplot(data = linelist,\n       mapping = aes(           # mapper les attributs qux variables\n         x = age,\n         y = wt_kg,\n         color = age_years)\n       ) + \n  geom_point(                   # ajouter des points pour chaque ligne de données\n    size = 1,\n    alpha = 0.5) +  \n  geom_smooth(                  # ajouter une courbe de tendance \n    method = \"lm\",              # avec une méthode linéaire\n    size = 2)                   # taille (largeur de la ligne) de 2"},{"path":"ggplot_basics.html","id":"ggplot_basics_map_loc","chapter":"30 Les bases de ggplot","heading":"Comment et quand faire le mappage","text":"Le mappage dans mapping = aes() peut être écrit à plusieurs endroits dans les commandes du ggplot et peut même être écrit plus d’une fois. Cela peut être écrit dans la commande supérieure ggplot(), et/ou pour chaque “geom” individuel en dessous. Les possibilités comprennent :Les affectations de mappage effectuées dans la commande supérieure ggplot() et qui seront héritées par défaut dans tous les “geom” inférieurs, comme c’est le cas pour x = et y = ci-dessous.Les affectations de mappage effectuées dans un “geom” et qui ne s’appliquent qu’à ce “geom”.De même, l’argument data = spécifié dans la commande supérieure ggplot() s’appliquera par défaut à tous les “geom” inférieurs. Toutefois peut aussi spécifier des jeux de données différents pour chaque “geom” (mais c’est plus complexe).Ainsi, chacune des 3 commandes suivantes (avec des mappages faits à différents niveaux du code) créera le même graphique :","code":"\n#  Ces commandes produiront exactement le même graphique.\nggplot(data = linelist, mapping = aes(x = age))+\n  geom_histogram()\n\nggplot(data = linelist)+\n  geom_histogram(mapping = aes(x = age))\n\nggplot()+\n  geom_histogram(data = linelist, mapping = aes(x = age))"},{"path":"ggplot_basics.html","id":"ggplotgroups","chapter":"30 Les bases de ggplot","heading":"Groupage","text":"peut facilement regrouper les données et les “représenter par groupe”. En fait, nous l’avons déjà fait !Pour cela nous allons assigner la colonne de “regroupement” à l’attribut approprié du graphique, dans un mapping = aes(). Ci-dessus, nous avons fait une démonstration en utilisant des valeurs continues lorsque nous avons assigné l’attributsize = à la variable age. Cependant, cela fonctionne de la même manière pour les colonnes discrètes/catégorielles.Par exemple, si nous voulons que les points soient affichés par sexe, nous pouvons définir mapping = aes(color = gender). Une légende apparaît automatiquement. Cette affectation peut être faite dans le mapping = aes() de la commande supérieure ggplot() (et elle va être héritée par le “geom”), ou elle peut être définie dans un mapping = aes() séparé dans le “geom”. Les deux approches sont présentées ci-dessous :Notez que selon le “geom”, vous devrez utiliser différents arguments pour regrouper les données. Pour geom_point(), vous utiliserez probablement color =, shape = ou size =. Alors que pour geom_bar(), vous utiliseriez plus probablement fill =. Cela dépend simplement du “geom” et de l’attribut du graphique que vous voulez utiliser pour refléter les groupages.Pour votre information - la manière la plus basique d’regrouper les données est d’utiliser seulement l’argument group = dans mapping = aes(). Cependant, cela ne changera pas les couleurs, le remplissage ou les formes. Elle ne créera pas non plus de légende. Pourtant, les données sont groupées, donc les affichages statistiques des données peuvent être affectés.Pour ajuster l’ordre des groupes dans un graphique, consultez la page Trucs et Astuces avec ggplot ou la page sur les Facteurs. Vous trouverez de nombreux exemples de graphiques groupés dans les sections ci-dessous sur la représentation des données continues et catégorielles.","code":"\nggplot(data = linelist,\n       mapping = aes(x = age, y = wt_kg, color = gender))+\n  geom_point(alpha = 0.5)\n# Cette autre version de code produit le même graphique\nggplot(data = linelist,\n       mapping = aes(x = age, y = wt_kg))+\n  geom_point(\n    mapping = aes(color = gender),\n    alpha = 0.5)"},{"path":"ggplot_basics.html","id":"ggplot_basics_facet","chapter":"30 Les bases de ggplot","heading":"30.6 Facets / Petits-multiples","text":"Les “facets”, ou “petits-multiples”, sont utilisés pour séparer un graphique en une figure à plusieurs sections selon les valeurs d’une ou plusieurs variables qualitatives. Le même type de graphique est ainsi créé plusieurs fois, chaque (sous-)graphique utilisant un sous-groupe du même ensemble de données.Le “faceting” est une fonctionnalité fournie avec ggplot2, de sorte que les légendes et les axes de chaque graphe d’un sous-groupe du jeu de données (“facet”) sont automatiquement alignés. Il existe d’autres paquets (“packages”) discutés dans la page Trucs et Astuces avec ggplot qui sont utilisés pour combiner des graphiques complètement différents (.e. qui cette fois ne sont pas les mêmes graphiques répétés pour chaque sous-groupe d’un même jeu de données) en une seule figure. peut citer cowplot et patchwork.Le “faceting” est effectué avec l’une des fonctions ggplot2 suivantes :facet_wrap() Pour montrer un graphique différent pour chaque niveau d’une seule variable. Un exemple de ceci pourrait être de montrer une courbe d’épidémie différente pour chaque hôpital dans une région. Les “facets” sont ordonnées par ordre alphabétique, sauf si la variable est un facteur avec un autre ordre défini.peut utiliser certaines options pour déterminer la disposition des “facets”, par exemple nrow = 1 ou ncol = 1 pour contrôler le nombre de lignes ou de colonnes dans lesquelles les “facets” sont disposés.facet_grid() Cette fonction est utilisée lorsque nous souhaitons introduire une seconde variable dans l’arrangement des “facets”. Ici, chaque graphe d’une grille montre l’intersection entre les valeurs de deux variables. Par exemple, des courbes épidémiques pour chaque combinaison hôpital-groupe d’âge avec les hôpitaux en haut (colonnes) et les groupes d’âge sur les côtés (lignes).Dans ce cas-ci nrow et ncol ne sont pas pertinents, car les sous-groupes sont présentés dans une grille.Chacune de ces fonctions accepte une syntaxe de formule pour spécifier la ou les variables à utiliser pour le “faceting” Les deux acceptent jusqu’à deux variables, une de chaque côté d’un tilde ~.Pour facet_wrap(), écrira le plus souvent le nom d’une seule variable précédée d’un tilde ~ comme facet_wrap(~hospital). Cependant peut préciser deux noms de variables si c’est que l’veut représenter facet_wrap(outcome ~hospital) - chaque combinaison unique s’affichera dans un graphique séparé, mais ils ne seront pas disposés dans une grille. Si décide de ne fournir qu’une seule variable à la fonction, un point . est utilisé comme bouche-trou de l’autre côté de la formule - voir les exemples de code.Pour facet_wrap(), écrira le plus souvent le nom d’une seule variable précédée d’un tilde ~ comme facet_wrap(~hospital). Cependant peut préciser deux noms de variables si c’est que l’veut représenter facet_wrap(outcome ~hospital) - chaque combinaison unique s’affichera dans un graphique séparé, mais ils ne seront pas disposés dans une grille. Si décide de ne fournir qu’une seule variable à la fonction, un point . est utilisé comme bouche-trou de l’autre côté de la formule - voir les exemples de code.Pour facet_grid() nous pouvons également spécifier une ou deux variables à la formule (facet_grid( rows ~ columns)). Si ne veut en spécifier qu’une, peut placer un point . de l’un ou l’autre côté du tilde comme facet_grid(. ~ hospital) ou facet_grid(hospital ~ .).Pour facet_grid() nous pouvons également spécifier une ou deux variables à la formule (facet_grid( rows ~ columns)). Si ne veut en spécifier qu’une, peut placer un point . de l’un ou l’autre côté du tilde comme facet_grid(. ~ hospital) ou facet_grid(hospital ~ .).Les “facets” peuvent rapidement contenir une quantité écrasante d’informations - il est important de s’assurer que nous n’avons pas trop de modalités pour chaque variable qualitative que nous choisissons de “facetter”. Voici quelques exemples rapides avec le jeu de données sur le paludisme (voir Télécharger le manuel et les données) qui contient les données sur le nombre de cas de paludisme quotidiens pour différentes structures de santé par groupe d’âge.Ci-dessous, nous importons ces données et effectuons quelques modifications rapides pour plus de simplicité :Les 50 premières lignes des données sur le paludisme sont affichées ci-dessous. Notez qu’il y une colonne malaria_tot, mais aussi des colonnes pour le nombre de cas par groupe d’âge (celles-ci seront utilisées dans le second exemple facet_grid()).","code":"\n# Ces donnees sont le nombre de cas de palu par jour par structure\nmalaria_data <- import(here(\"data\", \"malaria_facility_count_data.rds\")) %>%  # importer\n  select(-submitted_date, -Province, -newid)                                 # enlever les colonnes (variables) dont on n'a pas besoin pour les prochaines étapes"},{"path":"ggplot_basics.html","id":"facet_wrap","chapter":"30 Les bases de ggplot","heading":"facet_wrap()","text":"Pour le moment, concentrons-nous sur les variables malaria_tot et District. Ignorons pour l’instant les colonnes du nombre de cas par âge. Nous allons tracer des courbes épidémiques avec geom_col(), qui produit une colonne pour chaque jour à la hauteur spécifiée sur l’axe des y fournie par la variable malaria_tot (les données sont déjà des nombres de cas quotidiens, donc nous utilisons geom_col() - voir la section “Diagramme en barres” ci-dessous).Lorsque nous ajoutons la commande facet_wrap(), nous spécifions un tilde (~) et ensuite la variable à utiliser pour le “facet” (District dans ce cas). peut placer une autre variable sur le côté gauche du tilde, - cela créera un “facet” pour chaque combinaison - mais nous recommandons de le faire avec facet_grid() à la place. Dans ce cas d’utilisation, un “facet” est créé pour chaque valeur unique de District.","code":"\n# Un graphique avec des facets par district\nggplot(malaria_data, aes(x = data_date, y = malaria_tot)) +\n  geom_col(width = 1, fill = \"darkred\") +       # tracer le nombre de cas sous forme de colonnes\n  theme_minimal()+                              # simplifier les  arrière-plans\n  labs(                                         # ajouter  les noms d'axes, titres ... \n    x = \"Date of report\",\n    y = \"Malaria cases\",\n    title = \"Malaria cases by district\") +\n  facet_wrap(~District)                       # les facets sont créés"},{"path":"ggplot_basics.html","id":"facet_grid","chapter":"30 Les bases de ggplot","heading":"facet_grid()","text":"Nous pouvons utiliser une approche facet_grid() pour croiser deux variables. Disons que nous voulons croiser District et la variable âge. Eh bien, nous devons faire quelques transformations de données sur les colonnes d’âge pour obtenir ces données dans le format “long” préféré de ggplot. Les groupes d’âge ont tous leurs propres colonnes - nous les voulons dans une seule colonne appelée age_group et une autre appelée num_cases. Voir la page sur Pivoter les données pour plus d’informations sur ce processus.Les 50 premières lignes des données transformées ressemblent désormais comme suit :Lorsque vous passez les deux variables à facet_grid(), le plus simple est d’utiliser la notation de formule (par exemple x ~ y) où x représente les lignes et y les colonnes. Voici le graphique, utilisant facet_grid() pour montrer les graphiques pour chaque combinaison des colonnes age_group et District.","code":"\nmalaria_age <- malaria_data %>%\n  select(-malaria_tot) %>% \n  pivot_longer(\n    cols = c(starts_with(\"malaria_rdt_\")),  # choisir la variable à mettre en format \"long\"\n    names_to = \"age_group\",      # la nouvelle variable avec tous les groupes d'âge est nommée age_group\n    values_to = \"num_cases\"      # les valeurs dans les anciennes colonnes séparées sont regroupées dans une nouvelle unique colonne appelée num_cases\n  ) %>%\n  mutate(\n    age_group = str_replace(age_group, \"malaria_rdt_\", \"\"),\n    age_group = forcats::fct_relevel(age_group, \"5-14\", after = 1))\nggplot(malaria_age, aes(x = data_date, y = num_cases)) +\n  geom_col(fill = \"darkred\", width = 1) +\n  theme_minimal()+\n  labs(\n    x = \"Date of report\",\n    y = \"Malaria cases\",\n    title = \"Malaria cases by district and age group\"\n  ) +\n  facet_grid(District ~ age_group)"},{"path":"ggplot_basics.html","id":"axes-libres-ou-fixes","chapter":"30 Les bases de ggplot","heading":"Axes libres ou fixes","text":"Les échelles des axes affichées lors du “faceting” sont par défaut les mêmes (fixes) pour tous les “facets”. C’est utile pour les comparaisons croisées, mais pas toujours approprié.Lorsque l’utilise facet_wrap() ou facet_grid(), peut ajouter scales = \"free_y\" pour “libérer” ou rendre indépendant les axes y des “facets” afin qu’ils soient représentés à l’échelle de leur sous-ensemble de données spécifique. Ceci est particulièrement utile si les nombres sont faibles pour une des sous-catégories et que les tendances sont difficiles à voir en laissant l’échelle pareille pour tous les “facets”. Au lieu de “free_y”, peut aussi écrire “free_x” pour faire la même chose pour l’axe des x (par exemple pour les dates) ou pour faire court “free” pour les deux axes. Notez que dans facet_grid, les échelles y seront les mêmes pour les “facets” de la même ligne, et les échelles x seront les mêmes pour les “facets” de la même colonne.En utilisant uniquement facet_grid, peut ajouter space = \"free_y\" ou space = \"free_x\" pour que la hauteur ou la largeur réelle de la “facets” soit pondérée par les valeurs de la figure à l’intérieur. Cela ne fonctionne que si scales = \"free\" (y ou x) est déjà appliqué.","code":"\n# Axe des y libre\nggplot(malaria_data, aes(x = data_date, y = malaria_tot)) +\n  geom_col(width = 1, fill = \"darkred\") +       # tracer le nombre de cas sous forme de colonnes\n  theme_minimal()+                              # simplifier les  arrière-plans\n  labs(                                         # ajouter  les noms d'axes, titres ... \n    x = \"Date of report\",\n    y = \"Malaria cases\",\n    title = \"Malaria cases by district - 'free' x and y axes\") +\n  facet_wrap(~District, scales = \"free\")        # les facets sont créés"},{"path":"ggplot_basics.html","id":"réorganiser-laffichage-des-facets","chapter":"30 Les bases de ggplot","heading":"Réorganiser l’affichage des “facets”","text":"Voir ce post sur la façon de réorganiser les modalités/niveaux des variables facteurs dans les “facets”.","code":""},{"path":"ggplot_basics.html","id":"stocker-les-graphiques-produits","chapter":"30 Les bases de ggplot","heading":"30.7 Stocker les graphiques produits","text":"","code":""},{"path":"ggplot_basics.html","id":"sauvegarder-les-graphiques-dans-lenvironnement","chapter":"30 Les bases de ggplot","heading":"Sauvegarder les graphiques dans l’environnement","text":"Par défaut, lorsque nous exécutons une commande ggplot(), le graphique sera affiché dans l’onglet “Plots” de RStudio. Cependant, nous pouvons également enregistrer le celui-ci en tant qu’objet en utilisant l’opérateur d’affectation <- et en lui donnant un nom. Il ne s’affichera alors que si le nom de l’objet lui-même est exécuté. peut également l’afficher en faisant appel à la fonction R base print(), mais cela n’est nécessaire que dans certaines circonstances, par exemple si le graphique est créé à l’intérieur d’une boucle utilisée pour afficher plusieurs graphiques à la fois (voir la page Itération, boucles et listes).","code":"\n# definir le graphique\nage_by_wt <- ggplot(data = linelist, mapping = aes(x = age_years, y = wt_kg, color = age_years))+\n  geom_point(alpha = 0.1)\n\n# l'afficher\nage_by_wt    "},{"path":"ggplot_basics.html","id":"modifier-des-graphiques-de-lenvironnement","chapter":"30 Les bases de ggplot","heading":"Modifier des graphiques de l’environnement","text":"Une des particularités de ggplot2 est que nous pouvons définir un graphiquee (comme ci-dessus), puis lui ajouter des couches en commençant par son nom. Nous n’avons pas besoin de répéter toutes les commandes qui ont créé le graphique original !Par exemple, pour modifier le graphe age_by_wt qui été défini ci-dessus, pour inclure une ligne verticale à l’âge de 50 ans, il suffit d’ajouter un + et de commencer à ajouter des couches supplémentaires au graphe.","code":"\nage_by_wt+\n  geom_vline(xintercept = 50)"},{"path":"ggplot_basics.html","id":"exporter-les-graphiques","chapter":"30 Les bases de ggplot","heading":"Exporter les graphiques","text":"L’exportation de ggplots est facilitée par la fonction ggsave() de ggplot2. Elle peut fonctionner de deux façons :Spécifier le nom de l’objet graphique, puis le chemin d’accès au fichier et le nom du fichier avec l’extension.\nPar exemple : ggsave(my_plot, (\"plots\", \"my_plot.png\"))\nPar exemple : ggsave(my_plot, (\"plots\", \"my_plot.png\"))Exécutez la commande avec seulement un chemin d’accès au fichier, pour sauvegarder le dernier graphique qui été imprimé.\nPar exemple : ggsave((\"plots\", \"my_plot.png\")).\nPar exemple : ggsave((\"plots\", \"my_plot.png\")).Vous pouvez exporter en png, pdf, jpeg, tiff, bmp, svg, ou plusieurs autres types de fichiers, en spécifiant l’extension du fichier dans le chemin d’accès au fichier.Vous pouvez également spécifier les arguments width = (largeur), height = (hauteur), et units = (unités) (soit “”, “cm”, ou “mm”). Vous pouvez également spécifier dpi = avec un nombre pour la résolution du graphe (par exemple 300). Consultez les détails de la fonction en entrant ?ggsave ou en lisant la documentation en ligne.Rappelez-vous que vous pouvez utiliser la syntaxe () pour fournir le chemin d’accès au fichier souhaité. Voir la page Importation et exportation pour plus d’informations.","code":""},{"path":"ggplot_basics.html","id":"etiquettes-du-graphe","chapter":"30 Les bases de ggplot","heading":"30.8 Etiquettes du graphe","text":"Vous voudrez certainement ajouter ou ajuster les étiquettes du graphique. Ceci est le plus facile à faire avec la fonction labs() qui est ajoutée au graphe avec + tout comme les “geoms” l’ont été.Dans labs(), vous pouvez fournir des chaînes de caractères à ces arguments :x = et y = Le titre de l’axe des x et de l’axe des y (étiquettes des axes)title = Le titre du graphique principalsubtitle = Le sous-titre du graphique, en plus petit texte sous le titrecaption = La note de bas de graphe du graphique, en bas à droite par défaut.Voici un graphique que nous avons fait plus tôt, mais avec des étiquettes plus jolies :ASTUCE: Remarquez comment, dans l’affectation de la note de bas de graphe, nous avons utilisé str_glue() du package stringr pour implanter du code R dynamique dans le texte de la chaîne de caractères. La légende affichera la date “Data :” qui reflète la date d’hospitalisation maximale dans la liste linéaire utilisée pour dessiner le graphe. Pour en savoir plus, consultez la page Caractères et chaînes de caractères.NOTE: Une remarque sur la spécification du titre de la légende : Il n’y pas un unique argument “titre de légende”, car peut avoir plusieurs échelles dans votre légende. Dans labs(), peut écrire l’argument pour l’attribut graphique utilisé pour créer la légende, et fournir le titre de cette façon. Par exemple, ci-dessus, nous avons assigné color = age pour créer la légende. Par conséquent, nous fournissons color = à labs() et nous attribuons le titre de légende souhaité (“Age” avec un majuscule). Si crée la légende avec aes(fill = COLUMN), alors dans labs() écrira fill = pour ajuster le titre de cette légende. La section sur les échelles de couleurs dans la page ggplot tips fournit plus de détails sur l’édition des légendes, et une approche alternative utilisant les fonctions scales_().","code":"\nage_by_wt <- ggplot(\n  data = linelist,   # preciser le jeu de donnees\n  mapping = aes(     # mapper les attributs aux valeurs des variables\n         x = age,           # mapper l'axe des x à l'âge            \n         y = wt_kg,         # mapper l'axe des y au poids (weight)\n         color = age))+     # mapper la couleur à l'âge\n  geom_point()+           # afficher les données comme des points\n  labs(\n    title = \"Age and weight distribution\",\n    subtitle = \"Fictional Ebola outbreak, 2014\",\n    x = \"Age in years\",\n    y = \"Weight in kilos\",\n    color = \"Age\",\n    caption = stringr::str_glue(\"Data as of {max(linelist$date_hospitalisation, na.rm=T)}\"))\n\nage_by_wt"},{"path":"ggplot_basics.html","id":"ggplot_basics_themes","chapter":"30 Les bases de ggplot","heading":"30.9 Thèmes","text":"Une des meilleures parties de ggplot2 est le large contrôle que nous pouvons avoir sur le graphique - nous pouvons définir n’importe quoi ! Comme mentionné plus haut, les éléments du graphique qui ne sont pas reliés aux données sont ajustés par la fonction theme(). Par exemple, la couleur de fond du graphique, la présence/absence de lignes de grille, et la police/taille/couleur/alignement du texte (titres, sous-titres, légendes, texte des axes…). Ces ajustements peuvent être effectués de deux manières :Utiliser une fonction thème toute faite theme_() pour faire des ajustements généraux - ceux-ci incluent theme_classic(), theme_minimal(), theme_dark(), theme_light(), theme_grey(), theme_bw() entre autres.Ajustez chaque petit aspect du graphique individuellement dans theme().","code":""},{"path":"ggplot_basics.html","id":"fonctions-thème-toute-faites","chapter":"30 Les bases de ggplot","heading":"Fonctions thème toute faites","text":"Comme elles sont assez simples, nous allons démontrer l’utilisation des fonctions thème prêtes à l’utilisation ci-dessous et ne les décrirons pas davantage ici.NOTE: Notez que tout micro-ajustement supplémentaire avec theme() doit être fait après l’utilisation d’une fonction thème toute faite (sinon les ajustements ne seront pas pris en compte).Ecrivez-les avec des parenthèses vides.","code":"\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  \n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)+\n  labs(title = \"Theme classic\")+\n  theme_classic()\n\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  \n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)+\n  labs(title = \"Theme bw\")+\n  theme_bw()\n\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  \n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)+\n  labs(title = \"Theme minimal\")+\n  theme_minimal()\n\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  \n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)+\n  labs(title = \"Theme gray\")+\n  theme_gray()"},{"path":"ggplot_basics.html","id":"modifier-le-thème","chapter":"30 Les bases de ggplot","heading":"Modifier le thème","text":"La fonction theme() peut prendre un grand nombre d’arguments, dont chacun modifie un aspect très spécifique du graphique. Il n’est pas possible de couvrir tous les arguments, mais nous allons décrire le modèle général pour leur utilisation et vous montrer comment trouver le nom de l’argument dont vous avez besoin. La syntaxe de base est la suivante :Dans theme() écrivez le nom de l’argument pour l’élément du graphique que vous voulez modifier, comme plot.title =Fournissez une fonction element_() à l’argumentLe plus souvent, utilisez element_text(), mais d’autres incluent element_rect() pour les couleurs d’arrière-plan du canevas, ou element_blank() pour supprimer les éléments du graphiqueA l’intérieur de la fonction element_(), écrivez des affectations d’arguments pour faire les ajustements fins que vous désirez.Cette description était assez abstraite, voici donc quelques exemples.Le graphique ci-dessous l’air assez stupide, mais il sert à vous montrer une variété de façons dont vous pouvez ajuster vos graphes.Nous commençons avec le graphique age_by_wt défini juste au-dessus et ajoutons theme_classic().Pour des ajustements plus fins, ajoute theme() et inclut un argument pour chaque élément du graphe à ajuster.Il peut être intéressant d’organiser les arguments en sections logiques. Pour décrire quelques-uns de ceux utilisés ci-dessous :legend.position = est unique en ce qu’il accepte des valeurs simples comme “bottom”, “top”, “left” et “right”. Mais en général, les arguments liés au texte nécessitent que vous placiez les détails dans element_text().La taille du titre avec element_text(size = 30)L’alignement horizontal de la note de bas de graphe avec element_text(hjust = 0) (de droite à gauche)Le sous-titre est en italique avec element_text(face = \"italic\")Voici quelques arguments theme() particulièrement courants. Vous reconnaîtrez certains motifs, comme l’ajout de .x ou .y pour appliquer le changement seulement à un axe.Vous vous dîtes surement “Mais il y tellement d’arguments pour les thémes! Comment pourrais-je les rappeler tous ?”. Ne vous inquiétez pas - il est impossible de se souvenir de tous. Heureusement, il existe quelques outils pour vous aider :La documentation tidyverse sur modifier le thème, qui contient une liste complète.TIP: Exécutez la commande theme_get() de ggplot2 pour imprimer une liste de tous les >90 arguments de theme() sur la console.TIP: Si jamais vous voulez supprimer un élément d’un graphe, vous pouvez aussi le faire via theme(). Passez simplement element_blank() en argument pour le faire disparaître complètement. Pour les légendes, préciser legend.position = \"none\".","code":"\nage_by_wt + \n  theme_classic()+                                 # pre-definir les ajustements avec un theme tout-prêt\n  theme(\n    legend.position = \"bottom\",                    # déplacer la legende en dessous\n    \n    plot.title = element_text(size = 30),          # taille du titre à 30\n    plot.caption = element_text(hjust = 0),        # note de bas de graphe alignée à gauche\n    plot.subtitle = element_text(face = \"italic\"), # sous-titre en italique\n    \n    axis.text.x = element_text(color = \"red\", size = 15, angle = 90), # ajustement pour le texte sur l'axe des x uniquement \n    axis.text.y = element_text(size = 15),         # ajustement pour le texte sur l'axe des y uniquement\n    \n    axis.title = element_text(size = 20)           # ajustement pour les titres des deux axes\n    )     "},{"path":"ggplot_basics.html","id":"couleurs","chapter":"30 Les bases de ggplot","heading":"30.10 Couleurs","text":"Veuillez consulter cette section sur les échelles de couleurs de la page “Trucs et Astuces dans ggplot”.","code":""},{"path":"ggplot_basics.html","id":"utiliser-le-pipe-avec-ggplot2","chapter":"30 Les bases de ggplot","heading":"30.11 Utiliser le “pipe” avec ggplot2","text":"Lorsque vous utilisez des “pipes” pour nettoyer et transformer vos données, il est facile de passer les données transformées dans ggplot().Les “pipes” (qui passent le jeu de données d’une fonction à l’autre) laisseront place aux + une fois que la fonction ggplot() sera appelée. Notez que dans ce cas, il n’est pas nécessaire de spécifier l’argument data =, car il est automatiquement défini comme le jeu de données passé dans le pipe.Voici à quoi cela peut ressembler :","code":"\nlinelist %>%                                                     # commencer avec la liste lineaire\n  select(c(case_id, fever, chills, cough, aches, vomit)) %>%     # selectionner les  variables qui nous interessent\n  pivot_longer(                                                  # pivoter en format long\n    cols = -case_id,                                  \n    names_to = \"symptom_name\",\n    values_to = \"symptom_is_present\") %>%\n  mutate(                                                        # remplacer les valeurs  manquantes\n    symptom_is_present = replace_na(symptom_is_present, \"unknown\")) %>% \n  \n  ggplot(                                                        # commencer le ggplot!\n    mapping = aes(x = symptom_name, fill = symptom_is_present))+ # remarquez qu'ici on passe aux +\n  geom_bar(position = \"fill\", col = \"black\") +                    \n  theme_classic() +\n  labs(\n    x = \"Symptom\",\n    y = \"Symptom status (proportion)\"\n  )"},{"path":"ggplot_basics.html","id":"représenter-des-données-continues","chapter":"30 Les bases de ggplot","heading":"30.12 Représenter des données continues","text":"Tout au long de cette page, vous avez déjà vu de nombreux exemples de représentation de données continues. Nous les consolidons ici brièvement et présentons quelques variantes.\nLes visualisations couvertes ici incluent :Les graphiques pour une variable continue :\nHistogramme, un graphique classique pour présenter la distribution d’une variable continue.\nDiagramme en boîte (également appelé boîte à moustaches), pour montrer les 25ème, 50ème et 75ème percentiles, les extrémités de la distribution et les valeurs aberrantes (limitations importantes).Graphique de gigue, pour montrer toutes les valeurs sous forme de points qui sont “gigueux” afin qu’ils puissent (presque) tous être vus, même si deux d’entre eux ont la même valeur.Graphiques en violon, montre la distribution d’une variable continue basée sur la largeur symétrique du “violon”.\nSina plot, est une combinaison du graphique de gigue et du graphique de violin, où les points individuels sont montrés mais dans la forme symétrique de la distribution (via le “package” ggforce).Nuage de points pour deux variables continues.Heatmaps pour trois variables continues (lien vers la page Heat plots).\nHistogramme, un graphique classique pour présenter la distribution d’une variable continue.\nDiagramme en boîte (également appelé boîte à moustaches), pour montrer les 25ème, 50ème et 75ème percentiles, les extrémités de la distribution et les valeurs aberrantes (limitations importantes).Graphique de gigue, pour montrer toutes les valeurs sous forme de points qui sont “gigueux” afin qu’ils puissent (presque) tous être vus, même si deux d’entre eux ont la même valeur.Graphiques en violon, montre la distribution d’une variable continue basée sur la largeur symétrique du “violon”.\nSina plot, est une combinaison du graphique de gigue et du graphique de violin, où les points individuels sont montrés mais dans la forme symétrique de la distribution (via le “package” ggforce).Nuage de points pour deux variables continues.Heatmaps pour trois variables continues (lien vers la page Heat plots).","code":""},{"path":"ggplot_basics.html","id":"histogrammes","chapter":"30 Les bases de ggplot","heading":"Histogrammes","text":"Les histogrammes peuvent ressembler à des diagrammes en barres, mais ils sont distincts car ils mesurent la distribution d’une variable continue. Il n’y pas d’espace entre les “barres”, et une seule colonne est fournie à geom_histogram().Le code ci-dessous permet de générer des histogrammes, qui regroupent les données continues en gammes et les affichent dans des barres adjacentes de hauteur variable. Ceci est fait en utilisant geom_histogram(). Voir la section “Diagrammes en barres” de la page ggplot basics pour comprendre la différence entre geom_histogram(), geom_bar(), et geom_col().Nous allons montrer la distribution des âges des cas. Dans mapping = aes(), nous spécifierons la colonne dont nous voulons voir la distribution. peut affecter cette colonne à l’axe des x ou des y.Les lignes seront assignées à des “bins” basés sur leur âge numérique, et ces “bins” seront représentés graphiquement par des barres. Si vous spécifiez un nombre de “bins” avec l’attribut graphique bins =, les points de rupture sont espacés de manière égale entre les valeurs minimum et maximum de l’histogramme. Si bins = n’est pas spécifié, un nombre approprié de bins sera deviné et ce message sera affiché après le tracé :Si vous ne voulez pas spécifier un nombre de “bins” à bins =, vous pouvez alternativement spécifier binwidth = dans les unités de l’axe. Nous donnons quelques exemples montrant différents bins et largeurs de bins :Pour obtenir des proportions lissées, peut utiliser geom_density() :Pour obtenir un histogramme “empilé” (d’une colonne continue de données), nous pouvons faire l’une des choses suivantes :Utilisez geom_histogram() avec l’argument fill = dans aes() et affecté à la colonne de regroupement, ouUtilisez geom_freqpoly(), qui est probablement plus facile à lire (vous pouvez toujours définir binwidth =).Pour voir les proportions de toutes les valeurs, définissez le paramètre y = after_stat(density) (utilisez exactement cette syntaxe non modifiée pour vos données). Note : ces proportions seront affichées par groupe.Chacun d’entre eux est présenté ci-dessous (notez l’utilisation de color = ou fill = dans chacun d’entre eux) :Si vous voulez vous amuser un peu, essayez geom_density_ridges du “package” ggridges (vignette ici.Pour plus de détails sur les histogrammes, consultez la page tidyverse page sur geom_histogram().","code":"## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n# A) Histogramme tracé par défaut\nggplot(data = linelist, aes(x = age))+  # provide x variable\n  geom_histogram()+\n  labs(title = \"A) Default histogram (30 bins)\")\n\n# B) Plus de bins\nggplot(data = linelist, aes(x = age))+  # mapper la variable age à l'axe des x\n  geom_histogram(bins = 50)+\n  labs(title = \"B) Set to 50 bins\")\n\n# C) Moins de bins\nggplot(data = linelist, aes(x = age))+  # mapper la variable age à l'axe des x\n  geom_histogram(bins = 5)+\n  labs(title = \"C) Set to 5 bins\")\n\n\n# D) Plus de bins\nggplot(data = linelist, aes(x = age))+  # mapper la variable age à l'axe des x\n  geom_histogram(binwidth = 1)+\n  labs(title = \"D) binwidth of 1\")\n# Fréquence avec axe de proportion, lissée\nggplot(data = linelist, mapping = aes(x = age)) +\n  geom_density(size = 2, alpha = 0.2)+\n  labs(title = \"Proportional density\")\n\n# Fréquence empilée avec axe de proportion, lissée\nggplot(data = linelist, mapping = aes(x = age, fill = gender)) +\n  geom_density(size = 2, alpha = 0.2, position = \"stack\")+\n  labs(title = \"'Stacked' proportional densities\")\n# Histogramme \"empilé\"\nggplot(data = linelist, mapping = aes(x = age, fill = gender)) +\n  geom_histogram(binwidth = 2)+\n  labs(title = \"'Stacked' histogram\")\n\n# Frequence\nggplot(data = linelist, mapping = aes(x = age, color = gender)) +\n  geom_freqpoly(binwidth = 2, size = 2)+\n  labs(title = \"Freqpoly\")\n\n# Frequence avec axe en proportion \nggplot(data = linelist, mapping = aes(x = age, y = after_stat(density), color = gender)) +\n  geom_freqpoly(binwidth = 5, size = 2)+\n  labs(title = \"Proportional freqpoly\")\n\n# Frequence avec axe en proportion, lissé\nggplot(data = linelist, mapping = aes(x = age, y = after_stat(density), fill = gender)) +\n  geom_density(size = 2, alpha = 0.2)+\n  labs(title = \"Proportional, smoothed with geom_density()\")"},{"path":"ggplot_basics.html","id":"diagrammes-en-boîtes","chapter":"30 Les bases de ggplot","heading":"Diagrammes en boîtes","text":"Les diagrammes en boîte sont très utilisés, mais ils ont des limites importantes. Ils peuvent masquer la distribution réelle - par exemple, une distribution bimodale. Voir cette galerie de graphiques R et cet article data--viz pour plus de détails. Cependant, ils affichent joliment l’écart interquartile et les valeurs aberrantes - ils peuvent donc être superposés à d’autres types de graphiques qui montrent la distribution de manière plus détaillée.Nous vous rappelons ci-dessous les différentes composantes d’un diagramme en boîte :Lorsque vous utilisez geom_boxplot() pour créer un box plot, vous mappez généralement un seul axe (x ou y) dans aes(). L’axe spécifié détermine si les tracés sont horizontaux ou verticaux.Dans la plupart des “geoms”, nous créons un graphique par groupe en faisant correspondre un attribut comme color = ou fill = à une variable dans aes(). Cependant, pour les diagrammes en boîte, nous pouvons le faire en assignant la variable de regroupement à l’axe non assigné (x ou y). Ci-dessous se trouve le code pour un diagramme de boîte de toutes les valeurs d’âge dans l’ensemble de données, et ensuite le code pour afficher un box plot pour chaque sexe (non manquant) dans l’ensemble du jeu de données. Notez que les valeurs NA (manquantes) apparaîtront comme un diagramme de boîte séparé, sauf si elles sont supprimées. Dans cet exemple, nous avons également défini le “remplissage” de la colonne “gender” (issue finale de chaque cas) afin que chaque diagramme de boîtes soit d’une couleur différente - mais ce n’est pas nécessaire.Pour le code permettant d’ajouter un diagramme en boîte aux bords d’un nuage de points (diagrammes “marginaux”), voir la page Trucs et Astuces avec ggplot.","code":"\n# A) Diagramme de boîte d'ensemble\nggplot(data = linelist)+  \n  geom_boxplot(mapping = aes(y = age))+   # uniquement axe y mappé (non axe des x)\n  labs(title = \"A) Overall boxplot\")\n\n# B) Diagramme de boîte par groupe\nggplot(data = linelist, mapping = aes(y = age, x = gender, fill = gender)) + \n  geom_boxplot()+                     \n  theme(legend.position = \"none\")+   # supprimer la légende (redondant)\n  labs(title = \"B) Boxplot by gender\")      "},{"path":"ggplot_basics.html","id":"graphes-en-violon-gigue-et-sina","chapter":"30 Les bases de ggplot","heading":"Graphes en violon, gigue, et “sina”","text":"Ci-dessous, vous trouverez le code pour créer des diagrammes en violon (geom_violin) et jitter (gigue) (geom_jitter) pour montrer les distributions. Vous pouvez spécifier que le remplissage ou la couleur est également déterminé par les données, en insérant ces options dans aes().Vous pouvez combiner les deux en utilisant la fonction geom_sina() du “package” ggforce. La fonction trace les points de gigue dans la forme du tracé de violon. Lorsqu’il est superposé au tracé du violon (en ajustant les transparences), il peut être plus facile à interpréter visuellement.","code":"\n# A) Jitter par groupe\nggplot(data = linelist %>% drop_na(outcome),      # supprimer les valeurs manquantes\n       mapping = aes(y = age,                     # mapper la variable continue\n           x = outcome,                           # mapper la variable de regroupement\n           color = outcome))+                     # mapper la couleur avec la variable outcome \n  geom_jitter()+                                  # Creer le graphique\n  labs(title = \"A) jitter plot by gender\")     \n\n\n\n# B) Violin par groupe\nggplot(data = linelist %>% drop_na(outcome),       # supprimer les valeurs manquantes\n       mapping = aes(y = age,                      # mapper la variable continue\n           x = outcome,                            # mapper la variable de regroupement\n           fill = outcome))+                       # mapper la ouleur avec la variable outcome\n  geom_violin()+                                   # Creer le graphique\n  labs(title = \"B) violin plot by gender\")    \n# A) Sina  par group\nggplot(\n  data = linelist %>% drop_na(outcome), \n  aes(y = age,           # mapper la variable numérique\n      x = outcome)) +    # mapper la variable de regroupement\n  geom_violin(\n    aes(fill = outcome), # remplissage (couleur de fond du violon)\n    color = \"white\",     # contour blanc\n    alpha = 0.2)+        # transparence\n  geom_sina(\n    size=1,                # Changer la taille des gigues\n    aes(color = outcome))+ # mapper la couleur des points avec la variable outcome\n  scale_fill_manual(       # Definir des couleurs de remplissage (de fond) des violons en precisant quelle couleur prend chaque modalite de la variable outcome\n    values = c(\"Death\" = \"#bf5300\", \n              \"Recover\" = \"#11118c\")) + \n  scale_color_manual(      # Definir des couleurs des points en precisant quelle couleur prend chaque modalite de la variable outcome\n    values = c(\"Death\" = \"#bf5300\", \n              \"Recover\" = \"#11118c\")) + \n  theme_minimal() +                                # Supprimer l'arriere-plan gris\n  theme(legend.position = \"none\") +                # Supprimer la legende non-necessaire\n  labs(title = \"B) violin and sina plot by gender, with extra formatting\")      "},{"path":"ggplot_basics.html","id":"deux-variables-continues","chapter":"30 Les bases de ggplot","heading":"Deux variables continues","text":"En suivant une syntaxe similaire, geom_point() vous permettra de tracer deux variables continues l’une en fonction de l’autre dans un scatter plot (un nuage de points/un diagramme de dispersion). Ceci est utile pour montrer les valeurs réelles plutôt que leurs distributions. Un diagramme de dispersion basique de l’âge par rapport au poids est montré dans (). Dans (B), nous utilisons à nouveau facet_grid() pour montrer la relation entre deux variables continues dans la liste lineaire.","code":"\n# Diagramme de dispersion du poids et de l'âge\nggplot(data = linelist, \n       mapping = aes(y = wt_kg, x = age))+\n  geom_point() +\n  labs(title = \"A) Scatter plot of weight and age\")\n\n# Diagramme de dispersion du poids et de l'âge par sexe et issue finale du cas\nggplot(data = linelist %>% drop_na(gender, outcome), #garder que le sexe/issue finale non manquant\n       mapping = aes(y = wt_kg, x = age))+\n  geom_point() +\n  labs(title = \"B) Scatter plot of weight and age faceted by gender and outcome\")+\n  facet_grid(gender ~ outcome) "},{"path":"ggplot_basics.html","id":"trois-variables-continues","chapter":"30 Les bases de ggplot","heading":"Trois variables continues","text":"Vous pouvez afficher trois variables continues en utilisant l’argument fill = pour créer un graphique thermique (heat plot). La couleur de chaque “cellule” reflétera la valeur de la troisième colonne de données continues. Voir la page Astuces en ggplot et la page sur les Graphiques thermiques pour plus de détails et plusieurs exemples.Il existe des moyens de créer des graphiques 3D dans R, mais pour l’épidémiologie appliquée, ils sont souvent difficiles à interpréter et donc moins utiles pour la prise de décision.","code":""},{"path":"ggplot_basics.html","id":"représenter-des-données-catégorielles","chapter":"30 Les bases de ggplot","heading":"30.13 Représenter des données catégorielles","text":"Les données catégoriques peuvent être des valeurs de caractères, des valeurs logiques (VRAI/FAUX) ou des facteurs (voir la page Facteurs).","code":""},{"path":"ggplot_basics.html","id":"préparation-13","chapter":"30 Les bases de ggplot","heading":"Préparation","text":"","code":""},{"path":"ggplot_basics.html","id":"structure-des-données","chapter":"30 Les bases de ggplot","heading":"Structure des données","text":"La première chose à comprendre au sujet de vos données catégorielles est de savoir si elles existent sous forme d’observations brutes, comme une liste linéaire de cas, ou sous forme de résumé ou de tableau de données agrégées contenant des comptages ou des proportions. L’état de vos données aura un impact sur la fonction de traçage que vous utiliserez :Si vos données sont des observations brutes avec une ligne par observation, vous utiliserez probablement geom_bar().Si vos données sont déjà agrégées en nombres ou en proportions, vous utiliserez probablement geom_col().","code":""},{"path":"ggplot_basics.html","id":"classe-des-variables-et-ordre-des-valeurs","chapter":"30 Les bases de ggplot","heading":"Classe des variables et ordre des valeurs","text":"Ensuite, examinez la classe des colonnes que vous voulez tracer. Nous examinons hospital, d’abord avec class() de base R, et avec tabyl() de janitor.Nous pouvons voir que les valeurs à l’intérieur sont des caractères, car il s’agit de noms d’hôpitaux, et par défaut elles sont classées par ordre alphabétique. Il existe des valeurs “autres” et “manquantes”, que nous préférerions voir figurer dans les dernières sous-catégories lors de la présentation des répartitions. Nous transformons donc cette variable en facteur et la réorganisons. Ce point est traité plus en détail dans la page Facteurs.","code":"\n# Voir la classe de la variable hospital - on peut voir que c'est une variable de type caractère\nclass(linelist$hospital)## [1] \"character\"\n# Regardez les valeurs et les proportions dans la variable hospital\nlinelist %>% \n  tabyl(hospital)##                              hospital    n    percent\n##                      Central Hospital  454 0.07710598\n##                     Military Hospital  896 0.15217391\n##                               Missing 1469 0.24949049\n##                                 Other  885 0.15030571\n##                         Port Hospital 1762 0.29925272\n##  St. Mark's Maternity Hospital (SMMH)  422 0.07167120\n# Convertir en facteur et définir l'ordre des niveaux pour que \"Other\" et \"Missing\" soient les derniers.\nlinelist <- linelist %>% \n  mutate(\n    hospital = fct_relevel(hospital, \n      \"St. Mark's Maternity Hospital (SMMH)\",\n      \"Port Hospital\", \n      \"Central Hospital\",\n      \"Military Hospital\",\n      \"Other\",\n      \"Missing\"))\nlevels(linelist$hospital)## [1] \"St. Mark's Maternity Hospital (SMMH)\" \"Port Hospital\"                       \n## [3] \"Central Hospital\"                     \"Military Hospital\"                   \n## [5] \"Other\"                                \"Missing\""},{"path":"ggplot_basics.html","id":"ggplot_basics_bars","chapter":"30 Les bases de ggplot","heading":"geom_bar()","text":"Utilisez geom_bar() si vous voulez que la hauteur des barres (ou la hauteur des composants des barres empilées) reflète le nombre de lignes pertinentes dans les données. Ces barres auront des espaces entre elles, à moins que l’attribut graphique width = soit ajusté.Ne fournissez qu’une seule affectation de colonne d’axe (généralement l’axe des x). Si vous fournissez x et y, vous obtiendrez Error: stat_count() can x y aesthetic.Vous pouvez créer des barres empilées en ajoutant une affectation de colonne fill = dans mapping = aes().L’axe opposé sera intitulé “count” par défaut, car il représente le nombre de lignes.Ci-dessous, nous avons affecté la variable “outcome” (issue finale) à l’axe des y, mais il pourrait tout aussi bien être sur l’axe des x. Si vous avez des valeurs de caractères plus longues, il est parfois préférable de retourner les barres sur le côté et de placer la légende en bas. Cela peut avoir un impact sur la façon dont vos niveaux de facteurs sont ordonnés - dans ce cas, nous les inversons avec fct_rev() pour mettre les manquants et les autres en bas.","code":"\n# A) Issues finales pour l'ensemble des cas\nggplot(linelist %>% drop_na(outcome)) + \n  geom_bar(aes(y = fct_rev(hospital)), width = 0.7) +\n  theme_minimal()+\n  labs(title = \"A) Number of cases by hospital\",\n       y = \"Hospital\")\n\n\n# B) Issues finales pour les cas par hôpital\nggplot(linelist %>% drop_na(outcome)) + \n  geom_bar(aes(y = fct_rev(hospital), fill = outcome), width = 0.7) +\n  theme_minimal()+\n  theme(legend.position = \"bottom\") +\n  labs(title = \"B) Number of recovered and dead Ebola cases, by hospital\",\n       y = \"Hospital\")"},{"path":"ggplot_basics.html","id":"geom_col","chapter":"30 Les bases de ggplot","heading":"geom_col()","text":"Utilisez geom_col() si vous voulez que la hauteur des barres (ou la hauteur des composants des barres empilées) reflète des valeurs pré-calculées qui existent dans les données. Il s’agit souvent de chiffres ou de proportions résumés ou “agrégés”.Fournissez des affectations de variables pour les deux axes à geom_col(). Généralement, la colonne de l’axe des x est discrète et celle de l’axe des y est numérique.Disons que nous avons cet ensemble de données outcomes :Le code ci-dessous utilise geom_col pour créer des diagrammes en barres simples afin de montrer la distribution de l’issue finale des cas Ebola. Avec geom_col, x et y doivent être spécifiés. Ici, x est la variable catégorielle sur l’axe des x, et y est la colonne de proportions générée proportion.Pour montrer les répartitions par hôpital, il faudrait que notre tableau contienne plus d’informations et qu’il soit au format “long”. Nous créons ce tableau avec les fréquences des catégories combinées outcome et hospital (voir la page Travailler sur des données groupées pour des conseils sur le regroupement).Nous créons ensuite le ggplot avec quelques mises en forme supplémentaires :Inverser les axes : Nous avons inversé les axes avec coord_flip() pour pouvoir lire les noms des hôpitaux.\nBarres côte-à-côte : Nous avons ajouté d’un argument position = \"dodge\" pour que les barres pour les décès et la guérison soient présentées côte à côte plutôt qu’empilées. Notez que les barres empilées sont la valeur par défaut.Largeur de colonne : Nous avons spécifié ‘width’, donc les colonnes sont deux fois moins larges que la largeur maximale possible.\nOrdre des variable : Nous avons inversé l’ordre des catégories sur l’axe des y de sorte que ‘Autre’ et ‘Manquant’ soient en bas, avec scale_x_discrete(limits=rev). Notez que nous avons utilisé cette méthode plutôt que scale_y_discrete parce que l’hôpital est indiqué dans l’argument x de aes(), même si visuellement il est sur l’axe des ordonnées. Nous faisons cela parce que ggplot semble présenter les catégories à l’envers, sauf si nous lui disons de ne pas le faire.Autres détails : Les étiquettes/titres et couleurs ont été ajoutés dans labs et scale_fill_color respectivement.Notez que les proportions sont binaires, et que l’peut donc préférer ne pas utiliser le terme “guérison” et ne montrer que la proportion de décès. Ceci n’est qu’une illustration.Si vous utilisez geom_col() avec des données de dates (par exemple une courbe épidémique à partir de données regroupées) - vous voudrez ajuster l’argument width = pour supprimer les lignes de “gap” entre les barres. Si vous utilisez des données quotidiennes, réglez width = 1. Si vous utilisez des données hebdomadaires, width = 7.\nCAUTION: Les mois ne sont pas possibles car chaque mois un nombre de jours différent..","code":"## # A tibble: 2 × 3\n##   outcome     n proportion\n##   <chr>   <int>      <dbl>\n## 1 Death    1022       56.2\n## 2 Recover   796       43.8\n# Issues finales pour l'ensemble des cas\nggplot(outcomes) + \n  geom_col(aes(x=outcome, y = proportion)) +\n  labs(subtitle = \"Number of recovered and dead Ebola cases\")\noutcomes2 <- linelist %>% \n  drop_na(outcome) %>% \n  count(hospital, outcome) %>%  # compter les lignes par hôpital et issue finale\n  group_by(hospital) %>%        # regrouper pour que les proportions soient sur le total de \"hospital\"\n  mutate(proportion = n/sum(n)*100) # calculer les proportions de décès et de guerison au sein de chaque \"hospital\" \n\nhead(outcomes2) # Voir les premières lignes de la table ## # A tibble: 6 × 4\n## # Groups:   hospital [3]\n##   hospital                             outcome     n proportion\n##   <fct>                                <chr>   <int>      <dbl>\n## 1 St. Mark's Maternity Hospital (SMMH) Death     199       61.2\n## 2 St. Mark's Maternity Hospital (SMMH) Recover   126       38.8\n## 3 Port Hospital                        Death     785       57.6\n## 4 Port Hospital                        Recover   579       42.4\n## 5 Central Hospital                     Death     193       53.9\n## 6 Central Hospital                     Recover   165       46.1\n# Issue finale pour l'ensemble des cas par hopital\nggplot(outcomes2) +  \n  geom_col(\n    mapping = aes(\n      x = proportion,                 # mapper axe des x avec les proportions pre-calculées\n      y = fct_rev(hospital),          # inverser les catégories de la variable 'hospital' pour que missing/other sont en dernier\n      fill = outcome),                # remplissage par issue finale\n    width = 0.5)+                    # barres moins larges (sur 1)\n  theme_minimal() +                  # theme minimal \n  theme(legend.position = \"bottom\")+\n  labs(subtitle = \"Number of recovered and dead Ebola cases, by hospital\",\n       fill = \"Outcome\",             # titre légende \n       y = \"Count\",                  # titre axe des y \n       x = \"Hospital of admission\")+ # titre axe des x\n  scale_fill_manual(                 # préciser des couleurs manuellement\n    values = c(\"Death\"= \"#3B1c8C\",\n               \"Recover\" = \"#21908D\" )) "},{"path":"ggplot_basics.html","id":"geom_histogram","chapter":"30 Les bases de ggplot","heading":"geom_histogram()","text":"Les histogrammes peuvent ressembler à des diagrammes en barres, mais ils sont distincts car ils mesurent la distribution d’une variable continue. Il n’y pas d’espace entre les “barres”, et une seule colonne est fournie à geom_histogram(). Il existe des arguments spécifiques aux histogrammes tels que bin_width = et breaks = pour spécifier comment les données doivent être classées. La section ci-dessus sur les données continues et la page sur les Courbes épidémiques fournissent des détails supplémentaires.","code":""},{"path":"ggplot_basics.html","id":"ressources-15","chapter":"30 Les bases de ggplot","heading":"30.14 Ressources","text":"Il existe une grande quantité de ressources et d’aide en ligne, en particulier avec ggplot. Voir :Antisèche ggplot2Un autre antisèchePage tidyverse sur les bases de ggplotRepresentation des variables continuesPage R Data Science sur la visualisation des donneesPage R Data Science sur les graphiques pour mieux communiquer","code":""},{"path":"ggplot_tips.html","id":"ggplot_tips","chapter":"31 Trucs et Astuces avec ggplot","heading":"31 Trucs et Astuces avec ggplot","text":"Dans cette page, nous couvrirons les trucs et astuces pour rendre vos ggplots nets et esthétiques. Voir la page sur les bases de ggplot pour les principes de base.Il existe plusieurs tutoriels ggplot2 dont certains listés à la section Ressources. Vous pouvez également télécharger cette fiche technique sur la visualisation de données avec ggplot sur le site Web de RStudio. Nous vous recommandons vivement aussi de vous inspirer de la R graph gallery et de Data--viz.","code":""},{"path":"ggplot_tips.html","id":"préparation-14","chapter":"31 Trucs et Astuces avec ggplot","heading":"31.1 Préparation","text":"","code":""},{"path":"ggplot_tips.html","id":"charger-les-extensions-packages-1","chapter":"31 Trucs et Astuces avec ggplot","heading":"Charger les extensions (“packages”)","text":"Ce bout de code montre le chargement des “packages” nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur la fonction p_load() du “package” pacman, qui installe le (ou une liste de) “package (s)” que si nécessaire (uniquement si le package n’est pas déjà installé) et le charge pour l’utiliser . peut également charger des “packages” avec library() à partir de R base. Voir la page sur Bases de R pour plus d’informations sur les “packages” R.","code":"\npacman::p_load(\n  tidyverse,      # inclut ggplot2 et d'autres extensions de  data management\n  rio,            # importer/exporter\n  here,           # localiser des fichiers\n  stringr,        #  travailler avec des caracteres     \n  scales,         # transformer des valeurs numeriques\n  ggrepel,        # bien placer des  étiquettes \n  gghighlight,    # mettre en évidence une partie de l'intrigue\n  RColorBrewer    # gammes de couleurs\n)"},{"path":"ggplot_tips.html","id":"importer-des-données-5","chapter":"31 Trucs et Astuces avec ggplot","heading":"Importer des données","text":"Pour commencer, nous importons le jeu de données des cas d’une épidémie d’Ebola simulée. Si vous voulez suivre en travaillant sur la base, cliquez pour télécharger la version “clean”  (en fichier .rds). Importez les données avec la fonction import() du “package” rio (elle gère de nombreux types de fichiers comme .xlsx, .csv, .rds - voir la page Importation et exportation pour plus de détails).Les 50 premières lignes de la liste linéaire sont affichées ci-dessous.","code":"\nlinelist <- rio::import(\"linelist_cleaned.rds\")"},{"path":"ggplot_tips.html","id":"ggplot_tips_colors","chapter":"31 Trucs et Astuces avec ggplot","heading":"31.2 Palettes de couleur, le remplissage, les axes, etc.","text":"Nous avons déjà parlé du “mappage” dans la page sur les Bases de ggplot. Ainsi lorsque le mappage est établi, ie les attributs du graphique (par exemple, la taille, la couleur, la forme, le remplissage, l’axe du tracé) associés à des variables dans les données, pourrait amener à vouloir modifier ce mappage pour que notre graphique reflète mieux le message que nous voulons délivrer. Ceci est possible avec les commandes scales qui vont permettre des ajustements de l’affichage exact du résultat de nos mappages . Par exemple la couleur reliée à une variable précise sera modifiée ou précisée selon nos besoins avec scale_color, la taille (size) pourrait être ajustée selon les valeurs minimales et maximales avec scale_size etc. Dans cette section, nous développerons l’utilisation de certains scales courants.","code":""},{"path":"ggplot_tips.html","id":"palettes-de-couleurs","chapter":"31 Trucs et Astuces avec ggplot","heading":"31.2.1 Palettes de couleurs","text":"Une chose qui peut être initialement difficile à comprendre avec ggplot2 est le contrôle des palettes de couleurs. Notez que cette section traite de la couleur des objets du graphe (“geoms”/formes) tels que les points, les barres, les lignes, les tuiles, etc. Pour ajuster la couleur des textes accessoires (non reliés aux données) , des titres ou de la couleur de fond, consultez la section Themes de la page ggplot basics.Pour contrôler la “couleur” des objets du graphe, vous devrez ajuster soit l’attribut color = (la couleur extérieure), soit l’attribut fill = (la couleur intérieure). Une exception à cette configuration est geom_point(), où vous ne pouvez contrôler que color =, qui contrôle la couleur du point (intérieur et extérieur).Lorsque vous définissez la couleur ou le remplissage, vous pouvez soit utiliser des noms de couleurs reconnus par R comme “red” (voir complete list ou entrer dans ?colors), ou une couleur hexadécimale spécifique comme \"#ff0505\".Comme expliqué dans la page ggplot basics sur comment relier les données aux éléments graphiques, les attributs graphiques tels que fill = et color = peuvent être définis soit à l’extérieur d’une instruction mapping = aes() soit à l’intérieur d’une telle instruction. Si vous êtes en dehors de aes(), la valeur assignée doit être statique (par exemple, color = \"blue\") et s’appliquera à toutes les données tracées par le “geom”. Si elle est à l’intérieur, l’attribut doit être mise en correspondance avec une variable, comme color = hospital, et l’expression variera en fonction de la valeur de cette ligne dans les données. Quelques exemples :","code":"\n# histogramme - \nggplot(data = linelist, mapping = aes(x = age))+       # definir donnees et axes\n  geom_histogram(              # afficher l'histogramme\n    binwidth = 7,                # taille des bins\n    color = \"red\",               # couleur de ligne des bins\n    fill = \"lightblue\")          # couleur interieure des bins (fill) \n# Couleur statique pour les points et pour la ligne\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+     \n  geom_point(color = \"purple\")+\n  geom_vline(xintercept = 50, color = \"orange\")+\n  labs(title = \"Static color for points and line\")\n\n# Couleur mappée sur une variable continue\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+     \n  geom_point(mapping = aes(color = temp))+         \n  labs(title = \"Color mapped to continuous column\")\n\n# Couleur mappée sur une variable discrète\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+     \n  geom_point(mapping = aes(color = gender))+         \n  labs(title = \"Color mapped to discrete column\")\n\n# diagramme en barres, remplissage pour variable discrète, couleur pour la valeur statique\nggplot(data = linelist, mapping = aes(x = hospital))+     \n  geom_bar(mapping = aes(fill = gender), color = \"yellow\")+         \n  labs(title = \"Fill mapped to discrete column, static color\")"},{"path":"ggplot_tips.html","id":"ggplot_tips_scales","chapter":"31 Trucs et Astuces avec ggplot","heading":"Scales","text":"Une fois que vous avez associé une variable à un attribut graphique (par exemple x =, y =, fill =, color =…) via un mappage, la manière de l’affichage de celui-ci pourra être modifié par les “scales” qui vont aussi définir la façon dont la légende correspondante va être affichée. peut voir ci-dessus comment les “scales” peuvent être continues, discrètes, en format date, etc. en fonction du type/classe de variable assignée. Si vous avez plusieurs attributs affectés à des variables, votre graphique aura plusieurs “scales”.Vous pouvez contrôler les “scqles” avec la fonction scales_() appropriée. Les fonctions “scales” de ggplot() ont 3 parties qui s’écrivent comme ceci : scale_AESTHETIC_METHOD().La première partie, scale_(), est fixe.La deuxième partie (“AESTHETIC”), doit être l’attribut pour lequel vous voulez ajuster l’échelle (_fill_, _shape_, _color_, _size_, _alpha_…) - les options ici incluent également _x_ et _y_.La troisième partie (“METHOD”), sera soit _discrete(), continuous(), _date(), _gradient(), ou _manual() selon la classe de la variable et comment veut la contrôler. Il en existe d’autres, mais ce sont les plus utilisées.Assurez-vous que vous utilisez la bonne fonction pour la “scale” ! Sinon, votre commande “scale” n’aura pas l’air de changer quoi que ce soit. Si vous avez plusieurs “scales”, vous pouvez utiliser plusieurs fonctions “scale” pour les ajuster ! Par exemple :","code":""},{"path":"ggplot_tips.html","id":"arguments-des-scales","chapter":"31 Trucs et Astuces avec ggplot","heading":"Arguments des “Scales”","text":"Chaque type de “scale” ses propres arguments, bien qu’il y ait quelques chevauchements. Interrogez la fonction comme ?scale_color_discrete dans la console R pour voir la documentation des arguments de la fonction.Pour les “scales” continues, utilisez breaks = pour fournir une séquence de valeurs avec seq() (prenez =, =, et = comme indiqué dans l’exemple ci-dessous. Définissez expand = c(0,0) pour éliminer l’espace de remplissage autour des axes (ceci peut être utilisé sur toute “scale” _x_ ou _y_.Pour les “scales” discrètes, vous pouvez ajuster l’ordre d’apparition des modalités de la variable avec breaks =, et la façon dont les valeurs s’affichent avec l’argument labels =. Fournissez un vecteur caractère à chacun d’eux (voir l’exemple ci-dessous). Vous pouvez également écarter les valeurs manquantes NA facilement en définissant na.translate = FALSE.Les nuances des “scales” au format date sont traitées plus en détail dans la page Courbes épidémiques.","code":""},{"path":"ggplot_tips.html","id":"réglages-manuels","chapter":"31 Trucs et Astuces avec ggplot","heading":"Réglages manuels","text":"L’une des astuces les plus utiles consiste à utiliser des fonctions “scale” de façon “manuelle” pour assigner explicitement les couleurs comme vous le souhaitez. Ce sont des fonctions avec la syntaxe scale_xxx_manual() (par exemple scale_colour_manual() ou scale_fill_manual()). Chacun des arguments ci-dessous est démontré dans l’exemple de code ci-dessous.Attribuer des couleurs aux valeurs de données avec l’argument values = argument.Spécifier une couleur pour les données manquantes NA avec l’argument na.value =Modifier la façon dont les valeurs sont écrites dans la légende avec l’argument labels =Modifier le titre de la légende avec l’argument name =Ci-dessous, nous créons un graphique à barres et montrons comment il apparaît par défaut, puis avec trois “scales” ajustées - la “scale” continue de l’axe des y, la “scale” discrète de l’axe des x, et l’ajustement manuel du remplissage (couleur intérieure de la barre).","code":"\n# BASELINE - pas d'ajustement de la scale\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = outcome, fill = gender))+\n  labs(title = \"Baseline - no scale adjustments\")\n# SCALES AJUSTEES\nggplot(data = linelist)+\n  \n  geom_bar(mapping = aes(x = outcome, fill = gender), color = \"black\")+\n  \n  theme_minimal()+                   # simplifier le background\n  \n  scale_y_continuous(                # scale continue pour l'axe des y (comptage)\n    expand = c(0,0),                 # eviter un graphe trop rembourré\n    breaks = seq(from = 0,\n                 to = 3000,\n                 by = 500))+\n  \n  scale_x_discrete(                   # scale discrete pour l'axe des x (gender)\n    expand = c(0,0),                  # eviter un graphe trop rembourré\n    drop = FALSE,                     # afficher toutes les modalités de la variable facteur (même si non utilisée dans la représentation)\n    na.translate = FALSE,             # retirer les valeurs NA \n    labels = c(\"Died\", \"Recovered\"))+ # Changer l'affichage des valeurs\n    \n  \n  scale_fill_manual(                  # Spécifier Manuellement la couleur intérieure des barres\n    values = c(\"m\" = \"violetred\",     # préciser les couleurs que prennent chaque modalité\n               \"f\" = \"aquamarine\"),\n    labels = c(\"m\" = \"Male\",          #  ré-étiqueter la légende (utiliser l'affectation \"=\" pour éviter les erreurs)\n              \"f\" = \"Female\",\n              \"Missing\"),\n    name = \"Gender\",                  # titre de la legende\n    na.value = \"grey\"                 # assigner une couleur aux valeurs manquantes\n  )+\n  labs(title = \"Adjustment of scales\") # Préciser le titre"},{"path":"ggplot_tips.html","id":"scales-daxes-continus","chapter":"31 Trucs et Astuces avec ggplot","heading":"“Scales” d’axes continus","text":"Lorsque les données sont mappées sur les axes du graphique, ceux-ci peuvent également être ajustés à l’aide de commandes “scales’. Un exemple courant est l’ajustement de l’affichage d’un axe (par exemple l’axe des y) qui est mappé à une variable avec des données continues.Nous pouvons vouloir ajuster la continuité ou l’affichage des valeurs dans le ggplot en utilisant scale_y_continuous(). Comme indiqué ci-dessus, utilisez l’argument breaks = pour fournir une séquence de valeurs de graduation qui serviront de “ruptures” le long de la “scale”. cet argument, vous pouvez fournir un vecteur c() contenant le nombre de graduation souhaitées, ou vous pouvez fournir une séquence régulière de nombres en utilisant la fonction R base seq(). Cette fonction seq() accepte =, =, et =.","code":"\n# BASELINE - pas d'ajustement de la scale\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = outcome, fill = gender))+\n  labs(title = \"Baseline - no scale adjustments\")\n\n# \nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = outcome, fill = gender))+\n  scale_y_continuous(\n    breaks = seq(\n      from = 0,\n      to = 3000,\n      by = 100)\n  )+\n  labs(title = \"Adjusted y-axis breaks\")"},{"path":"ggplot_tips.html","id":"afficher-les-pourcentages","chapter":"31 Trucs et Astuces avec ggplot","heading":"Afficher les pourcentages","text":"Si les valeurs de vos données originales sont des proportions, vous pouvez facilement les afficher sous forme de pourcentages avec “%” en fournissant labels = scales::percent dans votre commande scales, comme montré ci-dessous.Une alternative serait de convertir les valeurs en caractères et d’ajouter un caractère “%” à la fin, mais cette approche entraînera des complications car vos données ne seront plus des valeurs numériques continues.","code":"\n# Axe des y originellement en proportions\n#############################\nlinelist %>%                                   # commencer avec les données d'intérêt: linelist\n  group_by(hospital) %>%                       # agréger les données selon les modalités de la variable hopital\n  summarise(                                   # créer un résumé par colonnes\n    n = n(),                                     # compter le nombre total de lignes \n    deaths = sum(outcome == \"Death\", na.rm=T),   # compter le nombre de décès par groupe\n    prop_death = deaths/n) %>%                   # calculer la proportion de décès par groupe\n  ggplot(                                      # tracer le graphique\n    mapping = aes(\n      x = hospital,\n      y = prop_death))+ \n  geom_col()+\n  theme_minimal()+\n  labs(title = \"Display y-axis original proportions\")\n\n\n\n# Afficher les proportions de l'axe des y avec des pourcentages\n########################################\nlinelist %>%         \n  group_by(hospital) %>% \n  summarise(\n    n = n(),\n    deaths = sum(outcome == \"Death\", na.rm=T),\n    prop_death = deaths/n) %>% \n  ggplot(\n    mapping = aes(\n      x = hospital,\n      y = prop_death))+\n  geom_col()+\n  theme_minimal()+\n  labs(title = \"Display y-axis as percents (%)\")+\n  scale_y_continuous(\n    labels = scales::percent                    # afficher les proportions comme des pourcentages\n  )"},{"path":"ggplot_tips.html","id":"échelle-logarithmique","chapter":"31 Trucs et Astuces avec ggplot","heading":"Échelle logarithmique","text":"Pour transformer un axe continu en échelle logarithmique, ajouter trans = \"log2\" à la commande “scale”. Pour les besoins de l’exemple, nous créons un jeu de données des régions avec leurs valeurs respectives de preparedness_index et de cas cumulés.Les cas cumulés pour la région “” sont nettement supérieurs à ceux de toutes les autres régions. Dans de telles circonstances, vous pouvez choisir d’afficher l’axe des y en utilisant une échelle logarithmique afin que le lecteur puisse voir les différences entre les régions ayant moins de cas cumulés.","code":"\nplot_data <- data.frame(\n  region = c(\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\"),\n  preparedness_index = c(8.8, 7.5, 3.4, 3.6, 2.1, 7.9, 7.0, 5.6, 1.0),\n  cases_cumulative = c(15, 45, 80, 20, 21, 7, 51, 30, 1442)\n)\n\nplot_data##   region preparedness_index cases_cumulative\n## 1      A                8.8               15\n## 2      B                7.5               45\n## 3      C                3.4               80\n## 4      D                3.6               20\n## 5      E                2.1               21\n## 6      F                7.9                7\n## 7      G                7.0               51\n## 8      H                5.6               30\n## 9      I                1.0             1442\n# Axe y original\npreparedness_plot <- ggplot(data = plot_data,  \n       mapping = aes(\n         x = preparedness_index,\n         y = cases_cumulative))+\n  geom_point(size = 2)+            # points pour chaque region \n  geom_text(\n    mapping = aes(label = region),\n    vjust = 1.5)+                  # ajouter les etiquette\n  theme_minimal()\n\npreparedness_plot                  # affichier le graphe originel\n\n\n# print with y-axis transformed\npreparedness_plot+                   # appeler le graphe créé ci-dessus\n  scale_y_continuous(trans = \"log2\") # ajouter la transformation pour l'axe des y"},{"path":"ggplot_tips.html","id":"gradient-de-couleur","chapter":"31 Trucs et Astuces avec ggplot","heading":"Gradient de couleur","text":"Les fonctions “scales” pour un remplissage en gradient de couleur (dégradé) peuvent impliquer des nuances supplémentaires. Les valeurs par défaut sont généralement très agréables, mais vous pouvez souhaiter ajuster les valeurs, les coupures, etc.Pour illustrer comment ajuster une “scale” de couleur continue, nous utiliserons un ensemble de données de la page Suivi des contacts qui contient les âges des cas et de leurs cas sources.Ci-dessous, nous produisons un diagramme “raster” de la densité des tuiles thermiques. Nous ne détaillerons pas comment (voir le lien dans le paragraphe ci-dessus) mais nous nous concentrerons sur la façon dont nous pouvons ajuster la “scale” de couleurs. Pour en savoir plus sur la fonction stat_density2d() ggplot2 ici. Notez que la “scale” de remplissage est continue.Nous allons maintenant montrer quelques variations de la “scale” de remplissage :Maintenant, nous allons montrer quelques exemples d’ajustement du nombre de graduations de l’échelle :scale_fill_gradient() accepte deux couleurs (haut/bas).scale_fill_gradientn() accepte un vecteur de n’importe quelle longueur de couleurs à values = (les valeurs intermédiaires seront interpolées)Utiliser scales::rescale() pour ajuster la façon dont les couleurs sont positionnées le long du gradient ; il redonne à votre vecteur de positions une valeur comprise entre 0 et 1.","code":"\ncase_source_relationships <- rio::import(here::here(\"data\", \"godata\", \"relationships_clean.rds\")) %>% \n  select(source_age, target_age) \ntrans_matrix <- ggplot(\n    data = case_source_relationships,\n    mapping = aes(x = source_age, y = target_age))+\n  stat_density2d(\n    geom = \"raster\",\n    mapping = aes(fill = after_stat(density)),\n    contour = FALSE)+\n  theme_minimal()\ntrans_matrix\ntrans_matrix + scale_fill_viridis_c(option = \"plasma\")\ntrans_matrix + \n  scale_fill_gradient(     # gradient à deux côtés\n    low = \"aquamarine\",    # petites valeurs\n    high = \"purple\",       # grandes valeurs\n    na.value = \"grey\",     # valeur des NA\n    name = \"Density\")+     # Titre de la Legende\n  labs(title = \"Manually specify high/low colors\")\n\n# 3+ couleurs à mapper\ntrans_matrix + \n  scale_fill_gradientn(    # gradient de 3 couleurs (low/mid/high)\n    colors = c(\"blue\", \"yellow\",\"red\") # fournir les couleurs dans un vecteur\n  )+\n  labs(title = \"3-color scale\")\n\n# Utiliser rescale() pour ajuster le positionnement des couleurs\ntrans_matrix + \n  scale_fill_gradientn(    # fournir autant de coleurs que l'on veut\n    colors = c(\"blue\", \"yellow\",\"red\", \"black\"),\n    values = scales::rescale(c(0, 0.05, 0.07, 0.10, 0.15, 0.20, 0.3, 0.5)) # positions des couleurs sont redimensionnées entre 0 and 1\n    )+\n  labs(title = \"Colors not evenly positioned\")\n\n# utilisation de limites pour découper les valeurs qui prennent une couleur de remplissage\ntrans_matrix + \n  scale_fill_gradientn(    \n    colors = c(\"blue\", \"yellow\",\"red\"),\n    limits = c(0, 0.0002))+\n  labs(title = \"Restrict value limits, resulting in grey space\")"},{"path":"ggplot_tips.html","id":"palettes","chapter":"31 Trucs et Astuces avec ggplot","heading":"Palettes","text":"","code":""},{"path":"ggplot_tips.html","id":"colorbrewer-et-viridis","chapter":"31 Trucs et Astuces avec ggplot","heading":"Colorbrewer et Viridis","text":"Plus généralement, si vous voulez des palettes prédéfinies, vous pouvez utiliser les fonctions scale_xxx_brewer ou scale_xxx_viridis_y.Les fonctions ‘brewer’ peuvent fonctionner à partir des palettes colorbrewer.org.Les fonctions ‘viridis’ s’inspirent des palettes viridis (adaptées aux daltoniens !), qui “fournissent des cartes de couleurs qui sont perceptiblement uniformes en couleur et en noir et blanc. Elles sont également conçues pour être perçues par des spectateurs souffrant de formes courantes de daltonisme.” (Pour en savoir plus, voir ici et ici). Préciser si la palette est discrète, continue ou binaire en le spécifiant à la fin de la fonction (par exemple, discrète est scale_xxx_viridis_d).Il est conseillé de tester votre graphe dans ce simulateur de daltonisme. Si vous avez un schéma de couleurs rouge/vert, essayez plutôt un schéma “chaud-froid” (rouge-bleu) comme décrit iciVoici un exemple tiré de la page ggplot basics, utilisant différents schémas de couleurs.","code":"\nsymp_plot <- linelist %>%                                         # commencer avec la linelist\n  select(c(case_id, fever, chills, cough, aches, vomit)) %>%     # selectionner les colonnes\n  pivot_longer(                                                  # pivoter en format long\n    cols = -case_id,                                  \n    names_to = \"symptom_name\",\n    values_to = \"symptom_is_present\") %>%\n  mutate(                                                        # remplacer les valeurs manquantes\n    symptom_is_present = replace_na(symptom_is_present, \"unknown\")) %>% \n  ggplot(                                                        # commencer le ggplot!\n    mapping = aes(x = symptom_name, fill = symptom_is_present))+\n  geom_bar(position = \"fill\", col = \"black\") +                    \n  theme_classic() +\n  theme(legend.position = \"bottom\")+\n  labs(\n    x = \"Symptom\",\n    y = \"Symptom status (proportion)\"\n  )\n\nsymp_plot  #afficher le graphe avec les couleurs par defaut\n\n#################################\n# afficher le graphe avec les couleurs specifiées manuellement\nsymp_plot +\n  scale_fill_manual(\n    values = c(\"yes\" = \"black\",         # definir explicitement les couleurs\n               \"no\" = \"white\",\n               \"unknown\" = \"grey\"),\n    breaks = c(\"yes\", \"no\", \"unknown\"), # ordonner les facteurs correctement\n    name = \"\"                           # ne pas afficher de titre pour la légende\n\n  ) \n\n#################################\n# afficher avec les couleurs discretes viridis\nsymp_plot +\n  scale_fill_viridis_d(\n    breaks = c(\"yes\", \"no\", \"unknown\"),\n    name = \"\"\n  )"},{"path":"ggplot_tips.html","id":"changement-de-lordre-des-variables-discrètes","chapter":"31 Trucs et Astuces avec ggplot","heading":"31.3 Changement de l’ordre des variables discrètes","text":"Changer l’ordre dans lequel les variables discrètes apparaissent est souvent difficile à comprendre pour les personnes qui ne connaissent pas les graphiques ggplot2. Il est cependant facile de comprendre comment faire cela une fois que vous avez compris comment ggplot2 gère les variables discrètes en intrinsèque. En général, si une variable discrète est utilisée, elle est automatiquement convertie en un type factor - qui ordonne les facteurs par ordre alphabétique par défaut. Pour gérer cela, vous devez simplement réorganiser les niveaux de facteurs (modalités) pour refléter l’ordre dans lequel vous souhaitez qu’ils apparaissent dans le graphique. Pour des informations plus détaillées sur la façon de réorganiser les objets facteur, voir la section Variables de type facteur du guide.Nous pouvons voir un exemple commun en utilisant les groupes d’âge - par défaut le groupe d’âge 5-9 sera placé au milieu des groupes d’âge (vu l’ordre alphanumérique), mais nous pouvons le déplacer derrière le groupe d’âge 0-4 du graphique en réordonnant les facteurs.","code":"\nggplot(\n  data = linelist %>% drop_na(age_cat5),                         # supprimer les lignes où age_cat5 est manquant\n  mapping = aes(x = fct_relevel(age_cat5, \"5-9\", after = 1))) +  # reordonner la var facteur\n\n  geom_bar() +\n  \n  labs(x = \"Age group\", y = \"Number of hospitalisations\",\n       title = \"Total hospitalisations by age group\") +\n  \n  theme_minimal()"},{"path":"ggplot_tips.html","id":"ggthemr","chapter":"31 Trucs et Astuces avec ggplot","heading":"31.3.0.1 ggthemr","text":"Pensez également à utiliser le “package” (extension) ggthemr. Vous pouvez télécharger ce “package” sur Github en suivant les instructions ici. Il propose des palettes très agréables d’un point de vue esthétique, mais sachez que celles-ci ont généralement un nombre maximal de valeurs qui peut être limitatif si vous voulez plus de 7 ou 8 couleurs.","code":""},{"path":"ggplot_tips.html","id":"courbes-de-niveau","chapter":"31 Trucs et Astuces avec ggplot","heading":"31.4 Courbes de niveau","text":"Les courbes de niveau sont utiles lorsque vous avez de nombreux points qui risquent de se superposer les uns les autres lors de la représentation (“surtraçage”). Elles permettent une différente visualisation de la répartition des points dans l’espace. Les données de cas utilisées ci-dessus sont à nouveau représentées, mais plus simplement en utilisant stat_density2d() et stat_density2d_filled() pour produire des niveaux de contour discrets - comme une carte topographique. Pour en savoir plus sur les statistiques, cliquez ici.","code":"\ncase_source_relationships %>% \n  ggplot(aes(x = source_age, y = target_age))+\n  stat_density2d()+\n  geom_point()+\n  theme_minimal()+\n  labs(title = \"stat_density2d() + geom_point()\")\n\n\ncase_source_relationships %>% \n  ggplot(aes(x = source_age, y = target_age))+\n  stat_density2d_filled()+\n  theme_minimal()+\n  labs(title = \"stat_density2d_filled()\")"},{"path":"ggplot_tips.html","id":"distributions-marginales","chapter":"31 Trucs et Astuces avec ggplot","heading":"31.5 Distributions marginales","text":"Pour montrer les distributions sur les rebords d’un nuage de points geom_point(), vous pouvez utiliser le “package” ggExtra et sa fonction ggMarginal(). Sauvegardez votre ggplot original comme un objet, puis passez-le à ggMarginal() comme indiqué ci-dessous. Voici les arguments clés :Vous devez spécifier le type = comme étant soit un histogramme (“histogram”), une densité (“density”), un “boxplot”, un graphe en violon (“violin”), ou un “densigram”).Par défaut, les graphiques marginaux apparaissent pour les deux axes. Vous pouvez définir margins = sur “x” ou “y” si vous n’en voulez qu’un seul.Parmi les autres arguments facultatifs, citons fill = (couleur de la barre), color = (couleur de la ligne), size = (taille du tracé par rapport à la taille de la marge, donc plus le nombre est grand, plus le tracé marginal est petit).Vous pouvez fournir d’autres arguments spécifiques aux axes à xparams = et yparams =. Par exemple, pour avoir des tailles de cases d’histogramme différentes, comme indiqué ci-dessous.Vous pouvez faire en sorte que les tracés marginaux reflètent les groupes (les variables qui ont été assignées à color = dans l’attribut de votre ggplot()). Si c’est le cas, définissez l’argument ggMarginal() groupColour = ou groupFill = à TRUE, comme indiqué ci-dessous.Pour en savoir plus, consultez cette vignette, la R Graph Gallery ou la documentation de la fonction R ?ggMarginal.Pour ajouter des histogrammes marginaux, utilisez type = \"histogram\". Vous pouvez éventuellement définir groupFill = TRUE pour obtenir des histogrammes empilés.Graphique de densité marginale avec valeurs groupées/colorées :Définissez l’argument size = pour ajuster la taille relative du graphe marginal. Plus le nombre est petit, plus le graphe marginal est grand. Vous pouvez également définir color = au besoin.Ci-dessous se trouve un boxplot marginal, avec une démonstration de l’utilisation de l’argument margins = pour avoir le graphique marginal que sur un seul axe :","code":"\n# Installer/charger ggExtra\npacman::p_load(ggExtra)\n\n# Diagramme de dispersion basique du poids et de l'âge\nscatter_plot <- ggplot(data = linelist)+\n  geom_point(mapping = aes(y = wt_kg, x = age)) +\n  labs(title = \"Scatter plot of weight and age\")\n# le graphe d'avant avec les histogrammes de chaque variable présentés sur les rebords\nggMarginal(\n  scatter_plot,                     # ajouter les histogrammes marginaux\n  type = \"histogram\",               # specifier qu'on veut un  histogramme\n  fill = \"lightblue\",               # couleur intérieure des barres de l'histogramme\n  xparams = list(binwidth = 10),    # autres parametres pour l'axe des x\n  yparams = list(binwidth = 5))     # autres parametres pour l'axe des y\n# Scatter plot, coloriée selon la variable d'interet (le sexe)\n# la variable d'interet est assignee à l'argument \"color\" dans ggplot. groupFill dans ggMarginal est fixée à TRUE\nscatter_plot_color <- ggplot(data = linelist %>% drop_na(gender))+\n  geom_point(mapping = aes(y = wt_kg, x = age, color = gender)) +\n  labs(title = \"Scatter plot of weight and age\")+\n  theme(legend.position = \"bottom\")\n\nggMarginal(scatter_plot_color, type = \"density\", groupFill = TRUE)\n# avec boxplot \nggMarginal(\n  scatter_plot,\n  margins = \"x\",      # afficher un graphe marginal uniquement sur l'axe x\n  type = \"boxplot\")   "},{"path":"ggplot_tips.html","id":"étiquetage-pratiqueintelligent","chapter":"31 Trucs et Astuces avec ggplot","heading":"31.6 Étiquetage pratique/intelligent","text":"Dans ggplot2, il est également possible d’ajouter du texte aux graphiques. Cependant, cela s’accompagne d’une limitation notable : les étiquettes de texte entrent souvent en conflit avec les points de données dans un graphique, ce qui les rend désordonnées ou difficiles à lire. Il n’y pas de moyen idéal de gérer ce problème dans le “package” de base, mais il existe un module complémentaire ggplot2, connu sous le nom de ggrepel, qui rend la gestion de ce problème très simple !Le “package” ggrepel fournit deux nouvelles fonctions, geom_label_repel() et geom_text_repel(), qui remplacent geom_label() et geom_text(). Utilisez simplement ces fonctions à la place des fonctions de base pour produire des étiquettes soignées. Dans la fonction, mappez l’attribut graphique aes() comme toujours, mais incluez l’argument label = auquel vous fournissez un nom de variable contenant les valeurs que vous voulez afficher (par exemple l’id du patient, ou le nom, etc.). Vous pouvez créer des étiquettes plus complexes en combinant des variables et des retours à la ligne (\\n) dans str_glue() comme indiqué ci-dessous.TIP: Quelques conseilsUtilisez min.segment.length = 0 pour toujours dessiner des segments de ligne, ou min.segment.length = Inf pour ne jamais les dessiner.Utilisez min.segment.length = 0 pour toujours dessiner des segments de ligne, ou min.segment.length = Inf pour ne jamais les dessiner.Utilisez size = en dehors de aes() pour définir la taille du texte.Utilisez size = en dehors de aes() pour définir la taille du texte.Utilisez force = pour modifier le degré de répulsion entre les étiquettes et leurs points respectifs (la valeur par défaut est 1).Utilisez force = pour modifier le degré de répulsion entre les étiquettes et leurs points respectifs (la valeur par défaut est 1).Incluez fill = dans aes() pour que l’étiquette soit colorée par la valeur.\nUne lettre “” peut apparaître dans la légende - ajoutez guides(fill = guide_legend(override.aes = aes(color = NA))) pour la supprimer\nIncluez fill = dans aes() pour que l’étiquette soit colorée par la valeur.Une lettre “” peut apparaître dans la légende - ajoutez guides(fill = guide_legend(override.aes = aes(color = NA))) pour la supprimerPour en savoir plus, consultez ce tutoriel très détaillé.Vous pouvez étiqueter seulement un sous-ensemble de points de données - en utilisant la syntaxe standard ggplot() pour fournir différentes data = pour chaque couche geom du graphique. Ci-dessous, tous les cas sont représentés, mais seulement quelques-uns sont étiquetés.","code":"\npacman::p_load(ggrepel)\n\nlinelist %>%                                               # commencer avec les données d'intérêt linelist\n  group_by(hospital) %>%                                   # agréger les données par les différentes modalités de la variable hopital\n  summarise(                                               # créer une nouvelles base avec les données résumées par hopital\n    n_cases = n(),                                           # nombre de cas pq hospital\n    delay_mean = round(mean(days_onset_hosp, na.rm=T),1),    # délai moyen par hopital\n  ) %>% \n  ggplot(mapping = aes(x = n_cases, y = delay_mean))+      # envoyer la base modifiée dans la fonction ggplot\n  geom_point(size = 2)+                                    # ajouter les points\n  geom_label_repel(                                        # ajouter les étiquettes des points \n    mapping = aes(\n      label = stringr::str_glue(\n        \"{hospital}\\n{n_cases} cases, {delay_mean} days\")  # comment les étiquettes vont apparaître\n      ), \n    size = 3,                                              # taille du texte pour les étiquettes\n    min.segment.length = 0)+                               # afficher  tous les segments de ligne              \n  labs(                                                    # ajouter des étiquettes aux axes \n    title = \"Mean delay to admission, by hospital\",\n    x = \"Number of cases\",\n    y = \"Mean delay (days)\")\nggplot()+\n  # Tous les points en gris\n  geom_point(\n    data = linelist,                                   # la base complète fournie à ggplot\n    mapping = aes(x = ht_cm, y = wt_kg),\n    color = \"grey\",\n    alpha = 0.5)+                                              # gris et semi-transparent\n  \n  # Quelques points en noir\n  geom_point(\n    data = linelist %>% filter(days_onset_hosp > 15),  # filtrer les données à représenter\n    mapping = aes(x = ht_cm, y = wt_kg),\n    alpha = 1)+                                                # couleur par défaut (noir) et non transparente\n  \n  # point labels for few points\n  geom_label_repel(\n    data = linelist %>% filter(days_onset_hosp > 15),  # filtrer les données pour les étiquettes à afficher\n    mapping = aes(\n      x = ht_cm,\n      y = wt_kg,\n      fill = outcome,                                          # couleurs des boites d'étiquettes selon outcome\n      label = stringr::str_glue(\"Delay: {days_onset_hosp}d\")), # étiquette créée avec str_glue()\n    min.segment.length = 0) +                                  # afficher  tous les segments de ligne \n  \n  # supprimer lettre \"a\" de l'intérieur des boites\n  guides(fill = guide_legend(override.aes = aes(color = NA)))+\n  \n  # étiquettes des axes\n  labs(\n    title = \"Cases with long delay to admission\",\n    y = \"weight (kg)\",\n    x = \"height(cm)\")"},{"path":"ggplot_tips.html","id":"axes-de-temps","chapter":"31 Trucs et Astuces avec ggplot","heading":"31.7 Axes de temps","text":"Travailler avec des axes temporels dans ggplot peut sembler intimidant, mais est très facile grâce à quelques fonctions clés. Rappelez-vous que lorsque vous travaillez avec le temps ou la date, vous devez vous assurer que les variables correctes sont formatées en tant que classe de date ou de “datetime” - voir la page Travailler avec les dates pour plus d’informations à ce sujet, ou la page Courbes épidémiques (section ggplot) pour des exemples.L’ensemble de fonctions les plus utiles pour travailler avec des dates dans ggplot2 sont les fonctions d’échelle (scale_x_date(), scale_x_datetime()), et leurs fonctions d’axe des ordonnées. Ces fonctions vous permettent de définir la fréquence des étiquettes d’axe et le format des étiquettes d’axe. Pour savoir comment formater les dates, consultez à nouveau la section travailler avec les dates ! Vous pouvez utiliser les arguments date_breaks et date_labels pour spécifier l’apparence des dates :date_breaks vous permet de spécifier la fréquence des ruptures d’axe (le nombre de graduations) - vous pouvez passer une chaîne ici (par exemple \"3 months\", ou “2 days\")date_breaks vous permet de spécifier la fréquence des ruptures d’axe (le nombre de graduations) - vous pouvez passer une chaîne ici (par exemple \"3 months\", ou “2 days\")date_labels vous permet de définir le format dans lequel les dates sont affichées. Vous pouvez passer une chaîne de format de date à ces arguments (par exemple, \"%b-%d-%Y\") :date_labels vous permet de définir le format dans lequel les dates sont affichées. Vous pouvez passer une chaîne de format de date à ces arguments (par exemple, \"%b-%d-%Y\") :Une solution facile pour obtenir des étiquettes de date efficaces sur l’axe des x est d’assigner l’argument labels = dans scale_x_date() à la fonction label_date_short() du “package” scales. Cette fonction construira automatiquement des étiquettes de date efficaces (pour en savoir plus, cliquez ici). Un avantage supplémentaire de cette fonction est que les étiquettes s’adapteront automatiquement à l’évolution de vos données dans le temps, des jours aux semaines, aux mois et aux années.Vous trouverez un exemple complet dans la section de la page Courbes épidémiques sur les étiquettes de date à plusieurs niveaux, mais un exemple rapide est présenté ci-dessous pour référence :","code":"\n# faire une courbe épi en fonction de la date d'apparition des symptômes, lorsque cela est disponible\nggplot(linelist, aes(x = date_onset)) +\n  geom_histogram(binwidth = 7) +\n  scale_x_date(\n    # graduation par mois\n    date_breaks = \"1 months\",\n    # les étiquettes vont afficher le mois puis le jour\n    date_labels = \"%b %d\"\n  ) +\n  theme_classic()\nggplot(linelist, aes(x = date_onset)) +\n  geom_histogram(binwidth = 7) +\n  scale_x_date(\n    labels = scales::label_date_short()  # étiquettes de date plus pratiques d'un coup\n  )+\n  theme_classic()"},{"path":"ggplot_tips.html","id":"mise-en-évidence","chapter":"31 Trucs et Astuces avec ggplot","heading":"31.8 Mise en évidence","text":"La mise en évidence d’éléments spécifiques dans un graphique est un moyen utile d’attirer l’attention sur une instance spécifique d’une variable tout en fournissant des informations sur la dispersion de l’ensemble des données. Bien que cela ne soit pas facile à faire dans la base ggplot2, il existe un “package” externe qui peut aider à le faire, connu sous le nom de gghighlight. Il est facile à utiliser dans la syntaxe ggplot.Le “package” gghighlight utilise la fonction gghighlight() pour obtenir cet effet. Pour utiliser cette fonction, fournissez une déclaration logique à la fonction - cela peut avoir des résultats assez flexibles, mais ici nous allons montrer un exemple de la distribution de l’âge des cas dans notre liste linéaire, en les mettant en évidence par résultat.Cela fonctionne aussi très bien avec les fonctions de “facet” - cela permet à l’utilisateur de produire des graphiques répétitifs (selon les modalités la variable d’intérêt) mais cette fois au lieu que chaque sous-graphe concerne une modalité particulière de la variable sur laquelle le “faceting” est fait, tout sera représenté dans chaque sous-graphe mais avec les données de la modalité d’intérêt qui seront mises en évidence avec une couleur spécifique! Ci-dessous, nous comptons les cas par semaine et traçons les courbes épidémiques par hôpital (color = et facet_wrap() réglé sur la colonne hospital).","code":"\n# charger gghighlight\nlibrary(gghighlight)\n\n# remplacer les valeurs NA avec \"unknown\" dans la variable \"outcome\"\nlinelist <- linelist %>%\n  mutate(outcome = replace_na(outcome, \"Unknown\"))\n\n# produire un histogramme de tous les cas par age\nggplot(\n  data = linelist,\n  mapping = aes(x = age_years, fill = outcome)) +\n  geom_histogram() + \n  gghighlight::gghighlight(outcome == \"Death\")     # mettre en évidence les cas ou le patient est décédé\n# produire un histogramme de tous les cas par age\nlinelist %>% \n  count(week = lubridate::floor_date(date_hospitalisation, \"week\"),\n        hospital) %>% \n  ggplot()+\n  geom_line(aes(x = week, y = n, color = hospital))+\n  theme_minimal()+\n  gghighlight::gghighlight() +                      # mettre en évidence les cas ou le patient est décédé\n  facet_wrap(~hospital)                              # créer les \"facets\" par outcome"},{"path":"ggplot_tips.html","id":"représenter-différentsmultiples-jeux-de-données","chapter":"31 Trucs et Astuces avec ggplot","heading":"31.9 Représenter différents/multiples jeux de données","text":"Notez qu’il peut être difficile d’aligner correctement les axes pour tracer les données de plusieurs ensembles de données différents dans le même graphique. Considérez l’une des stratégies suivantes :Fusionnez les données avant de les représenter, et convertissez-les au format “long” avec une colonne reflétant l’ensemble de données.Utilisez cowplot ou un logiciel similaire pour combiner deux graphiques (voir ci-dessous).","code":""},{"path":"ggplot_tips.html","id":"combiner-des-graphiques","chapter":"31 Trucs et Astuces avec ggplot","heading":"31.10 Combiner des graphiques","text":"Deux “packages” très utiles pour combiner des graphiques sont cowplot et patchwork. Dans cette page, nous nous concentrerons principalement sur cowplot, avec une utilisation occasionnelle de patchwork.Voici l’introduction au cowplot en ligne. Vous pouvez lire la documentation plus complète de chaque fonction ici. Nous couvrirons ci-dessous quelques-uns des cas d’utilisation et des fonctions les plus courantes.Le “package” cowplot fonctionne en tandem avec ggplot2 - essentiellement, vous l’utilisez pour arranger et combiner les ggplots et leurs légendes en figures composées. Il peut également accepter les graphiques R base.Bien que le “faceting” (décrit dans la page bases de ggplot) soit une approche pratique de la représentation graphique, il est parfois impossible d’obtenir les résultats souhaités avec son approche relativement restrictive. Dans ce cas, vous pouvez choisir de combiner des graphiques en les collant ensemble dans un graphique plus grand. Il y trois packages bien connus qui sont parfaits pour cela - cowplot, gridExtra, et patchwork. Cependant, ces package font largement les mêmes choses, donc nous nous concentrerons sur cowplot pour cette section.","code":"\npacman::p_load( #charger les packages dont on aura besoin\n  tidyverse,      # pour manipuler et visualiser des données\n  cowplot,        # pour combiner des graphes\n  patchwork       # pour combiner des graphes\n)"},{"path":"ggplot_tips.html","id":"plot_grid","chapter":"31 Trucs et Astuces avec ggplot","heading":"plot_grid()","text":"Le package cowplot une gamme assez large de fonctions, mais l’utilisation la plus simple peut être réalisée par l’utilisation de plot_grid(). Il s’agit en fait d’un moyen d’arranger des graphiques prédéfinis dans une formation en grille. Nous pouvons travailler sur un autre exemple avec le jeu de données sur le paludisme - ici, nous pouvons représenter le nombre total de cas par district, et également montrer la courbe épidémique dans le temps.","code":"\nmalaria_data <- rio::import(here::here(\"data\", \"malaria_facility_count_data.rds\")) \n\n# diagramme en barres du nombre total de cas par district\np1 <- ggplot(malaria_data, aes(x = District, y = malaria_tot)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    x = \"District\",\n    y = \"Total number of cases\",\n    title = \"Total malaria cases by district\"\n  ) +\n  theme_minimal()\n\n# courbe epidemique en fonction du temps\np2 <- ggplot(malaria_data, aes(x = data_date, y = malaria_tot)) +\n  geom_col(width = 1) +\n  labs(\n    x = \"Date of data submission\",\n    y =  \"number of cases\"\n  ) +\n  theme_minimal()\n\ncowplot::plot_grid(p1, p2,\n                  # 1 colonne et deux lignes - empilées l'une sur l'autre\n                   ncol = 1,\n                   nrow = 2,\n                   # le graphe du haut fait 2/3 de la hauteur du second\n                   rel_heights = c(2, 3))"},{"path":"ggplot_tips.html","id":"combiner-les-légendes","chapter":"31 Trucs et Astuces avec ggplot","heading":"Combiner les légendes","text":"Si vos graphiques ont la même légende, il est relativement simple de les combiner. Utilisez simplement l’approche cowplot ci-dessus pour combiner les graphiques, mais supprimez la légende de l’une d’entre elles (pour éviter la dé-duplication).Si vos graphiques ont des légendes différentes, vous devez utiliser une autre approche :Créez et enregistrez vos graphiques sans légendes en utilisant theme(legend.position = \"none\").Extrayez les légendes de chaque graphe en utilisant get_legend() comme indiqué ci-dessous - mais extrayez les légendes des graphes modifiés pour afficher réellement la légende.Combinez les légendes dans un panneau de légendes.Combinez les graphes et le panneau de légendes.Pour la démonstration, nous montrons les deux graphiques séparément, puis disposés dans une grille avec leurs propres légendes (utilisation laide et inefficace de l’espace) :Voici à quoi ressemblent les deux graphiques lorsqu’ils sont combinés en utilisant plot_grid() sans combiner leurs légendes :Et maintenant, nous montrons comment combiner les légendes. Essentiellement, ce que nous faisons est de définir chaque graphique sans sa légende (theme(legend.position = \"none\"), et ensuite nous définissons la légende de chaque graphe séparément, en utilisant la fonction get_legend() de cowplot. Lorsque nous extrayons la légende du graphe sauvegardé, nous devons ajouter + la légende à nouveau, y compris en spécifiant le placement (\"right\") et des ajustements plus petits pour l’alignement des légendes et de leurs titres. Ensuite, nous combinons les légendes ensemble verticalement, puis nous combinons les deux graphes avec les légendes nouvellement combinées. Voilà !Cette solution été tirée de cette pubication avec une correction mineure pour aligner les légendes inspiré de cette pubication.NOTE: Note amusante - le “cow” dans cowplot vient du nom du créateur - Claus O. Wilke.","code":"\np1 <- linelist %>% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %>% \n  count(hospital, outcome) %>% \n  ggplot()+\n  geom_col(mapping = aes(x = hospital, y = n, fill = outcome))+\n  scale_fill_brewer(type = \"qual\", palette = 4, na.value = \"grey\")+\n  coord_flip()+\n  theme_minimal()+\n  labs(title = \"Cases by outcome\")\n\n\np2 <- linelist %>% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %>% \n  count(hospital, age_cat) %>% \n  ggplot()+\n  geom_col(mapping = aes(x = hospital, y = n, fill = age_cat))+\n  scale_fill_brewer(type = \"qual\", palette = 1, na.value = \"grey\")+\n  coord_flip()+\n  theme_minimal()+\n  theme(axis.text.y = element_blank())+\n  labs(title = \"Cases by age\")\ncowplot::plot_grid(p1, p2, rel_widths = c(0.3))\n# Définir graphe 1 sans legende\np1 <- linelist %>% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %>% \n  count(hospital, outcome) %>% \n  ggplot()+\n  geom_col(mapping = aes(x = hospital, y = n, fill = outcome))+\n  scale_fill_brewer(type = \"qual\", palette = 4, na.value = \"grey\")+\n  coord_flip()+\n  theme_minimal()+\n  theme(legend.position = \"none\")+\n  labs(title = \"Cases by outcome\")\n\n\n# Définir graphe 2 sans legende\np2 <- linelist %>% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %>% \n  count(hospital, age_cat) %>% \n  ggplot()+\n  geom_col(mapping = aes(x = hospital, y = n, fill = age_cat))+\n  scale_fill_brewer(type = \"qual\", palette = 1, na.value = \"grey\")+\n  coord_flip()+\n  theme_minimal()+\n  theme(\n    legend.position = \"none\",\n    axis.text.y = element_blank(),\n    axis.title.y = element_blank()\n  )+\n  labs(title = \"Cases by age\")\n\n\n# extraire légende de p1 (de p1 + legend)\nleg_p1 <- cowplot::get_legend(p1 +\n                                theme(legend.position = \"right\",        # extraire légende verticale\n                                      legend.justification = c(0,0.5))+ # pour bien  aligner la légende\n                                labs(fill = \"Outcome\"))                 # titre de la légende\n# extraire légende de p2 (de p2 + legend)\nleg_p2 <- cowplot::get_legend(p2 + \n                                theme(legend.position = \"right\",         # extraire légende verticale   \n                                      legend.justification = c(0,0.5))+  # pour bien  aligner la légende\n                                labs(fill = \"Age Category\"))             # titre de la légende\n\n# créer un tracé vierge pour l'alignement de la légende\n#blank_p <- patchwork::plot_spacer() + theme_void()\n\n# créer un panneau de légendes, qui peut être superposé (ou utiliser l'espaceur commenté ci-dessus)\nlegends <- cowplot::plot_grid(leg_p1, leg_p2, nrow = 2, rel_heights = c(.3, .7))\n\n# combiner les deux graphiques et le panneau de légendes combiné\ncombined <- cowplot::plot_grid(p1, p2, legends, ncol = 3, rel_widths = c(.4, .4, .2))\n\ncombined  # afficher ce qui est enregistré sous \"combined\""},{"path":"ggplot_tips.html","id":"encastrer-des-graphiques","chapter":"31 Trucs et Astuces avec ggplot","heading":"Encastrer des graphiques","text":"Vous pouvez encastrer un graphique dans un autre en utilisant cowplot. Voici les points à prendre en compte :Définissez le graphique principal avec theme_half_open() de cowplot ; il peut être préférable d’avoir la légende en haut ou en bas.Définissez le graphique à encastrer. Le mieux est d’avoir un graphe où vous n’avez pas besoin de légende. Vous pouvez supprimer les éléments du thème du graphe avec element_blank() comme indiqué ci-dessous.Combinez-les en appliquant ggdraw() au graphe principal, puis en ajoutant draw_plot() au graphe à encastrer et en spécifiant les coordonnées (x et y du coin inférieur gauche), la hauteur et la largeur en tant que proportion par rapport au graphe principal.Cette technique est expliquée plus en détail dans ces deux vignettes:Wilke labDocumentation draw_plot()","code":"\n# Définir graphe principal\nmain_plot <- ggplot(data = linelist)+\n  geom_histogram(aes(x = date_onset, fill = hospital))+\n  scale_fill_brewer(type = \"qual\", palette = 1, na.value = \"grey\")+ \n  theme_half_open()+\n  theme(legend.position = \"bottom\")+\n  labs(title = \"Epidemic curve and outcomes by hospital\")\n\n\n# Définir graphe à encastrer\ninset_plot <- linelist %>% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %>% \n  count(hospital, outcome) %>% \n  ggplot()+\n    geom_col(mapping = aes(x = hospital, y = n, fill = outcome))+\n    scale_fill_brewer(type = \"qual\", palette = 4, na.value = \"grey\")+\n    coord_flip()+\n    theme_minimal()+\n    theme(legend.position = \"none\",\n          axis.title.y = element_blank())+\n    labs(title = \"Cases by outcome\") \n\n\n# Combiner graphe principal avec celui à encastrer\ncowplot::ggdraw(main_plot)+\n     draw_plot(inset_plot,\n               x = .6, y = .55,    #x = .07, y = .65,\n               width = .4, height = .4)"},{"path":"ggplot_tips.html","id":"axes-doubles","chapter":"31 Trucs et Astuces avec ggplot","heading":"31.11 Axes doubles","text":"Un axe y secondaire est souvent un ajout demandé à un graphique ggplot2. Bien que la validité de tels graphiques fasse l’objet d’un débat animé au sein de la communauté de la visualisation de données, et qu’ils ne sont souvent pas recommandés, il se peut que vous devriez y avoir recours. Nous présentons ci-dessous une méthode pour y parvenir : l’utilisation du package cowplot pour combiner deux graphiques séparés.Cette approche implique la création de deux graphiques distincts - l’un avec un axe y sur la gauche, et l’autre avec un axe y sur la droite. Tous deux utiliseront un theme_cowplot() spécifique et doivent avoir le même axe des x. Ensuite, dans une troisième commande, les deux graphiques sont alignés et superposés l’un sur l’autre. Les fonctionnalités de cowplot, dont celle-ci n’est qu’une partie, sont décrites en profondeur sur ce site.Pour démontrer cette technique, nous allons superposer la courbe épidémique avec une ligne représentant le pourcentage hebdomadaire de patients décédés. Nous utilisons cet exemple parce que l’alignement des dates sur l’axe des x est plus complexe que, par exemple, l’alignement d’un graphique à barres avec un autre graphique. Quelques points à noter :L’épicurve et la ligne sont agrégées en semaines avant d’être tracées et les date_breaks et les date_labels sont identiques - nous faisons cela pour que les axes x des deux graphiques soient les mêmes lorsqu’ils sont superposés.L’axe des y est déplacé vers la droite pour le graphique 2 avec l’argument position = de scale_y_continuous().Les deux graphiques utilisent theme_cowplot().Notez qu’il existe un autre exemple de cette technique sur la page Courbes épidémiques - superposition de l’incidence cumulée sur l’épicurve.Tracer le graphique 1\nCeci reste essentiellement une épicurve. Nous utilisons geom_area() juste pour démontrer son utilisation (aire sous une ligne, par défaut).Tracer le graphique 2\nCréez le deuxième graphique qui montre une ligne du pourcentage hebdomadaire de décès.Maintenant, nous alignons le graphique en utilisant la fonction align_plots(), en spécifiant l’alignement horizontal et vertical (“hv”, qui peut aussi être “h”, “v”, “none”). Nous spécifions également l’alignement de tous les axes (haut, bas, gauche et droite) avec “tblr”. Il en résulte un objet de classe liste (avec 2 éléments).Ensuite, nous dessinons les deux graphiques ensemble en utilisant ggdraw() (de cowplot) et en référençant les deux parties de l’objet aligned_plots.","code":"\npacman::p_load(cowplot)            # charger/installer cowplot au besoin\n\np1 <- linelist %>%                 # sauvegarder le graphe comme un objet nommé p1\n     count(\n       epiweek = lubridate::floor_date(date_onset, \"week\")) %>% \n     ggplot()+\n          geom_area(aes(x = epiweek, y = n), fill = \"grey\")+\n          scale_x_date(\n               date_breaks = \"month\",\n               date_labels = \"%b\")+\n     theme_cowplot()+\n     labs(\n       y = \"Weekly cases\"\n     )\n\np1                                      # afficher p1\np2 <- linelist %>%         # sauvegarder le graphe comme un objet nommé p2\n     group_by(\n       epiweek = lubridate::floor_date(date_onset, \"week\")) %>% \n     summarise(\n       n = n(),\n       pct_death = 100*sum(outcome == \"Death\", na.rm=T) / n) %>% \n     ggplot(aes(x = epiweek, y = pct_death))+\n          geom_line()+\n          scale_x_date(\n               date_breaks = \"month\",\n               date_labels = \"%b\")+\n          scale_y_continuous(\n               position = \"right\")+\n          theme_cowplot()+\n          labs(\n            x = \"Epiweek of symptom onset\",\n            y = \"Weekly percent of deaths\",\n            title = \"Weekly case incidence and percent deaths\"\n          )\n\np2     # afficher p2\naligned_plots <- cowplot::align_plots(p1, p2, align=\"hv\", axis=\"tblr\")         # aligner les deux graphes et les sauvegarder en tant que liste\naligned_plotted <- ggdraw(aligned_plots[[1]]) + draw_plot(aligned_plots[[2]])  # les superposer et sauvegarder le  visuel résultant\naligned_plotted                                                                # afficher les graphiques superposés"},{"path":"ggplot_tips.html","id":"packages-pour-vous-aider","chapter":"31 Trucs et Astuces avec ggplot","heading":"31.12 Packages pour vous aider","text":"Il existe quelques packages R très intéressants, spécialement conçus pour vous aider à naviguer dans ggplot2 :","code":""},{"path":"ggplot_tips.html","id":"faire-du-ggplot2-via-clique-boutton-avec-equisse","chapter":"31 Trucs et Astuces avec ggplot","heading":"Faire du ggplot2 via clique-boutton avec equisse","text":"equisse fournit une interface graphique pour la construction de graphiques avec ggplot2. “Cet addin vous permet d’explorer interactivement vos données en les visualisant avec le package ggplot2. Il vous permet de dessiner des diagrammes en barres, des courbes, des diagrammes de dispersion, des histogrammes, des boxplot et des objets sf, puis d’exporter le graphique ou de récupérer le code pour reproduire le graphique.”Installez puis lancez l’addin via le menu RStudio ou avec esquisse::esquisser().Voir la page GithubDocumentation","code":""},{"path":"ggplot_tips.html","id":"divers","chapter":"31 Trucs et Astuces avec ggplot","heading":"31.13 Divers","text":"","code":""},{"path":"ggplot_tips.html","id":"affichage-numérique","chapter":"31 Trucs et Astuces avec ggplot","heading":"Affichage numérique","text":"Vous pouvez désactiver la notation scientifique en exécutant cette commande avant le graphique.Ou appliquez number_format() du package scales à une valeur ou une colonne spécifique, comme indiqué ci-dessous.Utilisez les fonctions du package scales pour ajuster facilement l’affichage des nombres. Ces fonctions peuvent être appliquées aux variables de votre jeu de données, mais sont présentées sur des nombres individuels pour les besoins de l’exemple.","code":"\noptions(scipen=999)\nscales::number(6.2e5)## [1] \"620 000\"\nscales::number(1506800.62,  accuracy = 0.1,)## [1] \"1 506 800.6\"\nscales::comma(1506800.62, accuracy = 0.01)## [1] \"1,506,800.62\"\nscales::comma(1506800.62, accuracy = 0.01,  big.mark = \".\" , decimal.mark = \",\")## [1] \"1.506.800,62\"\nscales::percent(0.1)## [1] \"10%\"\nscales::dollar(56)## [1] \"$56\"\nscales::scientific(100000)## [1] \"1e+05\""},{"path":"ggplot_tips.html","id":"ressources-16","chapter":"31 Trucs et Astuces avec ggplot","heading":"31.14 Ressources","text":"Inspiration ggplot graph galleryGuide pour la présentation des données de surveillanceFacets et étiquettes Fonction d’étiquetageAjuster l’ordre des modalités des variables de type facteur fct_reorderfct_inorderRé-arranger un boxplotRé-ordonner une variable dans ggplot2R Data Science - FactorsLégendesAjuster l’ordre d’une légendeNotes de bas de graphique: Alignement des notes du graphiqueEtiquettesggrepelAnti-sèchesBeautiful plotting ggplot2","code":""},{"path":"epicurves.html","id":"epicurves","chapter":"32 Courbes épidémiques","heading":"32 Courbes épidémiques","text":"Une courbe épidémique (également connue sous le nom de “courbe épi”) est un graphique épidémiologique de base généralement utilisé pour visualiser le schéma temporel d’apparition de la maladie parmi un groupe de cas ou une épidémie.L’analyse de la courbe épi peut révéler des tendances temporelles, des valeurs aberrantes, l’ampleur de l’épidémie, la période d’exposition la plus probable, les intervalles de temps entre les générations de cas, et peut même aider à identifier le mode de transmission d’une maladie non identifie (par exemple, source ponctuelle, source commune continue, propagation de personne à personne). Une leçon en ligne sur l’interprétation des courbes épi est disponible sur le site Web du US CDC.Dans cette page, nous démontrons le paquet ggplot2 pour produire des épicurves dans R, qui permet une personnalisation avancé via des commandes plus complexes.Nous abordons également des cas d’utilisation spécifiques tels que :Les tracés de données de comptages agrégéesLe facettage ou la production de petits multiplesApplication de moyennes mobilesMontrer quelles données sont “provisoires” ou sujettes à des retards de rapportSuperposer l’incidence cumulative des cas à l’aide d’un deuxiéme axe","code":""},{"path":"epicurves.html","id":"préparation-15","chapter":"32 Courbes épidémiques","heading":"32.1 Préparation","text":"","code":""},{"path":"epicurves.html","id":"paquets-2","chapter":"32 Courbes épidémiques","heading":"Paquets","text":"Ce chunk de code montre le chargement des paquets nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire et le charge pour l’utiliser. Vous pouvez également charger les paquets installs avec library() de base R. Voir la page sur R basics pour plus d’informations sur les paquets R.","code":"\npacman::p_load(\n  rio,         # import/export de fichiers\n  here,        # chemins de fichiers relatifs \n  lubridate,   # travailler avec des dates/epiweeks\n  aweek,       # paquet alternatif pour travailler avec les dates/semaines\n  #incidence2, # paquet alternatif \n  i2extras,    # supplément à incidence2\n  stringr,      # recherche et manipulation de chaînes de caractères\n  forcats,      # travail avec des facteurs\n  RColorBrewer, # palettes de couleurs de colorbrewer2.org\n  tidyverse     # gestion des données + graphiques ggplot2\n) "},{"path":"epicurves.html","id":"importer-des-données-6","chapter":"32 Courbes épidémiques","heading":"Importer des données","text":"Deux exemples de jeux de données sont utilisés dans cette section :Liste de cas individuels d’une épidémie simulée.Comptage agrégé par hôpital à partir de la même épidémie simulée.Les jeux de données sont importés à l’aide de la fonction import() du paquetage rio. Voir la page Importation et exportation pour les différentes maniéres d’importer des données.Liste de casNous importons le jeu de données des cas d’une épidémie d’Ebola simulée. Si vous souhaitez télécharger les données pour les suivre pas à pas, consultez les instructions de la page Télécharger le manuel et les données. Nous supposons que le fichier est dans le répertoire de travail, donc aucun sous-dossier n’est spécifié dans ce chemin de fichier.Les 50 premiéres lignes sont affichées ci-dessous.Comptes de cas agrégés par hôpitalPour les besoins du manuel, le jeu de données des comptages hebdomadaires agrégés par hôpital est créé à partir de la linelist avec le code suivant.Les 50 premiéres lignes sont affichées ci-dessous :","code":"\nlinelist <- import(\"linelist_cleaned.xlsx\")\n# Importez les données de comptage dans R\ncount_data <- linelist %>% \n  group_by(hospital, date_hospitalisation) %>% \n  summarize(n_cases = dplyr::n()) %>% \n  filter(date_hospitalisation > as.Date(\"2013-06-01\")) %>% \n  ungroup()"},{"path":"epicurves.html","id":"définir-les-paramétres","chapter":"32 Courbes épidémiques","heading":"Définir les paramétres","text":"Pour la production d’un rapport, vous pouvez souhaiter définir des paramétres modifiables tels que la date à laquelle les données sont actuelles (la “date des données”). Vous pouvez ensuite faire référence à l’objet data_date dans votre code lorsque vous appliquez des filtres ou dans des légendes dynamiques.","code":"\n## définit la date du rapport pour le rapport\n## note : peut étre défini à Sys.Date() pour la date actuelle\ndata_date <- as.Date(\"2015-05-15\")"},{"path":"epicurves.html","id":"vérifier-les-dates","chapter":"32 Courbes épidémiques","heading":"Vérifier les dates","text":"Vérifiez que chaque colonne de date pertinente est de la classe Date et posséde une plage de valeurs appropriée. Vous pouvez le faire simplement en utilisant hist() pour les histogrammes, ou range() avec na.rm=TRUE, ou avec ggplot() comme ci-dessous.","code":"\n# vérifier la plage de dates d'apparition\nggplot(data = linelist)+\n  geom_histogram(aes(x = date_onset))"},{"path":"epicurves.html","id":"epicurves-avec-ggplot2","chapter":"32 Courbes épidémiques","heading":"32.2 Epicurves avec ggplot2","text":"L’utilisation de ggplot() pour construire votre épicurve permet plus de flexibilité et de personnalisation, mais nécessite plus d’efforts et de compréhension du fonctionnement de ggplot().Contrairement à l’utilisation du paquet incidence2, vous devez manuellement contrôler l’agrégation des cas par temps (en semaines, mois, etc.) et les intervalles des étiquettes sur l’axe des dates. Ceci doit étre soigneusement géré.Ces exemples utilisent un sous-ensemble de l’ensemble de données linelist - seulement les cas de l’hôpital central.Pour produire une épicurve avec ggplot(), il y trois éléments principaux :Un histogramme, avec les cas de la liste de lignes agrégés en “bins” distingués par des points de “rupture” spécifiques.Des échelles pour les axes et leurs étiquettesDes thèmes pour l’apparence du graphique, y compris les titres, les étiquettes, les légendes, etc.","code":"\ncentral_data <- linelist %>% \n  filter(hospital == \"Central Hospital\")"},{"path":"epicurves.html","id":"spécifier-les-cas-en-bacs","chapter":"32 Courbes épidémiques","heading":"spécifier les cas en bacs","text":"Nous montrons ici comment spécifier la façon dont les cas seront agrégés dans des cases d’histogramme (“barres”). Il est important de reconnaétre que l’agrégation des cas dans les cases de l’histogramme n’est pas nécessairement les mêmes intervalles que les dates qui apparaîtront sur l’axe des abscisses.Vous trouverez ci-dessous le code le plus simple pour produire des épicurves quotidiennes et hebdomadaires.Dans la commande globale ggplot(), le jeu de données est fourni avec data =. Sur cette base, la géométrie d’un histogramme est ajoutée avec un +. Dans la commande geom_histogram(), nous mappons l’esthétique de telle sorte que la colonne date_onset soit mappée sur l’axe des x. Toujours dans geom_histogram() mais non dans aes(), nous définissons la binwidth = des bins de l’histogramme, en jours. Si cette syntaxe ggplot2 est confuse, revoyez la page sur les bases de ggplot.CAUTION: Tracer des cas hebdomadaires en utilisant binwidth = 7 fait démarrer le premier bin de 7 jours au premier cas, qui pourrait étre n’importe quel jour de la semaine ! Pour créer des semaines spécifiques, voir la section ci-dessous .Notons que le premier cas de cet ensemble de données de l’hôpital Central vu ses symptômes apparaître le :Pour spécifier manuellement les ruptures des cases de l’histogramme, n’utilisez pas l’argument binwidth =, mais fournissez un vecteur de dates à breaks =..créez le vecteur de dates avec la fonction R base seq.Date(). Cette fonction attend les arguments =, =, et =. Par exemple, la commande ci-dessous renvoie les dates mensuelles commençant le 15 janvier et se terminant le 28 juin.Ce vecteur peut étre fourni à geom_histogram() sous la forme breaks = :Une simple séquence de date hebdomadaire peut étre retournée en définissant = \"week\". Par exemple :Une alternative à la fourniture de dates de début et de fin spécifiques consiste à écrire un code dynamique pour que les bacs hebdomadaires commencent le lundi précédant le premier cas. **Nous utiliserons ces vecteurs de date dans les exemples ci-dessous.Décortiquons le code plutôt déconcertant ci-dessus :La valeur “” (date la plus ancienne de la séquence) est crée comme suit : la valeur minimale de la date (min() avec na.rm=TRUE) dans la colonne date_onset est introduite dans floor_date() du paquet lubridate. floor_date() défini sur “week” renvoie la date de début de la “semaine” de ce cas, étant donné que le jour de début de chaque semaine est un lundi (week_start = 1).De même, la valeur “” (date de fin de la séquence) est créée en utilisant la fonction inverse ceiling_date() pour retourner le lundi aprés le dernier cas.L’argument “” de seq.Date() peut étre défini sur un nombre quelconque de jours, de semaines ou de mois.Utilisez week_start = 7 pour les semaines de dimanche.Comme nous utiliserons ces vecteurs de date tout au long de cette page, nous en définissons également un pour l’ensemble du foyer (ce qui précéde ne concerne que l’hôpital central).Ces sorties seq.Date() peuvent étre utilisées pour créer les ruptures des cases de l’histogramme, mais aussi les ruptures pour les étiquettes de date, qui peuvent étre indépendantes des cases. Vous en saurez plus sur les étiquettes de date dans les sections suivantes.TIP: Pour une commande ggplot() plus simple, sauvegardez à l’avance les ruptures de bacs et les ruptures d’étiquettes de dates en tant que vecteurs nommés, et fournissez simplement leurs noms à breaks =..","code":"\n# quotidien \nggplot(data = central_data) + # set data\n  geom_histogram( # ajouter un histogramme\n    mapping = aes(x = date_onset), # map date column to x-axis\n    binwidth = 1)+ # cas groupés par 1 jour \n  labs(title = \"Central Hospital - Quotidiennement\") # titre\n\n# hebdomadaire\nggplot(data = central_data) + # set data \n  geom_histogram( # ajouter un histogramme\n      mapping = aes(x = date_onset), # mappage de la colonne date sur l'axe des x\n      binwidth = 7)+ # cas classés tous les 7 jours, à partir du premier cas ( !) \n  labs(title = \"Central Hospital - Tranches de 7 jours, à partir du premier cas\") # titre\nformat(min(central_data$date_onset, na.rm=T), \"%A %d %b, %Y\")## [1] \"Thursday 01 May, 2014\"\nmonthly_breaks <- seq.Date(from = as.Date(\"2014-02-01\"),\n                           to = as.Date(\"2015-07-15\"),\n                           by = \"months\")\n\nmonthly_breaks # print##  [1] \"2014-02-01\" \"2014-03-01\" \"2014-04-01\" \"2014-05-01\" \"2014-06-01\" \"2014-07-01\"\n##  [7] \"2014-08-01\" \"2014-09-01\" \"2014-10-01\" \"2014-11-01\" \"2014-12-01\" \"2015-01-01\"\n## [13] \"2015-02-01\" \"2015-03-01\" \"2015-04-01\" \"2015-05-01\" \"2015-06-01\" \"2015-07-01\"\n# mensuel \nggplot(data = central_data) +  \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    breaks = monthly_breaks)+ # fournit le vecteur prédéfini de breaks                    \n  labs(title = \"Bins de cas mensuels\") # titre\nweekly_breaks <- seq.Date(from = as.Date(\"2014-02-01\"),\n                          to = as.Date(\"2015-07-15\"),\n                          by = \"week\")\n# Séquence de dates hebdomadaires du lundi pour CENTRAL HOSPITAL\nweekly_breaks_central <- seq.Date(\n  from = floor_date(min(central_data$date_onset, na.rm=T), \"week\", week_start = 1), # lundi avant le premier cas\n  to = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 1), # lundi aprés la derniére affaire\n  by = \"week\")\n# Séquence pour l'ensemble du foyer\nweekly_breaks_all <- seq.Date(\n  from = floor_date(min(linelist$date_onset, na.rm=T), \"week\", week_start = 1), # lundi avant le premier cas\n  to = ceiling_date(max(linelist$date_onset, na.rm=T), \"week\", week_start = 1), # lundi aprés la derniére affaire\n  by = \"week\")"},{"path":"epicurves.html","id":"exemple-dépicurve-hebdomadaire","chapter":"32 Courbes épidémiques","heading":"Exemple d’épicurve hebdomadaire","text":"Vous trouverez ci-dessous un exemple de code détaillé pour produire des épicurves hebdomadaires pour les semaines du lundi, avec des barres alignées, des étiquettes de date et des lignes de grille verticales. Cette section est destinée à l’utilisateur qui besoin de code rapidement. Pour comprendre en profondeur chaque aspect (thèmes, étiquettes de date, etc.), passez aux sections suivantes. noter :Les cassures de l’histogramme sont définies avec seq.Date() comme expliqué ci-dessus pour commencer le lundi avant le premier cas et pour finir le lundi aprés le dernier cas.L’intervalle des étiquettes de date est spécifié par date_breaks = dans scale_x_date().L’intervalle des petites lignes verticales entre les étiquettes de date est spécifié par date_minor_breaks =.expand = c(0,0) dans les échelles x et y supprime l’espace excédentaire de chaque côte des axes, ce qui garantit également que les étiquettes de date commencent à partir de la premiére barre.","code":"\n# ALIGNEMENT TOTAL DE LA SEMAINE DU LUNDI\n#############################\n# définir la séquence des pauses hebdomadaires\nweekly_breaks_central <- seq.Date(\n      from = floor_date(min(central_data$date_onset, na.rm=T), \"week\", week_start = 1), # lundi avant la premiére affaire\n      to = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 1), # lundi aprés la derniére affaire\n      by = \"week\")    # les bins sont de 7 jours \n\n\nggplot(data = central_data) + \n  \n  # créer un histogramme : spécifier les points de rupture des bacs : commence le lundi avant le premier cas, se termine le lundi aprés le dernier cas\n  geom_histogram(\n    \n    # esthétique de la mapping\n    mapping = aes(x = date_onset), # colonne de date mappée sur l'axe des x\n    \n    # ruptures de la case de l'histogramme\n    breaks = weekly_breaks_central, # pauses des cases de l'histogramme définies précédemment\n    \n    # barres\n    color = \"darkblue\", # couleur des lignes autour des barres\n    fill = \"lightblue\" # couleur de remplissage dans les barres\n  )+ \n    \n  # étiquettes de l'axe des x\n  scale_x_date(\n    expand = c(0,0), # suppression de l'espace excédentaire sur l'axe des x avant et aprés les barres de cas\n    date_breaks = \"4 weeks\", # les étiquettes de date et les principales lignes de grille verticales apparaissent toutes les 3 semaines du lundi\n    date_minor_breaks = \"week\", # les lignes verticales mineures apparaissent chaque lundi de semaine\n    date_labels = \"%a\\n%d %b\\n%Y\")+ # format des étiquettes de date\n  \n  # Axe des y\n  scale_y_continuous(\n    expand = c(0,0))+ # suppression de l'espace excédentaire sur l'axe des y en dessous de 0 (alignement de l'histogramme sur l'axe des x)\n  \n  # thèmes esthétiques\n  theme_minimal()+ # simplifie le fond du graphique\n  \n  theme(\n    plot.caption = element_text(hjust = 0, # légende sur le côte gauche\n                                face = \"italic\"), # légende en italique\n    axis.title = element_text(face = \"bold\"))+ # titres des axes en gras\n  \n  # étiquettes incluant une légende dynamique\n  labs(\n    title = \"Incidence hebdomadaire des cas (semaines de lundi)\",\n    subtitle = \"Notez l'alignement des barres, des lignes de grille verticales et des étiquettes d'axe sur les semaines du lundi\",\n    x = \"Semaine d'apparition des symptômes\",\n    y = \"Incidence hebdomadaire des cas signalés\",\n    caption = stringr::str_glue(\"n = {nrow(central_data)} de Central Hospital ; Les occurrences de cas ranges de {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} à {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}{nrow(central_data %>% filter(is.na(date_onset)))} cas dont la date d'apparition est manquante et qui ne sont pas indiqués\"))"},{"path":"epicurves.html","id":"semaines-de-dimanche","chapter":"32 Courbes épidémiques","heading":"Semaines de dimanche","text":"Pour obtenir le graphique ci-dessus pour les semaines de dimanche, quelques modifications sont nécessaires, car les date_breaks = \"weeks\" ne fonctionnent que pour les semaines de lundi.Les points de rupture des bins de l’histogramme doivent étre fixés au dimanche (week_start = 7)Dans scale_x_date(), les ruptures de date similaires doivent étre fournies à breaks = et minor_breaks = pour s’assurer que les étiquettes de date et les lignes de grille verticales s’alignent sur les dimanches.Par exemple, la commande scale_x_date() pour les semaines du dimanche pourrait ressembler à ceci :","code":"scale_x_date(\n    expand = c(0,0),\n    \n    # spécifie l'intervalle des étiquettes de date et des principales lignes de grille verticales\n    breaks = seq.Date(\n      from = floor_date(min(central_data$date_onset, na.rm=T), \"week\", week_start = 7), # dimanche avant la premiére affaire\n      to = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7), # dimanche aprés la derniére affaire\n      by = \"4 weeks\"),\n    \n    # spécifier l'intervalle de la ligne de grille verticale mineure \n    minor_breaks = seq.Date(\n      from = floor_date(min(central_data$date_onset, na.rm=T), \"week\", week_start = 7), # dimanche avant le premier cas\n      to = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7), # dimanche aprés la derniére affaire\n      by = \"week\"),\n   \n    # format des étiquettes de date\n    date_labels = \"%a\\n%d %b\\n%Y\")+ # jour, au-dessus abréviation du mois, au-dessus année à 2 chiffres"},{"path":"epicurves.html","id":"groupercolorer-par-valeur","chapter":"32 Courbes épidémiques","heading":"Grouper/colorer par valeur","text":"Les barres de l’histogramme peuvent étre colorées par groupe et “empilées”. Pour désigner la colonne de regroupement, effectuez les modifications suivantes. Voir la page ggplot basics pour plus de détails.Dans le mappage esthétique de l’histogramme aes(), mettez en correspondance le nom de la colonne avec les arguments group = et fill =.Supprimez tout argument fill = à l’extérieur de aes(), car il remplacera celui qui se trouve à l’intérieur.Les arguments inside de aes() s’appliqueront par groupe, alors que les arguments outside s’appliqueront à toutes les barres (par exemple, vous pouvez toujours vouloir color = à l’extérieur, pour que chaque barre ait la même bordure).Voici à quoi ressemblerait la commande aes() pour grouper et colorer les barres par sexe :Le voici appliqué :","code":"\naes(x = date_onset, group = gender, fill = gender)\nggplot(data = linelist) + # commencer avec linelist (many hospitals)\n  \n  # faire un histogramme : spécifier les points de rupture de la benne : commence le lundi avant le premier cas, se termine le lundi aprés le dernier cas\n  geom_histogram(\n    mapping = aes(\n      x = date_onset,\n      group = hospital, # définir les données pour qu'elles soient groupées par hôpital\n      fill = hospital), # remplissage des barres (couleur intérieure) par hôpital\n    \n    # les pauses sont les semaines de lundi\n    breaks = weekly_breaks_all, # séquence de pauses hebdomadaires du lundi pour toute l'épidémie, définie dans le code précédent \n    \n    closed = \"left\", # Compter les cas à partir du début du point d'arrêt\n    # Couleur autour des barres\n    color = \"black\")"},{"path":"epicurves.html","id":"ajuster-les-couleurs","chapter":"32 Courbes épidémiques","heading":"Ajuster les couleurs","text":"Pour manuellement régler le remplissage pour chaque groupe, utilisez scale_fill_manual() (note : scale_color_manual() est différent !).\nUtilisez l’argument values = pour appliquer un vecteur de couleurs.\nUtilisez na.value = pour spécifier une couleur pour les valeurs NA.\nUtilisez l’argument labels = pour changer le texte des éléments de la légende. Pour étre sur, fournissez un vecteur nommé comme c(\"old\" = \"new\", \"old\" = \"new\") ou ajustez les valeurs dans les données elles-mêmes.\nUtilisez name = pour donner un titre correct à la légende.\nUtilisez l’argument values = pour appliquer un vecteur de couleurs.Utilisez na.value = pour spécifier une couleur pour les valeurs NA.Utilisez l’argument labels = pour changer le texte des éléments de la légende. Pour étre sur, fournissez un vecteur nommé comme c(\"old\" = \"new\", \"old\" = \"new\") ou ajustez les valeurs dans les données elles-mêmes.Utilisez name = pour donner un titre correct à la légende.Pour plus d’informations sur les échelles et les palettes de couleurs, consultez la page sur les bases de ggplot.","code":"\nggplot(data = linelist)+ # commencer avec linelist (plusieurs hôpitaux)\n  \n  # faire un histogramme\n  geom_histogram(\n    mapping = aes(x = date_onset,\n        group = hospital, # cas groupés par hôpital\n        fill = hospital), # remplissage des barres par hôpital\n    \n    # bin breaks\n    breaks = weekly_breaks_all, # séquence de bin breaks hebdomadaires du lundi, définie dans le code précédent\n    \n    closed = \"left\", # Compter les cas à partir du début du point d'arrêt\n  \n    color = \"black\")+ # couleur de la bordure de chaque barre\n  \n  # spécification manuelle des couleurs\n  scale_fill_manual(\n    values = c(\"black\", \"orange\", \"grey\", \"beige\", \"blue\", \"brown\"),\n    labels = c(\"St. Mark's Maternity Hospital (SMMH)\" = \"St.Mark's\"),\n    name = \"Hospital\") # spécifier les couleurs de remplissage (\"values\") - attention à l'ordre !"},{"path":"epicurves.html","id":"ajuster-lordre-des-niveaux","chapter":"32 Courbes épidémiques","heading":"Ajuster l’ordre des niveaux","text":"Le meilleur moyen d’ajuster l’ordre dans lequel les barres groupées sont empilées est de classer la colonne de groupage en tant que classe Facteur. Vous pouvez alors désigner l’ordre des niveaux de facteurs (et leurs étiquettes d’affichage). Voir la page sur facteurs ou ggplot tips pour plus de détails.Avant de réaliser le tracé, utilisez la fonction fct_relevel() du paquet forcats pour convertir la colonne de regroupement en classe facteur et ajuster manuellement l’ordre des niveaux, comme détaillé dans la page sur les facteurs.Dans le graphique ci-dessous, les seules différences par rapport au précédent sont que la colonne hospital été consolidée comme ci-dessus, et que nous utilisons guides() pour inverser l’ordre de la légende, de sorte que “Missing” se trouve en bas de la légende.TIP: Pour inverser l’ordre de la légende uniquement, ajoutez cette commande ggplot2 : guides(fill = guide_legend(reverse = TRUE)).","code":"\n# charger le paquet forcats pour travailler avec les facteurs\npacman::p_load(forcats)\n\n# définir un nouvel ensemble de données avec l'hôpital comme facteur\nplot_data <- linelist %>% \n  mutate(hospital = fct_relevel(hospital, c(\"Missing\", \"Other\"))) # Convertir en facteur et définir \"Manquant\" et \"Autre\" comme niveaux supérieurs pour apparaétre sur le sommet de l'épicurve.\n\nlevels(plot_data$hospital) # Imprime les niveaux dans l'ordre## [1] \"Missing\"                              \"Other\"                               \n## [3] \"Central Hospital\"                     \"Military Hospital\"                   \n## [5] \"Port Hospital\"                        \"St. Mark's Maternity Hospital (SMMH)\"\nggplot(plot_data) + # Utiliser le NOUVEL ensemble de données avec les hôpitaux comme facteurs réordonnés.\n  \n  # créer un histogramme\n  geom_histogram(\n    mapping = aes(x = date_onset,\n        group = hospital, # cas groupés par hôpital\n        fill = hospital), # remplissage des barres (couleur) par hôpital\n    \n    breaks = weekly_breaks_all, # séquence de pauses hebdomadaires du lundi pour toute l'épidémie, définie en haut de la section ggplot\n    \n    color = \"black\")+ # couleur de la bordure autour de chaque barre\n    \n  # étiquettes de l'axe des x\n  scale_x_date(\n    expand = c(0,0), # supprimer l'espace excédentaire sur l'axe des x avant et aprés les barres de cas\n    date_breaks = \"3 weeks\", # les étiquettes apparaissent toutes les 3 semaines du lundi\n    date_minor_breaks = \"week\", # les lignes verticales apparaissent tous les lundis de la semaine\n    date_labels = \"%d\\n%b\\n'%y\")+ # format des étiquettes de date\n  \n  # Axe des y\n  scale_y_continuous(\n    expand = c(0,0))+ # suppression de l'espace excédentaire sur l'axe des y en dessous de 0\n  \n  # spécification manuelle des couleurs, ! attention à l'ordre\n  scale_fill_manual(\n    values = c(\"grey\", \"beige\", \"black\", \"orange\", \"blue\", \"brown\"),\n    labels = c(\"St. Mark's Maternity Hospital (SMMH)\" = \"St.Marks\"),\n    name = \"Hospital\")+ \n  \n  # thèmes esthétiques\n  theme_minimal()+ # simplifier le fond du graphique\n  \n  theme(\n    plot.caption = element_text(face = \"italic\", # légende à gauche en italique\n                                hjust = 0), \n    axis.title = element_text(face = \"bold\"))+ # titres des axes en gras\n  \n  # étiquettes\n  labs(\n    title = \"Incidence hebdomadaire des cas par hôpital\",\n    subtitle = \"Hospital as re-ordered factor\",\n    x = \"Semaine d'apparition des symptômes\",\n    y = \"Cas hebdomadaires\")"},{"path":"epicurves.html","id":"ajuster-la-légende","chapter":"32 Courbes épidémiques","heading":"Ajuster la légende","text":"Pour en savoir plus sur les légendes et les échelles, consultez la page ggplot tips. Voici quelques points saillants :Modifiez le titre de la légende soit dans la fonction d’échelle, soit avec labs(fill = \"Legend title\") (si vous utilisez color = esthétique, alors utilisez labs(color = \"\")).theme(legend.title = element_blank()) pour ne pas avoir de titre de légendetheme(legend.position = \"top\") (“bottom”, “left”, “right”, ou “none” pour supprimer la légende)theme(legend.direction = \"horizontal\") légende horizontaleguides(fill = guide_legend(reverse = TRUE)) pour inverser l’ordre de la légende","code":""},{"path":"epicurves.html","id":"barres-côte-à-côte","chapter":"32 Courbes épidémiques","heading":"Barres côte à côte","text":"L’affichage côte à côte des barres de groupe (par opposition à l’empilement) est spécifié dans geom_histogram() avec position = \"dodge\" placé en dehors de aes().S’il y plus de deux groupes de valeurs, ceux-ci peuvent devenir difficiles à lire. Envisagez plutôt d’utiliser un graphique à facettes (petits multiples). Pour améliorer la lisibilité dans cet exemple, les valeurs de sexe manquantes sont supprimées.","code":"\nggplot(central_data %>% drop_na(gender))+ # Commencez par les cas de l'hôpital central en supprimant les valeurs manquantes pour le sexe.\n    geom_histogram(\n        mapping = aes(\n          x = date_onset,\n          group = gender, # cas groupés par sexe\n          fill = gender), # barres remplies par sexe\n        \n        # histogramme bin breaks\n        breaks = weekly_breaks_central, # séquence de dates hebdomadaires pour le foyer central - définie en haut de la section ggplot\n        \n        closed = \"left\",\n        \n        color = \"black\", # couleur du bord des barres\n        \n        position = \"dodge\")+ # barres SIDE-BY-SIDE\n                      \n  \n  # Les étiquettes sur l'axe des x\n  scale_x_date(expand = c(0,0), # supprimer l'espace excédentaire de l'axe des x sous et aprés les barres de cas\n               date_breaks = \"3 weeks\", # les étiquettes apparaissent toutes les 3 semaines du lundi\n               date_minor_breaks = \"week\", # les lignes verticales apparaissent tous les lundis de la semaine\n               date_labels = \"%d\\n%b\\n'%y\")+ # format des étiquettes de date\n  \n  # Axe des y\n  scale_y_continuous(expand = c(0,0))+ # supprime l'espace excédentaire sur l'axe des y entre le bas des barres et les étiquettes\n  \n  #échelle des couleurs et des étiquettes de légende\n  scale_fill_manual(values = c(\"brown\", \"orange\"), # spécifie les couleurs de remplissage (\"values\") - attention à l'ordre !\n                    na.value = \"grey\" )+     \n\n  # thèmes esthétiques\n  theme_minimal()+ # un ensemble de thèmes pour simplifier le graphe\n  theme(plot.caption = element_text(face = \"italic\", hjust = 0), # légende à gauche en italique\n        axis.title = element_text(face = \"bold\"))+ # titres des axes en gras\n  \n  # étiquettes\n  labs(title = \"Incidence hebdomadaire des cas, par sexe\",\n       subtitle = \"Sous-titre\",\n       fill = \"Gender\", # fournir un nouveau titre pour la légende\n       x = \"Semaine d'apparition des symptômes\",\n       y = \"Incidence hebdomadaire des cas signalés\")"},{"path":"epicurves.html","id":"limites-de-laxe","chapter":"32 Courbes épidémiques","heading":"Limites de l’axe","text":"Il existe deux façons de limiter l’étendue des valeurs des axes.Généralement, la méthode préférée est d’utiliser la commande coord_cartesian(), qui accepte xlim = c(min, max) et ylim = c(min, max) (où vous fournissez les valeurs min et max). Ceci agit comme un “zoom” sans réellement supprimer de données, ce qui est important pour les statistiques et les mesures sommaires.Alternativement, vous pouvez définir les valeurs maximales et minimales de la date en utilisant limits = c() dans scale_x_date(). Par exemple :Si vous souhaitez que l’axe des abscisses s’tende jusqu’é une date spécifique (par exemple, la date du jour), même si aucun nouveau cas n’été signalé, vous pouvez utiliser :DANGER: Soyez prudent en fixant les ruptures d’échelle ou les limites de l’axe des y (par exemple, 0 à 30 par 5 : seq(0, 30, 5)). De tels nombres statiques peuvent couper votre tracé trop court si les données changent pour dépasser la limite !.","code":"\nscale_x_date(limits = c(as.Date(\"2014-04-01\"), NA)) # définit une date minimum mais laisse la date maximum ouverte.  \nscale_x_date(limits = c(NA, Sys.Date())) # garantit que l'axe des dates s'étendra jusqu'à la date du jour  "},{"path":"epicurves.html","id":"libellés-des-axes-de-date-lignes-de-grille","chapter":"32 Courbes épidémiques","heading":"Libellés des axes de date / lignes de grille","text":"TIP: Rappelez-vous que les étiquettes de l’axe des dates sont indépendantes de l’agrégation des données en barres, mais visuellement, il peut étre important d’aligner les bacs, les étiquettes de date et les lignes de grille verticales.Pour modifier les étiquettes de date et les lignes de grille, utilisez scale_x_date() de l’une de ces façons :Si vos bins d’histogramme sont des jours, lundi des semaines, des mois ou des années :\nUtilisez date_breaks = pour spécifier l’intervalle des étiquettes et des lignes de grille principales (par exemple “jour”, “semaine”, “3 semaines”, “mois” ou “année”).\nUtilisez date_minor_breaks = pour spécifier l’intervalle des lignes verticales mineures (entre les étiquettes de date)\nAjoutez expand = c(0,0) pour que les étiquettes commencent à la premiére barre.\nUtilisez date_labels = pour spécifier le format des étiquettes de date - voir la page Dates pour des conseils (utilisez \\n pour une nouvelle ligne).\nUtilisez date_breaks = pour spécifier l’intervalle des étiquettes et des lignes de grille principales (par exemple “jour”, “semaine”, “3 semaines”, “mois” ou “année”).Utilisez date_minor_breaks = pour spécifier l’intervalle des lignes verticales mineures (entre les étiquettes de date)Ajoutez expand = c(0,0) pour que les étiquettes commencent à la premiére barre.Utilisez date_labels = pour spécifier le format des étiquettes de date - voir la page Dates pour des conseils (utilisez \\n pour une nouvelle ligne).Si les cases de votre histogramme sont des semaines de dimanche :\nUtilisez breaks = et minor_breaks = en fournissant une séquence de ruptures de date pour chacun d’entre eux.\nVous pouvez toujours utiliser date_labels = et expand = pour le formatage comme décrit ci-dessus.\nUtilisez breaks = et minor_breaks = en fournissant une séquence de ruptures de date pour chacun d’entre eux.Vous pouvez toujours utiliser date_labels = et expand = pour le formatage comme décrit ci-dessus.Quelques notes :Voir la section ggplot d’ouverture pour des instructions sur la façon de créer une séquence de dates en utilisant seq.Date().Voir cette page ou la page travailler avec des dates pour des conseils sur la création d’étiquettes de date.","code":""},{"path":"epicurves.html","id":"démonstrations","chapter":"32 Courbes épidémiques","heading":"Démonstrations","text":"Vous trouverez ci-dessous une démonstration de tracés où les bacs et les étiquettes/grilles sont alignés et non alignés :","code":"\n# Bacs de 7 jours + étiquettes du lundi\n#############################\nggplot(central_data) +\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    binwidth = 7, # bins de 7 jours avec début au premier cas\n    color = \"darkblue\",\n    fill = \"lightblue\") +\n  \n  scale_x_date(\n    expand = c(0,0), # supprime l'espace excédentaire sur l'axe des x en dessous et aprés les barres de cas\n    date_breaks = \"3 weeks\", # Lundi toutes les 3 semaines\n    date_minor_breaks = \"week\", # lundi semaines\n    date_labels = \"%a\\n%d\\n%b\\n'%y\")+ # format des étiquettes\n  \n  scale_y_continuous(\n    expand = c(0,0))+ # suppression de l'espace excédentaire sous l'axe des x, mise à plat\n  \n  labs(\n    title = \"MAL ALIGNÉ\",\n    subtitle = \" ! ATTENTION : Les barres de 7 jours commencent le jeudi avec le premier cas.\\n Grandes lignes de grille et étiquettes de date au 1er de chaque mois.\\n Lignes de grille mineures chaque lundi.\")\n\n\n\n# Tranches de 7 jours + Mois\n#####################\nggplot(central_data) +\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    binwidth = 7,\n    color = \"darkblue\",\n    fill = \"lightblue\") +\n  \n  scale_x_date(\n    expand = c(0,0), # supprime l'espace excédentaire de l'axe des x sous et aprés les barres de cas\n    date_breaks = \"months\", # 1er du mois\n    date_minor_breaks = \"week\", # semaines de lundi\n    date_labels = \"%a\\n%d %b\\n%Y\")+ # format des étiquettes\n  \n  scale_y_continuous(\n    expand = c(0,0)) + # Suppression de l'espace excédentaire sous l'axe des x, mise à plat des données \n  \n  labs(\n    title = \"MAL ALIGNÉ\",\n    subtitle = \" ! ATTENTION : Les barres de 7 jours commencent le jeudi avec le premier cas\\nLes lignes de grille principales et les étiquettes de date au 1er de chaque mois\\nLes lignes de grille mineures sont hebdomadaires le lundi\\nNotez l'espacement inégal de certaines lignes de grille et les tics non alignés avec les barres\"\n    )\n\n\n# ALIGNEMENT TOTAL DU LUNDI : spécifier que les pauses manuelles sont des lundis\n#################################################################\nggplot(central_data) + \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    # les ruptures d'histogramme sont fixées à 7 jours commençant le lundi avant le premier cas\n    breaks = weekly_breaks_central, # défini plus tôt dans cette page\n    \n    closed = \"left\",\n    \n    color = \"darkblue\",\n    \n    fill = \"lightblue\") + \n  \n  scale_x_date(\n    expand = c(0,0), # supprime l'espace excédentaire sur l'axe x en dessous et aprés les barres de cas\n    date_breaks = \"4 weeks\", # Lundi toutes les 4 semaines\n    date_minor_breaks = \"week\", # lundi semaines \n    date_labels = \"%a\\n%d %b\\n%Y\")+ # format des étiquettes\n  \n  scale_y_continuous(\n    expand = c(0,0))+ # Suppression de l'espace excédentaire sous l'axe des x, mise à plat des données \n  \n  labs(\n    title = \"Lundis ALIGNÉS\",\n    subtitle = \"Les intervalles de 7 jours sont réglés manuellement pour commencer le lundi avant le premier cas (28 avr.)\\n Les étiquettes de date et les lignes de grille sont aussi sur les lundis\")\n\n\n# ALIGNEMENT TOTAL DES LUNDIS AVEC LES étiQUETTES DE MOIS :\n############################################\nggplot(central_data) + \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    # ruptures d'histogramme fixées à 7 jours commençant le lundi avant le premier cas\n    breaks = weekly_breaks_central, # défini plus tôt dans cette page\n    \n    color = \"darkblue\",\n    \n    closed = \"left\",\n    \n    fill = \"lightblue\") + \n  \n  scale_x_date(\n    expand = c(0,0), # supprime l'espace excédentaire sur l'axe x en dessous et aprés les barres de cas\n    date_breaks = \"months\", # Lundi toutes les 4 semaines\n    date_minor_breaks = \"week\", # lundi semaines \n    date_labels = \"%b\\n%Y\")+ # format des étiquettes\n  \n  scale_y_continuous(\n    expand = c(0,0))+ # suppression de l'espace excédentaire sous l'axe des x, mise à plat \n  \n  theme(panel.grid.major = element_blank())+ # Suppression des lignes de grille principales (tombent le 1er du mois)\n          \n  labs(\n    title = \"Lundis ALIGNÉS avec étiquettes MONTHLY\",\n    subtitle = \"Bacs de 7 jours réglés manuellement pour commencer le lundi avant le premier cas (28 avril) - étiquettes de date le 1er du mois - Suppression des principaux quadrillages mensuels\")\n\n\n# ALIGNEMENT TOTAL DU DIMANCHE : spécifier les ruptures manuelles des bacs ET les étiquettes pour les dimanches\n############################################################################\nggplot(central_data) + \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    # ruptures d'histogramme fixées à 7 jours commençant le dimanche avant le premier cas\n    breaks = seq.Date(from = floor_date(min(central_data$date_onset, na.rm=T), \"week\", week_start = 7),\n                      to = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7),\n                      by = \"7 days\"),\n    \n    color = \"darkblue\",\n    \n    closed = \"left\",\n    \n    fill = \"lightblue\") + \n  \n  scale_x_date(\n    expand = c(0,0),\n    # les ruptures de l'étiquette de date et les principales lignes de la grille sont fixées à toutes les 3 semaines, en commençant le dimanche avant le premier cas.\n    breaks = seq.Date(from = floor_date(min(central_data$date_onset, na.rm=T), \"week\", week_start = 7),\n                      to = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7),\n                      by = \"3 weeks\"),\n    \n    # grilles mineures fixées à la semaine commençant le dimanche avant le premier cas\n    minor_breaks = seq.Date(from = floor_date(min(central_data$date_onset, na.rm=T), \"week\", week_start = 7),\n                            to = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7),\n                            by = \"7 days\"),\n    \n    date_labels = \"%a\\n%d\\n%b\\n'%y\")+ # format des étiquettes\n  \n  scale_y_continuous(\n    expand = c(0,0))+ # suppression de l'espace excédentaire sous l'axe des x, mise à plat \n  \n  labs(title = \"Dimanches ALIGNÉS\",\n       subtitle = \"Les intervalles de 7 jours ont été réglés manuellement pour commencer le dimanche avant le premier cas (27 avril)\\n Les étiquettes de date et les lignes de grille ont également été réglées manuellement sur les dimanches\")"},{"path":"epicurves.html","id":"données-agrégées","chapter":"32 Courbes épidémiques","heading":"données agrégées","text":"Souvent, au lieu d’une liste de lignes, vous commencez par des comptages agrégés d’établissements, de districts, etc. Vous pouvez faire une épicurve avec ggplot() mais le code sera légérement différent. Cette section va utiliser le jeu de données count_data qui été importé plus tôt, dans la section de préparation des données. Ce jeu de données est la linelist agrégée au nombre de jours d’hospitalisation. Les 50 premiéres lignes sont affichôes ci-dessous.","code":""},{"path":"epicurves.html","id":"tracer-des-épicentres-quotidiens","chapter":"32 Courbes épidémiques","heading":"Tracer des épicentres quotidiens","text":"Nous pouvons tracer une épicurve quotidienne à partir de ces comptes quotidiens. Voici les différences par rapport au code :Dans le mappage esthétique aes(), spécifiez y = comme colonne de comptage (dans ce cas, le nom de la colonne est n_cases).Ajoutez l’argument stat = \"identity\" dans geom_histogram(), qui spécifie que la hauteur de la barre doit étre la valeur y =, et non le nombre de lignes comme c’est le cas par défaut.Ajoutez l’argument width = pour éviter les lignes blanches verticales entre les barres. Pour les données quotidiennes, fixez la valeur à 1. Pour les données de comptage hebdomadaire, fixez la valeur à 7. Pour les données de comptage mensuel, les lignes blanches sont un probléme (chaque mois un nombre de jours différent) - envisagez de transformer votre axe des x en un facteur ordonné catégorique (mois) et utilisez `geom_col()``.","code":"\nggplot(data = count_data) +\n  geom_histogram(\n    mapping = aes(x = date_hospitalisation, y = n_cases),\n    stat = \"identity\",\n    width = 1) + # pour les comptages quotidiens, définir width = 1 pour éviter les espaces blancs entre les barres\n  labs(\n    x = \"Date du rapport\", \n    y = \"Nombre de cas\",\n    title = \"Incidence quotidienne des cas, à partir des données de comptage quotidiennes\")"},{"path":"epicurves.html","id":"tracer-les-comptages-hebdomadaires","chapter":"32 Courbes épidémiques","heading":"Tracer les comptages hebdomadaires","text":"Si vos données sont déjà des comptages de cas par semaine, elles peuvent ressembler à cet ensemble de données (appelé count_data_weekly) :Les 50 premiéres lignes de count_data_weekly sont affichées ci-dessous. Vous pouvez voir que les comptes ont été agrégés en semaines. Chaque semaine est affichée par le premier jour de la semaine (lundi par défaut).Maintenant, tracez le graphique de façon à ce que x = la colonne epiweek. N’oubliez pas d’ajouter y = la colonne des comptes à la mapping esthétique, et ajoutez stat = \"identity\" comme expliqué ci-dessus.","code":"\nggplot(data = count_data_weekly)+\n  \n  geom_histogram(\n    mapping = aes(\n      x = epiweek, # l'axe des x est l'epiweek (en tant que classe Date)\n      y = n_cases_weekly, # l'axe des y est la hauteur du nombre de cas hebdomadaires\n      group = hospital, # nous regroupons les barres et les couleurs par hôpital\n      fill = hospital),\n    stat = \"identity\")+ # ceci est également nécessaire lorsque l'on trace des données de comptage\n     \n  # étiquettes pour l'axe des x\n  scale_x_date(\n    date_breaks = \"2 months\", # étiquettes tous les 2 mois \n    date_minor_breaks = \"1 month\", # grilles tous les mois\n    date_labels = '%b\\n%Y')+ # étiqueté par mois avec l'année en dessous\n     \n  # Choisissez la palette de couleurs (utilise le paquet RColorBrewer)\n  scale_fill_brewer(palette = \"Pastel2\")+ \n  \n  theme_minimal()+\n  \n  labs(\n    x = \"Semaine d'apparition\", \n    y = \"Incidence hebdomadaire des cas\",\n    fill = \"Hospital\",\n    title = \"Incidence hebdomadaire des cas, à partir des données de comptage agrégées par hôpital\")"},{"path":"epicurves.html","id":"moyennes-mobiles","chapter":"32 Courbes épidémiques","heading":"Moyennes mobiles","text":"Voir la page sur les Moyennes mobiles pour une description détaillée et plusieurs options. Vous trouverez ci-dessous une option pour calculer des moyennes mobiles avec le package slider. Dans cette approche, la moyenne mobile est calculée dans l’ensemble de données avant le tracé :Regroupez les données en comptes si nécessaire (quotidien, hebdomadaire, etc.) (voir la page sur groupage des données).créez une nouvelle colonne pour contenir la moyenne mobile, créée avec slide_index() du paquet slider.Tracez la moyenne mobile comme une geom_line() au-dessus (aprés) l’histogramme épicurvienVoir l’utile vignette pour le paquet slider","code":"\n# charger le paquet\npacman::p_load(slider) # slider utilisé pour calculer les moyennes mobiles\n\n# créer un jeu de données de comptages quotidiens et de moyennes mobiles sur 7 jours\n#######################################################\nll_counts_7day <- linelist %>% # commencer avec linelist\n  \n  ## compter les cas par date\n  count(date_onset, name = \"new_cases\") %>% # nommer une nouvelle colonne avec les comptages comme \"new_cases\".\n  drop_na(date_onset) %>% # supprime les cas dont la date_onset est manquante\n  \n  ## calculer le nombre moyen de cas dans la fenétre de 7 jours\n  mutate(\n    avg_7day = slider::slide_index( # créer une nouvelle colonne\n      new_cases, # calcul basé sur la valeur de la colonne new_cases\n      .i = date_onset, # l'index est la colonne date_onset, donc les dates non présentes sont incluses dans la fenétre \n      .f = ~mean(.x, na.rm = TRUE), # La fonction est mean() avec les valeurs manquantes supprimées.\n      .before = 6, # la fenétre est le jour et les 6 jours précédents\n      .complete = FALSE), # doit étre FALSE pour que unlist() fonctionne à l'étape suivante\n    avg_7day = unlist(avg_7day)) # convertit la liste des classes en classes numériques\n\n\n# tracer\n######\nggplot(data = ll_counts_7day) + # commencer avec le nouvel ensemble de données défini ci-dessus \n    geom_histogram( # crée un histogramme épicurve\n      mapping = aes(\n        x = date_onset, # colonne de date comme axe des x\n        y = new_cases), # la hauteur est le nombre de nouveaux cas quotidiens\n        stat = \"identity\", # la hauteur est la valeur y\n        fill=\"#92a8d1\", # couleur froide pour les barres\n        colour = \"#92a8d1\", # même couleur pour la bordure des barres\n        )+ \n    geom_line( # créer une ligne pour la moyenne mobile\n      mapping = aes(\n        x = date_onset, # colonne de date pour l'axe des x\n        y = avg_7day, # valeur y définie dans la colonne de la moyenne mobile\n        lty = \"7-day \\nrolling avg\"), # nom de la ligne dans la légende\n      color=\"red\", # couleur de la ligne\n      size = 1) + # largeur de la ligne\n    scale_x_date( # échelle de date\n      date_breaks = \"1 month\",\n      date_labels = '%d/%m',\n      expand = c(0,0)) +\n    scale_y_continuous( # échelle de l'axe des y\n      expand = c(0,0),\n      limits = c(0, NA)) +       \n    labs(\n      x=\"\",\n      y = \"Nombre de cas confirmés\",\n      fill = \"Legende\")+ \n    theme_minimal()+\n    theme(legend.title = element_blank()) # supprime le titre de la légende"},{"path":"epicurves.html","id":"facettespetits-multiples","chapter":"32 Courbes épidémiques","heading":"Facettes/petits-multiples","text":"Comme pour les autres ggplots, vous pouvez créer des graphiques à facettes (“petits multiples”). Comme expliqué dans la page ggplot tips de ce manuel, vous pouvez utiliser soit facet_wrap() soit facet_grid(). Ici, nous faisons une démonstration avec facet_wrap(). Pour les épicurves, facet_wrap() est typiquement plus facile car il est probable que vous n’ayez besoin de faire une facette que sur une seule colonne.La syntaxe générale est facet_wrap(rows ~ cols), où à gauche du tilde (~) est le nom d’une colonne à répartir sur les “rows” du graphique à facettes, et à droite du tilde est le nom d’une colonne à répartir sur les “columns” du graphique à facettes. Plus simplement, il suffit d’utiliser un seul nom de colonne, à droite du tilde : facet_wrap(~age_cat).Axes libres\nVous devrez décider si les échelles des axes pour chaque facette sont “fixées” aux mêmes dimensions (par défaut), ou “libres” (ce qui signifie qu’elles changeront en fonction des données de la facette). Faites-le avec l’argument scales = dans facet_wrap() en spécifiant “free_x” ou “free_y”, ou “free”.Nombre de cols et de rangs de facettes\nCela peut étre spécifié avec ncol = et nrow = dans facet_wrap().Ordre des facettes\nPour changer l’ordre d’apparition, changez l’ordre sous-jacent des niveaux de la colonne de facteurs utilisée pour créer les facettes.esthétique\nLa taille et le visage de la police, la couleur de la bande, etc. peuvent étre modifiés par theme() avec des arguments comme :strip.text = element_text() (taille, couleur, face, angle…)strip.background = element_rect() (par exemple element_rect(fill=“grey”))strip.position = (position de la bande “bas”, “haut”, “gauche” ou “droite”)Libellés des bandes\nLes étiquettes des graphiques à facettes peuvent étre modifiées par les “étiquettes” de la colonne comme facteur, ou par l’utilisation d’un “labeller”.Faites une étiquette comme celle-ci, en utilisant la fonction as_labeller() de ggplot2. Puis fournissez l’étiqueteuse à l’argument labeller = de facet_wrap() comme indiqué ci-dessous.Un exemple de graphique à facettes - facetté par la colonne age_cat.Voir ce lien pour plus d’informations sur les étiqueteuses.","code":"\nmy_labels <- as_labeller(c(\n     \"0-4\" = \"0-4 ans\",\n     \"5-9\" = \"5-9 ans\",\n     \"10-14\" = \"10-14 ans\",\n     \"15-19\" = \"15-19 ans\",\n     \"20-29\" = \"20-29 ans\",\n     \"30-49\" = \"30-49 ans\",\n     \"50-69\" = \"50-69 ans\",\n     \"70+\" = \"Plus de 70 ans\"))\n# faire le graphe\n###########\nggplot(central_data) + \n  \n  geom_histogram(\n    mapping = aes(\n      x = date_onset,\n      group = age_cat,\n      fill = age_cat), # les arguments à l'intérieur de aes() s'appliquent par groupe\n      \n    color = \"black\", # les arguments hors aes() s'appliquent à toutes les données\n        \n    # ruptures d'histogramme\n    breaks = weekly_breaks_central)+ # vecteur de date prédéfini (voir plus haut dans cette page)\n                      \n  # Les étiquettes sur l'axe des x\n  scale_x_date(\n    expand = c(0,0), # supprimez l'espace excédentaire sur l'axe des x en dessous et aprés les barres de cas\n    date_breaks = \"2 months\", # les étiquettes apparaissent tous les 2 mois\n    date_minor_breaks = \"1 month\", # les lignes verticales apparaissent tous les 1 mois \n    date_labels = \"%b\\n'%y\")+ # format des étiquettes de date\n  \n  # Axe des y\n  scale_y_continuous(expand = c(0,0))+ # supprime l'espace excédentaire sur l'axe des y entre le bas des barres et les étiquettes\n  \n  # thèmes esthétiques\n  theme_minimal()+ # un ensemble de thèmes pour simplifier le graphique\n  theme(\n    plot.caption = element_text(face = \"italic\", hjust = 0), # légende à gauche en italique\n    axis.title = element_text(face = \"bold\"),\n    legend.position = \"bottom\",\n    strip.text = element_text(face = \"bold\", size = 10),\n    strip.background = element_rect(fill = \"grey\"))+ # titres des axes en gras\n  \n  # créer des facettes\n  facet_wrap(\n    ~age_cat,\n    ncol = 4,\n    strip.position = \"top\",\n    labeller = my_labels)+             \n  \n  # étiquettes\n  labs(\n    title = \"Incidence hebdomadaire des cas, par catégorie d'âge\",\n    subtitle = \"Sous-titre\",\n    fill = \"Catégorie d'âge\", # fournir un nouveau titre pour la légende\n    x = \"Semaine d'apparition des symptômes\",\n    y = \"Cas incidents hebdomadaires signalés\",\n    caption = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital ; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} à {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}{nrow(central_data %>% filter(is.na(date_onset)))} cas dont la date d'apparition est manquante et qui ne sont pas indiqués\"))"},{"path":"epicurves.html","id":"épidémie-totale-dans-larriére-plan-de-la-facette","chapter":"32 Courbes épidémiques","heading":"32.2.0.1 Épidémie totale dans l’arriére-plan de la facette","text":"Pour afficher l’épidémie totale en arriére-plan de chaque facette, ajoutez la fonction gghighlight() avec des parenthôses vides au ggplot. Cette fonction provient du paquet gghighlight. Notez que le maximum de l’axe des y dans toutes les facettes est maintenant basé sur le pic de l’épidémie entiére. Il y plus d’exemples de ce package dans la page ggplot tips.","code":"\nggplot(central_data) + \n  \n  # Epicurves par groupe\n  geom_histogram(\n    mapping = aes(\n      x = date_onset,\n      group = age_cat,\n      fill = age_cat), # les arguments à l'intérieur de aes() s'appliquent par groupe\n    \n    color = \"black\", # les arguments hors aes() s'appliquent à toutes les données\n    \n    # ruptures d'histogramme\n    breaks = weekly_breaks_central)+ # vecteur de dates prédéfini (voir en haut de la section ggplot)                \n  \n  # ajoute une épidémie grise en arriére-plan à chaque facette\n  gghighlight::gghighlight()+\n  \n  # étiquettes sur l'axe des x\n  scale_x_date(\n    expand = c(0,0), # Suppression de l'espace excédentaire sur l'axe des x sous et aprés les barres de cas\n    date_breaks = \"2 months\", # les étiquettes apparaissent tous les 2 mois\n    date_minor_breaks = \"1 month\", # les lignes verticales apparaissent tous les 1 mois \n    date_labels = \"%b\\n'%y\")+ # format des étiquettes de date\n  \n  # Axe des y\n  scale_y_continuous(expand = c(0,0))+ # supprime l'espace excédentaire de l'axe des y en dessous de 0\n  \n  # thèmes esthétiques\n  theme_minimal()+ # un ensemble de thèmes pour simplifier le graphique\n  theme(\n    plot.caption = element_text(face = \"italic\", hjust = 0), # légende à gauche en italique\n    axis.title = element_text(face = \"bold\"),\n    legend.position = \"bottom\",\n    strip.text = element_text(face = \"bold\", size = 10),\n    strip.background = element_rect(fill = \"white\"))+ # titres des axes en gras\n  \n  # créer des facettes\n  facet_wrap(\n    ~age_cat, # chaque facette est une valeur de age_cat\n    ncol = 4, # nombre de colonnes\n    strip.position = \"top\", # position du titre/strip de la facette\n    labeller = my_labels)+ # labeller définit ci-dessus\n  \n  # étiquettes\n  labs(\n    title = \"Incidence hebdomadaire des cas, par catégorie d'âge\",\n    subtitle = \"Sous-titre\",\n    fill = \"Catégorie d'âge\", # fournit un nouveau titre pour la légende\n    x = \"Semaine d'apparition des symptômes\",\n    y = \"Cas incidents hebdomadaires signalés\",\n    caption = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital ; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} à {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}{nrow(central_data %>% filter(is.na(date_onset)))} cas dont la date d'apparition est manquante et qui ne sont pas indiqués\"))"},{"path":"epicurves.html","id":"une-facette-avec-des-données","chapter":"32 Courbes épidémiques","heading":"Une facette avec des données","text":"Si vous voulez avoir une seule boîte à facettes qui contient toutes les données, dupliquez l’ensemble des données et traitez les doublons comme une seule valeur de facette. La fonction “helper” CreateAllFacet() ci-dessous peut vous aider (gràce à cet article de blog). Quand elle est exécutée, le nombre de lignes double et il y aura une nouvelle colonne appelée facet dans laquelle les lignes dupliquées auront la valeur “”, et les lignes originales auront la valeur originale de la colonne de facettes. Il ne vous reste plus qu’à effectuer la facette sur la colonne facet.Voici la fonction d’aide. Exécutez-la pour qu’elle soit disponible pour vous.Appliquez maintenant la fonction d’aide à l’ensemble de données, sur la colonne age_cat :Les changements notables de la commande ggplot() sont les suivants :Les données utilisées sont maintenant central_data2 (deux fois plus de lignes, avec une nouvelle colonne “facet”).L’étiqueteuse devra étre mise à jour, si elle est utilisée.Optionnel : pour obtenir des facettes empilées verticalement : la colonne facette est déplacée vers les lignes de l’équation et remplacée à droite par “.” (facet_wrap(facet~.)), et ncol = 1. Vous pouvez aussi avoir besoin d’ajuster la largeur et la hauteur de l’image du graphique en png (voir ggsave() dans ggplot tips).","code":"\n# définir la fonction d'aide\nCreateAllFacet <- function(df, col){\n     df$facet <- df[[col]]\n     temp <- df\n     temp$facet <- \"all\"\n     merged <-rbind(temp, df)\n     \n     # s'assurer que la valeur de la facette est un facteur\n     merged[[col]] <- as.factor(merged[[col]])\n     \n     return(merged)\n}\n# créez un jeu de données dupliqué et avec une nouvelle colonne \"facet\" pour afficher \"toutes\" les catégories d'âge comme autre niveau de facette.\ncentral_data2 <- CreateAllFacet(central_data, col = \"age_cat\") %>%\n  \n  # définir les niveaux de facteurs\n  mutate(facet = fct_relevel(facet, \"all\", \"0-4\", \"5-9\",\n                             \"10-14\", \"15-19\", \"20-29\",\n                             \"30-49\", \"50-69\", \"70+\"))## Warning: There was 1 warning in `mutate()`.\n## ℹ In argument: `facet = fct_relevel(...)`.\n## Caused by warning:\n## ! 1 unknown level in `f`: 70+\n# vérifier les niveaux\ntable(central_data2$facet, useNA = \"always\")## \n##   all   0-4   5-9 10-14 15-19 20-29 30-49 50-69  <NA> \n##   454    84    84    82    58    73    57     7     9\nggplot(central_data2) + \n  \n  # Epicurves réelles par groupe\n  geom_histogram(\n        mapping = aes(\n          x = date_onset,\n          group = age_cat,\n          fill = age_cat), # les arguments à l'intérieur de aes() s'appliquent par groupe\n        color = \"black\", # les arguments hors aes() s'appliquent à toutes les données\n        \n        # ruptures d'histogramme\n        breaks = weekly_breaks_central)+ # vecteur de dates prédéfini (voir en haut de la section ggplot)\n                     \n  # étiquettes sur l'axe des x\n  scale_x_date(\n    expand = c(0,0), # supprime l'espace excédentaire de l'axe des x sous et aprés les barres de cas\n    date_breaks = \"2 months\", # les étiquettes apparaissent tous les 2 mois\n    date_minor_breaks = \"1 month\", # les lignes verticales apparaissent tous les 1 mois \n    date_labels = \"%b\\n'%y\")+ # format des étiquettes de date\n  \n  # Axe des y\n  scale_y_continuous(expand = c(0,0))+ # supprime l'espace excédentaire sur l'axe des y entre le bas des barres et les étiquettes\n  \n  # thèmes esthétiques\n  theme_minimal()+ # un ensemble de thèmes pour simplifier le graphique\n  theme(\n    plot.caption = element_text(face = \"italic\", hjust = 0), # légende à gauche en italique\n    axis.title = element_text(face = \"bold\"),\n    legend.position = \"bottom\")+               \n  \n  # créer des facettes\n  facet_wrap(facet~. , # chaque parcelle est une valeur de la facette\n             ncol = 1)+            \n\n  # étiquettes\n  labs(title = \"Incidence hebdomadaire des cas, par catégorie d'âge\",\n       subtitle = \"Sous-titre\",\n       fill = \"Catégorie d'âge\", # fournit un nouveau titre pour la légende\n       x = \"Semaine d'apparition des symptômes\",\n       y = \"Cas incidents hebdomadaires signalés\",\n       caption = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital ; Case onsets range from\n                                   {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} à\n                                   {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %>% filter(is.na(date_onset)))} cas dont la date d'apparition est manquante et qui ne sont pas indiqués\"))"},{"path":"epicurves.html","id":"données-provisoires","chapter":"32 Courbes épidémiques","heading":"32.3 Données provisoires","text":"Les données les plus récentes présentées dans les épicurves doivent souvent étre marquées comme provisoires, ou sujettes à des retards de déclaration. Ceci peut étre fait en ajoutant une ligne verticale et/ou un rectangle sur un nombre de jours spécifié. Voici deux options :Utilisez annotate() :\nPour une ligne, utilisez annotate(geom = \"segment\"). Fournissez x, xend, y, et yend. Ajustez la taille, le type de ligne (lty) et la couleur.\nPour un rectangle, utilisez annotate(geom = \"rect\"). Fournissez xmin/xmax/ymin/ymax. Ajustez la couleur et l’alpha.\nPour une ligne, utilisez annotate(geom = \"segment\"). Fournissez x, xend, y, et yend. Ajustez la taille, le type de ligne (lty) et la couleur.Pour un rectangle, utilisez annotate(geom = \"rect\"). Fournissez xmin/xmax/ymin/ymax. Ajustez la couleur et l’alpha.Regroupez les données par statut provisoire et colorez ces barres différemment.CAUTION: Vous pourriez essayer geom_rect() pour dessiner un rectangle, mais l’ajustement de la transparence ne fonctionne pas dans un contexte de linelist. Cette fonction superpose un rectangle pour chaque observation/rangée ! Utilisez soit un alpha trés faible (par exemple 0,01), soit une autre approche. ","code":""},{"path":"epicurves.html","id":"utilisation-de-annotate","chapter":"32 Courbes épidémiques","heading":"Utilisation de annotate()","text":"Dans annotate(geom = \"rect\"), les arguments xmin et xmax doivent recevoir des entrées de la classe Date.Notez que, comme ces données sont agrégées en barres hebdomadaires et que la derniére barre s’étend jusqu’au lundi suivant le dernier point de données, la région ombrée peut sembler couvrir 4 semaines.Voici un annotate() exemple en ligneLa même ligne verticale noire peut étre obtenue avec le code ci-dessous, mais en utilisant geom_vline() vous perdez la possibilité de contrôler la hauteur :","code":"\nggplot(central_data) + \n  \n  # histogramme\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    breaks = weekly_breaks_central, # vecteur de date prédéfini - voir en haut de la section ggplot\n    \n    color = \"darkblue\",\n    \n    closed = \"left\",\n    \n    fill = \"lightblue\") +\n\n  # échelles\n  scale_y_continuous(expand = c(0,0))+\n  scale_x_date(\n    expand = c(0,0), # Suppression de l'espace excédentaire sur l'axe des x sous et aprés les barres de cas\n    date_breaks = \"1 month\", # 1er du mois\n    date_minor_breaks = \"1 month\", # 1er du mois\n    date_labels = \"%b\\n'%y\")+ # format des étiquettes\n  \n  # étiquettes et theme\n  labs(\n    title = \"Utilisant annotate()\\nRectangle et ligne montrant que les données des 21 derniers jours sont provisoires\",\n    x = \"Semaine d'apparition des symptômes\",\n    y = \"Indication hebdomadaire des cas\")+ \n  theme_minimal()+\n  \n  # ajoute un rectangle rouge semi-transparent aux données provisoires\n  annotate(\n    \"rect\",\n    xmin = as.Date(max(central_data$date_onset, na.rm = T) - 21), # la note doit étre enveloppée dans as.Date()\n    xmax = as.Date(Inf), # la note doit étre enveloppée dans as.Date()\n    ymin = 0,\n    ymax = Inf,\n    alpha = 0.2, # alpha facile et intuitif à ajuster en utilisant annotate()\n    fill = \"red\")+\n  \n  # ajoute une ligne verticale noire au-dessus des autres couches\n  annotate(\n    \"segment\",\n    x = max(central_data$date_onset, na.rm = T) - 21, # 21 jours avant les derniéres données\n    xend = max(central_data$date_onset, na.rm = T) - 21, \n    y = 0, # la ligne commence à y = 0\n    yend = Inf, # ligne jusqu'au sommet du graphique\n    size = 2, # taille de la ligne\n    color = \"black\",\n    lty = \"solid\")+ # type de ligne, par exemple \"solid\", \"dashed\".\n\n  # ajouter du texte dans le rectangle\n  annotate(\n    \"text\",\n    x = max(central_data$date_onset, na.rm = T) - 15,\n    y = 15,\n    label = \"Sujet à des délais de déclaration\",\n    angle = 90)\ngeom_vline(xintercept = max(central_data$date_onset, na.rm = T) - 21,\n           size = 2,\n           color = \"black\")"},{"path":"epicurves.html","id":"couleur-des-barres","chapter":"32 Courbes épidémiques","heading":"Couleur des barres","text":"Une autre approche pourrait consister à ajuster la couleur ou l’affichage des barres de données provisoires elles-mêmes. Vous pouvez créer une nouvelle colonne dans l’étape de préparation des données et l’utiliser pour regrouper les données, de sorte que les ” aes(fill = )`” des données provisoires puissent avoir une couleur ou un alpha différent des autres barres.","code":"\n# ajouter une colonne\n############\nplot_data <- central_data %>% \n  mutate(tentative = case_when(\n    date_onset >= max(date_onset, na.rm=T) - 7 ~ \"Tentative\", # tenative si dans les 7 derniers jours\n    TRUE ~ \"Reliable\")) # tout le reste est fiable\n\n# tracé\n######\nggplot(plot_data, aes(x = date_onset, fill = tentative)) + \n  \n  # histogramme\n  geom_histogram(\n    breaks = weekly_breaks_central, # vecteur de données prédéfini, voir en haut de la page ggplot\n    color = \"black\") +\n\n  # échelles\n  scale_y_continuous(expand = c(0,0))+\n  scale_fill_manual(values = c(\"lightblue\", \"grey\"))+\n  scale_x_date(\n    expand = c(0,0), # Supprimez l'espace excédentaire de l'axe des x sous et aprés les barres de cas\n    date_breaks = \"3 weeks\", # Lundi toutes les 3 semaines\n    date_minor_breaks = \"week\", # lundi semaines \n    date_labels = \"%d\\n%b\\n'%y\")+ # format des étiquettes\n  \n  # étiquettes et theme\n  labs(title = \"Afficher les jours de déclaration provisoire\",\n    subtitle = \"\")+ \n  theme_minimal()+\n  theme(legend.title = element_blank()) # supprimer le titre de la légende"},{"path":"epicurves.html","id":"étiquettes-de-date-à-plusieurs-niveaux","chapter":"32 Courbes épidémiques","heading":"32.4 Étiquettes de date à plusieurs niveaux","text":"Si vous voulez des étiquettes de date à plusieurs niveaux (par exemple, le mois et l’année) sans dupliquer les niveaux d’étiquette inférieurs, envisagez l’une des approches ci-dessous :Rappelez-vous - vous pouvez utiliser des outils comme \\n avec les arguments date_labels ou labels pour mettre des parties de chaque étiquette sur une nouvelle ligne en dessous. Cependant, le code ci-dessous vous aide à prendre les années ou les mois (par exemple) sur une ligne inférieure et seulement une fois. Quelques notes sur le code ci-dessous :Le nombre de cas est agrégé en semaines pour des raisons esthétiques. Voir la page Epicurves (onglet données agrégées) pour plus de détails.Une ligne geom_area() est utilisée au lieu d’un histogramme, car l’approche par facettes ci-dessous ne fonctionne pas bien avec les histogrammes.Aggréger en comptages hebdomadairesFaire des graphiquesLes techniques ci-dessus ont été adaptées de et post sur stackoverflow.com.","code":"\n# créez un ensemble de données sur le nombre de cas par semaine.\n#######################################\ncentral_weekly <- linelist %>%\n  filter(hospital == \"Central Hospital\") %>% # Filtrer linelist\n  mutate(week = lubridate::floor_date(date_onset, unit = \"weeks\")) %>% # count(week) %>% # count(week)  \n  count(week) %>% # résume le nombre de cas hebdomadaires\n  drop_na(week) %>% # Suppression des cas dont la date d'apparition est manquante\n  complete( # remplir toutes les semaines où aucun cas n'a été signalé\n    week = seq.Date(\n      from = min(week),   \n      to = max(week),\n      by = \"week\"),\n    fill = list(n = 0))                        # convertir les nouvelles valeurs NA en comptage 0\n# tracer avec une bordure de boîte sur l'année\n##############################\nggplot(central_weekly) +\n  geom_area(aes(x = week, y = n), # faire une ligne, spécifier x et y\n            stat = \"identity\") + # car la hauteur de la ligne est un nombre compté\n  scale_x_date(date_labels=\"%b\", # le format des étiquettes de date montre le mois \n               date_breaks=\"month\", # étiquettes de date au 1er de chaque mois\n               expand=c(0,0)) + # suppression de l'espace excédentaire à chaque extrémité\n  scale_y_continuous(\n    expand = c(0,0))+ # Suppression de l'espace excédentaire sous l'axe des x\n  facet_grid(~lubridate::year(week), # facette sur l'année (de la colonne de la classe Date)\n             space=\"free_x\",                \n             scales=\"free_x\", # les axes x s'adaptent à la plage de données (pas \"fixe\")\n             switch=\"x\") + # étiquettes des facettes (année) en bas de page\n  theme_bw() +\n  theme(strip.placement = \"outside\", # placement des étiquettes de facettes\n        strip.background = element_rect(fill = NA, # facet labels no fill grey border\n                                        color = \"gray50\"),\n        panel.spacing = unit(0, \"cm\"))+ # pas d'espace entre les panneaux de facettes\n  labs(title = \"Étiquettes d'année imbriquées, bordure d'étiquette grise\")\n# tracé sans bordure sur l'année\n#################################\nggplot(central_weekly,\n       aes(x = week, y = n)) + # établir x et y pour tout le graphique\n  geom_line(stat = \"identity\", # créer une ligne, la hauteur de la ligne est le nombre de comptage\n            color = \"#69b3a2\") + # couleur de la ligne\n  geom_point(size=1, color=\"#69b3a2\") + # faire des points aux points de données hebdomadaires\n  geom_area(fill = \"#69b3a2\", # zone de remplissage sous la ligne\n            alpha = 0.4)+ # transparence du remplissage\n  scale_x_date(date_labels=\"%b\", # format de l'étiquette de la date pour montrer le mois \n               date_breaks=\"month\", # étiquettes de date au 1er de chaque mois\n               expand=c(0,0)) + # supprimer l'espace excédentaire\n  scale_y_continuous(\n    expand = c(0,0))+ # suppression de l'espace excédentaire sous l'axe des x\n  facet_grid(~lubridate::year(week), # facette sur l'année (de la colonne de la classe Date)\n             space=\"free_x\",                \n             scales=\"free_x\", # les axes x s'adaptent à la plage de données (pas \"fixe\")\n             switch=\"x\") + # étiquettes des facettes (année) en bas de page\n  theme_bw() +\n  theme(strip.placement = \"outside\", # placement des étiquettes de facettes\n          strip.background = element_blank(), # pas de fond d'étiquette de facette\n          panel.grid.minor.x = element_blank(),          \n          panel.border = element_rect(color=\"grey40\"), # bordure grise du PANEL de la facette\n          panel.spacing=unit(0, \"cm\"))+ # Pas d'espace entre les panneaux à facettes\n  labs(title = \"Étiquettes annuelles imbriquées - points, ombrées, pas de bordure d'étiquette\")"},{"path":"epicurves.html","id":"double-axe","chapter":"32 Courbes épidémiques","heading":"32.5 Double axe","text":"Bien qu’il y ait des discussions acharnées sur la validité des doubles axes au sein de la communauté de visualisation des données, de nombreux superviseurs d’épi veulent toujours voir une épicurve ou un graphique similaire avec un pourcentage superposé à un deuxiéme axe. Ce sujet est abordé plus en détail dans la page ggplot tips, mais un exemple utilisant la méthode cowplot est présenté ci-dessous :Deux graphiques distincts sont créés, puis combinés avec le paquet cowplot.Les graphiques doivent avoir exactement le même axe des x (limites définies), sinon les données et les étiquettes ne seront pas alignées.Chacun utilise theme_cowplot() et l’un d’entre eux l’axe des y déplacé sur le côte droit du graphiqueUtilisez maintenant cowplot pour superposer les deux graphiques. Une attention particuliére été portée à l’alignement de l’axe des x, au côte de l’axe des y et à l’utilisation de theme_cowplot().","code":"\n#Chargez le paquet\npacman::p_load(cowplot)\n\n# Faire le premier tracé de l'histogramme épicurve\n#######################################\nplot_cases <- linelist %>% \n  \n  # Tracer les cas par semaine\n  ggplot()+\n  \n  # créer un histogramme  \n  geom_histogram(\n    \n    mapping = aes(x = date_onset),\n    \n    # bin breaks chaque semaine en commençant le lundi avant le premier cas, jusqu'au lundi aprés le dernier cas\n    breaks = weekly_breaks_all)+ # vecteur prédéfini de dates hebdomadaires (voir en haut de la section ggplot)\n        \n  # spécifier le début et la fin de l'axe des dates pour l'aligner avec les autres graphiques\n  scale_x_date(\n    limits = c(min(weekly_breaks_all), max(weekly_breaks_all)))+ # min/max des pauses hebdomadaires prédéfinies de l'histogramme\n  \n  # étiquettes\n  labs(\n      y = \"Cas quotidiens\",\n      x = \"Date d'apparition des symptômes\"\n    )+\n  theme_cowplot()\n\n\n# faire un second tracé du pourcentage de décés par semaine\n###########################################\nplot_deaths <- linelist %>% # commence avec linelist\n  group_by(week = floor_date(date_onset, \"week\")) %>% # créer une colonne semaine\n  \n  # résumer pour obtenir le pourcentage hebdomadaire de cas décédés\n  summarise(n_cases = n(),\n            died = sum(outcome == \"Death\", na.rm=T),\n            pct_died = 100*died/n_cases) %>% \n  \n  # commencer le tracé\n  ggplot()+\n  \n  # ligne du pourcentage hebdomadaire de décés\n  geom_line( # créer une ligne de pourcentage de décés\n    mapping = aes(x = week, y = pct_died), # spécifie la hauteur des y comme colonne pct_died\n    stat = \"identity\", # fixer la hauteur de la ligne à la valeur de la colonne pct_death, et non au nombre de lignes (par défaut)\n    size = 2,\n    color = \"black\")+\n  \n  # mêmes limites de l'axe des dates que l'autre graphique - alignement parfait\n  scale_x_date(\n    limits = c(min(weekly_breaks_all), max(weekly_breaks_all)))+ # min/max des pauses hebdomadaires prédéfinies de l'histogramme\n  \n  \n  # ajustements de l'axe des y\n  scale_y_continuous( # ajuster l'axe des y\n    breaks = seq(0,100, 10), # définit les intervalles de rupture de l'axe des pourcentages\n    limits = c(0, 100), # définit l'étendue de l'axe des pourcentages\n    position = \"right\")+ # déplace l'axe des pourcentages vers la droite\n  \n  # étiquette pour l'axe des Y, pas d'étiquette pour l'axe des X\n  labs(x = \"\",\n       y = \"Pourcentage décédé\") +  # étiquette de l'axe des pourcentages\n  \n  theme_cowplot() # ajoutez ceci pour que les deux graphiques fusionnent bien ensemble\naligned_plots <- cowplot::align_plots(plot_cases, plot_deaths, align=\"hv\", axis=\"tblr\")\n\nggdraw(aligned_plots[[1]]) + draw_plot(aligned_plots[[2]])"},{"path":"epicurves.html","id":"incidence-cumulée","chapter":"32 Courbes épidémiques","heading":"32.6 Incidence cumulée","text":"Cette page traitera de la façon de calculer l’incidence cumulée et de la tracer avec ggplot().Si vous commencez avec une liste de cas, créez une nouvelle colonne contenant le nombre cumulé de cas par jour dans une épidémie en utilisant cumsum() de base R :Les 10 premiéres lignes sont affichôes ci-dessous :Cette colonne cumulative peut ensuite étre tracée en fonction de la date_onset, en utilisant `geom_line()`` :peut aussi le superposer à l’épicurve, avec un double axe en utilisant la méthode cowplot décrite ci-dessus et dans la page ggplot tips :Utilisez maintenant cowplot pour superposer les deux graphiques. Une attention particuliére été portée à l’alignement de l’axe des x, au côte de l’axe des y et à l’utilisation de theme_cowplot().","code":"\ncumulative_case_counts <- linelist %>% \n  count(date_onset) %>% # nombre de lignes par jour (retourné dans la colonne \"n\")   \n  mutate(                         \n    cumulative_cases = cumsum(n) # nouvelle colonne du nombre cumulé de lignes à chaque date\n    )\nplot_cumulative <- ggplot()+\n  geom_line(\n    data = cumulative_case_counts,\n    aes(x = date_onset, y = cumulative_cases),\n    size = 2,\n    color = \"blue\")\n\nplot_cumulative\n#charger le paquet\n\npacman::p_load(cowplot)\n\n\n# Faire le premier tracé de l'histogramme épicurve\nplot_cases <- ggplot()+\n  geom_histogram(          \n    data = linelist,\n    aes(x = date_onset),\n    binwidth = 1)+\n  labs(\n    y = \"Cas quotidiens\",\n    x = \"Date d'apparition des symptômes\"\n  ) +\n  theme_cowplot()\n\n# créer un second tracé de la ligne des cas cumulés\nplot_cumulative <- ggplot()+\n  geom_line(\n    data = cumulative_case_counts,\n    aes(x = date_onset, y = cumulative_cases),\n    size = 2,\n    color = \"blue\")+\n  scale_y_continuous(\n    position = \"right\")+\n  labs(x = \"\",\n       y = \"Cas cumulés\")+\n  theme_cowplot()+\n  theme(\n    axis.line.x = element_blank(),\n    axis.text.x = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks = element_blank())\naligned_plots <- cowplot::align_plots(plot_cases, plot_cumulative, align=\"hv\", axis=\"tblr\")\n\nggdraw(aligned_plots[[1]]) + draw_plot(aligned_plots[[2]])"},{"path":"epicurves.html","id":"ressources-17","chapter":"32 Courbes épidémiques","heading":"32.7 Ressources","text":"","code":""},{"path":"age_pyramid.html","id":"age_pyramid","chapter":"33 Pyramides démographiques et échelles de Likert","heading":"33 Pyramides démographiques et échelles de Likert","text":"Les pyramides démographiques sont utiles pour montrer les distributions d’âge et de sexe. Un code similaire peut être utilisé pour visualiser les résultats de questions d’enquête de type Likert (par exemple, “Tout à fait d’accord”, “D’accord”, “Neutre”, “Pas d’accord”, “Pas du tout d’accord”). Dans cette page, nous couvrons les points suivants :Des pyramides rapides et faciles à réaliser grâce au package apyramidDes pyramides plus personnalisables grâce à ggplot()Affichage de données démographiques “de référence” à l’arrière-plan de la pyramideUtilisation de graphiques de type pyramide pour afficher d’autres types de données (par exemple, les réponses à des questions d’enquête de type Likert).","code":""},{"path":"age_pyramid.html","id":"preparation-4","chapter":"33 Pyramides démographiques et échelles de Likert","heading":"33.1 Preparation","text":"","code":""},{"path":"age_pyramid.html","id":"charger-les-packages-2","chapter":"33 Pyramides démographiques et échelles de Likert","heading":"Charger les packages","text":"Ce morceau de code montre le chargement des packages nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le package si nécessaire et le charge pour l’utiliser. Vous pouvez également charger les packages installés avec library() à partir de la base R. Voir la page sur les bases de R pour plus d’informations sur les packages R.","code":"\npacman::p_load(rio,       # Pour importer les données\n               here,      # Pour localiser les fichiers\n               tidyverse, # Pour nettoyer, traiter et représenter les données (inclut le package ggplot2)\n               apyramid,  # Un package dédié à la création de pyramides des âges\n               janitor,   # Tableaux et nettoyage des données\n               stringr)   # Pour travailler avec des chaînes de caractères pour les titres, les légendes, etc."},{"path":"age_pyramid.html","id":"importer-les-données-2","chapter":"33 Pyramides démographiques et échelles de Likert","heading":"Importer les données","text":"Pour commencer, nous importons la liste de cas nettoyée d’une épidémie d’Ebola simulée. Si vous voulez le faire en même temps, cliquez pour télécharger la liste des cas “nettoyée”. (sous le format .rds). Importez des données à l’aide de la fonction import() du package rio (elle gère de nombreux types de fichiers tels que .xlsx, .csv, .rds - voir la page Importation et exportation pour plus de détails).Les 50 premières lignes de la liste des cas sont affichées ci-dessous.","code":"\n# Importer la liste des cas dans R\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"age_pyramid.html","id":"nettoyage","chapter":"33 Pyramides démographiques et échelles de Likert","heading":"Nettoyage","text":"Pour réaliser une pyramide démographique traditionnelle par âge/sexe, les données doivent d’abord être nettoyées de la manière suivante :La colonne sexe doit être nettoyée.La colonne sexe doit être nettoyée.Selon votre méthode, l’âge doit être stocké soit sous forme numérique, soit dans une colonne de catégorie d’âge.Selon votre méthode, l’âge doit être stocké soit sous forme numérique, soit dans une colonne de catégorie d’âge.Si vous utilisez des catégories d’âge, les valeurs de la colonne doivent être ordonnées correctement, soit par défaut en alphanumérique, soit intentionnellement en convertissant en facteur de classe.Ci-dessous nous utilisons tabyl() du package janitor pour inspecter les colonnes gender et age_cat5.Nous effectuons également un rapide histogramme sur la colonne age pour nous assurer qu’elle est propre et correctement classée :","code":"\nlinelist %>% \n  tabyl(age_cat5, gender)##  age_cat5   f   m NA_\n##       0-4 640 416  39\n##       5-9 641 412  42\n##     10-14 518 383  40\n##     15-19 359 364  20\n##     20-24 305 316  17\n##     25-29 163 259  13\n##     30-34 104 213   9\n##     35-39  42 157   3\n##     40-44  25 107   1\n##     45-49   8  80   5\n##     50-54   2  37   1\n##     55-59   0  30   0\n##     60-64   0  12   0\n##     65-69   0  12   1\n##     70-74   0   4   0\n##     75-79   0   0   1\n##     80-84   0   1   0\n##       85+   0   0   0\n##      <NA>   0   0  86\nhist(linelist$age)"},{"path":"age_pyramid.html","id":"le-package-apyramid","chapter":"33 Pyramides démographiques et échelles de Likert","heading":"33.2 Le package apyramid","text":"Le package apyramid est un produit du projet R4Epis. Vous pouvez en savoir plus sur ce paquet ici. Il vous permet de réaliser rapidement une pyramide des âges. Pour des situations plus nuancées, voir la section ci-dessous utilisez ggplot(). Vous pouvez en savoir plus sur le package apyramid dans sa page d’aide en entrant ?age_pyramid dans votre console R.","code":""},{"path":"age_pyramid.html","id":"données-sous-forme-de-liste-des-cas","chapter":"33 Pyramides démographiques et échelles de Likert","heading":"Données sous forme de liste des cas","text":"En utilisant l’ensemble de données linelist nettoyées, nous pouvons créer une pyramide des âges avec une simple commande age_pyramid(). Dans cette commande :Le paramètre data = est défini comme le tableau de données linelist.Le paramètre data = est défini comme le tableau de données linelist.Le paramètre age_group = (pour l’axe des ordonnées) est défini comme le nom de la colonne d’âge catégorique (entre guillemets).Le paramètre age_group = (pour l’axe des ordonnées) est défini comme le nom de la colonne d’âge catégorique (entre guillemets).Le paramètre split_by = (pour l’axe des abscisses) est défini comme la colonne sexe.Le paramètre split_by = (pour l’axe des abscisses) est défini comme la colonne sexe.La pyramide peut être affichée avec le pourcentage de tous les cas sur l’axe des abscisses, au lieu du nombre, en incluant proportional = TRUE.Lors de l’utilisation du package apyramid, si la colonne split_by est binaire (par exemple homme/femme, ou oui/non), le résultat apparaîtra comme une pyramide. Cependant, s’il y plus de deux valeurs dans la colonne split_by (sans compter NA), la pyramide apparaîtra comme un diagramme à barres à facettes avec des barres grises dans le “fond” indiquant la plage des données non facettées pour ce groupe d’âge. Dans ce cas, les valeurs de split_by = apparaîtront comme des libellés en haut de chaque panneau de facettes. Par exemple, voici ce qui se passe si la colonne hospital est attribuée à split_by =.","code":"\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"gender\")\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"gender\",\n                      proportional = TRUE)\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"hospital\")  "},{"path":"age_pyramid.html","id":"valeurs-manquantes-2","chapter":"33 Pyramides démographiques et échelles de Likert","heading":"Valeurs manquantes","text":"Les lignes qui ont des valeurs manquantes NA dans les colonnes split_by = ou age_group =, si elles sont codées comme NA, ne déclencheront pas les facettes indiquées ci-dessus. Par défaut, ces lignes ne seront pas affichées. Cependant, vous pouvez demander à ce qu’elle apparaissent dans un graphique à barres adjacent et en tant que groupe d’âge distinct en haut, en spécifiant na.rm = FALSE.","code":"\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"gender\",\n                      na.rm = FALSE)         # Montre les patients dont l'âge ou le sexe est manquant"},{"path":"age_pyramid.html","id":"proportions-couleurs-et-attributs-graphiques","chapter":"33 Pyramides démographiques et échelles de Likert","heading":"Proportions, couleurs et attributs graphiques","text":"Par défaut, les barres affichent les nombres (pas les pourcentages), une ligne en pointillés au milieu de chaque groupe est affichée, et les couleurs sont vertes/violettes. Chacun de ces paramètres peut être ajusté, comme indiqué ci-dessous :Vous pouvez également ajouter des commandes ggplot() supplémentaires au graphique en utilisant la syntaxe standard de ggplot() “+”, comme des attributs graphiques et des ajustements de libellés :","code":"\napyramid::age_pyramid(\n  data = linelist,\n  age_group = \"age_cat5\",\n  split_by = \"gender\",\n  proportional = TRUE,              # afficher les pourcentages, pas les chiffres\n  show_midpoint = FALSE,            # supprimer la ligne du milieu de la barre\n  #pal = c(\"orange\", \"purple\")      # permet de préciser des couleurs alternatives (mais pas des libellés différents)\n  )+                 \n  \n  # commandes supplémentaires de ggplot\n  theme_minimal()+                               # simplifier le fond\n  scale_fill_manual(                             # préciser des couleurs ET des libellés\n    values = c(\"orange\", \"purple\"),              \n    labels = c(\"m\" = \"Male\", \"f\" = \"Female\"))+\n  labs(y = \"Percent of all cases\",              # les libellés x et y sont inversées\n       x = \"Age categories\",                          \n       fill = \"Gender\", \n       caption = \"My data source and caption here\",\n       title = \"Title of my plot\",\n       subtitle = \"Subtitle with \\n a second line...\")+\n  theme(\n    legend.position = \"bottom\",                          # légende en bas\n    axis.text = element_text(size = 10, face = \"bold\"),  # polices/tailles\n    axis.title = element_text(size = 12, face = \"bold\"))"},{"path":"age_pyramid.html","id":"données-aggrégées","chapter":"33 Pyramides démographiques et échelles de Likert","heading":"Données aggrégées","text":"Les exemples ci-dessus supposent que vos données sont au format de liste de cas, avec une ligne par observation. Si vos données sont déjà agrégées par catégorie d’âge, vous pouvez toujours utiliser le package apyramid, comme indiqué ci-dessous.Pour la démonstration, nous agrégeons les données de la liste de cas en nombre de cas par catégorie d’âge et par sexe, dans un format “large”. Cela fera comme si vos données étaient aggrégées dès le départ. Pour en savoir plus sur le Regroupement des données et le Pivotage des données, consultez leurs pages respectives.…ce qui fait que le jeu de données ressemble à ceci : avec des colonnes pour la catégorie d’âge, et le nombre d’hommes, le nombre de femmes, et le nombre de valeurs manquantes.Pour préparer ces données pour la pyramide des âges, nous allons faire pivoter les données pour qu’elles soient “longues” avec la fonction pivot_longer() de dplyr. Ceci est dû au fait que ggplot() préfère généralement les données “longues”, et apyramid utilise ggplot().Utilisez ensuite les arguments split_by = et count = de age_pyramid() pour spécifier les colonnes respectives dans les données :Notez dans l’exemple ci-dessus que l’ordre des facteurs “m” et “f” est différent (pyramide inversée). Pour ajuster l’ordre, vous devez redéfinir le sexe dans les données agrégées comme un facteur et ordonner les niveaux comme vous le souhaitez. Voir la page Facteurs.","code":"\ndemo_agg <- linelist %>% \n  count(age_cat5, gender, name = \"cases\") %>% \n  pivot_wider(\n    id_cols = age_cat5,\n    names_from = gender,\n    values_from = cases) %>% \n  rename(`missing_gender` = `NA`)\n# Faire pivoter les données agrégées afin qu'elles soient \"longues\"\ndemo_agg_long <- demo_agg %>% \n  pivot_longer(\n    col = c(f, m, missing_gender),            # Colonnes à \"allonger\"\n    names_to = \"gender\",                # Nom de la nouvelle colonne de catégorie\n    values_to = \"counts\") %>%           # Nom pour la nouvelle colonne de comptage\n  mutate(\n    gender = na_if(gender, \"missing_gender\")) # On convertit  \"missing_gender\" en NA\napyramid::age_pyramid(data = demo_agg_long,\n                      age_group = \"age_cat5\",# Nom de la colonne pour la catégorie d'âge\n                      split_by = \"gender\",   # Nom de la colonne pour le sexe\n                      count = \"counts\")      # Nom de la colonne pour le nombre de cas"},{"path":"age_pyramid.html","id":"demo_pyr_gg","chapter":"33 Pyramides démographiques et échelles de Likert","heading":"33.3 ggplot()","text":"L’utilisation de ggplot() pour construire votre pyramide des âges offre plus de flexibilité, mais demande plus d’efforts et de compréhension du fonctionnement de ggplot(). Il est également plus facile de faire des erreurs accidentelles.Pour utiliser ggplot() afin de créer des pyramides démographiques, vous devez créer deux diagrammes à barres (un pour chaque sexe), convertir les valeurs de l’un des diagrammes en valeurs négatives, et enfin inverser les axes x et y pour afficher les diagrammes à barres verticalement, leurs bases se rejoignant au milieu du diagramme.","code":""},{"path":"age_pyramid.html","id":"préparation-16","chapter":"33 Pyramides démographiques et échelles de Likert","heading":"Préparation","text":"Cette approche utilise une colonne d’âge sous forme numérique, et non la colonne catégorielle age_cat5. Nous allons donc vérifier que la classe de cette colonne est bien numérique.Vous pourriez utiliser la même logique ci-dessous pour construire une pyramide à partir de données catégorielles en utilisant geom_col() au lieu de geom_histogram().","code":"\nclass(linelist$age)## [1] \"numeric\""},{"path":"age_pyramid.html","id":"construction-du-graphe","chapter":"33 Pyramides démographiques et échelles de Likert","heading":"Construction du graphe","text":"Tout d’abord, il faut comprendre que pour réaliser une telle pyramide à l’aide de ggplot(), l’approche est la suivante :Dans la fonction ggplot(), créez deux histogrammes en utilisant la colonne numérique de l’âge. Créez-en un pour chacune des deux valeurs de regroupement (dans ce cas, les sexes masculin et féminin). Pour ce faire, les données de chaque histogramme sont spécifiées dans leurs commandes geom_histogram() respectives, avec les filtres respectifs appliqués à linelist.Dans la fonction ggplot(), créez deux histogrammes en utilisant la colonne numérique de l’âge. Créez-en un pour chacune des deux valeurs de regroupement (dans ce cas, les sexes masculin et féminin). Pour ce faire, les données de chaque histogramme sont spécifiées dans leurs commandes geom_histogram() respectives, avec les filtres respectifs appliqués à linelist.Un graphique aura des valeurs de comptage positives, tandis que l’autre aura ses comptages convertis en valeurs négatives - cela crée la “pyramide” avec la valeur 0 au milieu du graphique. Les valeurs négatives sont créées en utilisant un terme spécial de ggplot2 ..count.. et en les multipliant par -1.Un graphique aura des valeurs de comptage positives, tandis que l’autre aura ses comptages convertis en valeurs négatives - cela crée la “pyramide” avec la valeur 0 au milieu du graphique. Les valeurs négatives sont créées en utilisant un terme spécial de ggplot2 ..count.. et en les multipliant par -1.La commande coord_flip() permute les axes X et Y, ce qui pour effet de rendre les graphiques verticaux et de créer la pyramide.La commande coord_flip() permute les axes X et Y, ce qui pour effet de rendre les graphiques verticaux et de créer la pyramide.Enfin, les étiquettes des valeurs de l’axe des comptes doivent être modifiées pour qu’elles apparaissent comme des comptes “positifs” des deux côtés de la pyramide (bien que les valeurs sous-jacentes d’un côté soient négatives).Enfin, les étiquettes des valeurs de l’axe des comptes doivent être modifiées pour qu’elles apparaissent comme des comptes “positifs” des deux côtés de la pyramide (bien que les valeurs sous-jacentes d’un côté soient négatives).Une version simple de cette méthode, utilisant geom_histogram(), est présentée ci-dessous :DANGER: Si les limites de votre axe de nombre de cas sont trop basses, et qu’une barre de compte les dépasse, la barre disparaîtra entièrement ou sera artificiellement raccourcie ! Faites attention à ce phénomène si vous analysez des données qui sont régulièrement mises à jour. Pour éviter cela, les limites de votre axe de comptage doivent s’ajuster automatiquement à vos données, comme ci-dessousIl y beaucoup de choses que vous pouvez changer/ajoutez à cette version simple :Ajuster automatiquement l’échelle de l’axe des comptes à vos données (éviter les erreurs discutées dans l’avertissement ci-dessous).Spécifier manuellement les couleurs et les étiquettes de légendeConvertir les nombre de cas en pourcentagesPour convertir les nombres de cas en pourcentages (du total), faites-le dans vos données avant de les représenter. Ci-dessous, nous obtenons les comptes d’âge et de sexe, puis utilise ungroup(), et enfin mutate() pour créer de nouvelles colonnes de pourcentage. Si vous voulez des pourcentages par sexe, sautez l’étape de dégroupage.Il est important de noter que nous enregistrons les valeurs max et min afin de connaître les limites de l’échelle. Elles seront utilisées dans la commande ggplot() ci-dessous.Enfin, nous effectuons le ggplot() sur les données en pourcentage. Nous spécifions scale_y_continuous() pour étendre les longueurs prédéfinies dans chaque direction (“positive” et “négative”). Nous utilisons floor() et ceiling() pour arrondir les décimales dans la direction appropriée (vers le bas ou vers le haut) pour le côté de l’axe.","code":"\n  # commencer le ggplot\n  ggplot(mapping = aes(x = age, fill = gender)) +\n  \n  # histogramme femmes\n  geom_histogram(data = linelist %>% filter(gender == \"f\"),\n                 breaks = seq(0,85,5),\n                 colour = \"white\") +\n  \n  # histogramme hommes (valeurs converties en négatif)\n  geom_histogram(data = linelist %>% filter(gender == \"m\"),\n                 breaks = seq(0,85,5),\n                 mapping = aes(y = ..count..*(-1)),\n                 colour = \"white\") +\n  \n  # Inversion des axes X et Y\n  coord_flip() +\n  \n  # Ajustement de l'échelle de l'axe des nombres de cas\n  scale_y_continuous(limits = c(-600, 900),\n                     breaks = seq(-600,900,100),\n                     labels = abs(seq(-600, 900, 100)))\n# créer un jeu de données avec la proportion du total\npyramid_data <- linelist %>%\n  count(age_cat5,\n        gender,\n        name = \"counts\") %>% \n  ungroup() %>%                 # dégrouper de sorte à ce que les pourcentages ne soit pas par groupe\n  mutate(percent = round(100*(counts / sum(counts, na.rm=T)), digits = 1), \n         percent = case_when(\n            gender == \"f\" ~ percent,\n            gender == \"m\" ~ -percent))    # convertir les hommes en négatif\n                              # les valeur NA doivent aussi être numériques\nmax_per <- max(pyramid_data$percent, na.rm=T)\nmin_per <- min(pyramid_data$percent, na.rm=T)\n\nmax_per## [1] 10.9\nmin_per## [1] -7.1\n# Commencer le ggplot\n  ggplot()+  # par défaut l'axe X est l'âge en années;\n\n  # graphe des données des cas\n  geom_col(data = pyramid_data,\n           mapping = aes(\n             x = age_cat5,\n             y = percent,\n             fill = gender),         \n           colour = \"white\")+       # contour blanc autour de chaque barre\n  \n  # Inverser les axes X et Y pour rendre la pyramide verticale\n  coord_flip()+\n  \n\n  # Ajuster les échelles des axes\n  # scale_x_continuous(breaks = seq(0,100,5), labels = seq(0,100,5)) +\n  scale_y_continuous(\n    limits = c(min_per, max_per),\n    breaks = seq(from = floor(min_per),                # suite des valeurs deux par deux\n                 to = ceiling(max_per),\n                 by = 2),\n    labels = paste0(abs(seq(from = floor(min_per),     # suite des valeurs absolues deux par deux, avec \"%\"\n                            to = ceiling(max_per),\n                            by = 2)),\n                    \"%\"))+  \n\n  # Préciser manuellement les couleurs et les étiquettes\n  scale_fill_manual(\n    values = c(\"f\" = \"orange\",\n               \"m\" = \"darkgreen\"),\n    labels = c(\"Female\", \"Male\")) +\n  \n  # Etiqueter les valeur (en se rappellant que X et Y sont inversés)\n  labs(\n    title = \"Age and gender of cases\",\n    x = \"Age group\",\n    y = \"Percent of total\",\n    fill = NULL,\n    caption = stringr::str_glue(\"Data are from linelist \\nn = {nrow(linelist)} (age or sex missing for {sum(is.na(linelist$gender) | is.na(linelist$age_years))} cases) \\nData as of: {format(Sys.Date(), '%d %b %Y')}\")) +\n  \n  # Attributs graphiques et élements du thème\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.background = element_blank(),\n    axis.line = element_line(colour = \"black\"),\n    plot.title = element_text(hjust = 0.5), \n    plot.caption = element_text(hjust=0, size=11, face = \"italic\")\n    )"},{"path":"age_pyramid.html","id":"comparer-à-une-référence","chapter":"33 Pyramides démographiques et échelles de Likert","heading":"Comparer à une référence","text":"Grâce à la flexibilité de ggplot(), vous pouvez avoir une deuxième couche de barres en arrière-plan qui représente la pyramide des âges “réelle” ou “de référence”. Cela peut fournir une visualisation agréable pour comparer les données observées avec les données de référence.Importez et visualisez les données de population (voir la page Télécharger le manuel et les données) :Tout d’abord, quelques étapes de gestion des données :Nous enregistrons ici l’ordre des catégories d’âge que nous voulons voir apparaître. En raison de certaines bizarreries dans l’implémentation de ggplot(), dans ce scénario spécifique, il est plus facile de stocker ces données comme un vecteur de caractères et de les utiliser plus tard dans la fonction graphique.Combinez les données de population et de cas à l’aide de la fonction du paquet dplyr, bind_rows() :Tout d’abord, assurez-vous qu’elles ont exactement les mêmes noms de colonnes, valeurs de catégories d’âge et valeurs de sexe.Faites en sorte qu’ils aient la même structure de données : colonnes de catégorie d’âge, de sexe, de nombre et de pourcentage du total.Liez-les ensemble, l’un au-dessus de l’autre (bind_rows()).Examiner les données de population modifiéesOn peut maintenant faire la même chose pour les données des cas. C’est légèrement différent car elle commence par les lignes de cas et non par des totaux.Examiner les données des cas modifiéesLes deux jeux de données sont maintenant combinés, l’un au-dessus de l’autre (ils ont les mêmes noms de colonnes). Nous pouvons “nommer” chaque jeux de données, et utiliser l’argument .id = pour créer une nouvelle colonne “data_source” qui indiquera de quel cadre de données chaque ligne provient. Nous pouvons utiliser cette colonne pour filtrer dans la fonction ggplot().Enregistre les valeurs maximales et minimales en pourcentage, utilisées dans la fonction de traçage pour définir l’étendue du tracé (et ne pas couper les barres !).Le graphique est maintenant réalisé avec ggplot() :Un graphique en barres des données de population (barres plus larges et plus transparentes)Un histogramme des données de cas (petites barres, plus solides)","code":"\n# i Import des données démographiques d'une population\npop <- rio::import(\"country_demographics.csv\")\n# enregistrer les niveaux d'âge catégoriel corrects\nage_levels <- c(\"0-4\",\"5-9\", \"10-14\", \"15-19\", \"20-24\",\n                \"25-29\",\"30-34\", \"35-39\", \"40-44\", \"45-49\",\n                \"50-54\", \"55-59\", \"60-64\", \"65-69\", \"70-74\",\n                \"75-79\", \"80-84\", \"85+\")\n# Créer/transformer les données de population, avec le pourcentage du total\n########################################################\npop_data <- pop %>% \n  pivot_longer(      # On faire \"pivoter\" la colonne sexe à l'aide de pivot_longer\n    cols = c(m, f),\n    names_to = \"gender\",\n    values_to = \"counts\") %>% \n  \n  mutate(\n    percent  = round(100*(counts / sum(counts, na.rm=T)),1),  # % du total\n    percent  = case_when(                                                        \n     gender == \"f\" ~ percent,\n     gender == \"m\" ~ -percent))  # Pour les hommes on converti le pourcentage en négatif\n# créer des données sur les cas par âge/sexe, avec le pourcentage du total\n#######################################################\ncase_data <- linelist %>%\n  count(age_cat5, gender, name = \"counts\") %>%  # nombre par groupes age-sexe\n  ungroup() %>% \n  mutate(\n    percent = round(100*(counts / sum(counts, na.rm=T)),1),  # calculer le % du total pour les groupes d'âge et de sexe\n    percent = case_when(                                     # our les hommes on converti le pourcentage en négatif\n      gender == \"f\" ~ percent,\n      gender == \"m\" ~ -percent))\n# combiner les données de cas et de population (mêmes noms de colonnes, valeurs age_cat et valeurs de sexe)\npyramid_data <- bind_rows(\"cases\" = case_data, \"population\" = pop_data, .id = \"data_source\")\n# Définir l'étendue de l'axe des pourcentages, utilisé pour les limites du graphe.\nmax_per <- max(pyramid_data$percent, na.rm=T)\nmin_per <- min(pyramid_data$percent, na.rm=T)\n# Entamer le ggplot\n##############\nggplot()+  # l'axe des x par défaut est l'âge en années;\n\n  # Graphe des données de population\n  geom_col(\n    data = pyramid_data %>% filter(data_source == \"population\"),\n    mapping = aes(\n      x = age_cat5,\n      y = percent,\n      fill = gender),\n    colour = \"black\",                               # Contour noir autour des barres\n    alpha = 0.2,                                    # plus transparent\n    width = 1)+                                     # plein largeur\n  \n  # Graphe des données des cas\n  geom_col(\n    data = pyramid_data %>% filter(data_source == \"cases\"), \n    mapping = aes(\n      x = age_cat5,                               # Catégorie d'âge comme axes des x d'origine\n      y = percent,                                # % comme axe des Y d'origine\n      fill = gender),                             # Couleur de remplissage des barres en fonctio ns du sexe\n    colour = \"black\",                               # Contour noir autour des barres\n    alpha = 1,                                      # pas transparent \n    width = 0.3)+                                   # largeur réduite\n  \n  # inversersion des axes X et Y pour rendre la pyramide verticale\n  coord_flip()+\n  \n  # s'assurer à la main que l'axe de l'âge est ordonné correctement\n  scale_x_discrete(limits = age_levels)+     # défini dans le morceua de code ci-dessus\n  \n  # définir l'axe des pourcentages \n  scale_y_continuous(\n    limits = c(min_per, max_per),                                          # Le min et le max sont définis ci-dessus\n    breaks = seq(floor(min_per), ceiling(max_per), by = 2),                #  De min_per (pourcentage minimum) à max_per (pourcentage maximum) par 2 \n    labels = paste0(                                                       # Pour les libellés, coller ensemble... \n              abs(seq(floor(min_per), ceiling(max_per), by = 2)), \"%\"))+                                                  \n\n  # Définir manuellement les couleurs et les étiquettes de légende\n  scale_fill_manual(\n    values = c(\"f\" = \"orange\",         # attribuer des couleurs aux valeurs des données\n               \"m\" = \"darkgreen\"),\n    labels = c(\"f\" = \"Female\",\n               \"m\"= \"Male\"),      # modifier les libellés qui apparaissent dans la légende, noté l'ordre\n  ) +\n\n  # Ajouter au graphes les libellés et les titres \n  labs(\n    title = \"Case age and gender distribution,\\nas compared to baseline population\",\n    subtitle = \"\",\n    x = \"Age category\",\n    y = \"Percent of total\",\n    fill = NULL,\n    caption = stringr::str_glue(\"Cases shown on top of country demographic baseline\\nCase data are from linelist, n = {nrow(linelist)}\\nAge or gender missing for {sum(is.na(linelist$gender) | is.na(linelist$age_years))} cases\\nCase data as of: {format(max(linelist$date_onset, na.rm=T), '%d %b %Y')}\")) +\n  \n  # Paramètres graphiques optionnels\n  theme(\n    legend.position = \"bottom\",                             # Deplacer la légende en bas du graphe\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.background = element_blank(),\n    axis.line = element_line(colour = \"black\"),\n    plot.title = element_text(hjust = 0), \n    plot.caption = element_text(hjust=0, size=11, face = \"italic\"))"},{"path":"age_pyramid.html","id":"échelle-de-likert","chapter":"33 Pyramides démographiques et échelles de Likert","heading":"33.4 Échelle de Likert","text":"Les techniques utilisées pour réaliser une pyramide des âges avec ggplot() peuvent également être utilisées pour réaliser des graphiques de données d’enquêtes à échelle de Likert.Importez les données (voir la page Télécharger le manuel et les données si vous le souhaitez).Commencez avec des données qui ressemblent à ceci, avec une classification catégorielle de chaque répondant (statut) et leurs réponses à 8 questions sur une échelle de type Likert à 4 points (“Très mauvais”, “Mauvais”, “Bon”, “Très bon”).Tout d’abord, quelques étapes de gestion des données :Pivoter les données afin qu’elles soient “longues” plutôt que “larges”Créer une nouvelle colonne direction qui indique si une réponse était globalement “positive” ou “négative”Définisser l’ordre du niveau de Facteur pour la colonne status et la colonne ResponseEnregistrez la valeur maximale pour que les limites du graphique soient appropriées.Maintenant, créez le graphique. Comme dans les pyramides des âges ci-dessus, nous créons deux graphes à barres et inversons les valeurs de l’un d’entre eux en négatif.utilise geom_bar() parce que nos données sont une ligne par observation, et non pas des comptes agrégés. Nous utilisons le terme spécial de ggplot2 ..count.. dans l’un des graphiques en barres pour inverser les valeurs négatives (-1), et nous définissons position = \"stack\" pour que les valeurs s’empilent les unes sur les autres.","code":"\n# importer les données de réponse de l'enquête likert\nlikert_data <- rio::import(\"likert_data.csv\")\nmelted <- likert_data %>% \n  pivot_longer(\n    cols = Q1:Q8,\n    names_to = \"Question\",\n    values_to = \"Response\") %>% \n  mutate(\n    \n    direction = case_when(\n      Response %in% c(\"Poor\",\"Very Poor\")  ~ \"Negative\",\n      Response %in% c(\"Good\", \"Very Good\") ~ \"Positive\",\n      TRUE                                 ~ \"Unknown\"),\n    \n    status = fct_relevel(status, \"Junior\", \"Intermediate\", \"Senior\"),\n    \n    # On inverse  'Very Poor' et 'Poor' pour que l'ordre soit le bon\n    Response = fct_relevel(Response, \"Very Good\", \"Good\", \"Very Poor\", \"Poor\")) \n\n# Permet d'obtenir la plus grande valeur pour les limites d'échelle\nmelted_max <- melted %>% \n  count(status, Question) %>% # nombre de ligne\n  pull(n) %>%                 # Colonne 'n'\n  max(na.rm=T)                # Maximum\n# Créer le graphe\nggplot()+\n     \n  # graphique à barres des réponses \"négatives\" \n     geom_bar(\n       data = melted %>% filter(direction == \"Negative\"),\n       mapping = aes(\n         x = status,\n         y = ..count..*(-1),    # counts inverted to negative\n         fill = Response),\n       color = \"black\",\n       closed = \"left\",\n       position = \"stack\")+\n     \n     #  graphique à barres des réponses \"positives\" \n     geom_bar(\n       data = melted %>% filter(direction == \"Positive\"),\n       mapping = aes(\n         x = status,\n         fill = Response),\n       colour = \"black\",\n       closed = \"left\",\n       position = \"stack\")+\n     \n     # inversion des axes x et y\n     coord_flip()+\n  \n     # Ligne noire verticale à 0\n     geom_hline(yintercept = 0, color = \"black\", size=1)+\n     \n    # On convertit les libellés pour qu'il n'y ai que des chiffres positifs\n    scale_y_continuous(\n      \n      # limites de l'échelle des x\n      limits = c(-ceiling(melted_max/10)*11,    # séquence de négatif à positif par 10, bords arrondis vers l'extérieur au 5 le plus proche\n                 ceiling(melted_max/10)*10),   \n      \n      # valeurs de l'échelle de l'axe des x\n      breaks = seq(from = -ceiling(melted_max/10)*10,\n                   to = ceiling(melted_max/10)*10,\n                   by = 10),\n      \n      # libellés de l'échelle de l'axe des x\n      labels = abs(unique(c(seq(-ceiling(melted_max/10)*10, 0, 10),\n                            seq(0, ceiling(melted_max/10)*10, 10))))) +\n     \n    # échelle de couleur attribuées manuellement\n    scale_fill_manual(\n      values = c(\"Very Good\"  = \"green4\", # attribue les couleurs\n                \"Good\"      = \"green3\",\n                \"Poor\"      = \"yellow\",\n                \"Very Poor\" = \"red3\"),\n      breaks = c(\"Very Good\", \"Good\", \"Poor\", \"Very Poor\"))+ # donne l'ordre de la légende\n     \n    \n     \n    # Convertit le graphe de sorte à ce que chaque sous graphe corresponde à une question\n    facet_wrap( ~ Question, ncol = 3)+\n     \n    # libellés, titres, légende\n    labs(\n      title = str_glue(\"Likert-style responses\\nn = {nrow(likert_data)}\"),\n      x = \"Respondent status\",\n      y = \"Number of responses\",\n      fill = \"\")+\n\n     # Paramètres graphiques \n     theme_minimal()+\n     theme(axis.text = element_text(size = 12),\n           axis.title = element_text(size = 14, face = \"bold\"),\n           strip.text = element_text(size = 14, face = \"bold\"),  # Titre de chaque sous graphique\n           plot.title = element_text(size = 20, face = \"bold\"),\n           panel.background = element_rect(fill = NA, color = \"black\")) # Cadre noir autour de chaque sous graphique"},{"path":"age_pyramid.html","id":"resources-8","chapter":"33 Pyramides démographiques et échelles de Likert","heading":"33.5 Resources","text":"Documentation de apyramid","code":""},{"path":"heatmaps.html","id":"heatmaps","chapter":"34 Graphiques thermiques","heading":"34 Graphiques thermiques","text":"Les diagrammes de chaleur, également connus sous le nom de “cartes de chaleur” ou “tuiles de chaleur”, peuvent être des visualisations utiles lorsqu’essaie d’afficher 3 variables (axe des x, axe des y et remplissage). Nous présentons ci-dessous deux exemples :Une matrice visuelle des événements de transmission par âge (“qui infecté qui”).Le suivi des métriques de déclaration dans de nombreux établissements/juridictions au fil du temps.","code":""},{"path":"heatmaps.html","id":"préparation-17","chapter":"34 Graphiques thermiques","heading":"34.1 Préparation","text":"","code":""},{"path":"heatmaps.html","id":"chargement-des-paquets-6","chapter":"34 Graphiques thermiques","heading":"Chargement des paquets","text":"Ce morceau de code montre le chargement des paquets nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire et le charge pour l’utiliser. Vous pouvez également charger les paquets installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les paquets R.Ensembles de donnéesCette page utilise la liste de cas d’une épidémie simulée pour la section de la matrice de transmission, et un jeu de données séparé du nombre quotidien de cas de paludisme par établissement pour la section du suivi des mesures. Ils sont chargés et nettoyés dans leurs sections individuelles.","code":"\npacman::p_load(\n  tidyverse, # manipulation et visualisation de données\n  rio, # importation de données \n  lubridate # travail avec les dates\n  )"},{"path":"heatmaps.html","id":"matrice-de-transmission","chapter":"34 Graphiques thermiques","heading":"34.2 Matrice de transmission","text":"Les tuiles thermiques peuvent être utiles pour visualiser les matrices. Un exemple est d’afficher “qui infecté qui” dans une épidémie. Cela suppose que vous disposiez d’informations sur les événements de transmission.Notez que la page Recherche des contacts contient un autre exemple de création d’une matrice de contacts en tuiles thermiques, à l’aide d’un ensemble de données différent (peut-être plus simple) où les âges des cas et leurs sources sont soigneusement alignés sur la même ligne du cadre de données. Ces mêmes données sont utilisées pour réaliser une carte de densité dans la page Astuces de ggplot. L’exemple ci-dessous part d’une liste de cas et implique donc une manipulation considérable des données avant d’obtenir un cadre de données traçable. Il existe donc de nombreux scénarios parmi lesquels choisir…Nous commençons à partir de la liste de cas d’une épidémie d’Ebola simulée. Si vous souhaitez nous suivre, cliquez pour télécharger la linelist “propre” (en tant que fichier .rds). Importez vos données avec la fonction import() du paquet rio (elle accepte de nombreux types de fichiers comme .xlsx, .rds, .csv - voir la page Importation et exportation pour plus de détails).Les 50 premières lignes de la liste de lignes sont présentées ci-dessous à titre de démonstration :Dans cette linelist :Il y une ligne par cas, identifié par case_id.Il y une colonne ultérieure infector qui contient le case_id de l’infector, qui est aussi un cas dans la linelist","code":"\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"heatmaps.html","id":"préparation-des-données","chapter":"34 Graphiques thermiques","heading":"Préparation des données","text":"Objectif : Nous devons obtenir un cadre de données de type “long” qui contient une ligne par route de transmission âge-âge possible, avec une colonne numérique contenant la proportion de cette ligne de tous les événements de transmission observés dans la liste de lignes.Il faudra plusieurs étapes de manipulation des données pour y parvenir :","code":""},{"path":"heatmaps.html","id":"créer-un-cadre-de-données-pour-les-cas","chapter":"34 Graphiques thermiques","heading":"Créer un cadre de données pour les cas","text":"Pour commencer, nous créons un cadre de données des cas, de leurs âges, et de leurs infecteurs - nous appelons ce cadre de données case_ages. Les 50 premières lignes sont affichées ci-dessous.","code":"\ncase_ages <- linelist %>% \n  select(case_id, infector, age_cat) %>% \n  rename(\"case_age_cat\" = \"age_cat\")"},{"path":"heatmaps.html","id":"création-dun-cadre-de-données-dinfecteurs","chapter":"34 Graphiques thermiques","heading":"Création d’un cadre de données d’infecteurs","text":"Ensuite, nous créons un cadre de données des infecteurs - pour l’instant, il est constitué d’une seule colonne. Il s’agit des identifiants des infecteurs de la liste de diffusion. Tous les cas n’ont pas un infecteur connu, nous supprimons donc les valeurs manquantes. Les 50 premières lignes sont affichées ci-dessous.Ensuite, nous utilisons des jointures pour obtenir l’âge des infecteurs. Ce n’est pas simple, car dans la linelist, les âges des infecteurs ne sont pas listés en tant que tels. Nous obtenons ce résultat en joignant le cas linelist aux infecteurs. Nous commençons par les infecteurs, et left_join() (ajoutons) la case linelist de sorte que la colonne infector id du cadre de données “baseline” de gauche rejoint la colonne case_id du cadre de données linelist de droite.Ainsi, les données de l’enregistrement du cas de l’infecteur dans la linelist (y compris l’âge) sont ajoutées à la ligne de l’infecteur. Les 50 premières lignes sont affichées ci-dessous.Ensuite, nous combinons les cas et leurs âges avec les infecteurs et leurs âges. Chacun de ces cadres de données possède la colonne infector, elle est donc utilisée pour la jointure. Les premières lignes sont affichées ci-dessous :Ci-dessous, un simple tableau croisé des chiffres entre les groupes d’âge des cas et des infecteurs. Des étiquettes ont été ajoutées pour plus de clarté.Nous pouvons convertir ce tableau en un cadre de données avec data.frame() de base R, qui le convertit aussi automatiquement au format “long”, ce qui est souhaité pour le ggplot(). Les premières lignes sont présentées ci-dessous.Maintenant, nous faisons la même chose, mais nous appliquons prop.table() de base R au tableau pour qu’au lieu de compter, nous obtenions des proportions du total. Les 50 premières lignes sont affichées ci-dessous.","code":"\ninfectors <- linelist %>% \n  select(infector) %>% \n  drop_na(infector)\ninfector_ages <- infectors %>% # commence par infectors\n  left_join( # ajoute les données de la linelist à chaque infecteur  \n    linelist,\n    by = c(\"infector\" = \"case_id\")) %>% # faire correspondre l'infector à ses informations en tant que cas\n  select(infector, age_cat) %>% # ne conserve que les colonnes d'intérêt\n  rename(\"infector_age_cat\" = \"age_cat\") # renommer pour plus de clarté\nages_complete <- case_ages %>%  \n  left_join(\n    infector_ages,\n    by = \"infector\") %>% # chacun a la colonne infector\n  drop_na() # supprime les lignes avec des données manquantes## Warning in left_join(., infector_ages, by = \"infector\"): Detected an unexpected many-to-many relationship between `x` and `y`.\n## ℹ Row 1 of `x` matches multiple rows in `y`.\n## ℹ Row 6 of `y` matches multiple rows in `x`.\n## ℹ If a many-to-many relationship is expected, set `relationship = \"many-to-many\"` to\n##   silence this warning.\ntable(cases = ages_complete$case_age_cat,\n      infectors = ages_complete$infector_age_cat)##        infectors\n## cases   0-4 5-9 10-14 15-19 20-29 30-49 50-69 70+\n##   0-4   105 156   105   114   143   117    13   0\n##   5-9   102 132   110   102   117    96    12   5\n##   10-14 104 109    91    79   120    80    12   4\n##   15-19  85 105    82    39    75    69     7   5\n##   20-29 101 127   109    80   143   107    22   4\n##   30-49  72  97    56    54    98    61     4   5\n##   50-69   5   6    15     9     7     5     2   0\n##   70+     1   0     2     0     0     0     0   0\nlong_counts <- data.frame(table(\n    cas = ages_complete$case_age_cat,\n    infectors = ages_complete$infector_age_cat))\nlong_prop <- data.frame(prop.table(table(\n    cases = ages_complete$case_age_cat,\n    infectors = ages_complete$infector_age_cat)))"},{"path":"heatmaps.html","id":"créer-un-diagramme-de-chaleur","chapter":"34 Graphiques thermiques","heading":"Créer un diagramme de chaleur","text":"Maintenant, nous pouvons enfin créer le graphique de chaleur avec le paquet ggplot2, en utilisant la fonction geom_tile(). Consultez la page Astuces de ggplot pour en savoir plus sur les échelles de couleur et de remplissage, en particulier la fonction scale_fill_gradient().Dans l’esthétique aes() de geom_tile(), définissez x et y comme l’âge du cas et l’âge de l’infecteur.De plus, dans aes(), mettez l’argument fill = dans la colonne Freq - c’est la valeur qui sera convertie en une couleur de tuile.Définissez une couleur d’échelle avec scale_fill_gradient() - vous pouvez spécifier les couleurs hautes et basses.\nNotez que scale_color_gradient() est différent ! Dans ce cas, vous voulez le remplissage\nNotez que scale_color_gradient() est différent ! Dans ce cas, vous voulez le remplissageComme la couleur est faite via “fill”, vous pouvez utiliser l’argument fill = dans labs() pour changer le titre de la légende.","code":"\nggplot(data = long_prop)+ # utilise des données longues, avec des proportions comme Freq\n  geom_tile( # visualisation en tuiles\n    aes(\n      x = cases, # l'axe des x est l'âge du cas\n      y = infectors, # l'axe des y est l'âge de l'infecteur\n      fill = Freq))+ # la couleur de la tuile correspond à la colonne Freq dans les données\n  scale_fill_gradient( # ajuste la couleur de remplissage des tuiles\n    low = \"blue\",\n    high = \"orange\")+\n  labs( # étiquettes\n    x = \"Âge du cas\",\n    y = \"Âge du contaminateur\",\n    title = \"Qui a infecté qui\",\n    subtitle = \"Matrice de fréquence des événements de transmission\",\n    fill = \"Proportion de tous les événements de transmission\" # titre de la légende\n  )"},{"path":"heatmaps.html","id":"rapport-sur-les-mesures-dans-le-temps","chapter":"34 Graphiques thermiques","heading":"34.3 Rapport sur les mesures dans le temps","text":"Souvent, en santé publique, un objectif est d’évaluer les tendances dans le temps pour de nombreuses entités (établissements, juridictions, etc.). Une façon de visualiser ces tendances dans le temps est un diagramme de chaleur où l’axe des x est le temps et l’axe des y sont les nombreuses entités.","code":""},{"path":"heatmaps.html","id":"préparation-des-données-1","chapter":"34 Graphiques thermiques","heading":"Préparation des données","text":"Nous commençons par importer un jeu de données de rapports quotidiens sur le paludisme provenant de nombreux établissements. Les rapports contiennent une date, une province, un district et un nombre de cas de paludisme. Voir la page Télécharger le manuel et les données pour savoir comment télécharger ces données. Voici les 30 premières lignes :","code":"\nfacility_count_data <- import(\"malaria_facility_count_data.rds\")"},{"path":"heatmaps.html","id":"agréger-et-résumer","chapter":"34 Graphiques thermiques","heading":"Agréger et résumer","text":"L’objectif de cet exemple est de transformer les comptages quotidiens de cas de paludisme totaux de l’établissement (vus dans l’onglet précédent) en statistiques récapitulatives hebdomadaires des performances de déclaration de l’établissement - dans ce cas, la proportion de jours par semaine où l’établissement déclaré des données. Pour cet exemple, nous allons montrer les données uniquement pour le District de Spring.Pour ce faire, nous allons procéder aux étapes suivantes de gestion des données :Filtrer les données comme il convient (par lieu, par date).Créer une colonne hebdomadaire en utilisant floor_date() du package lubridate.\nCette fonction renvoie la date de début de la semaine d’une date donnée, en utilisant une date de début spécifiée de chaque semaine (par exemple “Lundi”)\nCette fonction renvoie la date de début de la semaine d’une date donnée, en utilisant une date de début spécifiée de chaque semaine (par exemple “Lundi”)Les données sont regroupées par les colonnes “lieu” et “semaine” pour créer des unités d’analyse de “semaine d’installation”.La fonction summarise() crée de nouvelles colonnes pour refléter les statistiques sommaires par groupe de semaine d’installation :\nNombre de jours par semaine (7 - une valeur statique)\nNombre de rapports reçus de la semaine d’installation (peut être plus de 7 !)\nSomme des cas de malaria rapportés par la semaine d’installation (juste pour l’intérêt)\nNombre de jours uniques dans la semaine d’installation pour lesquels des données ont été rapportées.Pourcentage des 7 jours par semaine d’installation pour lesquels des données ont été déclarées.\nNombre de jours par semaine (7 - une valeur statique)Nombre de rapports reçus de la semaine d’installation (peut être plus de 7 !)Somme des cas de malaria rapportés par la semaine d’installation (juste pour l’intérêt)Nombre de jours uniques dans la semaine d’installation pour lesquels des données ont été rapportées.Pourcentage des 7 jours par semaine d’installation pour lesquels des données ont été déclarées.Le cadre de données est joint avec right_join() à une liste complète de toutes les combinaisons possibles de semaine d’installation, pour rendre l’ensemble de données complet. La matrice de toutes les combinaisons possibles est créée en appliquant expand() aux deux colonnes du cadre de données tel qu’il est à ce moment-là dans la chaîne de production (représenté par .). Comme un right_join() est utilisé, toutes les lignes du cadre de données expand() sont conservées, et ajoutées à agg_weeks si nécessaire. Ces nouvelles lignes apparaissent avec des valeurs résumées NA (manquantes).Nous faisons ci-dessous une démonstration étape par étape :Maintenant, le jeu de données 608 lignes, alors qu’il avait précédemment 3038.Ensuite, nous créons une colonne week reflétant la date de début de la semaine pour chaque enregistrement. Ceci est réalisé avec le package lubridate et la fonction floor_date(), qui est définie sur “week” et pour que les semaines commencent le lundi (jour 1 de la semaine - le dimanche serait le 7). Les lignes du haut sont présentées ci-dessous.La nouvelle colonne de semaine est visible à l’extrême droite du cadre de données.Maintenant, nous regroupons les données en semaines d’installation et les résumons pour produire des statistiques par semaine d’installation. Consultez la page sur les Tableaux descriptifs pour obtenir des conseils. Le regroupement en lui-même ne modifie pas la trame de données, mais il un impact sur la façon dont les statistiques récapitulatives suivantes sont calculées.Les lignes du haut sont présentées ci-dessous. Notez comment les colonnes ont complètement changé pour refléter les statistiques récapitulatives souhaitées. Chaque ligne reflète une semaine d’installation.Enfin, nous exécutons la commande ci-dessous pour nous assurer que TOUTES les semaines d’installation possibles sont présentes dans les données, même si elles étaient absentes auparavant.Nous utilisons un right_join() sur lui-même (l’ensemble de données est représenté par “.”) mais il été étendu pour inclure toutes les combinaisons possibles des colonnes week et location_name. Voir la documentation sur la fonction expand() dans la page sur Pivoter les donnees. Avant d’exécuter ce code, l’ensemble de données contient 107 lignes.Voici expanded_weeks, avec 180 lignes:Avant d’exécuter ce code, agg_weeks contient 107 lignes.Après avoir exécuté ce code, agg_weeks contient 180 lignes.","code":"\n# Créer un ensemble de données de résumé hebdomadaire\nagg_weeks <- facility_count_data %>% \n  \n  # Filtrez les données comme il se doit\n  filter(\n    District == \"Spring\",\n    data_date < as.Date(\"2020-08-01\")) \nagg_weeks <- agg_weeks %>% \n  # Créez une colonne semaine à partir de data_date\n  mutate(\n    week = lubridate::floor_date( # créer une nouvelle colonne de semaines\n      data_date, # colonne de date\n      unit = \"week\", # donne le début de la semaine\n      week_start = 1))                                # les semaines commencent le lundi \nagg_weeks <- agg_weeks %>%   \n\n  # Regroupement en semaines d'installation\n  group_by(location_name, week) %>%\n  \n  # Créez des colonnes de statistiques récapitulatives sur les données groupées\n  summarize(\n    n_days = 7, # 7 jours par semaine           \n    n_reports = dplyr::n(), # nombre de rapports reçus par semaine (peut être >7)\n    malaria_tot = sum(malaria_tot, na.rm = T), # nombre total de cas de paludisme signalés\n    n_days_reported = length(unique(data_date)), # nombre de jours uniques de déclaration par semaine\n    p_days_reported = round(100*(n_days_reported / n_days))) %>%      # pourcentage de jours de déclaration\n  ungroup(location_name, week)    #ungroup() alors expand() marche dans les prochaines etapes\n# Créez un cadre de données pour chaque semaine d'installation possible.\nexpanded_weeks <- agg_weeks %>% \n  tidyr::expand(location_name, week) # étendre le cadre de données pour inclure toutes les combinaisons possibles établissement-semaine\n# Utilisez une jointure à droite avec la liste étendue des semaines d'installation pour combler les lacunes dans les données.\nagg_weeks <- agg_weeks %>%      \n  right_join(expanded_weeks) %>% # Assurez-vous que toutes les combinaisons possibles de semaines d'installation apparaissent dans les données.\n  mutate(p_days_reported = replace_na(p_days_reported, 0))  # Convertir les valeurs manquantes en 0                           ## Joining with `by = join_by(location_name, week)`"},{"path":"heatmaps.html","id":"créer-un-graphique-de-chaleur","chapter":"34 Graphiques thermiques","heading":"Créer un graphique de chaleur","text":"Le ggplot() est réalisé en utilisant geom_tile() du paquet ggplot2 :Les semaines sur l’axe des x sont transformées en dates, permettant l’utilisation de scale_x_date().L’axe des ordonnées affiche tous les noms des établissements.Le “remplissage” est “p_days_reported”, la performance pour cette semaine d’installation (numérique).scale_fill_gradient() est utilisé sur le remplissage numérique, en spécifiant des couleurs pour le haut, le bas, et NA.La fonction scale_x_date() est utilisée sur l’axe des x pour spécifier les étiquettes toutes les 2 semaines et leur format.Les thèmes d’affichage et les étiquettes peuvent être ajustés si nécessaire.","code":""},{"path":"heatmaps.html","id":"basique","chapter":"34 Graphiques thermiques","heading":"Basique","text":"Un graphique thermique de base est produit ci-dessous, en utilisant les couleurs, les échelles, etc. par défaut. Comme expliqué ci-dessus, dans le aes() pour le geom_tile() vous devez fournir une colonne pour l’axe des x, une colonne pour l’axe des y, et une colonne pour le fill =. Le remplissage est la valeur numérique qui présente comme couleur de tuile.","code":"\nggplot(data = agg_weeks)+\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported))"},{"path":"heatmaps.html","id":"tracé-nettoyé","chapter":"34 Graphiques thermiques","heading":"Tracé nettoyé","text":"Nous pouvons améliorer l’apparence de ce graphique en ajoutant des fonctions ggplot2 supplémentaires, comme indiqué ci-dessous. Voir la page sur les astuces de ggplot pour plus de détails.","code":"\nggplot(data = agg_weeks)+ \n  \n  # affiche les données sous forme de tuiles\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported),      \n    color = \"white\")+ # lignes de grille blanches\n  \n  scale_fill_gradient(\n    low = \"orange\",\n    high = \"darkgreen\",\n    na.value = \"grey80\")+\n  \n  # axe des dates\n  scale_x_date(\n    expand = c(0,0), # supprimer l'espace supplémentaire sur les côtés\n    date_breaks = \"2 weeks\", # étiquettes toutes les 2 semaines\n    date_labels = \"%d\\n%b\")+ # le format est jour sur mois (\\n dans la nouvelle ligne)\n  \n  # thèmes esthétiques\n  theme_minimal()+ # simplifier l'arrière-plan\n  \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1, \"cm\"), # hauteur de la clé de légende\n    legend.key.width = grid::unit(0.6, \"cm\"), # largeur de la clé de légende\n    \n    axis.text.x = element_text(size=12), # taille du texte de l'axe\n    axis.text.y = element_text(vjust=0.2), # alignement du texte de l'axe\n    axis.ticks = element_line(size=0.4),               \n    axis.title = element_text(size=12, face=\"bold\"), # taille et gras du titre de l'axe\n    \n    plot.title = element_text(hjust=0,size=14,face=\"bold\"), # titre aligné à droite, large, gras\n    plot.caption = element_text(hjust = 0, face = \"italic\"), # légende alignée à droite et en italique\n    )+\n  \n  # étiquettes du graphique\n  labs(x = \"Semaine\",\n       y = \"Nom de l'établissement\",\n       fill = \"Reporting\\nperformance (%)\", # titre de la légende, car la légende montre le remplissage\n       title = \"Pourcentage de jours par semaine où l'établissement a déclaré des données\",\n       subtitle = \"Établissements de santé du district, mai-juillet 2020\",\n       caption = \"Semaines de 7 jours commençant le lundi\")"},{"path":"heatmaps.html","id":"axe-des-y-ordonné","chapter":"34 Graphiques thermiques","heading":"Axe des y ordonné","text":"Actuellement, les installations sont ordonnées “alpha-numériquement” de bas en haut. Si vous voulez ajuster l’ordre des installations de l’axe des y, convertissez-les en facteur de classe et fournissez l’ordre. Voir la page sur les Facteurs pour des conseils.Puisqu’il y beaucoup d’installations et que nous ne voulons pas les écrire toutes, nous allons essayer une autre approche - classer les installations dans un cadre de données et utiliser la colonne de noms résultante comme ordre de niveau de facteur. Ci-dessous, la colonne location_name est convertie en un facteur, et l’ordre de ses niveaux est établi sur la base du nombre total de jours de déclaration déposés par l’installation sur l’ensemble de la période.Pour ce faire, nous créons un cadre de données qui représente le nombre total de rapports par établissement, classés par ordre croissant. Nous pouvons utiliser ce vecteur pour ordonner les niveaux de facteurs dans le graphique.Voir le cadre de données ci-dessous :Utilisez maintenant une colonne du cadre de données ci-dessus (facility_order$location_name) comme ordre des niveaux de facteur de location_name dans le cadre de données agg_weeks :Et maintenant, les données sont à nouveau tracées, le nom de l’emplacement étant un facteur ordonné :","code":"\nfacility_order <- agg_weeks %>% \n  group_by(location_name) %>% \n  summarize(tot_reports = sum(n_days_reported, na.rm=T)) %>% \n  arrange(tot_reports) # ordre ascendant\n# charger le paquet \npacman::p_load(forcats)\n\n# créer le facteur et définir les niveaux manuellement\nagg_weeks <- agg_weeks %>% \n  mutate(location_name = fct_relevel(\n    location_name, facility_order$location_name)\n    )\nggplot(data = agg_weeks)+ \n  \n  # afficher les données sous forme de tuiles\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported),      \n    color = \"white\")+ # lignes de grille blanches\n  \n  scale_fill_gradient(\n    low = \"orange\",\n    high = \"darkgreen\",\n    na.value = \"grey80\")+\n  \n  # axe des dates\n  scale_x_date(\n    expand = c(0,0), # supprimer l'espace supplémentaire sur les côtés\n    date_breaks = \"2 weeks\", # étiquettes toutes les 2 semaines\n    date_labels = \"%d\\n%b\")+ # le format est jour sur mois (\\n dans la nouvelle ligne)\n  \n  # thèmes esthétiques\n  theme_minimal()+ # simplifier l'arrière-plan\n  \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1, \"cm\"), # hauteur de la clé de légende\n    legend.key.width = grid::unit(0.6, \"cm\"), # largeur de la clé de légende\n    \n    axis.text.x = element_text(size=12), # taille du texte de l'axe\n    axis.text.y = element_text(vjust=0.2), # alignement du texte de l'axe\n    axis.ticks = element_line(size=0.4),               \n    axis.title = element_text(size=12, face=\"bold\"), # taille et gras du titre de l'axe\n    \n    plot.title = element_text(hjust=0,size=14,face=\"bold\"), # titre aligné à droite, large, gras\n    plot.caption = element_text(hjust = 0, face = \"italic\"), # légende alignée à droite et en italique\n    )+\n  \n  # étiquettes du graphique\n  labs(x = \"Semaine\",\n       y = \"Nom de l'établissement\",\n       fill = \"Reporting\\nperformance (%)\", # titre de la légende, car la légende montre le remplissage\n       title = \"Pourcentage de jours par semaine où l'établissement a déclaré des données\",\n       subtitle = \"Établissements de santé du district, mai-juillet 2020\",\n       caption = \"Semaines de 7 jours commençant le lundi\")"},{"path":"heatmaps.html","id":"afficher-les-valeurs","chapter":"34 Graphiques thermiques","heading":"Afficher les valeurs","text":"Vous pouvez ajouter une couche geom_text() au dessus des tuiles, pour afficher les numéros réels de chaque tuile. Attention, cela peut ne pas être joli si vous avez beaucoup de petites tuiles !Le code suivant été ajouté : geom_text(aes(label = p_days_reported)). Ceci ajoute du texte sur chaque tuile. Le texte affiché est la valeur assignée à l’argument label =, qui dans ce cas été fixé à la même colonne numérique p_days_reported qui est aussi utilisée pour créer le gradient de couleur.","code":"\nggplot(data = agg_weeks)+ \n  \n  # affiche les données sous forme de tuiles\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported),      \n    color = \"white\")+ # lignes de grille blanches\n  \n  # Texte\n  geom_text(\n    aes(\n      x = week,\n      y = location_name,\n      label = p_days_reported))+ # ajouter le texte au dessus de la tuile\n  \n  # remplir l'échelle\n  scale_fill_gradient(\n    low = \"orange\",\n    high = \"darkgreen\",\n    na.value = \"grey80\")+\n  \n  # axe des dates\n  scale_x_date(\n    expand = c(0,0), # supprimer l'espace supplémentaire sur les côtés\n    date_breaks = \"2 weeks\", # étiquettes toutes les 2 semaines\n    date_labels = \"%d\\n%b\")+ # le format est jour sur mois (\\n dans la nouvelle ligne)\n  \n  # thèmes esthétiques\n  theme_minimal()+ # simplifier l'arrière-plan\n  \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1, \"cm\"), # hauteur de la clé de légende\n    legend.key.width = grid::unit(0.6, \"cm\"), # largeur de la clé de légende\n    \n    axis.text.x = element_text(size=12), # taille du texte de l'axe\n    axis.text.y = element_text(vjust=0.2), # alignement du texte de l'axe\n    axis.ticks = element_line(size=0.4),               \n    axis.title = element_text(size=12, face=\"bold\"), # taille et gras du titre de l'axe\n    \n    plot.title = element_text(hjust=0,size=14,face=\"bold\"), # titre aligné à droite, large, gras\n    plot.caption = element_text(hjust = 0, face = \"italic\"), # légende alignée à droite et en italique\n    )+\n  \n  # étiquettes du graphique\n  labs(x = \"Semaine\",\n       y = \"Nom de l'établissement\",\n       fill = \"Reporting\\nperformance (%)\", # titre de la légende, car la légende montre le remplissage\n       title = \"Pourcentage de jours par semaine où l'établissement a déclaré des données\",\n       subtitle = \"Établissements de santé du district, mai-juillet 2020\",\n       caption = \"Semaines de 7 jours commençant le lundi\")"},{"path":"heatmaps.html","id":"ressources-18","chapter":"34 Graphiques thermiques","heading":"34.4 Ressources","text":"scale_fill_gradient()Galerie de graphiques R - carte thermique","code":""},{"path":"diagrams.html","id":"diagrams","chapter":"35 Diagrammes et schémas","heading":"35 Diagrammes et schémas","text":"Cette page passe en revue le code pour produire:Des diagrammes de flux en utilisant DiagrammemeR et le langage DOT.Diagrammes Alluviaux/SankeyDes chronologies d’événements","code":""},{"path":"diagrams.html","id":"préparation-18","chapter":"35 Diagrammes et schémas","heading":"35.1 Préparation","text":"","code":""},{"path":"diagrams.html","id":"chargement-des-paquets-7","chapter":"35 Diagrammes et schémas","heading":"Chargement des paquets","text":"Ce chunk de code montre le chargement des paquets nécessaires pour les analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire et le charge pour l’utiliser. Vous pouvez également charger les paquets installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les paquets bases de R.","code":"\npacman::p_load(\n  DiagrammeR, # pour les diagrammes de flux\n  networkD3, # pour les diagrammes alluviaux/Sankey\n  tidyverse) # gestion et visualisation des données"},{"path":"diagrams.html","id":"importer-des-données-7","chapter":"35 Diagrammes et schémas","heading":"Importer des données","text":"La plupart du contenu de cette page ne nécessite pas de jeu de données. Cependant, dans la section sur le diagramme de Sankey, nous utiliserons la liste de cas d’une simulation d’épidémie d’Ebola. Si vous souhaitez suivre cette partie, cliquez pour télécharger la liste de cas “propre” (en fichier format .rds). Importez les données avec la fonction import() du paquet rio (elle gère de nombreux types de fichiers comme .xlsx, .csv, .rds - voir la page Importation et exportation pour plus de détails).Les 50 premières lignes de la linelist sont affichées ci-dessous.","code":"\n# Importez la liste de cas\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"diagrams.html","id":"diagrammes-de-flux","chapter":"35 Diagrammes et schémas","heading":"35.2 Diagrammes de flux","text":"peut utiliser le paquet R DiagrammeR pour créer des diagrammes/schémas de flux. Ils peuvent être statiques, ou s’ajuster dynamiquement en fonction des changements dans un ensemble de données.OutilsLa fonction grViz() est utilisée pour créer un diagramme “Graphviz”. Cette fonction accepte une chaîne de caractères en entrée contenant les instructions pour réaliser le diagramme. Dans cette chaîne de caractères, les instructions sont écrites dans un langage différent, DOT; il est assez facile d’apprendre les bases de le langage DOT.Structure de baseOuvrez les instructions grViz(\"Spécifiez la direction et le nom du graphique, et ouvrez les parenthèses, par exemple digraph mon_diagramme_de_flux {Déclaration du graphique (disposition, direction du rang)Déclaration des noeuds (crée les noeuds)Déclarations de contours/bords (donne les liens entre les noeuds)Fermer les instructions }\")","code":""},{"path":"diagrams.html","id":"exemples-simples","chapter":"35 Diagrammes et schémas","heading":"Exemples simples","text":"Vous trouverez ci-dessous deux exemples simplesUn exemple très minimal :Un exemple avec un contexte de santé publique un peu plus appliqué :","code":"\n## Un tracé minimal\nDiagrammeR::grViz(\"digraph {\n  \ngraph[layout = dot, rankdir = LR]\n\na\nb\nc\n\na -> b -> c\n}\")\n# Toutes les instructions se trouvent dans une grande chaîne de caractères\n# 'digraph' signifie 'graphique directionnel', puis le nom du graphique \n\n# déclaration du graphique, déclaration des noueds, forme et largeur de noueds, noms des noeuds, bords ou contours\n  #######\n  #################\n\ngrViz(\"    \ndigraph surveillance_diagram { \n  \n  \n  graph [layout = dot,\n         rankdir = TB,\n         overlap = true,\n         fontsize = 10]\n  \n  \n  node [shape = circle, \n       fixedsize = true\n       width = 1.3]               \n  \n  Primary\n  Secondary\n  Tertiary\n\n  \n  Primary -> Secondary [label = ' transfert de cas']\n  Secondary -> Tertiary [label = ' transfert de cas']\n}\n\")"},{"path":"diagrams.html","id":"syntaxe","chapter":"35 Diagrammes et schémas","heading":"Syntaxe","text":"Syntaxe de baseLes noms de nouds, ou les déclarations de bords, peuvent être séparés par des espaces, des points-virgules ou des nouvelles lignes.Direction du rangUn graphique peut être réorienté pour se déplacer de gauche à droite en ajustant l’argument rankdir dans la déclaration du graphique. Le défaut est TB (top--bottom; de haut en bas), mais il peut être LR (left--right, gauche-à-droite), ou l’inverse\n(RL,BT).Noms de noudsLes noms de noeuds peuvent être des mots simples, comme dans l’exemple ci-dessus. Pour utiliser des noms de plusieurs mots ou des caractères spéciaux (par exemple, parenthèses, tirets), placez le nom du noud entre guillemets simples (’ ’). Il peut être plus facile d’avoir un nom de nœud court et d’attribuer un label, comme indiqué ci-dessous entre crochets [ ]. Si vous voulez avoir une nouvelle ligne dans le nom du nœud, vous devez le faire via une étiquette. Utilisez \\n dans l’étiquette du nœud entre guillemets simples, comme indiqué ci-dessous.Sous-groupes\nDans les déclarations des bords/contours, des sous-groupes peuvent être créés de chaque côté de le bords avec des crochets ({ }). Le bord s’applique alors à tous les nouds entre crochets. Ceci est un raccourci.Mise en pagedot (définir rankdir comme soit TB, LR, RL, ou BT)neatotwopicircoNoeuds - attributs modifiableslabel (texte, entre guillemets simples si plusieurs mots)fillcolor (plusieurs couleurs possibles)fontcoloralpha (transparence 0-1)shape (ellipse, ovale, diamant, ouf, texte en clair, point, carré, triangle)stylesidesperipheriesfixedsize (h x l)heightwidthdistortionpenwidth (largeur de la bordure de la forme)x (déplacement gauche/droite)y (déplacement haut/bas)fontnamefontsizeiconBords - attributs modifiablesarrowsizearrowhead (normal, box, crow, curve, diamond, dot, inv, none, tee, vee)arrowtaildir (direction, )style (pointillé, …)coloralphaheadport (texte devant la tête de la flèche)tailport (texte situé derrière la queue de flèche)fontnamefontsizefontcolor (couleur de la police)penwidth (largeur de la flèche)minlen (longueur minimale)Noms de couleurs : valeurs hexadécimales ou noms de couleurs ‘X11’, voir ici pour les détails sur X11","code":""},{"path":"diagrams.html","id":"exemples-complexes","chapter":"35 Diagrammes et schémas","heading":"Exemples complexes","text":"L’exemple ci-dessous développe le diagramme de surveillance, en ajoutant des noms de noeuds complexes, des bords groupées, des couleurs et un style spécifique.Groupements de sous-graphiquesPour regrouper les noeuds dans des clusters encadrés, placez-les dans le même sous-graphique nommé (subgraph name {}). Pour que chaque sous-graphe soit identifié dans une boîte de délimitation, commencez le nom du sous-graphique par “cluster”, comme le montrent les 4 boîtes ci-dessous.Formes des noudsL’exemple ci-dessous, emprunté à ce tutoriel, montre les formes de nouds appliquées et une abréviation pour les connexions de bords en série.","code":"\n# Toutes les instructions se trouvent dans une grande chaîne de caractères\n# 'digraph' signifie 'graphique directionnel', puis le nom du graphique \n# déclaration du graphique\n# disposition de haut en bas\n  #################\n# nouds (formes cercles)\n  #################\n  #bords et bord groupé\n\n\n\nDiagrammeR::grViz(\" \ndigraph surveillance_diagram { \n  \n  \n  graph [layout = dot,\n         rankdir = TB, \n         fontsize = 10]\n  \n\n  \n  node [shape = circle, \n       fixedsize = true\n       width = 1.3]                      \n  \n  Primary [label = 'Site Primaire'] \n  Secondary [label = 'Site Secondaire'] \n  Tertiary [label = 'Site Tertiaire'] \n  SC [label = 'Coordination de\\nla Surveillance',\n             fontcolor = darkgreen] \n\n\n  Primary -> Secondary [label = 'Transfert de cas',\n                          fontcolor = red,\n                          color = red]\n  Secondary -> Tertiary [label = 'Transfert de cas',\n                          fontcolor = red,\n                          color = red]\n  \n\n  {Primary Secondary Tertiary} -> SC [label = 'déclaration des cas',\n                                      fontcolor = darkgreen,\n                                      couleur = darkgreen,\n                                      style = dashed]\n}\n\")\nDiagrammeR::grViz(\"             # All instructions are within a large character string\ndigraph surveillance_diagram {  # 'digraph' means 'directional graph', then the graph name \n  \n  # graph statement\n  #################\n  graph [layout = dot,\n         rankdir = TB,            \n         overlap = true,\n         fontsize = 10]\n  \n  # nodes (circles)\n  #################\n  node [shape = circle,                  # shape = circle\n       fixedsize = true\n       width = 1.3]                      # width of circles\n  \n  subgraph cluster_passive {\n    Primary   [label = 'Site Primaire'] \n    Secondary [label = 'Site Secondaire'] \n    Tertiary  [label = 'Site Tertiaire'] \n    SC        [label = 'Coordination de\\nla Surveillance',\n               fontcolor = darkgreen] \n  }\n  \n  # nodes (boxes)\n  ###############\n  node [shape = box,                     # node shape\n        fontname = Helvetica]            # text font in node\n  \n  subgraph cluster_active {\n    Active [label = 'Surveillance\\nActive'] \n    HCF_active [label = 'HCF\\nRecherche Active']\n  }\n  \n  subgraph cluster_EBD {\n    EBS [label = 'Surveillance basée sur\\n les événements (SBE)'] \n    'Social Media'\n    Radio\n  }\n  \n  subgraph cluster_CBS {\n    CBS [label = 'Surveillance basée sur\\n les communautés(SBC)']\n    RECOs\n  }\n  \n  # edges\n  #######\n  {Primary Secondary Tertiary} -> SC [label = 'déclaration des cas']\n  Primary   -> Secondary [label = 'transfert de cas',\n                          fontcolor = red]\n  Secondary -> Tertiary [label = 'transfert de cas',\n                          fontcolor = red]\n  \n  HCF_active -> Active\n  \n  {'Social Media' Radio} -> EBS\n  \n  RECOs -> CBS\n}\n\")\n# définir les styles globaux des noeuds. Nous pouvons les remplacer dans la boîte si nous le souhaitons.\n# définitions des bords avec les ID des nouds\nDiagrammeR::grViz(\"digraph {\n\ngraph [layout = dot, rankdir = LR]\n\n\nnode [shape = rectangle, style = filled, fillcolor = Linen]\n\ndata1 [label = 'Dataframe 1', shape = folder, fillcolor = Beige]\ndata2 [label = 'Dataframe 2', shape = folder, fillcolor = Beige]\nprocess [label = 'Process \\n Data']\nstatistical [label = 'Analyse\\nStatistique'] \nresults [label= 'Résultats']\n\n\n{data1 data2} -> process -> statistical -> results\n}\")"},{"path":"diagrams.html","id":"sorties","chapter":"35 Diagrammes et schémas","heading":"Sorties","text":"Comment gérer et sauvegarder les sortiesLes résultats apparaîtront dans le volet de visualisation de RStudio, par défaut dans le coin inférieur droit, à côté de Files, Plots, Packages et Help.Pour exporter, vous pouvez “Enregistrer en tant qu’image” ou “Copier le presse-papiers” à partir de la Viewer. Le graphique s’ajustera à la taille spécifiée.","code":""},{"path":"diagrams.html","id":"figures-paramétrées","chapter":"35 Diagrammes et schémas","heading":"Figures paramétrées","text":"Voici une citation de ce tutoriel : https://mikeyharper.uk/flowcharts--r-using-diagrammer/“Figures paramétrées : L’un des grands avantages de la conception de figures dans R est que nous sommes en mesure de connecter les figures directement à notre analyse en lisant les valeurs R directement dans nos schemas de flux. Par exemple, supposons que vous ayez créé un processus de filtrage qui supprime les valeurs après chaque étape d’un processus, vous pouvez avoir une figure montrant le nombre de valeurs restantes dans l’ensemble de données après chaque étape de votre processus. Pour ce faire, vous pouvez utiliser le symbole @@X directement dans la figure, puis y faire référence dans le pied de page du graphique en utilisant [X] :, où X est un indice numérique unique.”Nous vous encourageons à revoir ce tutoriel si le paramétrage est quelque chose qui vous intéresse.","code":""},{"path":"diagrams.html","id":"diagrammes-alluvialsankey","chapter":"35 Diagrammes et schémas","heading":"35.3 Diagrammes Alluvial/Sankey","text":"","code":""},{"path":"diagrams.html","id":"chargement-des-paquets-8","chapter":"35 Diagrammes et schémas","heading":"Chargement des paquets","text":"Ce morceau de code montre le chargement des paquets nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire et le charge pour l’utiliser. Vous pouvez également charger les paquets installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les paquets R.Nous chargeons le paquet networkD3 pour produire le diagramme, et aussi tidyverse pour les étapes de préparation des données.","code":"\npacman::p_load(\n  networkD3,\n  tidyverse)"},{"path":"diagrams.html","id":"graphique-à-partir-dun-ensemble-de-données","chapter":"35 Diagrammes et schémas","heading":"Graphique à partir d’un ensemble de données","text":"Tracer les connexions dans un jeu de données. Nous démontrons ci-dessous l’utilisation de le package networkD3 sur le cas linelist. Voici un tutoriel en ligne.Nous commençons par obtenir le nombre de cas pour chaque combinaison unique de catégorie d’âge et d’hôpital. Pour plus de clarté, nous avons supprimé les valeurs dont la catégorie d’âge est manquante. Nous renommons également les colonnes hospital et age_cat en source et target respectivement. Ce seront les deux côtés du diagramme alluvial.L’ensemble de données ressemble maintenant à ceci :Maintenant, nous créons un jeu de données de tous les noeuds du diagramme, sous la colonne name. Il s’agit de toutes les valeurs de hospital et age_cat. Notez que nous nous assurons qu’elles sont toutes de classe caractères avant de les combiner, et ajustons les colonnes ID pour qu’elles soient des numeros au lieu d’étiquettes :Nous éditons le cadre de données links, que nous avons créé ci-dessus avec count(). Nous ajoutons deux colonnes numériques, IDsource et IDtarget, qui reflèteront/créeront réellement les liens entre les noeuds. Ces colonnes contiendront les numéros numéros de rangs (position) des noeuds de source et de target. soustrait 1 pour que ces numéros de position commencent à 0 (et pas à 1).Le jeu de données des liens ressemble maintenant à ceci :Tracez maintenant le diagramme de Sankey avec sankeyNetwork(). Vous pouvez en savoir plus sur chaque argument en exécutant ?sankeyNetwork dans la console. Notez que si vous ne définissiez pas iterations = 0, l’ordre de vos noeuds ne serait pas celui attendu.Voici un exemple où le résultat du patient est également inclus. Notez que dans l’étape de préparation des données, nous devons calculer le nombre de cas entre l’âge et l’hôpital, et séparément entre l’hôpital et le résultat - puis lier tous ces comptes ensemble avec bind_rows().https://www.displayr.com/sankey-diagrams-r/","code":"\n# comptes par hôpital et par catégorie d'âge\nlinks <- linelist %>% \n  drop_na(age_cat) %>% \n  select(hospital, age_cat) %>%\n  count(hospital, age_cat) %>% \n  rename(source = hospital,\n         target = age_cat)\n# Les noms uniques des noeuds\nnodes <- data.frame(\n  name=c(as.character(links$source), as.character(links$target)) %>% \n    unique()\n  )\n\nnodes # imprimer##                                    name\n## 1                      Central Hospital\n## 2                     Military Hospital\n## 3                               Missing\n## 4                                 Other\n## 5                         Port Hospital\n## 6  St. Mark's Maternity Hospital (SMMH)\n## 7                                   0-4\n## 8                                   5-9\n## 9                                 10-14\n## 10                                15-19\n## 11                                20-29\n## 12                                30-49\n## 13                                50-69\n## 14                                  70+\n# correspond aux nombres, pas aux noms\nlinks$IDsource <- match(links$source, nodes$name)-1 \nlinks$IDtarget <- match(links$target, nodes$name)-1\n# graphique\n######\np <- sankeyNetwork(\n  Links = links,\n  Nodes = nodes,\n  Source = \"IDsource\",\n  Target = \"IDtarget\",\n  Value = \"n\",\n  NodeID = \"name\",\n  units = \"TWh\",\n  fontSize = 12,\n  nodeWidth = 30,\n  iterations = 0) # Assurez-vous que l'ordre des noeuds est celui des données.\np\n# Nombre de cas par hôpital et par catégorie d'âge\nage_hosp_links <- linelist %>% \n  drop_na(age_cat) %>% \n  select(hospital, age_cat) %>%\n  count(hospital, age_cat) %>% \n  rename(source = age_cat, \n         target = hospital)\n\nhosp_out_links <- linelist %>% \n    drop_na(age_cat) %>% \n    select(hospital, outcome) %>% \n    count(hospital, outcome) %>% \n    rename(source = hospital, \n           target = outcome)\n\n# combiner les liens\nlinks <- bind_rows(age_hosp_links, hosp_out_links)\n\n# Les noms uniques des noeuds\nnodes <- data.frame(\n  name=c(as.character(links$source), as.character(links$target)) %>% \n    unique()\n  )\n\n# Créer des numéros d'identification\nlinks$IDsource <- match(links$source, nodes$name)-1 \nlinks$IDtarget <- match(links$target, nodes$name)-1\n\n# graphique\n######\np <- sankeyNetwork(Links = links,\n                   Nodes = nodes,\n                   Source = \"IDsource\",\n                   Target = \"IDtarget\",\n                   Value = \"n\",\n                   NodeID = \"name\",\n                   units = \"TWh\",\n                   fontSize = 12,\n                   nodeWidth = 30,\n                   iterations = 0)\np"},{"path":"diagrams.html","id":"chronologie-des-événements","chapter":"35 Diagrammes et schémas","heading":"35.4 Chronologie des événements","text":"Pour faire une timeline montrant des événements spécifiques, vous pouvez utiliser le paquet vistime.Voir cette vignetteVoici l’ensemble de données d’événements avec lequel nous commençons :","code":"\n# charger le paquet\npacman::p_load(vistime, # créer la ligne de temps\n               plotly # pour la visualisation interactive\n               )\np <- vistime(data) # appliquer vistime\n\nlibrary(plotly)\n\n# étape 1 : transformation en liste\npp <- plotly_build(p)\n\n# étape 2 : taille des marqueurs\nfor(i in 1:length(pp$x$data)){\n  if(pp$x$data[[i]]$mode == \"markers\") pp$x$data[[i]]$marker$size <- 10\n}\n\n# étape 3 : taille du texte\nfor(i in 1:length(pp$x$data)){\n  if(pp$x$data[[i]]$mode == \"text\") pp$x$data[[i]]$textfont$size <- 10\n}\n\n\n# étape 4 : position du texte\nfor(i in 1:length(pp$x$data)){\n  if(pp$x$data[[i]]$mode == \"text\") pp$x$data[[i]]$textposition <- \"right\"\n}\n\n#imprimer\npp"},{"path":"diagrams.html","id":"dags","chapter":"35 Diagrammes et schémas","heading":"35.5 DAGs","text":"Vous pouvez construire un DAG manuellement en utilisant le paquet DiagammeR et le langage DOT comme décrit ci-dessus.Alternativement, il existe des paquets comme ggdag et daggity.Introduction aux DAGs - vignette ggdagInférence causale avec les dags dans R","code":""},{"path":"diagrams.html","id":"ressources-19","chapter":"35 Diagrammes et schémas","heading":"35.6 Ressources","text":"Une grande partie de ce qui précède concernant le langage DOT est adaptée du tutoriel sur ce site.Un autre tutoriel sur DiagammeR plus approfondi.Ici, un page sur les diagrammes de Sankey.","code":""},{"path":"combination_analysis.html","id":"combination_analysis","chapter":"36 Analyse des combinaisons","heading":"36 Analyse des combinaisons","text":"Cette analyse représente la fréquence des différentes combinaisons de valeurs/réponses. Dans cet exemple, nous traçons la fréquence à laquelle les cas ont présenté diverses combinaisons de symptômes.Cette analyse est aussi souvent appelée :“Analyse des réponses multiples”“Analyse des ensembles”“Analyse des combinaisons”Dans l’exemple de graphique ci-dessus, cinq symptômes sont représentés. Sous chaque barre verticale se trouve une ligne et des points indiquant la combinaison de symptômes reflétée par la barre ci-dessus. À droite, des barres horizontales reflètent la fréquence de chaque symptôme individuel.La première méthode que nous montrons utilise le paquet ggupset, et la seconde utilise le paquet UpSetR.","code":""},{"path":"combination_analysis.html","id":"préparation-19","chapter":"36 Analyse des combinaisons","heading":"36.1 Préparation","text":"","code":""},{"path":"combination_analysis.html","id":"chargement-des-paquets-9","chapter":"36 Analyse des combinaisons","heading":"Chargement des paquets","text":"Ce chunk de code montre le chargement des paquets nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire et le charge pour l’utiliser. Vous pouvez également charger les paquets installés avec library() de base R. Voir la page sur R - les bases pour plus d’informations sur les paquets R.","code":"\npacman::p_load(\n  tidyverse, # gestion et visualisation de données\n  UpSetR,    # paquet spécial pour les graphiques combinés\n  ggupset)   # paquet spécial pour les tracés combinés"},{"path":"combination_analysis.html","id":"importer-les-données-3","chapter":"36 Analyse des combinaisons","heading":"Importer les données","text":"Pour commencer, nous importons la linelist nettoyée des cas d’une épidémie d’Ebola simulée. Si vous voulez suivre, cliquez pour télécharger la linelist “propre” (en tant que fichier .rds). Importez des données avec la fonction import() du paquet rio (elle gère de nombreux types de fichiers comme .xlsx, .csv, .rds - voir la page Importer et exporter des données pour plus de détails).Cette linelist comprend cinq variables “oui/non” sur les symptômes déclarés. Nous devrons transformer un peu ces variables pour utiliser le paquet ggupset afin de réaliser notre tracé. Visualisez les données (faites défiler vers la droite pour voir les variables de symptômes).","code":"\n# importer la liste de cas linelist \nlinelist_sym <- import(\"linelist_cleaned.rds\")"},{"path":"combination_analysis.html","id":"re-formatage-des-valeurs","chapter":"36 Analyse des combinaisons","heading":"Re-formatage des valeurs","text":"Pour s’aligner sur le format attendu par ggupset, nous convertissons les “yes” (“oui”) et “” (“non”) en nom de symptôme réel, en utilisant case_when() de dplyr. Si “non”, nous mettons la valeur en blanc, donc les valeurs sont soit NA ou le symptôme.Maintenant, nous faisons deux dernières colonnes :Concaténation (collage) de tous les symptômes du patient (une colonne de caractères)Convertir la colonne ci-dessus en classe list, afin qu’elle puisse être acceptée par ggupset pour faire le graphe.Voir la page sur Caractères et chaînes de caractères pour en savoir plus sur la fonction unite() de stringr.Visualisez les nouvelles données. Notez les deux colonnes vers l’extrémité droite - les valeurs combinées collées, et la liste","code":"\n# crée une colonne avec les symptômes nommés, séparés par des points-virgules\nlinelist_sym_1 <- linelist_sym %>% \n  \n  # convertissez les valeurs \"oui\" et \"non\" dans le nom du symptôme lui-même\n  mutate(fever = ifelse(fever == \"yes\", \"fever\", NA), \n       chills = ifelse(chills == \"yes\", \"chills\", NA),\n       cough = ifelse(cough == \"yes\", \"cough\", NA),\n       aches = ifelse(aches == \"yes\", \"aches\", NA),\n       vomit = ifelse(vomit == \"yes\", \"vomit\", NA))\nlinelist_sym_1 <- linelist_sym_1 %>% \n  unite(col = \"all_symptoms\",\n        c(fever, chills, cough, aches, vomit), \n        sep = \" ; \",\n        remove = TRUE,\n        na.rm = TRUE) %>% \n  mutate(\n    # Faites une copie de la colonne all_symptoms, mais de la classe \"list\" (qui est nécessaire pour utiliser ggupset() à l'étape suivante).\n    all_symptoms_list = as.list(strsplit(all_symptoms, \" ; \"))\n    )"},{"path":"combination_analysis.html","id":"ggupset","chapter":"36 Analyse des combinaisons","heading":"36.2 ggupset","text":"Charger le paquetCréez le graphique. Nous commençons par un ggplot() et un geom_bar(), mais ensuite nous ajoutons la fonction spéciale scale_x_upset() du ggupset.De plus amples informations sur ggupset peuvent être trouvées en ligne ou hors ligne dans la documentation du paquet dans votre onglet d’aide RStudio ?ggupset.","code":"\npacman::p_load(ggupset)\nggplot(\n  data = linelist_sym_1,\n  mapping = aes(x = all_symptoms_list)) +\ngeom_bar() +\nscale_x_upset(\n  reverse = FALSE,\n  n_intersections = 10,\n  sets = c(\"fever\", \"chills\", \"cough\", \"aches\", \"vomit\"))+\nlabs(\n  title = \"Signes et symptômes\",\n  subtitle = \"Les 10 combinaisons les plus fréquentes de signes et de symptômes\",\n  caption = \"Caption ici\",\n  x = \"Combinaison de symptômes\",\n  y = \"Fréquence dans l'ensemble de données\")"},{"path":"combination_analysis.html","id":"upsetr","chapter":"36 Analyse des combinaisons","heading":"36.3 UpSetR","text":"Le paquet UpSetR permet de personnaliser davantage le tracé, mais il peut être plus difficile à exécuter :Chargez le paquetNettoyage des donnéesNous devons convertir les valeurs des symptômes de la linelist en 1 / 0.Si vous êtes intéressé par une commande plus efficace, vous pouvez profiter de la fonction +(), qui convertit les 1 et les 0 en fonction d’une déclaration logique. Cette commande utilise la fonction across() pour modifier plusieurs colonnes à la fois (pour en savoir plus, lisez la section Nettoyage des données et des fonctions de base).Maintenant, faites le graphique en utilisant la fonction personnalisée upset() - en utilisant seulement les colonnes de symptômes. Vous devez désigner les “ensembles” à comparer (les noms des colonnes de symptômes). Vous pouvez aussi utiliser nsets = et order.= \"freq\" pour n’afficher que les X combinaisons les plus importantes.","code":"\npacman::p_load(UpSetR)\nlinelist_sym_2 <- linelist_sym %>% \n  \n  # convertissez les valeurs \"oui\" et \"non\" dans le nom du symptôme lui-même\n     mutate(fever = ifelse(fever == \"yes\", 1, 0), \n            chills = ifelse(chills == \"yes\", 1, 0),\n            cough = ifelse(cough == \"yes\", 1, 0),\n            aches = ifelse(aches == \"yes\", 1, 0),\n            vomit = ifelse(vomit == \"yes\", 1, 0))\n# convertissez \"oui\" et \"non\" a 1 et 0\nlinelist_sym_2 <- linelist_sym %>% \n  \n  mutate(across(c(fever, chills, cough, aches, vomit), .fns = ~+(.x == \"yes\")))\n# Créer le graphique\nUpSetR::upset(\n  select(linelist_sym_2, fever, chills, cough, aches, vomit),\n  sets = c(\"fever\", \"chills\", \"cough\", \"aches\", \"vomit\"),\n  order.by = \"freq\",\n  sets.bar.color = c(\"blue\", \"red\", \"yellow\", \"darkgreen\", \"orange\"), # couleurs optionnelles\n  empty.intersections = \"on\",\n  # nsets = 3,\n  number.angles = 0,\n  point.size = 3.5,\n  line.size = 2, \n  mainbar.y.label = \"Symptoms Combinations\",\n  sets.x.label = \"Patients with Symptom\")"},{"path":"combination_analysis.html","id":"ressources-20","chapter":"36 Analyse des combinaisons","heading":"36.4 Ressources","text":"La page github de UpSetRUne version Shiny App - vous pouvez télécharger vos propres données*documentation - difficile à interpréter","code":""},{"path":"transmission_chains.html","id":"transmission_chains","chapter":"37 Chaînes de transmission","heading":"37 Chaînes de transmission","text":"","code":""},{"path":"transmission_chains.html","id":"aperçu-4","chapter":"37 Chaînes de transmission","heading":"37.1 Aperçu","text":"L’outil principal pour manipuler, analyser, et visualiser les chaînes de transmission et les données de recherche de contact est le paquet epicontacts, développé par RECON. Essayez le graphique interactif ci-dessous en passant la souris sur les noeuds pour obtenir plus d’informations et en cliquant dessus pour surligner les cas descendants.","code":""},{"path":"transmission_chains.html","id":"préparation-20","chapter":"37 Chaînes de transmission","heading":"37.2 Préparation","text":"","code":""},{"path":"transmission_chains.html","id":"charger-les-paquets-1","chapter":"37 Chaînes de transmission","heading":"Charger les paquets","text":"Commencez par charger les paquets standards nécessaires à l’importation et à la manipulation des données. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire et le charge pour l’utiliser. Vous pouvez également charger des paquets avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les paquets R.Vous aurez besoin de la version de développement de epicontacts, qui peut être installée de github en utilisant la fonction p_install_github() de pacman. Vous n’avez besoin d’exécuter cette commande ci-dessous qu’une seule fois, et pas à chaque fois que vous utilisez le paquet (par la suite, vous pouvez utiliser p_load() comme d’habitude).","code":"\npacman::p_load(\n   rio, # Importation de fichiers\n   here, # Localisation de fichiers\n   tidyverse, # Gestion des données + graphiques ggplot2\n   remotes # Installation de paquets depuis github\n)\npacman::p_install_gh(\"reconhub/epicontacts@timeline\")"},{"path":"transmission_chains.html","id":"importer-les-données-4","chapter":"37 Chaînes de transmission","heading":"Importer les données","text":"Nous importons le jeu de données des cas d’une épidémie d’Ebola simulée. Si vous souhaitez télécharger les données pour suivre le code, consultez les instructions de la page Télécharger le manuel et les données. Le jeu de données est importé à l’aide de la fonction import() du paquet rio. Voir la page Importation et exportation pour connaître les différentes methodes d’importer des données.Les 50 premières lignes de la linelist sont affichées ci-dessous. Les colonnes case_id, generation, infector, et source sont particulièrement intéressantes.","code":"\n# Importez la liste de cas\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"transmission_chains.html","id":"création-dun-objet-epicontacts","chapter":"37 Chaînes de transmission","heading":"Création d’un objet epicontacts","text":"Nous devons ensuite créer un objet epicontacts, qui nécessite deux types de données:une linelist documentant les cas où les colonnes sont des variables et les lignes correspondent à des cas uniques.une liste de bords définissant les liens entre les cas sur la base de leurs identifiants uniques (il peut s’agir de contacts,\ndes événements de transmission, etc.)Comme nous avons déjà une linelist, il nous suffit de créer une liste de bord entre les cas, plus précisément entre leurs ID. Nous pouvons extraire les liens de transmission de la linelist en liant la colonne infector avec la colonne case_id. ce stade, nous pouvons également ajouter des “propriétés de bords”, c’est-à-dire toute variable décrivant le lien entre les deux cas, mais pas les cas eux-mêmes. Pour illustration, nous allons ajouter une variable location décrivant l’emplacement de l’événement de transmission, et une variable duration (durée) décrivant la durée du contact en jours.Dans le code ci-dessous, la fonction transmute de le paquet dplyr est similaire à mutate, sauf qu’elle ne conserve que les colonnes que nous avons spécifiées dans la fonction. La fonction drop_na enlevera toutes les lignes où les colonnes spécifiées ont une valeur NA. Dans ce cas, nous ne voulons conserver que les lignes où l’infecteur est connu.Nous pouvons maintenant créer l’objet epicontacts en utilisant la fonction make_epicontacts . Nous devons spécifier quelle colonne de la linelist correspond à l’identifiant unique du cas, ainsi que les colonnes des contacts qui pointent vers les identifiants uniques des cas impliqués dans chaque lien. Ces liens sont directionnels en le sens que l’infection va de l’infecteur à le cas, les arguments et en conséquence. Nous définissons donc l’argument directed (direction) à TRUE (VRAI), ce qui affectera les opérations futures.En examinant les objets epicontacts, peut voir que la colonne case_id de la linelist été renommée à id et que les colonnes case_id et infector des contacts ont été renommées à et . Cela garantit la cohérence dans le traitement, visualisation et analyse de l’objet epicontacts.","code":"\n## générer des contacts\ncontacts <- linelist %>%\n  transmute(\n    infector = infector,\n    case_id = case_id,\n    location = sample(c(\"Community\", \"Nosocomial\"), n(), TRUE),\n    duration = sample.int(10, n(), TRUE)\n  ) %>%\n  drop_na(infector)\n## générer un objet epicontacts\nepic <- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts,\n  id = \"case_id\",\n  from = \"infector\",\n  to = \"case_id\",\n  directed = TRUE\n)\n## visualiser l'objet epicontacts\nepic## \n## /// Epidemiological Contacts //\n## \n##   // class: epicontacts\n##   // 5,888 cases in linelist; 3,800 contacts; directed \n## \n##   // linelist\n## \n## # A tibble: 5,888 × 30\n##    id     generation date_infection date_onset date_hospitalisation date_outcome outcome\n##    <chr>       <dbl> <date>         <date>     <date>               <date>       <chr>  \n##  1 5fe599          4 2014-05-08     2014-05-13 2014-05-15           NA           <NA>   \n##  2 8689b7          4 NA             2014-05-13 2014-05-14           2014-05-18   Recover\n##  3 11f8ea          2 NA             2014-05-16 2014-05-18           2014-05-30   Recover\n##  4 b8812a          3 2014-05-04     2014-05-18 2014-05-20           NA           <NA>   \n##  5 893f25          3 2014-05-18     2014-05-21 2014-05-22           2014-05-29   Recover\n##  6 be99c8          3 2014-05-03     2014-05-22 2014-05-23           2014-05-24   Recover\n##  7 07e3e8          4 2014-05-22     2014-05-27 2014-05-29           2014-06-01   Recover\n##  8 369449          4 2014-05-28     2014-06-02 2014-06-03           2014-06-07   Death  \n##  9 f393b4          4 NA             2014-06-05 2014-06-06           2014-06-18   Recover\n## 10 1389ca          4 NA             2014-06-05 2014-06-07           2014-06-09   Death  \n## # ℹ 5,878 more rows\n## # ℹ 23 more variables: gender <chr>, age <dbl>, age_unit <chr>, age_years <dbl>,\n## #   age_cat <fct>, age_cat5 <fct>, hospital <chr>, lon <dbl>, lat <dbl>,\n## #   infector <chr>, source <chr>, wt_kg <dbl>, ht_cm <dbl>, ct_blood <dbl>,\n## #   fever <chr>, chills <chr>, cough <chr>, aches <chr>, vomit <chr>, temp <dbl>,\n## #   time_admission <chr>, bmi <dbl>, days_onset_hosp <dbl>\n## \n##   // contacts\n## \n## # A tibble: 3,800 × 4\n##    from   to     location   duration\n##    <chr>  <chr>  <chr>         <int>\n##  1 f547d6 5fe599 Community         6\n##  2 f90f5f b8812a Nosocomial        1\n##  3 11f8ea 893f25 Community         2\n##  4 aec8ec be99c8 Nosocomial        8\n##  5 893f25 07e3e8 Nosocomial        3\n##  6 133ee7 369449 Nosocomial        5\n##  7 996f3a 2978ac Community        10\n##  8 133ee7 57a565 Community         7\n##  9 37a6f6 fc15ef Community        10\n## 10 9f6884 2eaa9a Community         3\n## # ℹ 3,790 more rows"},{"path":"transmission_chains.html","id":"manipulation","chapter":"37 Chaînes de transmission","heading":"37.3 Manipulation","text":"","code":""},{"path":"transmission_chains.html","id":"sous-ensemble","chapter":"37 Chaînes de transmission","heading":"Sous-ensemble","text":"La méthode subset() pour les objets epicontacts permet, entre autres, de filtrer les réseaux en fonction des propriétés de la linelinst (“attributs de noeuds”) et de la jeu de données de contacts (“attributs de bords”).Ces valeurs doivent être passées comme des listes nommées à l’argument respectif. Par exemple, dans le code ci-dessous, nous ne gardons dans la linelist que les cas masculins qui ont une date d’infection entre avril et juillet 2014 (les dates sont spécifiées en tant que plages) et des liens de transmission qui ont eu lieu dans l’hôpital.Nous pouvons utiliser la fonction thin pour filtrer la linelist afin d’inclure les cas trouvés dans les contacts en définissant l’argument = \"linelist\", ou pour filtrer les contacts pour inclure les cas qui sont trouvés dans la linelist en définissant l’argument = \"contacts\". Dans le code ci-dessous, nous filtrons davantage l’objet epicontacts pour ne garder que les liens de transmission impliquant les cas masculins infectés entre avril et juillet que nous avons filtrés ci-dessus. Nous pouvons voir que seulement deux liens de transmission correspondent à cette spécification.Les réseaux peuvent être élagués pour n’inclure que les composants qui sont connectés à certains noeuds. L’argument cluster_id\nprend un vecteur d’identifiants de cas et renvoie la linelist des individus qui sont liés, directement ou indirectement, à ces IDs. Dans le code ci-dessous, nous pouvons voir qu’un total de 13 cas de la linelist sont impliqués dans les clusters contenant 2ae019 et 71577a.La méthode subset() pour les objets epicontacts permet aussi de filtrer par la taille des cluster en utilisant les arguments cs, cs_min et cs_max. Dans le code ci-dessous, nous gardons seulement les cas liés à des clusters de 10 cas ou plus, et nous pouvons voir que 271 cas de la linelist sont impliqués dans de tels clusters.","code":"\nsub_attributes <- subset(\n  epic,\n  node_attribute = list(\n    gender = \"m\",\n    date_infection = as.Date(c(\"2014-04-01\", \"2014-07-01\"))\n  ), \n  edge_attribute = list(location = \"Nosocomial\")\n)\nsub_attributes## \n## /// Epidemiological Contacts //\n## \n##   // class: epicontacts\n##   // 69 cases in linelist; 1,866 contacts; directed \n## \n##   // linelist\n## \n## # A tibble: 69 × 30\n##    id     generation date_infection date_onset date_hospitalisation date_outcome outcome\n##    <chr>       <dbl> <date>         <date>     <date>               <date>       <chr>  \n##  1 5fe599          4 2014-05-08     2014-05-13 2014-05-15           NA           <NA>   \n##  2 893f25          3 2014-05-18     2014-05-21 2014-05-22           2014-05-29   Recover\n##  3 2978ac          4 2014-05-30     2014-06-06 2014-06-08           2014-06-15   Death  \n##  4 57a565          4 2014-05-28     2014-06-13 2014-06-15           NA           Death  \n##  5 fc15ef          6 2014-06-14     2014-06-16 2014-06-17           2014-07-09   Recover\n##  6 99e8fa          7 2014-06-24     2014-06-28 2014-06-29           2014-07-09   Recover\n##  7 f327be          6 2014-06-14     2014-07-12 2014-07-13           2014-07-14   Death  \n##  8 90e5fe          5 2014-06-18     2014-07-13 2014-07-14           2014-07-16   <NA>   \n##  9 a47529          5 2014-06-13     2014-07-17 2014-07-18           2014-07-26   Death  \n## 10 da8ecb          5 2014-06-20     2014-07-18 2014-07-20           2014-08-01   <NA>   \n## # ℹ 59 more rows\n## # ℹ 23 more variables: gender <chr>, age <dbl>, age_unit <chr>, age_years <dbl>,\n## #   age_cat <fct>, age_cat5 <fct>, hospital <chr>, lon <dbl>, lat <dbl>,\n## #   infector <chr>, source <chr>, wt_kg <dbl>, ht_cm <dbl>, ct_blood <dbl>,\n## #   fever <chr>, chills <chr>, cough <chr>, aches <chr>, vomit <chr>, temp <dbl>,\n## #   time_admission <chr>, bmi <dbl>, days_onset_hosp <dbl>\n## \n##   // contacts\n## \n## # A tibble: 1,866 × 4\n##    from   to     location   duration\n##    <chr>  <chr>  <chr>         <int>\n##  1 f90f5f b8812a Nosocomial        1\n##  2 aec8ec be99c8 Nosocomial        8\n##  3 893f25 07e3e8 Nosocomial        3\n##  4 133ee7 369449 Nosocomial        5\n##  5 4802b1 bbfa93 Nosocomial       10\n##  6 8e104d ddddee Nosocomial        2\n##  7 ab634e 99e8fa Nosocomial        4\n##  8 b799eb bc2adf Nosocomial       10\n##  9 894024 e56412 Nosocomial       10\n## 10 a2086d a47529 Nosocomial        1\n## # ℹ 1,856 more rows\nsub_attributes <- thin(sub_attributes, what = \"contacts\")\nnrow(sub_attributes$contacts)## [1] 5\nsub_id <- subset(epic, cluster_id = c(\"2ae019\", \"71577a\"))\nnrow(sub_id$linelist)## [1] 13\nsub_cs <- subset(epic, cs_min = 10)\nnrow(sub_cs$linelist)## [1] 271"},{"path":"transmission_chains.html","id":"accéder-les-ids","chapter":"37 Chaînes de transmission","heading":"Accéder les IDs","text":"La fonction get_id() récupère les informations sur les IDs des cas dans les\ndonnées, et peut être paramétrée comme la suite:linelist : IDs dans les données de la linelistcontacts : IDs dans la jeu de données des contacts (“” et “” combinés): IDs dans la colonne “” de la base de données des contacts.: IDs dans la colonne “” du jeu de données des contactsall : IDs qui apparaissent n’importe où dans l’un ou l’autre des jeu de données.common : IDs qui apparaissent à la fois dans la jeu de données des contacts et dans la linelist.Par exemple, quels sont les dix premiers ID dans la jeu de données des contacts ?Combien d’identifiants sont trouvés à la fois dans la linelist et dans les contacts ?","code":"\ncontacts_ids <- get_id(epic, \"contacts\")\nhead(contacts_ids, n = 10)##  [1] \"f547d6\" \"f90f5f\" \"11f8ea\" \"aec8ec\" \"893f25\" \"133ee7\" \"996f3a\" \"37a6f6\" \"9f6884\"\n## [10] \"4802b1\"\nlength(get_id(epic, \"common\"))## [1] 4352"},{"path":"transmission_chains.html","id":"visualisation","chapter":"37 Chaînes de transmission","heading":"37.4 Visualisation","text":"","code":""},{"path":"transmission_chains.html","id":"graphique-de-base","chapter":"37 Chaînes de transmission","heading":"Graphique de base","text":"Toutes les visualisations des objets epicontacts sont gérées par la fonction plot. Nous allons d’abord filtrer l’objet epicontacts pour n’inclure que les cas ayant une date d’apparition en juin 2014, en utilisant la fonction subset, et filtrer seulement les contacts liés à ces cas à l’aide de la fonction thin.Nous pouvons ensuite créer le graphique interactif de base très simplement comme suit :Vous pouvez déplacer les noeuds en les faisant glisser, les survoler pour obtenir plus d’informations et cliquer dessus pour subligner les cas connectés.Il existe un grand nombre d’arguments pour modifier ce graphique. Nous allons couvrir les principaux ici, mais consultez la documentation via ?vis_epicontacts (la fonction appelée lors de l’utilisation de plot sur un objet epicontacts) pour obtenir une description complète des arguments de la fonction.","code":"\n## sous-ensemble objet epicontacts\nsub <- epic %>%\n  subset(\n    node_attribute = list(date_onset = c(as.Date(c(\"2014-06-30\", \"2014-06-01\"))))\n  ) %>%\n thin(\"contacts\")\n## tracer l'objet epicontacts\nplot(\n  sub,\n  width = 700,\n  height = 700\n)"},{"path":"transmission_chains.html","id":"visualiser-les-attributs-des-noeuds","chapter":"37 Chaînes de transmission","heading":"Visualiser les attributs des noeuds","text":"La couleur, la forme et la taille d’un noeud peuvent être associées à une colonne specifiée de la linelist, en utilisant les arguments node_color, node_shape et node_size. Ceci est similaire à la syntaxe aes de ggplot2.Les couleurs, formes et tailles spécifiques des noeuds peuvent être spécifiées comme suit :Couleurs via l’argument col_pal, soit en fournissant une liste de noms pour la spécification manuelle de chaque couleur comme fait ci-dessous, ou en fournissant une fonction de palette de couleurs, telle que colorRampPalette(c(\"black\", \"red\", \"orange\")) fournira un gradient de couleurs entre les trois spécifiées.Couleurs via l’argument col_pal, soit en fournissant une liste de noms pour la spécification manuelle de chaque couleur comme fait ci-dessous, ou en fournissant une fonction de palette de couleurs, telle que colorRampPalette(c(\"black\", \"red\", \"orange\")) fournira un gradient de couleurs entre les trois spécifiées.Shapes en passant une liste nommée à l’argument shapes, et en spécifiant une forme pour chaque élément unique dans la colonne de la linelist spécifiée avec l’argument node_shape. Voir codeawesome pour les formes disponibles.Shapes en passant une liste nommée à l’argument shapes, et en spécifiant une forme pour chaque élément unique dans la colonne de la linelist spécifiée avec l’argument node_shape. Voir codeawesome pour les formes disponibles.Taille en passant une gamme de taille des noeuds à l’argument size_range.Taille en passant une gamme de taille des noeuds à l’argument size_range.Voici un exemple, où la couleur représente le résultat, la forme le sexe et la taille l’âge :","code":"\nplot(\n  sub, \n  node_color = \"outcome\",\n  node_shape = \"gender\",\n  node_size = \"age\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  shapes = c(f = \"female\", m = \"male\"),\n  size_range = c(40, 60),\n  height = 700,\n  width = 700\n)"},{"path":"transmission_chains.html","id":"visualisation-des-attributs-de-bords","chapter":"37 Chaînes de transmission","heading":"Visualisation des attributs de bords","text":"La couleur, la largeur et le type de ligne de le bords peuvent être associés à une colonne du jeu de données contacts en utilisant les arguments edge_color, edge_width et edge_linetype, comme la suite:Couleurs via l’argument edge_col_pal, de la même manière que pour col_pal.Couleurs via l’argument edge_col_pal, de la même manière que pour col_pal.Largeurs en passant une gamme de taille des noeuds à l’argument width_range.Largeurs en passant une gamme de taille des noeuds à l’argument width_range.Voici un exemple :","code":"\nplot(\n  sub, \n  node_color = \"outcome\",\n  node_shape = \"gender\",\n  node_size = \"age\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  shapes = c(f = \"female\", m = \"male\"),\n  size_range = c(40, 60),\n  edge_color = 'location',\n  edge_linetype = 'location',\n  edge_width = 'duration',\n  #edge_col_pal = c(Community = \"orange\", Nosocomial = \"violet\"),\n  width_range = c(1, 3),\n  height = 700,\n  width = 700\n)"},{"path":"transmission_chains.html","id":"axe-temporel","chapter":"37 Chaînes de transmission","heading":"Axe temporel","text":"Nous pouvons également visualiser le réseau selon un axe temporel en faisant correspondre l’argument x_axis à une colonne de la linelist. Dans l’exemple ci-dessous, l’axe des x représente la date d’apparition des symptômes. Nous avons également spécifié l’argument arrow_size pour nous assurer que les flèches ne sont pas trop grandes, et nous avons défini label = FALSE pour rendre la figure moins encombrée.Il existe un grand nombre d’arguments supplémentaires pour spécifier d’avantage la façon dont ce réseau est visualisé le long d’un axe temporel, que vous pouvez vérifier via ?vis_temporal_interactive (la fonction appelée lors de l’utilisation de plot sur un objet epicontacts avec x_axis spécifié). Nous allons voir quelques examples ci-dessous.","code":"\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)"},{"path":"transmission_chains.html","id":"spécifier-la-forme-de-larbre-de-transmission","chapter":"37 Chaînes de transmission","heading":"Spécifier la forme de l’arbre de transmission","text":"Il y deux formes principales que l’arbre de transmission peut prendre, spécifiées en utilisant l’argument network_shape. La première est une forme branchée comme indiqué ci-dessus, où un bord droite relie deux noeuds connectes. C’est la représentation la plus intuitive mais elle peut donner lieu à des bords qui se chevauchent dans un réseau dense. La deuxième forme est le rectangle, qui produit un arbre ressemblant à une phylogénie. Par exemple :peut assigner à chaque noud de cas une position verticale unique en modifiant l’argument position_dodge. La position des cas non liés (c’est-à-dire sans contacts signalés) est spécifiée à l’aide de l’argument unlinked_pos.La position du noeud parent par rapport aux noeuds enfants peut être spécifiée en utilisant l’argument parent_pos. L’option par défaut est de placer le noeud parent au milieu, mais il peut être placé en bas (parent_pos = 'bottom') ou en haut (parent_pos = 'top').","code":"\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  position_dodge = TRUE,\n  unlinked_pos = \"bottom\",\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  hieght = 700,\n  width = 700\n)\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  parent_pos = \"top\",\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)"},{"path":"transmission_chains.html","id":"enregistrement-des-graphiques-et-des-figures","chapter":"37 Chaînes de transmission","heading":"Enregistrement des graphiques et des figures","text":"Vous pouvez enregistrer un graphique sous forme de fichier html interactif et autonome avec la fonction visSave du paquet VisNetwork :L’enregistrement de ces sorties de réseau sous forme d’image est malheureusement moins facile et nécessite d’enregistrer le fichier en tant que html et ensuite de faire une capture d’écran utilisant le paquet webshot. Dans le code ci-dessous, nous convertissons le fichier html sauvegardé ci-dessus en un PNG :","code":"\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  parent_pos = \"top\",\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n) %>%\n  visNetwork::visSave(\"network.html\")\nwebshot(url = \"network.html\", file = \"network.png\")"},{"path":"transmission_chains.html","id":"ligne-chronologique","chapter":"37 Chaînes de transmission","heading":"Ligne chronologique","text":"Vous pouvez également ajouter les chronologie de cas sur le réseau, qui sont représentées sur l’axe des x de chaque cas. Ceci peut être utilisé pour visualiser localisations des cas, par exemple, ou le temps jusqu’au résultat. Pour générer une ligne chronologique, nous devons créer un dataframe d’au moins trois colonnes indiquant l’ID du cas, la date de début de l’“événement” et la date de fin de l’“événement”. Vous pouvez également ajouter n’importe quel nombre d’autres colonnes qui peuvent ensuite être mappées aux noeuds et aux bords. Dans le code ci-dessous, nous générons une ligne chronologique allant de la date de l’apparition des symptômes à la date du résultat. Nous conservons les variables de résultat et d’hôpital que nous utilisons pour définir la forme et la couleur des noeuds. Notez que vous pouvez avoir plus qu’une ligne/événement chronologique par cas, par exemple si un cas etait transféré entre plusieurs hôpitaux.Nous passons ensuite l’élément chronologique à l’argument timeline. Nous pouvons faire correspondre les attributs de la ligne chronologique aux couleurs, formesm et tailles des noeuds de la même manière que celle définie dans les sections précédentes, sauf que nous avons deux noeuds: le noeud de début et de fin de chaque ligne chronologique qui ont des arguments distincts. Par exemple, tl_start_node_color définit quelle colonne de la ligne chronologique est mappée à la couleur du noeud de départ, tandis que tl_end_node_shape définit quelle colonne de la ligne chronologique est utilise pour la forme du noeud final. Nous pouvons également faire correspondre la couleur, la largeur, le type de ligne et les étiquettes de bord de la ligne chronologique via les arguments tl_edge_*.Voir ?vis_temporal_interactive (la fonction appelée de plot() avec un objet epicontacts) pour plus de détails. Chaque argument est également annoté dans le code ci-dessous :","code":"\n## générer une ligne chronologique\ntimeline <- linelist %>%\n  transmute(\n    id = case_id,\n    start = date_onset,\n    end = date_outcome,\n    outcome = outcome,\n    hospital = hospital\n  )\n## définir les formes\nshapes <- c(\n  f = \"female\",\n  m = \"male\",\n  Death = \"user-times\",\n  Recover = \"heartbeat\",\n  \"NA\" = \"question-circle\"\n)\n\n## définir les couleurs\ncolours <- c(\n  Death = \"firebrick\",\n  Recover = \"green\",\n  \"NA\" = \"grey\"\n)\n\n## faire un graphique\nplot(\n  sub,\n  ## coordonnée x maximale de la date d'apparition de la maladie\n  x_axis = \"date_onset\",\n  ## utiliser une forme de réseau rectangulaire\n  network_shape = \"rectangle\",\n  ## mappe les formes de noeuds de cas à la colonne de sexe\n  node_shape = \"gender\",\n  ## nous ne voulons pas mapper la couleur des noeuds à aucune colonne, cela est important car la valeur par défaut est de mapper à l'id du noeud, ce qui va perturber le schéma de couleurs\n  node_color = NULL,\n  ## définir la taille du noeud de cas à 30 (comme il ne s'agit pas d'un caractère, node_size n'est pas mappée à une colonne mais interprétée comme la taille réelle du noeud)\n  node_size = 30,\n  ## définir la largeur du lien de transmission à 4 (comme il ne s'agit pas d'un caractère, edge_width n'est pas affectée à une colonne mais interprétée comme la largeur réelle du bord)\n  edge_width = 4,\n  ## fournir l'objet ligne chronologique\n  timeline = timeline,\n  ## mappe la forme du noeud de fin à la colonne de résultat dans l'objet de ligne chronologique\n  tl_end_node_shape = \"outcome\",\n  ## définir la taille du noeud final à 15 (comme il ne s'agit pas d'un caractère, cet argument n'est pas associé à la colonne des résultats dans l'objet ligne  chronologique).\n  tl_end_node_size = 15,\n  ## mappez la couleur du bord de la ligne de temps à la colonne de l'hôpital\n  tl_edge_color = \"hospital\",\n  ## Définir la largeur du bord de la ligne de temps à 2 (comme il ne s'agit pas d'un caractère, cet argument n'est pas associé à la colonne de l'hôpital).\n  tl_edge_width = 2,\n  ## mappez les étiquettes des bords à la variable hospital\n  tl_edge_label = \"hospital\",\n  ## spécifier la forme pour chaque attribut de noeud (défini ci-dessus)\n  shapes = shapes,\n  ## spécifier la palette de couleurs (définie ci-dessus)\n  col_pal = colours,\n  ## définir la taille de la flèche à 0.5\n  arrow_size = 0.5,\n  ## utiliser deux colonnes dans la légende\n  legend_ncol = 2,\n  ## définir la taille de la police\n  font_size = 15,\n  ## définir le formatage des dates\n  date_labels = c(\"%d %b %Y\"),\n  ## ne pas tracer les étiquettes d'identification sous les noeuds\n  label = FALSE,\n  ## spécifier la hauteur\n  height = 1000,\n  ## spécifier la largeur\n  width = 1200,\n  ## assurez-vous que chaque noeud de cas a une coordonnée y unique, ceci est très important\n  ## lors de l'utilisation de lignes chronologiques, sinon les lignes chronologiques se chevauchant de différents cas\n  position_dodge = TRUE\n)## Warning in assert_timeline(timeline, x, x_axis): 5865 timeline row(s) removed as ID not\n## found in linelist or start/end date is NA"},{"path":"transmission_chains.html","id":"analyse","chapter":"37 Chaînes de transmission","heading":"37.5 Analyse","text":"","code":""},{"path":"transmission_chains.html","id":"résumé","chapter":"37 Chaînes de transmission","heading":"Résumé","text":"Nous pouvons obtenir un aperçu de certaines propriétés du réseau en utilisant la fonction summary.Par exemple, nous pouvons voir que seulement 57% des contacts ont les deux cas dans la linelist ; cela signifie que nous ne disposons pas de données de le linelist sur un nombre significatif de cas impliqués dans ces chaînes de transmission.","code":"\n## résumer l'objet epicontacts\nsummary(epic)## \n## /// Overview //\n##   // number of unique IDs in linelist: 5888\n##   // number of unique IDs in contacts: 5511\n##   // number of unique IDs in both: 4352\n##   // number of contacts: 3800\n##   // contacts with both cases in linelist: 56.868 %\n## \n## /// Degrees of the network //\n##   // in-degree summary:\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##  0.0000  0.0000  1.0000  0.5392  1.0000  1.0000 \n## \n##   // out-degree summary:\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##  0.0000  0.0000  0.0000  0.5392  1.0000  6.0000 \n## \n##   // in and out degree summary:\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   0.000   1.000   1.000   1.078   1.000   7.000 \n## \n## /// Attributes //\n##   // attributes in linelist:\n##  generation date_infection date_onset date_hospitalisation date_outcome outcome gender age age_unit age_years age_cat age_cat5 hospital lon lat infector source wt_kg ht_cm ct_blood fever chills cough aches vomit temp time_admission bmi days_onset_hosp\n## \n##   // attributes in contacts:\n##  location duration"},{"path":"transmission_chains.html","id":"caractéristiques-par-paires","chapter":"37 Chaînes de transmission","heading":"Caractéristiques par paires","text":"La fonction get_pairwise() permet de traiter les variables de la linelist en fonction de chaque paire dans l’ensemble de données de contact. Dans l’exemple suivant, la date d’apparition de la maladie est extraite de la liste de lignes afin de calculer la différence entre la date d’apparition de la maladie pour chaque paire dans l’ensemble de données de contact. La valeur produite par cette comparaison représente l’ intervalle de série (si).La fonction get_pairwise() va interpréter la classe de la colonne utilisée pour la comparaison, et adaptera sa méthode de comparaison des valeurs en conséquence. Pour les nombres et les dates (comme l’exemple si ci-dessus), la fonction va soustraire les valeurs. Lorsqu’elle est appliquée à des colonnes qui sont des caractères ou des catégories,\nget_pairwise() collera les valeurs ensemble. Comme la fonction permet également un traitement arbitraire (voir l’argument “f”), ces combinaisons discrètes peuvent être facilement mises en tableau et analysées.Ici, nous voyons une association significative entre les liens de transmission et le sexe.","code":"\nsi <- get_pairwise(epic, \"date_onset\")   \nsummary(si)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n##    0.00    5.00    9.00   11.01   15.00   99.00    1820\ntibble(si = si) %>%\n  ggplot(aes(si)) +\n  geom_histogram() +\n  labs(\n    x = \"Intervalle de série\",\n    y = \"Fréquence\"\n  )## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.## Warning: Removed 1820 rows containing non-finite values (`stat_bin()`).\nhead(get_pairwise(epic, \"gender\"), n = 10)##  [1] \"f -> m\" NA       \"m -> m\" NA       \"m -> f\" \"f -> f\" NA       \"f -> m\" NA      \n## [10] \"m -> f\"\nget_pairwise(epic, \"gender\", f = table)##            values.to\n## values.from   f   m\n##           f 464 516\n##           m 510 468\nfisher.test(get_pairwise(epic, \"gender\", f = table))## \n##  Fisher's Exact Test for Count Data\n## \n## data:  get_pairwise(epic, \"gender\", f = table)\n## p-value = 0.03758\n## alternative hypothesis: true odds ratio is not equal to 1\n## 95 percent confidence interval:\n##  0.6882761 0.9892811\n## sample estimates:\n## odds ratio \n##  0.8252575"},{"path":"transmission_chains.html","id":"identifier-les-clusters","chapter":"37 Chaînes de transmission","heading":"Identifier les clusters","text":"La fonction get_clusters() peut être utilisée pour identifier les composants connectés dans un objet epicontacts. Tout d’abord, nous l’utilisons pour récupérer un data.frame contenant les informations sur les clusters :Examinons les plus grands clusters. Pour cela, nous ajoutons des informations sur les clusters à l’objet epicontacts, puis nous le sous-ensemblons pour ne garder que les plus grands clusters :","code":"\nclust <- get_clusters(epic, output = \"data.frame\")\ntable(clust$cluster_size)## \n##    1    2    3    4    5    6    7    8    9   10   11   12   13   14 \n## 1536 1680 1182  784  545  342  308  208  171  100   99   24   26   42\nggplot(clust, aes(cluster_size)) +\n  geom_bar() +\n  labs(\n    x = \"Taille des clusters\",\n    y = \"Fréquence\"\n  )\nepic <- get_clusters(epic)\nmax_size <- max(epic$linelist$cluster_size)\nplot(subset(epic, cs = max_size))"},{"path":"transmission_chains.html","id":"calcul-des-degrés","chapter":"37 Chaînes de transmission","heading":"Calcul des degrés","text":"Le degré d’un noeud correspond à son nombre de bords ou de connexions avec d’autres noeuds. get_degree() fournit une méthode simple pour calculer cette valeur pour les objets epicontacts. Un degré élevé dans ce contexte indique un individu qui était en contact avec beaucoup d’autres personnes. L’argument type indique que nous souhaitons compter à la fois le degré d’entrée et le degré de sortie, l’argument only_linelist indique que nous voulons calculer le degré pour les cas de la linelist.Quels sont les individus qui ont les dix plus grands contacts ?Quel est le nombre moyen de contacts ?","code":"\ndeg_both <- get_degree(epic, type = \"both\", only_linelist = TRUE)\nhead(sort(deg_both, decreasing = TRUE), 10)## 916d0a 858426 6833d7 f093ea 11f8ea 3a4372 38fc71 c8c4d5 a127a7 02d8fd \n##      7      6      6      6      5      5      5      5      5      5\nmean(deg_both)## [1] 1.078473"},{"path":"transmission_chains.html","id":"ressources-21","chapter":"37 Chaînes de transmission","heading":"37.6 Ressources","text":"Le site pour le paquet epicontacts fournit une vue d’ensemble des fonctions du paquet et contient quelques vignettes plus approfondies.La page github peut être utilisée pour soulever des\nproblèmes et demander des fonctionnalités.","code":""},{"path":"phylogenetic_trees.html","id":"phylogenetic_trees","chapter":"38 Les arbres phylogénétiques","heading":"38 Les arbres phylogénétiques","text":"","code":""},{"path":"phylogenetic_trees.html","id":"aperçu-5","chapter":"38 Les arbres phylogénétiques","heading":"38.1 Aperçu","text":"Les arbres phylogénétiques sont utilisés pour visualiser et décrire la parenté et l’évolution des organismes à partir de la séquence de leur code génétique.peut les construire à partir de séquences génétiques en utilisant des méthodes basées sur la distance (comme la méthode neighbor-joining) ou les méthodes probabiliste (comme la méthode de maximum de vraisemblance et la méthode Bayesian Markov Chain Monte Carlo). Le séquençage de nouvelle génération (NGS) devient de plus en plus abordable et populaire en santé publique pour caractériser des agents pathogènes à l’origine des maladies infectieuses. Les appareils de séquençage portables réduisent le délai d’exécution et offrent la possibilité de rendre les résultats disponible en temps réel pour les enquêtes sur les épidémies. Les données NGS peuvent être utilisées pour identifier l’origine ou la source d’une souche épidémique ainsi que sa propagation, et pour déterminer la présence de gènes de résistance antimicrobienne. Pour visualiser la parenté génétique entre les échantillons, un arbre phylogénétique est construit.Dans cette page, nous allons apprendre à utiliser le package ggtree, qui permet la visualisation combinée d’arbres phylogénétiques avec des données d’échantillons supplémentaires sous la forme de tableaux de données. Cela nous permettra d’observer les tendances et de comprendre la dynamique de l’épidémie.","code":""},{"path":"phylogenetic_trees.html","id":"préparation-21","chapter":"38 Les arbres phylogénétiques","heading":"38.2 Préparation","text":"","code":""},{"path":"phylogenetic_trees.html","id":"importation-des-packages-2","chapter":"38 Les arbres phylogénétiques","heading":"Importation des packages","text":"Ces lignes de code importe les packages necessaire pour l’analyse. Dans ce guide, nous mettons l’accent sur p_load() de pacman, qui installe le package si nécessaire puis l’importe pour l’utiliser dans la session de Rstudio. Vous pouvez également charger les packages installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les packages en R.","code":"\npacman::p_load(\n  rio,             # import/export\n  here,            # gestion des chemins d'accès\n  tidyverse,       # gestion des données + graphiques (ggplot2)\n  ape,             # pour importer and exporter les fichiers phylogénétiques\n  ggtree,          # pour visualiser les fichiers phylogénétiques\n  treeio,          # pour visualiser les fichiers phylogénétiques\n  ggnewscale)      # pour ajouter les palettes de couleurs supplémentaire"},{"path":"phylogenetic_trees.html","id":"import-data-1","chapter":"38 Les arbres phylogénétiques","heading":"Import data","text":"Les données pour cette page peuvent être téléchargées suivant les instructions de la page Télécharger le manuel et les données.Il existe plusieurs formats différents dans lesquels un arbre phylogénétique peut être enregistré (par exemple, Newick, NEXUS, Phylip). Un format couramment utilisés est celui des fichiers Newick (.nwk), qui est la norme pour représenter les arbres sous une forme facilement exploitable par ordinateur. Cela signifie qu’un arbre entier peut être représenté par un format de chaîne de caractères tel que “((t2:0.04,t1:0.34):0.89,(t5:0.37,(t4:0.03,t3:0.67):0.9):0.59) ;”, énumérant tous les nœuds, les extrémités et leur relation (longueur de branche) les uns avec les autres.Note : Il est important de comprendre que le fichier de l’arbre phylogénétique en lui-même ne contient pas de données de séquençage, mais est simplement le résultat des distances génétiques entre les séquences. Nous ne pouvons donc pas extraire les données de séquençage d’un fichier arbre.Tout d’abord, nous utilisons la fonction read.tree() du package ape pour importer un fichier d’arbre phylogénétique de Newick au format .txt, et le enregistrer dans un objet liste de classe “phylo”. Si nécessaire, utilisez la fonction () du package pour spécifier le chemin relatif du fichier.Note : Dans ce cas, l’arbre Newick est enregistré au format .txt pour faciliter sa manipulation et son téléchargement de Github.Nous inspectons notre objet arbre et voyons qu’il contient 299 pointes (ou échantillons) et 236 nœuds.Ensuite, nous importons un fichier en format .csv contenant des informations supplémentaires pour chaque échantillon séquencé, tel que le sexe, le pays d’origine et les attributs de résistance antimicrobienne, en utilisant la fonction import() du package rio :Ci-dessous, vous trouverez les 50 premières lignes de données :","code":"\ntree <- ape::read.tree(\"Shigella_tree.txt\")\ntree## \n## Phylogenetic tree with 299 tips and 236 internal nodes.\n## \n## Tip labels:\n##   SRR5006072, SRR4192106, S18BD07865, S18BD00489, S17BD08906, S17BD05939, ...\n## Node labels:\n##   17, 29, 100, 67, 100, 100, ...\n## \n## Rooted; includes branch lengths.\nsample_data <- import(\"sample_data_Shigella_tree.csv\")"},{"path":"phylogenetic_trees.html","id":"nettoyer-et-inspecter","chapter":"38 Les arbres phylogénétiques","heading":"Nettoyer et inspecter","text":"Nous nettoyons et inspectons nos données : Pour pouvoir associer les données échantillon à l’arbre phylogénétique, les valeurs de la colonne Sample_ID dans le tableau de données sample_data doit correspondre aux valeurs tip.labels dans le fichier tree :Nous vérifions le format du tip.labels dans le fichier tree en regardant les 6 premières entrées en utilisant head() de base R.Nous nous assurons également que la première colonne de notre tableau de données sample_data est Sample_ID. Nous regardons les noms des colonnes de notre jeu de données en utilisant colnames() de base R.Nous regardons les Sample_IDs dans le jeu de données pour nous assurer que le format est le même que dans le tip.label (par exemple, les lettres sont en majuscules, pas de soulignement supplémentaire _ entre les lettres et les chiffres, etc.)Nous pouvons aussi vérifier si tous les échantillons sont présents dans le fichier tree et vice versa en générant un vecteur logique de VRAI ou FAUX là où ils correspondent ou non. Ceux-ci ne sont pas imprimés ici, pour plus de simplicité.Nous pouvons utiliser ces vecteurs pour démontrer les ID des échantillons qui ne sont pas sur l’arbre (il n’y en pas).Après inspection, nous pouvons voir que le format de Sample_ID dans le dataframe correspond au format des noms d’échantillons dans le tip.labels. Ceux-ci n’ont pas besoin d’être triés dans le même ordre pour être appariés.Voilà est prêts à partir !","code":"\nhead(tree$tip.label) ## [1] \"SRR5006072\" \"SRR4192106\" \"S18BD07865\" \"S18BD00489\" \"S17BD08906\" \"S17BD05939\"\ncolnames(sample_data)   ##  [1] \"Sample_ID\"                  \"serotype\"                  \n##  [3] \"Country\"                    \"Continent\"                 \n##  [5] \"Travel_history\"             \"Year\"                      \n##  [7] \"Belgium\"                    \"Source\"                    \n##  [9] \"Gender\"                     \"gyrA_mutations\"            \n## [11] \"macrolide_resistance_genes\" \"MIC_AZM\"                   \n## [13] \"MIC_CIP\"\nhead(sample_data$Sample_ID) # Nous vérifions les 6 premières entrées en utilisant head()## [1] \"S17BD05944\" \"S15BD07413\" \"S18BD07247\" \"S19BD07384\" \"S18BD07338\" \"S18BD02657\"\nsample_data$Sample_ID %in% tree$tip.label\n\ntree$tip.label %in% sample_data$Sample_ID\nsample_data$Sample_ID[!tree$tip.label %in% sample_data$Sample_ID]## character(0)"},{"path":"phylogenetic_trees.html","id":"visualisation-simple-de-larbre","chapter":"38 Les arbres phylogénétiques","heading":"38.3 Visualisation simple de l’arbre","text":"","code":""},{"path":"phylogenetic_trees.html","id":"diverses-configurations-darbres","chapter":"38 Les arbres phylogénétiques","heading":"Diverses configurations d’arbres","text":"ggtree offre nombreux formats de configuration d’arbres différents et certains peuvent être plus adéquats que d’autres pour votre usage spécifique. Ci-dessous, vous trouverez quelques illustrations. Pour d’autres options, voir ce livre en ligne.Voici quelques exemples des configurations d’arbres :","code":"\nggtree(tree)                                            # arbre linéaire simple\nggtree(tree,  branch.length = \"none\")                   # arbre linéaire simple avec toutes les pointes alignées \nggtree(tree, layout=\"circular\")                         # arbre circulaire simple\nggtree(tree, layout=\"circular\", branch.length = \"none\") # arbre circulaire simple avec toutes les pointes alignées "},{"path":"phylogenetic_trees.html","id":"arbre-simple-plus-données-échantillons","chapter":"38 Les arbres phylogénétiques","heading":"Arbre simple plus données échantillons","text":"L’opérateur %<+% est utilisé pour connecter le tableau de donnees sample_data avec le fichier arbre. L’annotation la plus facile de votre arbre est l’ajout des noms des échantillons aux extrémités, ainsi que la coloration des points d’extrémité et si désiré des branches :Voici un exemple d’arbre circulaire :Vous pouvez exporter le graphique de votre arbre avec ggsave() comme vous le feriez avec n’importe quel autre objet ggplot. Écrit de cette façon, ggsave() enregistre la dernière image produite dans le chemin de fichier que vous spécifiez. Rappelez-vous que vous pouvez utiliser () et les chemins de fichiers relatifs pour sauvegarder facilement dans des sous-dossiers, etc.","code":"\nggtree(tree, layout = \"circular\", branch.length = 'none') %<+% sample_data + # %<+% ajoute le tableau des données l'échantillon à l'arbre\n  aes(color = (Belgium))+                       # colore les branches en fonction d'une variable de votre tableau de données \n  scale_color_manual(\n    name = \"Sample Origin\",                      # le nom de votre palette de couleurs (qui apparaîtra dans la légende comme ceci)\n    breaks = c(\"Yes\", \"No\"),                     # les différentes options de votre variable\n    labels = c(\"NRCSS Belgium\", \"Other\"),        # comment vous voulez que les différentes options soient nommées dans votre légende, ce qui permet de les formater\n    values = c(\"blue\", \"black\"),                  # la couleur que vous voulez attribuer à la variable\n    na.value = \"black\") +                        # colorer les valeurs NA en noir également\n  new_scale_color()+                             # permet d'ajouter une couleur supplémentaire pour une autre variable\n    geom_tippoint(\n      mapping = aes(color = Continent),          # colorer les pointes par continent. Vous pouvez changer la forme en ajoutant \"shape = \"\n      size = 1.5)+                               # Définit la taille du point à la extremite \n  scale_color_brewer(\n    name = \"Continent\",                    # nom de votre palette de couleurs (qui apparaîtra dans la légende comme ceci)\n    palette = \"Set1\",                      # nous choisissons un ensemble de couleurs fournies avec le package brewer \n    na.value = \"grey\") +                    # pour les valeurs NA nous choisissons la couleur grise\n  geom_tiplab(                             # ajoute le nom de l'échantillon à l'extrémité de sa branche\n    color = 'black',                       # (ajoutez autant de lignes de texte que vous souhaitez avec + , mais vous devrez ajuster la valeur du décalage pour les placer les à côté des autres) \n    offset = 1,\n    size = 1,\n    geom = \"text\",\n    align = TRUE) +    \n  ggtitle(\"Phylogenetic tree of Shigella sonnei\")+       # titre de votre graphique\n  theme(\n    axis.title.x = element_blank(), # supprime le titre de l'axe x\n    axis.title.y = element_blank(), # supprime le titre de l'axe y\n    legend.title = element_text(    # définit la taille de la police et le format du titre de la légende\n      face = \"bold\",\n      size = 12),   \n    legend.text=element_text(       # définit la taille de la police et le format du texte de la légende\n      face = \"bold\",\n      size = 10),  \n    plot.title = element_text(      # définit la taille de la police et le format du titre du graphique\n      size = 12,\n      face = \"bold\"),  \n    legend.position = \"bottom\",     # # définit le position du légende\n    legend.box = \"vertical\",        # # définit le position du légende\n    legend.margin = margin())   \nggsave(\"example_tree_circular_1.png\", width = 12, height = 14)"},{"path":"phylogenetic_trees.html","id":"manipulation-de-larbre","chapter":"38 Les arbres phylogénétiques","heading":"38.4 Manipulation de l’arbre","text":"Parfois, vous pouvez avoir un très grand arbre phylogénétique et vous n’êtes intéressé que par une partie de l’arbre. Par exemple, si vous avez produit un arbre incluant des échantillons historiques ou internationaux afin d’obtenir un aperçu de la place de l’ensemble de vos données dans le schema général. Mais ensuite, pour examiner vos données de plus près, vous ne voulez inspecter que cette partie du grand arbre.Comme le fichier de l’arbre phylogénétique n’est que le résultat de l’analyse des données de séquençage, nous ne pouvons pas manipuler l’ordre des nœuds et des branches dans le fichier lui-même. Ceux-ci ont déjà été déterminés dans une analyse précédente à partir des données de séquençage brutes. Nous sommes cependant en mesure de zoomer sur certaines parties, de cacher certaines parties et même de sous-ensembler une partie de l’arbre.","code":""},{"path":"phylogenetic_trees.html","id":"zoomer-pour-agrandir","chapter":"38 Les arbres phylogénétiques","heading":"Zoomer pour agrandir","text":"Si vous ne voulez pas “couper” votre arbre, mais seulement en inspecter une partie de plus près, vous pouvez zoomer pour voir une partie spécifique.Tout d’abord, nous traçons l’arbre entier au format linéaire et ajoutons des étiquettes numériques à chaque nœud de l’arbre.Pour zoomer sur une branche particulière (qui déborde à droite), utilisez viewClade() sur l’objet ggtree p et fournissez le numéro du noeud pour obtenir une vue plus détaillée :","code":"\np <- ggtree(tree,) %<+% sample_data +\n  geom_tiplab(size = 1.5) +                # étiquette les extrémités de toutes les branches avec le nom de l'échantillon dans le fichier de l'arbre\n  geom_text2(\n    mapping = aes(subset = !isTip,\n                  label = node),\n    size = 5,\n    color = \"darkred\",\n    hjust = 1,\n    vjust = 1)                            # étiquette tous les nœuds de l'arbre\n\np  # imprime\nviewClade(p, node = 452)"},{"path":"phylogenetic_trees.html","id":"réduire-les-branches","chapter":"38 Les arbres phylogénétiques","heading":"Réduire les branches","text":"Cependant, nous pouvons vouloir ignorer cette branche et la réduire à ce même noeud (noeud n° 452) en utilisant collapse(). Cet arbre est défini comme p_collapsed.Pour plus de clarté, lorsque nous imprimons p_collapsed, nous ajoutons un geom_point2() (un diamant bleu) au noeud de la branche réduite.","code":"\np_collapsed <- collapse(p, node = 452)\np_collapsed\np_collapsed + \ngeom_point2(aes(subset = (node == 452)),  # nous attribuons un symbole au nœud réduit\n            size = 5,                     # définir la taille du symbole\n            shape = 23,                   # définir la forme du symbole\n            fill = \"steelblue\")           # définir la coleur du symbole"},{"path":"phylogenetic_trees.html","id":"sous-ensembler-un-arbre","chapter":"38 Les arbres phylogénétiques","heading":"Sous-ensembler un arbre","text":"Si nous voulons faire un changement plus permanent et créer un nouvel arbre réduit avec lequel travailler, nous pouvons sous-ensembler une partie avec tree_subset(). Vous pouvez ensuite le sauvegarder comme un nouveau fichier newick tree ou un fichier .txt.Tout d’abord, nous inspectons les noeuds de l’arbre et les étiquettes des extrémités afin de décider ce qu’il faut sous-ensembler.Maintenant, disons que nous avons décidé de sous-ensembler l’arbre au noeud 528 (ne garder que les pointes dans cette branche après le noeud 528) et nous le sauvegardons comme un nouvel objet sub_tree1 :Examinons l’arbre subset tree 1:Vous pouvez également effectuer un sous-ensemble basé sur un échantillon particulier, en spécifiant le nombre de noeuds “en arrière” que vous souhaitez inclure. Sous-ensemble la même partie de l’arbre basé sur un échantillon, dans ce cas S17BD07692, en remontant de 9 noeuds et nous le sauvegardons comme un nouvel objet sub_tree2 :Examinons l’arbre subset tree 2:Vous pouvez également sauvegarder votre nouvel arbre soit comme un type Newick ou même un fichier texte en utilisant la fonction write.tree() du package ape :","code":"\nggtree(\n  tree,\n  branch.length = 'none',\n  layout = 'circular') %<+% sample_data +               # nous ajoutons les données de l'échantillon en utilisant l'opérateur %<+%.\n  geom_tiplab(size = 1)+                                # étiqueter les extrémités de toutes les branches avec le nom de l'échantillon dans le fichier arbre\n  geom_text2(\n    mapping = aes(subset = !isTip, label = node),\n    size = 3,\n    color = \"darkred\") +                                # étiquette tous les noeuds de l'arbre \n theme(\n   legend.position = \"none\",                            # supprime la légende tous ensemble\n   axis.title.x = element_blank(),\n   axis.title.y = element_blank(),\n   plot.title = element_text(size = 12, face=\"bold\"))\nsub_tree1 <- tree_subset(\n  tree,\n  node = 528)                                            # nous sous-ensemblons l'arbre au nœud 528\nggtree(sub_tree1) +\n  geom_tiplab(size = 3) +\n  ggtitle(\"Subset tree 1\")\nsub_tree2 <- tree_subset(\n  tree,\n  \"S17BD07692\",\n  levels_back = 9) # levels_back définit le nombre de nœuds en arrière de la pointe de l'échantillon que vous voulez atteindre.\nggtree(sub_tree2) +\n  geom_tiplab(size =3)  +\n  ggtitle(\"Subset tree 2\")\n# pour sauvegarder en format .nwk format\nape::write.tree(sub_tree2, file='data/phylo/Shigella_subtree_2.nwk')\n\n# pour sauvegarder en format .txt format\nape::write.tree(sub_tree2, file='data/phylo/Shigella_subtree_2.txt')"},{"path":"phylogenetic_trees.html","id":"rotation-des-nœuds-dans-un-arbre","chapter":"38 Les arbres phylogénétiques","heading":"Rotation des nœuds dans un arbre","text":"Comme mentionné précédemment, nous ne pouvons pas modifier l’ordre des pointes ou des noeuds dans l’arbre, car cela est basé sur leur parenté génétique et ne peut pas être manipulé de manière visuelle. Mais nous pouvons roter des branches autour des nœuds si cela facilite notre visualisation.Tout d’abord, nous traçons notre nouveau subset tree 2 avec des étiquettes de nœuds pour choisir le nœud que nous voulons manipuler et nous enregistrons dans un objet ggtree plot p.Nous pouvons ensuite manipuler les nœuds en appliquant ggtree::rotate() ou ggtree::flip() : Note : pour illustrer quels noeuds nous manipulons, nous appliquons d’abord la fonction geom_hilight() de ggtree pour mettre en évidence les échantillons dans les noeuds qui nous intéressent et nous enregistrons cet objet ggtree plot dans un nouvel objet p1.Maintenant nous pouvons faire tourner le noeud 37 dans l’objet p1 de sorte que les échantillons sur le noeud 38 se déplacent vers le haut. Nous enregistrons l’arbre pivoté dans un nouvel objet p2.Ou nous pouvons utiliser la commande flip pour faire pivoter le noeud 36 de l’objet p1 et faire passer le noeud 37 en haut et le noeud 39 en bas. Nous enregistrons l’arbre retourné dans un nouvel objet p3.","code":"\np <- ggtree(sub_tree2) +  \n  geom_tiplab(size = 4) +\n  geom_text2(aes(subset=!isTip, label=node), # étiquette tous les nœuds de l'arbre\n             size = 5,\n             color = \"darkred\", \n             hjust = 1, \n             vjust = 1) \np\np1 <- p + geom_hilight(  # met en évidence le nœud 39 en bleu, \"extend =\" nous permet de définir la longueur du bloc de couleur\n  node = 39,\n  fill = \"steelblue\",\n  extend = 0.0017) +  \ngeom_hilight(            # met en évidence le nœud 39 en jaune\n  node = 37,\n  fill = \"yellow\",\n  extend = 0.0017) +               \nggtitle(\"Original tree\")\n\n\np1 # imprime\np2 <- ggtree::rotate(p1, 37) + \n      ggtitle(\"Rotated Node 37\")\n\n\np2   # imprime\np3 <-  flip(p1, 39, 37) +\n      ggtitle(\"Rotated Node 36\")\n\n\np3   # imprime"},{"path":"phylogenetic_trees.html","id":"exemple-de-sous-arbre-avec-annotation-déchantillon-de-données","chapter":"38 Les arbres phylogénétiques","heading":"Exemple de sous-arbre avec annotation d’échantillon de données","text":"Disons que nous investiguons le cluster de cas avec expansion clonale qui s’est produit en 2017 et 2018 au nœud 39 de notre sous-arbre. Nous ajoutons l’année d’isolement de la souche ainsi que l’historique des voyages et la couleur par pays pour voir l’origine d’autres souches étroitement liées :Notre observation pointe vers un événement d’importation de souches en provenance d’Asie, qui ont ensuite circulé en Belgique au fil des ans et semblent avoir causé notre dernière épidémie.","code":"\nggtree(sub_tree2) %<+% sample_data +     # nous utilisons l'opérateur %<+% pour faire le lien avec le fichier sample_data \n  geom_tiplab(                          # étiquette les extrémités de toutes les branches avec le nom de l'échantillon dans le fichier arbre\n    size = 2.5,\n    offset = 0.001,\n    align = TRUE) + \n  theme_tree2()+\n  xlim(0, 0.015)+                       # définir les limites de l'axe x de notre arbre \n  geom_tippoint(aes(color=Country),     # colorer le point d'extrémité par continent\n                size = 1.5)+ \n  scale_color_brewer(\n    name = \"Country\", \n    palette = \"Set1\", \n    na.value = \"grey\")+\n  geom_tiplab(                          # ajouter l'année d'isolation comme étiquette de texte aux extrémités\n    aes(label = Year),\n    color = 'blue',\n    offset = 0.0045,\n    size = 3,\n    linetype = \"blank\" ,\n    geom = \"text\",\n    align = TRUE)+ \n  geom_tiplab(                          # ajouter l'historique de voyage comme étiquette de texte aux extrémités, en couleur rouge\n    aes(label = Travel_history),\n    color = 'red',\n    offset = 0.006,\n    size = 3,\n    linetype = \"blank\",\n    geom = \"text\",\n    align = TRUE)+ \n  ggtitle(\"Phylogenetic tree of Belgian S. sonnei strains with travel history\")+  # ajouter le titre du graphique\n  xlab(\"genetic distance (0.001 = 4 nucleotides difference)\")+                    # ajouter une étiquette à l'axe x \n  theme(\n    axis.title.x = element_text(size = 10),\n    axis.title.y = element_blank(),\n    legend.title = element_text(face = \"bold\", size = 12),\n    legend.text = element_text(face = \"bold\", size = 10),\n    plot.title = element_text(size = 12, face = \"bold\"))"},{"path":"phylogenetic_trees.html","id":"arbres-plus-complexes-ajout-de-cartes-thermiques-des-données-de-léchantillon","chapter":"38 Les arbres phylogénétiques","heading":"Arbres plus complexes : ajout de cartes thermiques des données de l’échantillon","text":"Nous pouvons ajouter des informations plus complexes, telles que la présence catégorielle de gènes de résistance aux antimicrobiens et des valeurs numériques pour la résistance aux antimicrobiens effectivement mesurée sous la forme d’une carte thermique en utilisant la fonction ggtree::gheatmap().Tout d’abord, nous devons tracer notre arbre (qui peut être linéaire ou circulaire) et le enregistrer dans un nouvel objet ggtree plot p : Nous allons utiliser le sub_tree de la partie 3).Ensuite, nous préparons nos données. Pour visualiser différentes variables avec de nouveaux schémas de couleurs, nous sous-ensemblons notre dataframe à la variable désirée. Il est important d’ajouter le Sample_ID comme rownames sinon il ne pourra pas faire correspondre les données à l’arbre tip.labels :Dans notre exemple, nous voulons examiner le sexe et les mutations qui pourraient conférer une résistance à la Ciprofloxacine, un important antibiotique de première ligne utilisé pour traiter les infections à Shigella.Nous créons un tableau de données pour le sexe :Nous créons un tableau de données pour les mutations du gène gyrA, qui confèrent une résistance à la ciprofloxacine :Nous créons un tableau de données pour la concentration minimale inhibitrice (CMI) mesurée pour la Ciprofloxacine en provenance du laboratoire :Nous créons un premier graphique en ajoutant une carte thermique binaire pour le sexe à l’arbre phylogénétique et en la sauvegardant dans un nouvel objet graphique ggtree h1 :Nous ajoutons ensuite des informations sur les mutations du gène gyrA, qui confèrent une résistance à la Ciprofloxacine :Note : La présence de mutations ponctuelles chromosomiques dans les données WGS été déterminée au préalable à l’aide de l’outil PointFinder développé par Zankari et al. (voir la référence dans la section des références supplémentaires)Tout d’abord, nous attribuons un nouveau schéma de couleurs à notre objet de tracé existant h1 et le sauvegardons dans un nouvel objet h2. Cela nous permet de définir et de modifier les couleurs de notre deuxième variable dans la carte thermique.Ensuite, nous ajoutons la deuxième couche de carte thermique à h2 et nous enregistrons les graphiques combinés dans un nouvel objet h3 :Nous répétons le processus ci-dessus, en ajoutant d’abord une nouvelle couche d’échelle de couleurs à notre objet existant h3, puis en ajoutant les données continues sur la concentration minimale inhibitrice (CMI) de la Ciprofloxacine pour chaque souche à l’objet résultant h4 pour produire l’objet final h5 :can exercise linear tree:Tout d’abord, nous ajoutons le sexe :Puis nous ajoutons les mutations de résistance à la Ciprofloxacine après avoir ajouté une autre couche de schéma de couleurs :ajoute ensuite la concentration minimale inhibitrice déterminée par le laboratoire (CMI) :","code":"\np <- ggtree(sub_tree2, branch.length='none', layout='circular') %<+% sample_data +\n  geom_tiplab(size =3) + \n theme(\n   legend.position = \"none\",\n    axis.title.x = element_blank(),\n    axis.title.y = element_blank(),\n    plot.title = element_text(\n      size = 12,\n      face = \"bold\",\n      hjust = 0.5,\n      vjust = -15))\np\ngender <- data.frame(\"gender\" = sample_data[,c(\"Gender\")])\nrownames(gender) <- sample_data$Sample_ID\ncipR <- data.frame(\"cipR\" = sample_data[,c(\"gyrA_mutations\")])\nrownames(cipR) <- sample_data$Sample_ID\nMIC_Cip <- data.frame(\"mic_cip\" = sample_data[,c(\"MIC_CIP\")])\nrownames(MIC_Cip) <- sample_data$Sample_ID\nh1 <-  gheatmap(p, gender,                                 # Nous ajoutons une couche de carte thermique du tableau de données de sexe à notre graphique arbre.\n                offset = 10,                               # l'offset déplace la carte thermique vers la droite,\n                width = 0.10,                              # la largeur définit la largeur de la colonne de la carte thermique,\n                color = NULL,                              # la couleur définit la bordure des colonnes de la carte thermique.\n         colnames = FALSE) +                               # cache les noms des colonnes de la carte thermique\n  scale_fill_manual(name = \"Gender\",                       # définit le schéma de coloration et la légende pour le sexe\n                    values = c(\"#00d1b1\", \"purple\"),\n                    breaks = c(\"Male\", \"Female\"),\n                    labels = c(\"Male\", \"Female\")) +\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())## Scale for y is already present.\n## Adding another scale for y, which will replace the existing scale.\n## Scale for fill is already present.\n## Adding another scale for fill, which will replace the existing scale.\nh1\nh2 <- h1 + new_scale_fill() \nh3 <- gheatmap(h2, cipR,         # ajoute la deuxième ligne de la carte thermique décrivant les mutations de résistance à la Ciprofloxacine\n               offset = 12, \n               width = 0.10, \n               colnames = FALSE) +\n  scale_fill_manual(name = \"Ciprofloxacin resistance \\n conferring mutation\",\n                    values = c(\"#fe9698\",\"#ea0c92\"),\n                    breaks = c( \"gyrA D87Y\", \"gyrA S83L\"),\n                    labels = c( \"gyrA d87y\", \"gyrA s83l\")) +\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())+\n  guides(fill = guide_legend(nrow = 2,byrow = TRUE))## Scale for y is already present.\n## Adding another scale for y, which will replace the existing scale.\n## Scale for fill is already present.\n## Adding another scale for fill, which will replace the existing scale.\nh3\n# D'abord nous ajoutons le nouveau schéma de coloration :\nh4 <- h3 + new_scale_fill()\n\n# puis nous combinons les deux en une nouvelle graphique :\nh5 <- gheatmap(h4, MIC_Cip,  \n               offset = 14, \n               width = 0.10,\n                colnames = FALSE)+\n  scale_fill_continuous(name = \"MIC for Ciprofloxacin\",  # nous définissons ici un schéma de couleurs de gradient pour la variable continue de CMI\n                      low = \"yellow\", high = \"red\",\n                      breaks = c(0, 0.50, 1.00),\n                      na.value = \"white\") +\n   guides(fill = guide_colourbar(barwidth = 5, barheight = 1))+\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())## Scale for y is already present.\n## Adding another scale for y, which will replace the existing scale.\n## Scale for fill is already present.\n## Adding another scale for fill, which will replace the existing scale.\nh5\np <- ggtree(sub_tree2) %<+% sample_data +\n  geom_tiplab(size = 3) + # etiquetter les pointes\n  theme_tree2()+\n  xlab(\"genetic distance (0.001 = 4 nucleotides difference)\")+\n  xlim(0, 0.015)+\n theme(legend.position = \"none\",\n      axis.title.y = element_blank(),\n      plot.title = element_text(size = 12, \n                                face = \"bold\",\n                                hjust = 0.5,\n                                vjust = -15))\np\nh1 <-  gheatmap(p, gender, \n                offset = 0.003,\n                width = 0.1, \n                color=\"black\", \n         colnames = FALSE)+\n  scale_fill_manual(name = \"Gender\",\n                    values = c(\"#00d1b1\", \"purple\"),\n                    breaks = c(\"Male\", \"Female\"),\n                    labels = c(\"Male\", \"Female\"))+\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())## Scale for y is already present.\n## Adding another scale for y, which will replace the existing scale.\n## Scale for fill is already present.\n## Adding another scale for fill, which will replace the existing scale.\nh1\nh2 <- h1 + new_scale_fill()\nh3 <- gheatmap(h2, cipR,   \n               offset = 0.004, \n               width = 0.1,\n               color = \"black\",\n                colnames = FALSE)+\n  scale_fill_manual(name = \"Ciprofloxacin resistance \\n conferring mutation\",\n                    values = c(\"#fe9698\",\"#ea0c92\"),\n                    breaks = c( \"gyrA D87Y\", \"gyrA S83L\"),\n                    labels = c( \"gyrA d87y\", \"gyrA s83l\"))+\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())+\n  guides(fill = guide_legend(nrow = 2,byrow = TRUE))## Scale for y is already present.\n## Adding another scale for y, which will replace the existing scale.\n## Scale for fill is already present.\n## Adding another scale for fill, which will replace the existing scale.\n h3\nh4 <- h3 + new_scale_fill()\nh5 <- gheatmap(h4, MIC_Cip, \n               offset = 0.005,  \n               width = 0.1,\n               color = \"black\", \n                colnames = FALSE)+\n  scale_fill_continuous(name = \"MIC for Ciprofloxacin\",\n                      low = \"yellow\", high = \"red\",\n                      breaks = c(0,0.50,1.00),\n                      na.value = \"white\")+\n   guides(fill = guide_colourbar(barwidth = 5, barheight = 1))+\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 10),\n        legend.text = element_text(size = 8),\n        legend.box = \"horizontal\", legend.margin = margin())+\n  guides(shape = guide_legend(override.aes = list(size = 2)))## Scale for y is already present.\n## Adding another scale for y, which will replace the existing scale.\n## Scale for fill is already present.\n## Adding another scale for fill, which will replace the existing scale.\nh5"},{"path":"phylogenetic_trees.html","id":"resources-9","chapter":"38 Les arbres phylogénétiques","heading":"38.5 Resources","text":"http://hydrodictyon.eeb.uconn.edu/eebedia/index.php/Ggtree# Clade_Colors https://bioconductor.riken.jp/packages/3.2/bioc/vignettes/ggtree/inst/doc/treeManipulation.html https://guangchuangyu.github.io/ggtree-book/chapter-ggtree.html https://bioconductor.riken.jp/packages/3.8/bioc/vignettes/ggtree/inst/doc/treeManipulation.htmlEa Zankari, Rosa Allesøe, Katrine G Joensen, Lina M Cavaco, Ole Lund, Frank M Aarestrup, PointFinder: novel web tool WGS-based detection antimicrobial resistance associated chromosomal point mutations bacterial pathogens, Journal Antimicrobial Chemotherapy, Volume 72, Issue 10, October 2017, Pages 2764–2768, https://doi.org/10.1093/jac/dkx217","code":""},{"path":"interactive_plots.html","id":"interactive_plots","chapter":"39 Graphiques interactifs","heading":"39 Graphiques interactifs","text":"La visualisation de données est de plus en plus demandée d’être interactive par le public. Il est donc de plus en plus nécessaire de créer des graphiques interactifs. Il existe plusieurs méthodes pour les concevoir, mais les deux methodes plus utilisées sont plotly et shiny.Dans cette page, nous allons nous concentrer sur la conversion d’un graphique de type ggplot() en un graphique interactif avec plotly. Vous pouvez en savoir plus sur shiny dans la page [Dashboards Shiny]. Il est important de noter que les graphiques interactifs ne sont utilisables que dans les documents R markdown au format HTML, pas dans les documents PDF ou Word.Ci-dessous, nous présentons un épicurve de base qui été transformé pour être interactif en utilisant l’intégration de ggplot2 et plotly (survolez votre souris sur le graphique, faites un zoom ou cliquez sur les éléments de la légende).","code":""},{"path":"interactive_plots.html","id":"préparation-22","chapter":"39 Graphiques interactifs","heading":"39.1 Préparation","text":"","code":""},{"path":"interactive_plots.html","id":"importation-des-packages-3","chapter":"39 Graphiques interactifs","heading":"Importation des packages","text":"Ces lignes de code importe les packages necessaire pour l’analyse. Dans ce guide, nous mettons l’accent sur p_load() de pacman, qui installe le package si nécessaire puis l’importe pour l’utiliser. Vous pouvez également charger les packages installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les packages en R.","code":"\npacman::p_load(\n  rio,       # Importation/exportation\n  here,      # chemins de fichiers\n  lubridate, # Travailler avec les dates\n  plotly,    # Graphiques interactifs\n  scales,    # les pourcentages rapides\n  tidyverse  # gestion et visualisation des données \n  ) "},{"path":"interactive_plots.html","id":"commencez-avec-un-ggplot","chapter":"39 Graphiques interactifs","heading":"Commencez avec un ggplot()","text":"Dans cette page, nous supposons que vous commencez avec un graphique ggplot() que vous voulez rendre interactif. Nous allons construire plusieurs de ces graphiques dans cette page, en utilisant le case linelist utilisé dans la plupart des pages de ce manuel.","code":""},{"path":"interactive_plots.html","id":"importation-des-données-5","chapter":"39 Graphiques interactifs","heading":"Importation des données","text":"Pour commencer, nous allons importer une base de données appelée linelist_cleaned contenant les cas d’une épidémie d’Ebola simulée. Pour suivre, click download “clean” linelist (.rds file). Importez les données avec la fonction import() du package rio (cette fonction supporte de nombreux types de fichiers comme .xlsx, .csv, .rds - voir la page [Import Export] pour plus de détails).Les 50 premières lignes de la liste des lignes sont affichées ci-dessous.","code":"\n# importer le cas de la liste de lignes\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"interactive_plots.html","id":"tracer-avec-ggplotly","chapter":"39 Graphiques interactifs","heading":"39.2 Tracer avec ggplotly()","text":"La fonction ggplotly() du package plotly permet de facilement rendre un ggplot() interactif. Il suffit de sauvegarder votre ggplot() et de le passer à la fonction ggplotly().Ci-dessous, nous traçons une simple courbe représentant la proportion de cas décédés au cours d’une semaine donnée :Nous commençons par créer un tableau résumé de chaque semaine épidémiologique, et le pourcentage de cas avec un bilan connu qui sont décédés.first 50 rows weekly_deaths dataset.Ensuite, nous créons le graphique avec ggplot2, en utilisant geom_line().Nous pouvons rendre ce graphique interactif en le passant simplement à ggplotly(), comme ci-dessous. Survolez votre souris sur la ligne pour afficher les valeurs x et y. Vous pouvez zoomer sur le tracé, et le déplacer. Vous pouvez également voir des icônes en haut à droite du graphe. Dans cet ordre, elles vous permettent de :Télécharger la vue actuelle sous forme d’image PNGZoomer avec une boîte de sélectionFaire un panoramique, ou déplacer le graphe en cliquant et en faisant rouler le grapheFaire un zoom ou , ou revenir au zoom par défaut.Rétablir les axes par défautActivation/désactivation des “lignes de pointes”, qui sont les lignes pointillées partant du point interactif et s’étendant vers les axes x et y.Ajustements pour que les données s’affichent lorsque vous ne survolez pas la ligne.Les données groupées fonctionnent également avec ggplotly(). Ci-dessous, un épicurve hebdomadaire est fait, groupé par outcome. Les barreaux empilés sont interactifs. Cliquez sur les différents éléments de la légende (ils apparaîtront/disparaîtront).","code":"\nweekly_deaths <- linelist %>%\n  group_by(epiweek = floor_date(date_onset, \"week\")) %>%  # créer et regrouper les données par la colonne epiweek\n  summarise(                                              # créer un nouveau tableau de données résumé  :\n    n_known_outcome = sum(!is.na(outcome), na.rm=T),      # nombre de cas par groupe dont le statut est connu\n    n_death  = sum(outcome == \"Death\", na.rm=T),          # nombre de cas par groupe qui sont décédés\n    pct_death = 100*(n_death / n_known_outcome)           # pourcentage des cas de statut connu qui sont décédés \n  )\ndeaths_plot <- ggplot(data = weekly_deaths)+            # commencer par les données hebdomadaires des décès \n  geom_line(mapping = aes(x = epiweek, y = pct_death))  # faire la ligne  \n\ndeaths_plot   # imprimer\ndeaths_plot %>% plotly::ggplotly()\n# Faire une courbe épidémique avec incidence2 pacakge\np <- incidence2::incidence(\n  linelist,\n  date_index = date_onset,\n  interval = \"weeks\",\n  groups = outcome) %>% plot(fill = outcome)\n# Faire le graphique interactif \np %>% plotly::ggplotly()"},{"path":"interactive_plots.html","id":"modifications","chapter":"39 Graphiques interactifs","heading":"39.3 Modifications","text":"","code":""},{"path":"interactive_plots.html","id":"taille-du-fichier","chapter":"39 Graphiques interactifs","heading":"Taille du fichier","text":"Quand vous exportez dans un HTML généré par R Markdown (comme ce livre!), vous voulez que le graphe ait une taille de données aussi réduite que possible (sans effets secondaires négatifs dans la plupart des cas). Pour cela, il suffit de passer le graphique interactif à partial_bundle(), également de plotly.","code":"\np <- p %>% \n  plotly::ggplotly() %>%\n  plotly::partial_bundle()"},{"path":"interactive_plots.html","id":"boutons","chapter":"39 Graphiques interactifs","heading":"Boutons","text":"Certains des boutons sur un plotly standard sont superflus et peuvent être distrayants, vous pouvez donc les supprimer. Vous pouvez le faire simplement en passant la sortie dans config() de plotly et en spécifiant les boutons à enlever. Dans l’exemple ci-dessous, nous spécifions en avance les noms des boutons à supprimer, et les transmettons à l’argument modeBarButtonsToRemove =. Nous définissons également displaylogo = FALSE pour supprimer le logo plotly.","code":"\n## ces boutons sont distrayants et nous voulons les enlever\nplotly_buttons_remove <- list('zoom2d','pan2d','lasso2d', 'select2d','zoomIn2d',\n                              'zoomOut2d','autoScale2d','hoverClosestCartesian',\n                              'toggleSpikelines','hoverCompareCartesian')\n\np <- p %>%          # re-définir le graphique interactif sans ces boutons \n  plotly::config(displaylogo = FALSE, modeBarButtonsToRemove = plotly_buttons_remove)"},{"path":"interactive_plots.html","id":"heat-tiles","chapter":"39 Graphiques interactifs","heading":"39.4 Heat tiles","text":"Vous pouvez rendre presque tous les graphiques ggplot() interactifs, y compris les heat tiles. Dans la page sur les Graphiques thermiques, vous pouvez lire comment créer le graphique ci-dessous, qui affiche la proportion de jours par semaine pendant lesquels certains facilités ont rapporté des données à leur province.Voici le code, bien que nous ne le décriions pas en détails ici.Ci-dessous, nous le rendons interactif et le modifions pour les boutons simples et la taille du fichier.–>\n","code":"\n# importer les données\nfacility_count_data <- rio::import(here::here(\"data\", \"malaria_facility_count_data.rds\"))\n\n# regrouper les données en semaines pour le Spring district \nagg_weeks <- facility_count_data %>% \n  filter(District == \"Spring\",\n         data_date < as.Date(\"2020-08-01\")) %>% \n  mutate(week = aweek::date2week(\n    data_date,\n    start_date = \"Monday\",\n    floor_day = TRUE,\n    factor = TRUE)) %>% \n  group_by(location_name, week, .drop = F) %>%\n  summarise(\n    n_days          = 7,\n    n_reports       = n(),\n    malaria_tot     = sum(malaria_tot, na.rm = T),\n    n_days_reported = length(unique(data_date)),\n    p_days_reported = round(100*(n_days_reported / n_days))) %>% \n  ungroup(location_name, week) %>% \n  right_join(tidyr::expand(., week, location_name)) %>% \n  mutate(week = aweek::week2date(week))\n\n# Créer le graphique\nmetrics_plot <- ggplot(agg_weeks,\n       aes(x = week,\n           y = location_name,\n           fill = p_days_reported))+\n  geom_tile(colour=\"white\")+\n  scale_fill_gradient(low = \"orange\", high = \"darkgreen\", na.value = \"grey80\")+\n  scale_x_date(expand = c(0,0),\n               date_breaks = \"2 weeks\",\n               date_labels = \"%d\\n%b\")+\n  theme_minimal()+ \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text  = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1,\"cm\"),\n    legend.key.width  = grid::unit(0.6,\"cm\"),\n    axis.text.x = element_text(size=12),\n    axis.text.y = element_text(vjust=0.2),\n    axis.ticks = element_line(size=0.4),\n    axis.title = element_text(size=12, face=\"bold\"),\n    plot.title = element_text(hjust=0,size=14,face=\"bold\"),\n    plot.caption = element_text(hjust = 0, face = \"italic\")\n    )+\n  labs(x = \"Semaine\",\n       y = \"Nom de l'établissement\",\n       fill = \"Rapport de\\nperformance (%)\",\n       title = \"Pourcentage de jours par semaine où l'établissement a déclaré des données\",\n       subtitle = \" Les établissements de santé de district, Avril-Mai 2019 \",\n       caption = \"Semaines de 7 jours commençant le lundi.\")\n\nmetrics_plot # imprimer\nmetrics_plot %>% \n  plotly::ggplotly() %>% \n  plotly::partial_bundle() %>% \n  plotly::config(displaylogo = FALSE, modeBarButtonsToRemove = plotly_buttons_remove)"},{"path":"interactive_plots.html","id":"ressources-22","chapter":"39 Graphiques interactifs","heading":"39.5 Ressources","text":"Plotly n’est pas seulement conçu pour R, mais fonctionne aussi très bien avec Python (et en fait avec tous les langages de Data science puisqu’il est construit en JavaScript). Vous pouvez en savoir plus à ce sujet sur le site plotly website","code":""},{"path":"rmarkdown.html","id":"rmarkdown","chapter":"40 Production de rapports avec R Markdown","heading":"40 Production de rapports avec R Markdown","text":"R Markdown est un outil largement utilisé pour créer des résultats automatisés, reproductibles et prêts à être partagés, tels que des rapports. Il peut générer des sorties statiques ou interactives, aux formats Word, PDF, HTML, Powerpoint et autres.Un script R Markdown associe le code R et le texte de sorte que le script devient votre document de sortie. Vous pouvez créer un document formaté complet, y compris un texte narratif (qui peut être dynamique pour changer en fonction de vos données), des tableaux, des figures, des puces/chiffres, des bibliographies, etc.Ces documents peuvent être produits pour être mis à jour régulièrement (par exemple, des rapports de surveillance quotidiens) et/ou être exécutés sur des sous-ensembles de données (par exemple, des rapports pour chaque compétence).D’autres pages de ce manuel traitent de ce sujet :La page Organisation des rapports de routine montre comment organiser la production de vos rapports avec des dossiers horodatés générés automatiquement.La page Tableaux de bord avec R Markdown explique comment formater un rapport R Markdown en tant que tableau de bord.Il convient de noter que le projet R4Epis développé des modèles de scripts R Markdown pour les épidémies et les scénarios d’enquête les plus courants rencontrés sur les sites des projets MSF.","code":""},{"path":"rmarkdown.html","id":"préparation-23","chapter":"40 Production de rapports avec R Markdown","heading":"40.1 Préparation","text":"Contexte du R MarkdownPour expliquer certains des concepts et des “packages” impliqués :Markdown est un “langage” qui vous permet d’écrire un document en texte brut, qui peut être converti en HTML et autres formats. Il n’est pas spécifique à R. Les fichiers écrits en Markdown ont une extension ‘.md’.R Markdown : est une variante de markdown qui est spécifique à R - il vous permet d’écrire un document en utilisant markdown pour produire du texte et pour incorporer du code R et afficher leurs sorties. Les fichiers R Markdown ont une extension ‘.Rmd’.rmarkdown - le “package” : Il est utilisé par R pour convertir le fichier .Rmd en la sortie souhaitée. Il se concentre sur la conversion de la syntaxe markdown (texte), nous avons donc également besoin de…knitr : Ce “package” R lira les morceaux de code, les exécutera et les ” tricotera” dans le document. C’est ainsi que les tableaux et les graphiques sont inclus à côté du texte.Pandoc : Enfin, pandoc convertit le résultat en Word/PDF/Powerpoint, etc. Il s’agit d’un logiciel distinct de R mais qui est installé automatiquement avec RStudio.En résumé, le processus qui se déroule en arrière-plan (vous n’avez pas besoin de connaître toutes ces étapes !) consiste à transmettre le fichier .Rmd à knitr, qui exécute les morceaux de code R et crée un nouveau fichier .md (markdown) comprenant le code R et son résultat rendu. Le fichier .md est ensuite traité par pandoc pour créer le produit fini : un document Microsoft Word, un fichier HTML, un document Powerpoint, un PDF, etc.(source: https://rmarkdown.rstudio.com/authoring_quick_tour.html):InstallationPour créer une sortie R Markdown, vous devez avoir installé les éléments suivants :Le package rmarkdown (knitr sera également installé automatiquement).Pandoc, qui doit être installé avec RStudio. Si vous n’utilisez pas RStudio, vous pouvez télécharger Pandoc ici.Si vous souhaitez générer une sortie PDF (un peu plus délicat), vous devrez installer LaTeX. Pour les utilisateurs de R Markdown qui n’ont pas installé LaTeX auparavant, nous vous recommandons d’installer TinyTeX. Vous pouvez utiliser les commandes suivantes:","code":"\npacman::p_load(tinytex)     # installer le package tinytex \ntinytex::install_tinytex()  # commande R pour installer TinyTeX "},{"path":"rmarkdown.html","id":"démarrage","chapter":"40 Production de rapports avec R Markdown","heading":"40.2 Démarrage","text":"","code":""},{"path":"rmarkdown.html","id":"installer-le-package-r-rmarkdown","chapter":"40 Production de rapports avec R Markdown","heading":"Installer le package R rmarkdown","text":"Installez le “package” R rmarkdown. Dans ce manuel, nous mettons l’accent sur la fonction p_load() du “package” pacman, qui installe le (ou une liste de) “package (s)” que si nécessaire (uniquement si le package n’est pas déjà installé) et le charge pour l’utiliser . peut également charger des “packages” avec library() à partir de R base. Voir la page sur R - les bases pour plus d’informations sur les packages R.","code":"\npacman::p_load(rmarkdown)"},{"path":"rmarkdown.html","id":"créer-un-nouveau-fichier-rmd","chapter":"40 Production de rapports avec R Markdown","heading":"Créer un nouveau fichier Rmd","text":"Dans RStudio, ouvrez un nouveau fichier R markdown, en commençant par ‘File’, puis ‘New file’ et enfin ‘R markdown…’.R Studio vous donnera quelques options de sortie parmi lesquelles choisir. Dans l’exemple ci-dessous, nous sélectionnons “HTML” car nous voulons créer un document HTML. Le titre et les noms des auteurs ne sont pas importants. Si le type de document de sortie que vous voulez n’est pas l’un de ceux-là, ne vous inquiétez pas - vous pouvez choisir n’importe lequel et le changer dans le script plus tard.Cela ouvrira un nouveau script .Rmd.","code":""},{"path":"rmarkdown.html","id":"important-à-savoir","chapter":"40 Production de rapports avec R Markdown","heading":"Important à savoir","text":"Le répertoire de travailLe répertoire de travail d’un fichier markdown est l’endroit où le fichier Rmd lui-même est enregistré. Par exemple, si le projet R se trouve dans ~/Documents/projetX et que le fichier Rmd lui-même se trouve dans un sous-dossier ~/Documents/projetX/markdownfiles/markdown.Rmd, le code read.csv(\"data.csv\") dans le markdown cherchera un fichier csv dans le dossier markdownfiles, et non dans le dossier racine du projet où les scripts dans les projets chercheraient normalement automatiquement.Pour faire référence à des fichiers ailleurs, vous devrez soit utiliser le chemin complet du fichier, soit utiliser le package . Le package définit le répertoire de travail comme étant le dossier racine du projet R et est expliqué en détail dans les pages Projets R et Importer et exporter des données de ce manuel. Par exemple, pour importer un fichier appelé “data.csv” depuis le dossier projectX, le code serait import((\"data.csv\")).Notez que l’utilisation de setwd() dans les scripts R Markdown n’est pas recommandée – elle ne s’applique qu’au morceau de code dans lequel elle est écrite.Travailler sur un disque plutôt que sur votre ordinateurParce que R Markdown peut rencontrer des problèmes avec pandoc lorsqu’il est exécuté sur un serveur de stockage partagé, il est recommandé que votre dossier soit sur votre machine locale, par exemple dans un projet dans “Mes Documents”. Si vous utilisez Git (fortement recommandé !), cela vous sera familier. Pour plus de détails, consultez les pages du manuel intitulées R sur les lecteurs réseau et Erreurs fréquentes.","code":""},{"path":"rmarkdown.html","id":"les-composantes-du-r-markdown","chapter":"40 Production de rapports avec R Markdown","heading":"40.3 Les composantes du R Markdown","text":"Un document R Markdown peut être édité dans RStudio tout comme un script R standard. Lorsque vous démarrez un nouveau script R Markdown, RStudio essaie d’être utile en affichant un modèle qui explique les différentes sections d’un script R Markdown.Ce qui suit est ce qui apparaît lorsque vous démarrez un nouveau script Rmd destiné à produire une sortie HTML (comme dans la section précédente).Comme vous pouvez le constater, un fichier Rmd comporte trois éléments de base : YAML, le texte Markdown et les morceaux de code R.Ces éléments vont créer et devenir votre document de sortie. Voir le diagramme ci-dessous :","code":""},{"path":"rmarkdown.html","id":"métadonnées-yaml","chapter":"40 Production de rapports avec R Markdown","heading":"Métadonnées YAML","text":"Appelées “métadonnées YAML” ou simplement “YAML”, elles se trouvent en haut du document R Markdown. Cette section du script indique à votre fichier Rmd le type de sortie à produire, les préférences de formatage et d’autres métadonnées telles que le titre du document, l’auteur et la date. Il existe d’autres utilisations qui ne sont pas mentionnées ici (mais auxquelles il est fait référence dans la section “Produire une sortie”). Notez que l’indentation est importante ; les tabulations ne sont pas acceptées, mais les espaces le sont.Cette section doit commencer par une ligne contenant seulement trois tirets --- et doit se terminer par une ligne contenant seulement trois tirets ---. Les paramètres YAML se présentent sous forme de paires key:value. L’emplacement des deux points dans YAML est important : les paires key:value sont séparées par des deux points (et non par des signes égaux !).Le fichier YAML doit commencer par les métadonnées du document. L’ordre de ces paramètres YAML primaires (non indentés) n’pas d’importance. Par exemple :Vous pouvez utiliser du code R dans des valeurs YAML en l’écrivant en tant que code en ligne (précédé de r dans les crochets arrière) mais aussi entre guillemets (voir l’exemple ci-dessus pour date:).Dans l’image ci-dessus, parce que nous avons cliqué que notre sortie par défaut serait un fichier html, nous pouvons voir que le YAML dit output: html_document. Cependant, nous pouvons aussi changer cela pour dire powerpoint_presentation ou word_document ou même pdf_document.","code":"title: \"Mon document\"\nauthor: \"Moi\"\ndate: \"2023-05-21\""},{"path":"rmarkdown.html","id":"texte","chapter":"40 Production de rapports avec R Markdown","heading":"Texte","text":"Il s’agit de la narration de votre document, y compris les titres et les en-têtes. Il est écrit dans le langage “markdown”, qui est utilisé dans de nombreux logiciels différents.Vous trouverez ci-dessous les principales façons d’écrire ce texte. Vous trouverez une documentation plus complète sur l’antisèche R Markdown sur le site Web de RStudio.","code":""},{"path":"rmarkdown.html","id":"nouvelles-lignes","chapter":"40 Production de rapports avec R Markdown","heading":"Nouvelles lignes","text":"Dans le format R Markdown, pour aller à une nouvelle ligne, saisissez deux espaces à la fin de la ligne précédente, puis appuyez sur Entrée/Retour.","code":""},{"path":"rmarkdown.html","id":"police","chapter":"40 Production de rapports avec R Markdown","heading":"Police","text":"Entourez votre texte normal de ces caractères pour modifier la façon dont il apparaît dans le fichier de sortie.Caractères de soulignement (_text_) ou astérisque simple (*text*) pour italiciser.Double astérisque (**text**) pour mettre le texte en gras.Des “quotes” inversés (text) pour afficher le texte sous forme de code.L’apparence réelle de la police peut être définie en utilisant des modèles spécifiques (spécifiés dans les métadonnées YAML ; voir l’exemple des onglets).","code":""},{"path":"rmarkdown.html","id":"couleur","chapter":"40 Production de rapports avec R Markdown","heading":"Couleur","text":"Il n’existe pas de mécanisme simple pour modifier la couleur du texte dans R Markdown. Une solution de contournement, si votre fichier de sortie est un fichier HTML, consiste à ajouter une ligne HTML dans le texte Markdown. Le code HTML ci-dessous imprimera une ligne de texte en rouge gras.DANGER: Ceci est un avertissement.","code":"<span style=\"color: red;\">**_DANGER:_** Ceci est un avertissement.<\/span>  "},{"path":"rmarkdown.html","id":"titres-et-en-têtes","chapter":"40 Production de rapports avec R Markdown","heading":"Titres et en-têtes","text":"Un symbole de hachage dans une partie de texte d’un script R Markdown crée un titre. C’est différent d’un morceau de code R dans le script, dans lequel un symbole de hachage est un mécanisme pour commenter/annoter/désactiver, comme dans un script R normal.Différents niveaux de titre sont établis avec différents nombres de symboles de hachage au début d’une nouvelle ligne. Un symbole de hachage est un titre ou une rubrique primaire. Deux symboles de hachage correspondent à un sous-titre (deuxième niveau). Les titres de troisième et quatrième niveaux peuvent être établis avec un nombre croissant de symboles de hachage.","code":"# Titre (Titre 1)\n\n## Sous-titre (Titre 2)\n\n### Sous-sous-titre (Titre 3)"},{"path":"rmarkdown.html","id":"puces-et-numérotation","chapter":"40 Production de rapports avec R Markdown","heading":"Puces et numérotation","text":"Utilisez des astérisques (*) pour créer une liste de puces. Terminez la phrase précédente, saisissez deux espaces, tapez sur Entrée/Retour deux fois, puis commencez vos puces. Insérez un espace entre l’astérisque et le texte de votre puce. Après chaque puce, saisissez deux espaces, puis appuyez sur la touche Entrée/Retour. Les sous-puces fonctionnent de la même manière, mais sont en retrait. Les numérotations fonctionnent de la même manière, mais au lieu d’un astérisque, écrivez 1), 2), etc. Voici à quoi pourrait ressembler le texte de votre script R Markdown.","code":"\nVoici mes puces (il y a deux espaces après ce deux-points):    \n\n\n* Puce 1 (suivi de deux espaces et Entrée/Retour) \n* Puce 2 (suivi de deux espaces et Entrée/Retour) \n  * Sous-puce 1 (suivi de deux espaces et Entrée/Retour)  \n  * Sous-puce 2 (suivi de deux espaces et Entrée/Retour)  \n  "},{"path":"rmarkdown.html","id":"commenter-du-texte","chapter":"40 Production de rapports avec R Markdown","heading":"Commenter du texte","text":"Vous pouvez “commenter” du texte R Markdown de la même manière que vous pouvez utiliser le “#” pour commenter une ligne de code R dans un chunk R. Il suffit de mettre le texte en surbrillance et d’appuyer sur Ctrl+Shift+c (Cmd+Shift+c pour Mac). Le texte sera entouré de flèches et deviendra vert. Il n’apparaîtra pas dans votre résultat.","code":""},{"path":"rmarkdown.html","id":"morceaux-de-code","chapter":"40 Production de rapports avec R Markdown","heading":"Morceaux de code","text":"Les sections du script qui sont dédiées à l’exécution du code R sont appelées “chunks”. C’est là que vous pouvez charger des “packages”, importer des données et effectuer la gestion et la visualisation des données. Il peut y avoir de nombreux “chunks” de code (mettez en autant qu’il en faut pour un code plus lisible et comprehensible), ils peuvent donc vous aider à organiser votre code R en parties, éventuellement entrecoupées de texte. Remarque : ces “chunks” auront une couleur de fond légèrement différente de celle de la partie narrative du document.Chaque chunk s’ouvre sur une ligne qui commence par trois “quotes” inversés et des crochets qui contiennent les paramètres du chunk ({ }). Le chunk se termine par trois autres “quotes” inversés.Vous pouvez créer un nouveau chunk en le tapant vous-même, en utilisant le raccourci clavier “Ctrl + Alt + ” (ou Cmd + Shift + r sur Mac), ou en cliquant sur l’icône verte “insérer un nouveau chunk de code” en haut de votre éditeur de script.Quelques remarques sur le contenu des accolades { }:Ils commencent par ‘r’ pour indiquer que le nom du langage dans le chunk est R.Après le r, vous pouvez éventuellement écrire un “nom” de chunk – ceux-ci ne sont pas nécessaires mais peuvent vous aider à organiser votre travail. Notez que si vous nommez vos morceaux, vous devez TOUJOURS utiliser des noms uniques, sinon R se plaindra lorsque vous essaierez de compiler le rendu.Les accolades peuvent également inclure d’autres options, écrites comme tag=value, telles que :eval = FALSE pour ne pas exécuter le code Recho = FALSE pour ne pas imprimer le code source R du chunk dans le document de sortie.warning = FALSE pour ne pas afficher les avertissements générés par le code Rmessage = FALSE pour ne pas imprimer les messages produits par le code R.include = soit TRUE/FALSE si l’veut inclure les sorties du chunk (par exemple les graphiques) dans le document..width = et .height = - à fournir dans le style .width = \"75%\"fig.align = \"center\" ajuste l’alignement d’une figure sur la page.fig.show='hold' si votre chunk imprime plusieurs figures et que vous souhaitez qu’elles soient affichées les unes à côté des autres (à associer à .width = c(\"33%\", \"67%\"). Vous pouvez également définir fig.show='asis' pour les afficher en dessous du code qui les génère, 'hide' pour les cacher, ou 'animate' pour concaténer plusieurs d’entre elles dans une animation.`Un en-tête de chunk doit être écrit en une ligne.Essayez d’éviter les points, les caractères de soulignement et les espaces. Utilisez des tirets ( - ) à la place si vous avez besoin d’un séparateur.Lisez plus en détail les options knitr ici.Certaines des options ci-dessus peuvent être configurées par clique-bouton en utilisant les boutons de réglage en haut à droite du chunk. Ici, vous pouvez spécifier quelles parties du chunk vous voulez que le document rendu inclue, à savoir le code, les sorties et les avertissements. Cela se traduira par des préférences écrites entre les crochets, par exemple echo=FALSE si vous spécifiez que vous voulez seulement afficher le rendu et non le code qui le produit ‘Show output ’.Il y aussi deux flèches en haut à droite de chaque chunk, qui sont utiles pour exécuter du code dans un chunk, ou tout le code des chunks précédents. Survolez-les pour voir ce qu’elles font.Pour que les options globales soient appliquées à tous les chunks du script, vous pouvez les configurer dans le tout premier chunk de code R du script. Par exemple, pour que seules les sorties soient affichées pour chaque chunk de code et non le code lui-même, vous pouvez inclure cette commande dans le chunk de code R :","code":"\nknitr::opts_chunk$set(echo = FALSE) "},{"path":"rmarkdown.html","id":"inclure-du-code-r-dans-la-partie-texte-du-markdown","chapter":"40 Production de rapports avec R Markdown","heading":"Inclure du code R dans la partie Texte du Markdown","text":"Vous pouvez également inclure un minimum de code R dans le corps du texte de votre document Markdown en utilisant les “quotes” inversés. Dans les “quotes” inversés, commencez le code par “r” et un espace, afin que RStudio sache qu’il doit évaluer le code en tant que code R. Voir l’exemple ci-dessous.L’exemple ci-dessous montre plusieurs niveaux de titres, des puces, et utilise du code R pour la date actuelle (Sys.Date()) pour l’évaluer en une date imprimée.L’exemple ci-dessus est simple (affichage de la date actuelle), mais en utilisant la même syntaxe, vous pouvez afficher des valeurs produites par un code R plus complexe (par exemple, pour calculer le min, la médiane, le max d’une colonne). Vous pouvez également intégrer des objets R ou des valeurs qui ont été créés dans des morceaux de code R plus tôt dans le script.Par exemple, le script ci-dessous calcule la proportion de cas âgés de moins de 18 ans, en utilisant les fonctions tidyverse, et crée les objets less18, total, et less18prop. Cette valeur dynamique est insérée dans le texte suivant. Nous voyons à quoi cela ressemble lorsqu’il est rendu dans un document Word.","code":""},{"path":"rmarkdown.html","id":"images","chapter":"40 Production de rapports avec R Markdown","heading":"Images","text":"Vous pouvez inclure des images dans votre document R Markdown en utilisant l’une des méthodes suivantes:Si la première méthode ne marche pas, esssayez d’utiliser: knitr::include_graphics() Rappelez-vous, votre chemin de fichier pourrait être écrit en utilisant le package. ","code":"![](\"path/to/image.png\")  \nknitr::include_graphics(\"path/to/image.png\")\nknitr::include_graphics(here::here(\"path\", \"to\", \"image.png\"))"},{"path":"rmarkdown.html","id":"tables","chapter":"40 Production de rapports avec R Markdown","heading":"Tables","text":"Créez un tableau en utilisant des traits d’union ( - ) et des barres ( | ). Le nombre de traits d’union avant/entre les barres permet de déterminer le nombre d’espaces dans la cellule avant que le texte ne commence à se positionner.Le code ci-dessus produit le tableau ci-dessous :","code":"Column 1 |Column  2 |Column 3\n---------|----------|--------\nCell A   |Cell B    |Cell C\nCell D   |Cell E    |Cell F"},{"path":"rmarkdown.html","id":"sections-à-onglets","chapter":"40 Production de rapports avec R Markdown","heading":"Sections à onglets","text":"Pour les sorties HTML, peut organiser les sections en “onglets”. Il suffit d’ajouter .tabset dans les accolades { } qui sont ouvertes juste après le titre de la section. Tous les sous-titres situés sous ce titre (jusqu’à un autre titre de même niveau) apparaîtront sous forme d’onglets sur lesquels l’utilisateur pourra cliquer. En savoir plus iciVous pouvez ajouter une option supplémentaire .tabset-pills après .tabset pour donner aux onglets eux-mêmes un aspect plus esthétique avec un fond en noir.","code":""},{"path":"rmarkdown.html","id":"structure-du-fichier-r-markdown","chapter":"40 Production de rapports avec R Markdown","heading":"40.4 Structure du fichier R Markdown","text":"Il existe plusieurs façons de structurer votre fichier R Markdown et les scripts R associés. Chacune présente des avantages et des inconvénients :R Markdown autonome - tout ce qui est nécessaire pour le rapport est importé ou créé dans le même fichier R Markdown.\nFaire appel à (sourcer) d’autres fichiers - Vous pouvez exécuter des scripts R externes avec la commande source() et utiliser leurs sorties dans le Rmd.\nScripts dépendant ou dérivé (“child script”) - un mécanisme alternatif pour la commande source()\nR Markdown autonome - tout ce qui est nécessaire pour le rapport est importé ou créé dans le même fichier R Markdown.Faire appel à (sourcer) d’autres fichiers - Vous pouvez exécuter des scripts R externes avec la commande source() et utiliser leurs sorties dans le Rmd.Scripts dépendant ou dérivé (“child script”) - un mécanisme alternatif pour la commande source()Utiliser un “runfile” - Exécuter des commandes dans un script R avant de rendre le Markdown R.Utiliser un “runfile” - Exécuter des commandes dans un script R avant de rendre le Markdown R.","code":""},{"path":"rmarkdown.html","id":"rmd-autonome","chapter":"40 Production de rapports avec R Markdown","heading":"Rmd autonome","text":"Pour un rapport relativement simple, peut choisir d’organiser notre script R Markdown de manière à ce qu’il soit “autonome” et n’implique pas de scripts externes.Tout ce dont besoin pour exécuter le script R Markdown est importé ou créé dans le fichier Rmd, y compris tous les morceaux de code et le chargement des “packages”. Cette approche “autonome” est appropriée lorsqu’n’pas besoin de faire beaucoup de traitement de données (par exemple, elle apporte un fichier de données propre ou semi-propre) et que le rendu du R Markdown ne prendra pas trop de temps.Dans ce scénario, une organisation logique du script R Markdown pourrait être la suivante :Définir les options globales de knitr.Chargement des “packages”Importer les donnéesTraiter les donnéesProduire des résultats (tableaux, graphiques, etc.)Sauvegarder les résultats, le cas échéant (.csv, .png, etc.)","code":""},{"path":"rmarkdown.html","id":"faire-appel-à-sourcer-dautres-fichiers","chapter":"40 Production de rapports avec R Markdown","heading":"Faire appel à (sourcer) d’autres fichiers","text":"Une variante de l’approche “autonome” consiste à faire en sorte que les morceaux de code R Markdown “sourcent” (exécutent) d’autres scripts R. Cela peut rendre votre script R Markdown moins encombré, plus simple et plus facile à organiser. Cela peut rendre votre script R Markdown moins encombré, plus simple et plus facile à organiser. Elle peut également être utile si vous souhaitez afficher les chiffres finaux au début du rapport. Dans cette approche, le script R Markdown final combine simplement les sorties prétraitées dans un document.Une façon de le faire est de fournir les scripts R (chemin et nom de fichier avec extension) à la commande base R source().Notez que lorsque vous utilisez source() dans le R Markdown, les fichiers externes seront toujours exécutés pendant le rendu de votre fichier Rmd. Par conséquent, chaque script est exécuté à chaque fois que vous rendez le rapport. Ainsi, le fait d’avoir ces commandes source() dans le R Markdown n’accélère pas votre temps d’exécution, et ne vous aide pas beaucoup à débloquer, puisque les erreurs produites seront toujours affichées lors de l’exécution du R Markdown.Une alternative est d’utiliser l’option child = knitr.Vous devez être conscient des différents environnements de R. Les objets créés dans un environnement ne seront pas nécessairement disponibles dans l’environnement utilisé par le Markdown R.","code":"\nsource(\"your-script.R\", local = knitr::knit_global())\n# ou sys.source(\"your-script.R\", envir = knitr::knit_global())"},{"path":"rmarkdown.html","id":"runfile","chapter":"40 Production de rapports avec R Markdown","heading":"Runfile","text":"Par exemple, vous pouvez charger les “packages”, charger et nettoyer les données, et même créer les graphiques d’intérêt avant render(). Ces étapes peuvent se produire dans le script R, ou dans d’autres scripts qui sont “sourcés”. Tant que ces commandes se produisent dans la même session RStudio et que les objets sont enregistrés dans l’environnement, les objets peuvent ensuite être appelés dans le contenu Rmd. Ensuite, le R markdown lui-même ne sera utilisé que pour l’étape finale - pour produire la sortie avec tous les objets prétraités. Il est beaucoup plus facile de débloquer si quelque chose dans le code ne va pas.Cette approche implique l’utilisation du script R qui contient la ou les commandes render() pour pré-traiter les objets qui alimentent le balisage R.Cette approche est utile pour les raisons suivantes :Des messages d’erreur plus informatifs - ces messages seront générés par le script R, et non par le Markdown R. Les erreurs du Markdown R ont tendance à vous indiquer que vous n’avez pas besoin de les corriger. Les erreurs du Markdown R ont tendance à vous indiquer quel “chunk” un problème, mais ne vous diront pas quelle ligne.Le cas échéant, vous pouvez exécuter des étapes de traitement longues avant la commande render() - elles ne seront exécutées qu’une seule fois.Dans l’exemple ci-dessous, nous avons un script R séparé dans lequel nous pré-traitons un objet data dans l’environnement R, puis nous rendons le fichier “create_output.Rmd” en utilisant render().","code":"\ndata <- import(\"datafile.csv\") %>%       # Charger les données et les sauvegarder dans l'environnement\n  select(age, hospital, weight)          # Sélectionner les colonnes d'interet\n\nrmarkdown::render(input = \"create_output.Rmd\")   # Creer le fichier Rmd "},{"path":"rmarkdown.html","id":"structure-du-dossier","chapter":"40 Production de rapports avec R Markdown","heading":"Structure du dossier","text":"Le flux de travail concerne également la structure globale des dossiers, par exemple un dossier “output” pour les documents et figures créés, et des dossiers “data” ou “inputs” pour les données nettoyées. Nous n’entrerons pas dans les détails ici, mais consultez la page Organisation des rapports de routine.","code":""},{"path":"rmarkdown.html","id":"production","chapter":"40 Production de rapports avec R Markdown","heading":"40.5 Produire le document","text":"Vous pouvez produire le document de la manière suivante :Manuellement en appuyant sur le bouton “Knit” en haut de l’éditeur de script RStudio (rapide et facile).Exécuter la commande render() (exécutée en dehors du script R Markdown)","code":""},{"path":"rmarkdown.html","id":"option-1-bouton-knit","chapter":"40 Production de rapports avec R Markdown","heading":"Option 1: Bouton “Knit”","text":"Une fois le fichier Rmd ouvert, appuyez sur l’icône/bouton “Knit” en haut du fichier.R Studio affichera la progression dans un onglet “R Markdown” près de votre console R. Le document s’ouvrira automatiquement une fois terminé.Le document sera enregistré dans le même dossier que votre script R markdown, et avec le même nom de fichier (à l’exception de l’extension). Ce n’est évidemment pas idéal pour le contrôle de version (il sera écrasé à chaque fois que vous cliquerez pour produire le fichier Rmd, à moins d’être déplacé manuellement), car vous devrez peut-être renommer le fichier vous-même (par exemple, ajouter une date).C’est le bouton de raccourci de RStudio pour la fonction render() de rmarkdown. Cette approche n’est compatible qu’avec un fihcier R markdown autonome, où tous les composants nécessaires existent ou proviennent du fichier.","code":""},{"path":"rmarkdown.html","id":"option-2-commande-render","chapter":"40 Production de rapports avec R Markdown","heading":"Option 2: Commande render()","text":"Une autre façon de produire votre sortie R Markdown est d’exécuter la fonction render() (du “package” rmarkdown). Vous devez exécuter cette commande en dehors du script R Markdown - donc soit dans un script R séparé (souvent appelé “fichier d’exécution”), soit comme une commande autonome dans la Console R.Comme avec “knit”, les paramètres par défaut enregistreront la sortie Rmd dans le même dossier que le script Rmd, avec le même nom de fichier (à part l’extension de fichier). Par exemple, “mon_rapport.Rmd”, une fois exécuté, créera “mon_rapport.docx” si vous décider de sortir le fichier vers un document Word. Cependant, en utilisant render() vous avez la possibilité d’utiliser des paramètres différents. render() peut accepter des arguments tels que :output_format = C’est le format de sortie vers lequel convertir (par exemple, \"html_document\", \"pdf_document\", \"word_document\", ou \"\"). Vous pouvez également le spécifier dans le YAML à l’intérieur du script R Markdown.output_file = C’est le nom du fichier de sortie (et le chemin du fichier). Il peut être créé par des fonctions R telles que () ou str_glue(), comme illustré ci-dessous.output_dir = C’est un répertoire de sortie (dossier) pour enregistrer le fichier. Cela vous permet de choisir un autre répertoire que celui dans lequel le fichier Rmd est enregistré.output_options = Vous pouvez fournir une liste d’options qui remplaceront celles du script YAML (par exemple )output_yaml = Vous pouvez fournir le chemin d’accès à un fichier .yml qui contient des spécifications YAML.params = Voir la section sur les paramètres ci-dessous.Voir la liste complète iciPar exemple, pour améliorer le contrôle de version, la commande suivante enregistre le fichier de sortie dans un sous-dossier “outputs”, avec la date du jour dans le nom du fichier. Pour créer le nom du fichier, la fonction str_glue() du paquet stringr est utilisée pour ‘coller’ ensemble des chaînes statiques (écrites en clair) avec du code R dynamique (écrit entre crochets). Par exemple, si nous sommes le 10 avril 2021, le nom du fichier ci-dessous sera “Report_2021-04-10.docx”. Voir la page sur Caractères et chaînes de caractères pour plus de détails sur str_glue().Au fur et à mesure de l’exécution du fichier Rmarkdown, la console RStudio vous montrera la progression du rendu jusqu’à 100%, et un message final pour indiquer que l’exécution est achevée.","code":"\nrmarkdown::render(input = \"my_report.Rmd\")\nrmarkdown::render(\n  input = \"create_output.Rmd\",\n  output_file = stringr::str_glue(\"outputs/Report_{Sys.Date()}.docx\")) "},{"path":"rmarkdown.html","id":"option-3-package-reportfactory","chapter":"40 Production de rapports avec R Markdown","heading":"Option 3 : package reportfactory","text":"Le “package” R reportfactory offre une méthode alternative d’organisation et de compilation de rapports R Markdown adapté aux cas où vous exécutez des rapports régulièrement (par exemple, quotidiennement, hebdomadairement…). Il facilite la compilation de plusieurs fichiers R Markdown et l’organisation de leurs sorties. Essentiellement, il fournit une “usine” à partir de laquelle vous pouvez exécuter les rapports R Markdown, obtenir des dossiers automatiquement horodatés pour les fichiers de sortie, et avoir un contrôle de version “léger”.Pour en savoir plus sur ce flux de travail, consultez la page Organisation des rapports de routine.","code":""},{"path":"rmarkdown.html","id":"rapports-paramétrés","chapter":"40 Production de rapports avec R Markdown","heading":"40.6 Rapports paramétrés","text":"Vous pouvez utiliser le paramétrage pour rendre un rapport dynamique, de sorte qu’il puisse être exécuté avec des paramètres spécifiques (par exemple, une date ou un lieu spécifique ou avec certaines options d’exécution). Nous nous concentrons ci-dessous sur les principes de base, mais il existe d’autres détails en ligne sur les rapports paramétrés.En utilisant la liste linéaire des cas Ebola comme exemple, disons que nous voulons exécuter un rapport de surveillance standard pour chaque hôpital chaque jour. Nous montrons comment peut le faire en utilisant des paramètres.Important: les rapports dynamiques sont également possibles sans la structure formelle des paramètres (sans params:), en utilisant de simples objets R dans un script R adjacent. Ceci est expliqué à la fin de cette section.","code":""},{"path":"rmarkdown.html","id":"définition-des-paramètres","chapter":"40 Production de rapports avec R Markdown","heading":"Définition des paramètres","text":"Vous avez plusieurs options pour spécifier les valeurs des paramètres pour votre sortie R Markdown.","code":""},{"path":"rmarkdown.html","id":"option-1-définir-les-paramètres-dans-yaml","chapter":"40 Production de rapports avec R Markdown","heading":"Option 1 : Définir les paramètres dans YAML","text":"Editez le YAML pour inclure une option params:, avec des déclarations indentées pour chaque paramètre que vous voulez définir. Dans cet exemple, nous créons les paramètres date et hôpital, pour lesquels nous spécifions des valeurs. Ces valeurs sont susceptibles de changer à chaque fois que le rapport est exécuté. Si vous utilisez le bouton “Knit” pour produire le résultat, les paramètres auront ces valeurs par défaut. De même, si vous utilisez render(), les paramètres auront ces valeurs par défaut, sauf indication contraire dans la commande render().En arrière-plan, ces valeurs de paramètres sont contenues dans une liste en lecture seule appelée params. Ainsi, vous pouvez insérer les valeurs des paramètres dans le code R comme vous le feriez pour un autre objet/valeur R dans votre environnement. Tapez simplement params$ suivi du nom du paramètre. Par exemple params$hospital pour représenter le nom de l’hôpital (“Central Hospital” par défaut).Notez que les paramètres peuvent également contenir les valeurs vrai ou faux, et donc ceux-ci peuvent être inclus dans vos options knitr pour un “chunk” R. Par exemple, vous pouvez définir {r, eval=params$run} au lieu de {r, eval=FALSE}, et maintenant si le chunk s’exécute ou non dépend de la valeur d’un paramètre run:.Notez que pour les paramètres qui sont des dates, ils seront entrés comme une chaîne. Donc, pour que params$date soit interprété dans le code R, il faudra probablement l’envelopper avec .Date() ou une fonction similaire pour le convertir en classe Date.","code":"---\ntitle: Surveillance report\noutput: html_document\nparams:\n date: 2021-04-10\n hospital: Central Hospital\n---"},{"path":"rmarkdown.html","id":"option-2-définir-les-paramètres-dans-render","chapter":"40 Production de rapports avec R Markdown","heading":"Option 2 : Définir les paramètres dans render()","text":"Comme mentionné plus haut, une alternative à l’appui sur le bouton “Knit” pour produire la sortie est d’exécuter la fonction render() à partir d’un script séparé. Dans ce dernier cas, vous pouvez spécifier les paramètres à utiliser dans ce rendu à l’argument params = de render().Notez que toutes les valeurs de paramètres fournies ici vont écraser leurs valeurs par défaut si elles sont écrites dans le YAML. Nous écrivons les valeurs entre guillemets car dans ce cas, elles doivent être définies comme des valeurs de type chaîne de caractères.La commande ci-dessous rend “surveillance_report.Rmd”, spécifie un nom de fichier de sortie dynamique et un dossier, et fournit une list() de deux paramètres et leurs valeurs à l’argument params =.","code":"\nrmarkdown::render(\n  input = \"surveillance_report.Rmd\",  \n  output_file = stringr::str_glue(\"outputs/Report_{Sys.Date()}.docx\"),\n  params = list(date = \"2021-04-10\", hospital  = \"Central Hospital\"))"},{"path":"rmarkdown.html","id":"option-3-définir-les-paramètres-à-laide-dune-interface-utilisateur-graphique","chapter":"40 Production de rapports avec R Markdown","heading":"Option 3 : Définir les paramètres à l’aide d’une interface utilisateur graphique","text":"Pour une sensation plus interactive, vous pouvez également utiliser l’interface utilisateur graphique (GUI) pour sélectionner manuellement les valeurs des paramètres. Pour ce faire, nous pouvons cliquer sur le menu déroulant à côté du bouton “Knit” et choisir “Knit parameters”.Une fenêtre pop-apparaît alors pour vous permettre de saisir les valeurs des paramètres établis dans le YAML du document.Vous pouvez réaliser la même chose avec une commande render() en spécifiant params = \"ask\", comme démontré ci-dessous.Toutefois, la saisie de valeurs dans cette fenêtre “pop-” est sujette à des erreurs et à des fautes d’orthographe. Vous préférerez peut-être ajouter des restrictions aux valeurs qui peuvent être saisies dans les menus déroulants. Vous pouvez le faire en ajoutant dans le YAML plusieurs spécifications pour chaque entrée params: .label: est le titre de ce menu déroulant particulier.value: est la valeur par défaut (de départ)input: est défini sur select pour le menu déroulantchoices: Donne les valeurs éligibles dans le menu déroulantCi-dessous, ces spécifications sont écrites pour le paramètre hôpital.Lors de l’exécution du fichier (via le bouton “tricot avec des paramètres” ou par render()), la fenêtre pop-aura des options déroulantes à sélectionner.","code":"rmarkdown::render(\n  input = \"surveillance_report.Rmd\",  \n  output_file = stringr::str_glue(\"outputs/Report_{Sys.Date()}.docx\"),\n  params = “ask”)---\ntitle: Surveillance report\noutput: html_document\nparams:\n date: 2021-04-10\n hospital: \n  label: “Town:”\n  value: Central Hospital\n  input: select\n  choices: [Central Hospital, Military Hospital, Port Hospital, St. Mark's Maternity Hospital (SMMH)]\n---"},{"path":"rmarkdown.html","id":"exemple-paramétré","chapter":"40 Production de rapports avec R Markdown","heading":"Exemple paramétré","text":"Le code suivant crée des paramètres pour date et ’hôpital, qui sont utilisés dans le R Markdown comme params$date et params$hospital, respectivement.Dans le rapport qui en résulte, vous pouvez voir comment les données sont filtrées sur l’hôpital spécifique, et le titre du graphique fait référence à l’hôpital et à la date corrects. Nous utilisons ici le fichier “linelist_cleaned.rds”, mais il serait particulièrement approprié que la linelist elle-même comporte également un horodatage pour s’aligner sur la date paramétrée.Lancer l’excecution produit la sortie finale avec la police et la mise en page par défaut.","code":""},{"path":"rmarkdown.html","id":"paramétrisation-sans-params","chapter":"40 Production de rapports avec R Markdown","heading":"Paramétrisation sans params","text":"Si vous exécutez un fichier R Markdown avec render() à partir d’un script séparé, vous pouvez en fait avoir le résultat du paramétrage sans utiliser la fonctionnalité params:.Par exemple, dans le script R qui contient la commande render(), vous pouvez simplement définir hôpital et date comme deux objets R (valeurs) avant la commande render(). Dans le R Markdown, vous n’auriez pas besoin d’avoir une section params: dans le YAML, et nous ferions référence à l’objet date plutôt qu’à params$date et à hôpital plutôt qu’à params$hospital.Suivre cette approche signifie que vous ne pouvez pas “Exécuter avec des paramètres”, utiliser l’interface graphique ou inclure des options d’exécution dans les paramètres. Cependant, elle permet de simplifier le code, ce qui peut être avantageux.","code":"\n# Il s'agit d'un script R distinct du fichier R Markdown.\n\n# définir les objets R\nhospital <- \"Central Hospital\"\ndate <- \"2021-04-10\"\n\n# Exécuter le fichier R markdown\nrmarkdown::render(input = \"create_output.Rmd\") "},{"path":"rmarkdown.html","id":"rapports-en-boucle","chapter":"40 Production de rapports avec R Markdown","heading":"40.7 Rapports en boucle","text":"Nous pouvons vouloir exécuter un rapport plusieurs fois, en faisant varier les paramètres d’entrée, afin de produire un rapport pour chaque juridiction/unité. Cela peut être fait en utilisant des outils d’itération, qui sont expliqués en détail dans la page Itération, boucles et listes. Les options comprennent le paquet purrr, ou l’utilisation d’une boucle comme expliqué ci-dessous.Ci-dessous, nous utilisons une simple boucle pour générer un rapport de surveillance pour tous les hôpitaux d’intérêt. Ceci est fait avec une seule commande (au lieu de changer manuellement le paramètre de l’hôpital un par un). La commande permettant de rendre les rapports doit exister dans un script séparé sauf le rapport Rmd. Ce script contiendra également des objets définis à parcourir en boucle - la date du jour, et un vecteur de noms d’hôpitaux à parcourir en boucle.Nous introduisons ensuite ces valeurs une par une dans la commande render() en utilisant une boucle, qui exécute la commande une fois pour chaque valeur du vecteur hospitals. La lettre représente la position de l’index (1 à 4) de l’hôpital actuellement utilisé dans cette itération, tel que hospital_list[1] serait “Central Hospital”. Cette information est fournie à deux endroits dans la commande render() :Au nom du fichier, de sorte que le nom du fichier de la première itération, s’il est produit le 10 avril 2021, sera “Report_Central Hospital_2021-04-10.docx”, enregistré dans le sous-dossier “output” du répertoire de travail.Pour params = de sorte que le Rmd utilise le nom de l’hôpital en interne chaque fois que la valeur params$hospital est appelée (par exemple pour filtrer l’ensemble de données sur l’hôpital particulier uniquement). Dans cet exemple, quatre fichiers seront créés - un pour chaque hôpital.","code":"\nhospitals <- c(\"Central Hospital\",\n                \"Military Hospital\", \n                \"Port Hospital\",\n                \"St. Mark's Maternity Hospital (SMMH)\") \nfor(i in 1:length(hospitals)){\n  rmarkdown::render(\n    input = \"surveillance_report.Rmd\",\n    output_file = str_glue(\"output/Report_{hospitals[i]}_{Sys.Date()}.docx\"),\n    params = list(hospital  = hospitals[i]))\n}       "},{"path":"rmarkdown.html","id":"canevas-modèles-de-document","chapter":"40 Production de rapports avec R Markdown","heading":"40.8 Canevas (Modèles de document)","text":"En utilisant un canevas de document (exemple type) qui contient le formatage souhaité, vous pouvez ajuster l’esthétique de la sortie Rmd. Vous pouvez par exemple créer un fichier MS Word ou Powerpoint qui contient des pages/diapositives avec les dimensions, les filigranes, les fonds et les polices de caractères souhaités.","code":""},{"path":"rmarkdown.html","id":"documents-word","chapter":"40 Production de rapports avec R Markdown","heading":"Documents Word","text":"Pour créer un canevas, commencez un nouveau document Word (ou utilisez une sortie existante avec un formatage qui vous convient), et modifiez les polices en définissant les Styles. Dans Style,les titres 1, 2 et 3 font référence aux différents niveaux d’en-tête markdown (respectivement # Header 1, ## Header 2 et ## Header 3). Cliquez avec le bouton droit de la souris sur le style et cliquez sur “modifier” pour changer le formatage de la police ainsi que le paragraphe (par exemple, vous pouvez introduire des sauts de page avant certains styles, ce qui peut faciliter l’espacement). D’autres aspects du document Word, tels que les marges, la taille de la page, les en-têtes, etc., peuvent être modifiés comme un document Word habituel dans lequel vous travaillez directement.","code":""},{"path":"rmarkdown.html","id":"documents-powerpoint","chapter":"40 Production de rapports avec R Markdown","heading":"Documents Powerpoint","text":"Comme ci-dessus, créez un nouveau jeu de diapositives ou utilisez un fichier Powerpoint existant avec le formatage souhaité. Pour une édition plus poussée, cliquez sur ‘View’ et ‘Slide Master’. À partir de là, vous pouvez modifier l’apparence de la diapositive “de base” en modifiant le formatage du texte dans les zones de texte, ainsi que les dimensions de l’arrière-plan/de la page pour l’ensemble de la page.Malheureusement, l’édition des fichiers Powerpoint est un peu moins souple :Un en-tête de premier niveau (# Header 1) deviendra automatiquement le titre d’une nouvelle diapositive,Un texte ## Header 2 n’apparaîtra pas comme un sous-titre mais comme un texte dans la zone de texte principale de la diapositive (à moins que vous ne trouviez un moyen de manoeuvrer la slide de base).Les graphiques et les tableaux générés seront automatiquement placés dans de nouvelles diapositives. Vous devrez les combiner, par exemple avec la fonction patchwork pour combiner les ggplots, afin qu’ils apparaissent sur la même page. Consultez cet article de blog sur l’utilisation du paquet patchwork pour placer plusieurs images sur une seule diapositive.Voir le paquet officer pour un outil permettant de travailler plus en profondeur avec les présentations Powerpoint.","code":""},{"path":"rmarkdown.html","id":"intégration-des-canevas-modèle-de-document-dans-le-yaml","chapter":"40 Production de rapports avec R Markdown","heading":"Intégration des canevas (modèle de document) dans le YAML","text":"Une fois qu’un canevas est préparé, le détail de celui-ci peut être ajouté dans le YAML du fichier Rmd sous la ligne “output” et sous l’endroit où le type de document est spécifié (qui va sur une ligne séparée elle-même). Notons que reference_doc peut être utilisé pour les modèles de diapositives Powerpoint.Il est plus facile de sauvegarder le canevas dans le même dossier que celui où se trouve le fichier Rmd (comme dans l’exemple ci-dessous), ou dans un sous-dossier.","code":"---\ntitle: Surveillance report\noutput: \n word_document:\n  reference_docx: \"template.docx\"\nparams:\n date: 2021-04-10\n hospital: Central Hospital\ntemplate:\n \n---"},{"path":"rmarkdown.html","id":"formatage-des-fichiers-html","chapter":"40 Production de rapports avec R Markdown","heading":"Formatage des fichiers HTML","text":"Les fichiers HTML n’utilisent pas de modèles, mais les styles peuvent être configurés dans le YAML. Les HTML sont des documents interactifs, et sont particulièrement flexibles. Nous couvrons ici quelques options de base.Table des matières : peut ajouter une table des matières avec toc: true ci-dessous, et aussi spécifier qu’elle reste visible (“flottante”) quand la fait défiler, avec toc_float: true.Table des matières : peut ajouter une table des matières avec toc: true ci-dessous, et aussi spécifier qu’elle reste visible (“flottante”) quand la fait défiler, avec toc_float: true.Thèmes : Nous pouvons nous référer à certains thèmes pré-faits, qui proviennent d’une bibliothèque de thèmes Bootswatch. Dans l’exemple ci-dessous, nous utilisons cerulean. D’autres options incluent : journal, flatly, darkly, readable, spacelab, united, cosmo, lumen, paper, sandstone, simplex, et yeti.Thèmes : Nous pouvons nous référer à certains thèmes pré-faits, qui proviennent d’une bibliothèque de thèmes Bootswatch. Dans l’exemple ci-dessous, nous utilisons cerulean. D’autres options incluent : journal, flatly, darkly, readable, spacelab, united, cosmo, lumen, paper, sandstone, simplex, et yeti.Mise en évidence : Cette configuration modifie l’aspect du texte mis en évidence (par exemple, le code dans les morceaux qui sont affichés). Les styles pris en charge sont default, tango, pygments, kate, monochrome, espresso, zenburn, haddock, breezedark et textmate.Mise en évidence : Cette configuration modifie l’aspect du texte mis en évidence (par exemple, le code dans les morceaux qui sont affichés). Les styles pris en charge sont default, tango, pygments, kate, monochrome, espresso, zenburn, haddock, breezedark et textmate.Voici un exemple de la manière d’intégrer les options ci-dessus dans le YAML.Vous trouverez ci-dessous deux exemples de sorties HTML comportant toutes deux des tables des matières flottantes, mais avec des thèmes et des styles de mise en évidence différents :","code":"---\ntitle: \"HTML example\"\noutput:\n  html_document:\n    toc: true\n    toc_float: true\n    theme: cerulean\n    highlight: kate\n    \n---"},{"path":"rmarkdown.html","id":"contenu-dynamique","chapter":"40 Production de rapports avec R Markdown","heading":"40.9 Contenu dynamique","text":"Dans une sortie HTML, le contenu de votre rapport peut être dynamique. Voici quelques exemples :","code":""},{"path":"rmarkdown.html","id":"tableaux","chapter":"40 Production de rapports avec R Markdown","heading":"Tableaux","text":"Dans un rapport HTML, vous pouvez imprimer des tableaux de données de telle sorte que le contenu soit dynamique, avec des filtres et des barres de défilement. Il existe plusieurs “packages” qui offrent cette possibilité.Pour ce faire, avec le “package” DT, tel qu’il est utilisé dans ce manuel, vous pouvez insérer un morceau de code comme celui-ci :La fonction datatable() affichera le tableau de données fourni comme un tableau dynamique pour le lecteur. Vous pouvez définir rownames = FALSE pour simplifier le côté gauche de la table. filter = \"top\" fournit un filtre sur chaque colonne. Dans l’argument option(), fournissez une liste d’autres spécifications. Nous en incluons deux ci-dessous : pageLength = 5 fixe le nombre de lignes qui apparaissent à 5 (les lignes restantes peuvent être visualisées en cliquant sur les flèches), et scrollX=TRUE active une barre de défilement en bas du tableau (pour les colonnes qui s’étendent trop à droite).Si votre jeu de données est très grand, pensez à n’afficher que les X premières lignes en enveloppant le nom du jeu de données dans head().","code":""},{"path":"rmarkdown.html","id":"les-widgets-html","chapter":"40 Production de rapports avec R Markdown","heading":"Les widgets HTML","text":"Les widgets HTML pour R sont une classe spéciale de “packages” R qui permettent une interactivité accrue en utilisant des bibliothèques JavaScript. Vous pouvez les intégrer dans des sorties HTML R Markdown.Voici quelques exemples courants de ces widgets :Plotly (utilisé dans cette page du manuel et dans la page Graphiques interactifs).visNetwork (utilisé dans la page Chaînes de transmission de ce manuel)Leaflet (utilisé dans la page Bases des GIS de ce manuel)dygraphs (utile pour afficher de manière interactive des données de séries chronologiques)DT (datatable()) (utilisé pour afficher des tableaux dynamiques avec filtre, tri, etc.)La fonction ggplotly() de plotly est particulièrement facile à utiliser. Voir la page Graphiques interactifs.","code":""},{"path":"rmarkdown.html","id":"ressources-23","chapter":"40 Production de rapports avec R Markdown","heading":"40.10 Ressources","text":"De plus amples informations sont disponibles sur le site:https://bookdown.org/yihui/rmarkdown/https://rmarkdown.rstudio.com/articles_intro.htmlUne bonne explication de markdown vs knitr vs Rmarkdown se trouve ici: https://stackoverflow.com/questions/40563479/relationship--r-markdown-knitr-pandoc--bookdown","code":""},{"path":"reportfactory.html","id":"reportfactory","chapter":"41 Organisation des rapports de routine","heading":"41 Organisation des rapports de routine","text":"Cette page couvre le “package” reportfactory, qui est un complément à la page sur Production de rapports avec R Markdown .Ce package est adapté aux cas où exécute des rapports régulièrement (par exemple, quotidiennement, hebdomadairement…). Il facilite la compilation de plusieurs fichiers R Markdown et l’organisation de leurs fichiers de sortie. Essentiellement, il fournit une “fabrique de rapports” (“factory”) qui est une machine d’exécution à partir de laquelle vous pouvez exécuter les rapports R Markdown, obtenir des dossiers automatiquement horodatés pour les fichiers de sortie, et avoir un contrôle de version “léger”.reportfactory est l’un des “packages” développés par RECON (R Epidemics Consortium). Voici leur site Web et Github.","code":""},{"path":"reportfactory.html","id":"préparation-24","chapter":"41 Organisation des rapports de routine","heading":"41.1 Préparation","text":"","code":""},{"path":"reportfactory.html","id":"charger-les-packages-3","chapter":"41 Organisation des rapports de routine","heading":"Charger les packages","text":"Depuis RStudio, installez la dernière version du package reportfactory depuis Github.Vous pouvez le faire via le “package” pacman avec p_load_current_gh() qui forcera l’installation de la dernière version depuis Github. Tapez la chaîne de caractères “reconverse/reportfactory”, qui spécifie l’organisation Github (reconverse) et le répertoire (reportfactory). Vous pouvez également utiliser install_github() du “package” remotes, comme alternative.","code":"\n# Installer et charger la dernière version du package depuis Github\npacman::p_load_current_gh(\"reconverse/reportfactory\")\n#remotes::install_github(\"reconverse/reportfactory\") # alternative"},{"path":"reportfactory.html","id":"nouvelle-factory","chapter":"41 Organisation des rapports de routine","heading":"41.2 Nouvelle “factory”","text":"Pour créer une nouvelle “factory”, exécutez la fonction new_factory(). Ceci créera un nouveau dossier de projet R autonome. Par défaut :“factory” sera ajoutée à votre répertoire de travail.Le nom du projet R de la “factory” sera appelé “new_factory.Rproj”.Votre session RStudio s’installera dans ce projet R.En regardant à l’intérieur de la “factory”, vous pouvez voir que des sous-dossiers et certains fichiers ont été créés automatiquement.Le dossier report_sources contient vos scripts R Markdown, qui génèrent vos rapports.Le dossier outputs contient les fichiers de sortie du rapport (par exemple, HTML, Word, PDF, etc.).Le dossier scripts peut être utilisé pour stocker d’autres scripts R (par exemple, ceux qui proviennent de vos scripts Rmd).Le dossier data peut être utilisé pour contenir vos données à partir desquelles vous travvaillez (les sous-dossiers “raw” et “clean” sont inclus).Un fichier ., afin que vous puissiez utiliser le package pour faire appel aux fichiers dans les sous-dossiers selon leur relation avec le dossier à la racine (voir la page Projets R pour plus de détails).Un fichier gitignore été créé au cas où vous lieriez ce projet R à un répertoire Github (voir Contrôle de version et collaboration avec Git et Github).Un fichier README vide, si vous utilisez un dépôt Github.CAUTION: selon les paramètres de votre ordinateur, des fichiers tels que “.” peuvent exister mais restés cachés.Parmi les paramètres par défaut, en voici quelques-uns que vous pourriez vouloir ajuster dans la commande new_factory() :factory = - Fournit un nom pour le dossier de la “factory” (par défaut “new_factory”)path = - Désigne un chemin de fichier pour la nouvelle “factory” (par défaut le répertoire de travail)report_sources = - Donne un autre nom au sous-dossier qui contient les scripts R Markdown (par défaut, “report_sources”)outputs = Fournit un nom alternatif pour le dossier qui contient les fichiers de sortie du rapport (par défaut “outputs”).Voir ?new_factory pour une liste complète des arguments.Lorsque vous créez la nouvelle “factory”, votre session R est transférée vers le nouveau projet R, vous devez donc charger à nouveau le “package” reportfactory.Maintenant vous pouvez lancer la commande factory_overview() pour voir la structure interne (tous les dossiers et fichiers) de la “factory”.L’“arbre” suivant des dossiers et fichiers de la “factory” est affiché dans la console R. Notez que dans le dossier “data”, il y des sous-dossiers pour les données “raw” et “clean”, et des exemples de données CSV. Il y aussi “example_report.Rmd” dans le dossier “report_sources”.","code":"\n# Ceci créera la \"factory\" dans le répertoire de travail\nnew_factory()\npacman::p_load(reportfactory)\nfactory_overview()            #  afficher l'aperçu de la factory dans la console"},{"path":"reportfactory.html","id":"créer-un-rapport","chapter":"41 Organisation des rapports de routine","heading":"41.3 Créer un rapport","text":"À partir du projet R de la fabrique, créez un rapport R Markdown comme vous le feriez normalement, et enregistrez-le dans le dossier “report_sources”. Consultez la page Production de rapports avec R Markdown pour obtenir des instructions. À titre d’exemple, nous avons ajouté les éléments suivants à la fabrique :Un nouveau script R markdown intitulé “daily_sitrep.Rmd”, enregistré dans le dossier “report_sources”.Les données du rapport (“linelist_cleaned.rds”), enregistrées dans le sous-dossier “clean” du dossier “data”.Nous pouvons voir en utilisant factory_overview() notre R Markdown dans le dossier “report_sources” et le fichier de données dans le dossier “clean” data (en surbrillance) :Voici une capture d’écran du début du fihier R Markdown “daily_sitrep.Rmd”. Vous pouvez voir que le format de sortie est défini comme étant HTML, via l’en-tête YAML output: html_document.Dans ce script simple, il y des commandes pour :Charger les “packages” nécessairesImporter les données de la liste linéaire en utilisant un chemin de fichier du “package” (pour en savoir plus, consultez la page Importer et exporter des données).Imprimer un tableau récapitulatif des cas, et exportez-le avec export() comme un fichier .csv.Imprimer une courbe épidemiologique, et l’exporter avec ggsave() comme un fichier .png.Vous pouvez examiner la liste des rapports R Markdown dans le dossier “report_sources” avec cette commande :","code":"\nlinelist <- import(here(\"data\", \"clean\", \"linelist_cleaned.rds\"))\nlist_reports()"},{"path":"reportfactory.html","id":"compiler","chapter":"41 Organisation des rapports de routine","heading":"41.4 Compiler","text":"Dans une “factory”, “compiler” un rapport R Markdown signifie que le script .Rmd sera exécuté et que la sortie sera produite (comme spécifié dans le script YAML, par exemple en HTML, Word, PDF, etc).La fabrique créera automatiquement un dossier daté et horodaté pour les sorties dans le dossier “outputs”.Le rapport lui-même et tous les fichiers exportés produits par le script (par exemple, csv, png, xlsx) seront enregistrés dans ce dossier. En outre, le script Rmd lui-même sera enregistré dans ce dossier, de sorte que vous ayez une trace de cette version du script.Cela contraste avec le comportement normal d’un R Markdown exécuté en indépendant, qui enregistre les sorties à l’emplacement du script Rmd. Ce comportement par défaut peut donner lieu à des dossiers encombrés et désordonnés. La “factory” vise à améliorer l’organisation lorsque l’doit exécuter des rapports fréquemment.","code":""},{"path":"reportfactory.html","id":"compiler-par-nom","chapter":"41 Organisation des rapports de routine","heading":"Compiler par nom","text":"Vous pouvez compiler un rapport spécifique en exécutant compile_reports() et en fournissant le nom du script Rmd (sans extension .Rmd) à reports =. Pour simplifier, vous pouvez sauter le reports = et juste écrire le nom R Markdown entre guillemets, comme ci-dessous.Cette commande compile uniquement le rapport “daily_sitrep.Rmd”, en sauvegardant le rapport HTML, le tableau .csv et les exportations des courbes épi .png dans un sous-dossier daté et horodaté spécifique au rapport, dans le dossier “outputs”.Notez que si vous choisissez de fournir l’extension .Rmd, vous devez saisir correctement l’extension telle qu’elle est enregistrée dans le nom du fichier (.rmd vs. .Rmd).Notez également que lorsque vous compilez, vous pouvez voir plusieurs fichiers apparaître temporairement dans le dossier “report_sources” - mais ils disparaîtront rapidement lorsqu’ils seront transférés dans le bon dossier “outputs”.","code":""},{"path":"reportfactory.html","id":"compiler-par-numéro","chapter":"41 Organisation des rapports de routine","heading":"Compiler par numéro","text":"Vous pouvez également spécifier le script Rmd à compiler en fournissant un nombre ou un vecteur de nombres à reports =. Les nombres doivent correspondre à l’ordre dans lequel les rapports apparaissent lorsque vous exécutez list_reports().","code":"\n# Compilez les deuxième et quatrième Rmds dans le dossier \"report_sources\".\ncompile_reports(reports = c(2, 4))"},{"path":"reportfactory.html","id":"compiler-tous-les-rapports","chapter":"41 Organisation des rapports de routine","heading":"Compiler tous les rapports","text":"Vous pouvez compiler tous les rapports R Markdown dans le dossier “report_sources” en mettant l’argument reports = à TRUE.","code":""},{"path":"reportfactory.html","id":"compilation-à-partir-du-sous-dossier","chapter":"41 Organisation des rapports de routine","heading":"Compilation à partir du sous-dossier","text":"Vous pouvez ajouter des sous-dossiers au dossier “report_sources”. Pour exécuter un rapport R Markdown à partir d’un sous-dossier, il suffit de fournir le nom du dossier à subfolder =. Voici un exemple de code pour compiler un rapport Rmd qui se trouve dans un sous-dossier de “report_sources”.Vous pouvez compiler tous les rapports Rmd dans un sous-dossier en fournissant le nom du sous-dossier à reports =, avec un slash à la fin, comme ci-dessous.","code":"\ncompile_reports(\n     reports = \"summary_for_partners.Rmd\",\n     subfolder = \"for_partners\")\ncompile_reports(reports = \"for_partners/\")"},{"path":"reportfactory.html","id":"paramétrisation","chapter":"41 Organisation des rapports de routine","heading":"Paramétrisation","text":"Comme indiqué dans la page sur Production de rapports avec R Markdown, vous pouvez exécuter des rapports avec des paramètres spécifiques. Vous pouvez passer ces paramètres comme une liste à compile_reports() via l’argument params =. Par exemple, dans ce rapport fictif, trois paramètres sont fournis aux rapports R Markdown.","code":"\ncompile_reports(\n  reports = \"daily_sitrep.Rmd\",\n  params = list(most_recent_data = TRUE,\n                region = \"NORTHERN\",\n                rates_denominator = 10000),\n  subfolder = \"regional\"\n)"},{"path":"reportfactory.html","id":"en-utilisant-un-run-file","chapter":"41 Organisation des rapports de routine","heading":"En utilisant un “run-file”","text":"Si vous avez plusieurs rapports à exécuter, pensez à créer un script R qui contient toutes les commandes compile_reports(). Un utilisateur peut simplement exécuter toutes les commandes de ce script R et tous les rapports seront compilés. Vous pouvez enregistrer ce “fichier d’exécution” dans le dossier “scripts”.","code":""},{"path":"reportfactory.html","id":"fichiers-de-sortie","chapter":"41 Organisation des rapports de routine","heading":"41.5 Fichiers de sortie","text":"Après avoir compilé les rapports plusieurs fois, le dossier “outputs” pourrait ressembler à ceci (certains éléments surlignés pour plus de clarté) :Dans “outputs”, des sous-dossiers ont été créés pour chaque rapport Rmd.Dans ces dossiers, d’autres sous-dossiers ont été créés pour chaque compilation unique.\nCes dossiers sont datés et horodatés (“2021-04-23_T11-07-36” signifie 23 avril 2021 à 11:07:36).\nVous pouvez modifier le format de l’horodatage. Voir ?compile_reports.\nCes dossiers sont datés et horodatés (“2021-04-23_T11-07-36” signifie 23 avril 2021 à 11:07:36).Vous pouvez modifier le format de l’horodatage. Voir ?compile_reports.Dans chaque dossier de compilation par date/heure, la sortie du rapport est stockée (par exemple HTML, PDF, Word) avec le script Rmd (contrôle de version !) et tout autre fichier exporté (par exemple table.csv, epidemic_curve.png).Voici une vue de l’intérieur d’un des dossiers horodatés, pour le rapport “daily_sitrep”. Le chemin du fichier est surligné en jaune pour plus de clarté.Enfin, vous trouverez ci-dessous une capture d’écran de la sortie du rapport HTML.Vous pouvez utiliser list_outputs() pour consulter une liste des fichiers de sortie.","code":""},{"path":"reportfactory.html","id":"divers-1","chapter":"41 Organisation des rapports de routine","heading":"41.6 Divers","text":"","code":""},{"path":"reportfactory.html","id":"exécution","chapter":"41 Organisation des rapports de routine","heading":"Exécution","text":"Vous pouvez toujours “exécuter” un de vos rapports R Markdown en cliquant sur le bouton “Knit”, si vous le souhaitez. Si vous faites cela, comme par défaut, les sorties apparaîtront dans le dossier où le Rmd est enregistré - le dossier “report_sources”. Dans les versions précédentes de reportfactory, avoir des fichiers non-Rmd dans “report_sources” empêchait la compilation, mais ce n’est plus le cas. Vous pouvez exécuter compile_reports() et aucune erreur ne se produira.","code":""},{"path":"reportfactory.html","id":"scripts-2","chapter":"41 Organisation des rapports de routine","heading":"Scripts","text":"Nous vous encourageons à utiliser le dossier “scripts” pour stocker les “fichiers d’exécution” ou les scripts .R qui proviennent de vos scripts .Rmd. Consultez la page Production de rapports avec R Markdown pour obtenir des conseils sur la manière de structurer votre code dans plusieurs fichiers.","code":""},{"path":"reportfactory.html","id":"extras","chapter":"41 Organisation des rapports de routine","heading":"Extras","text":"Avec reportfactory, vous pouvez utiliser la fonction list_deps() pour lister tous les “packages” requis pour tous les rapports dans l’ensemble de la fabrique.Avec reportfactory, vous pouvez utiliser la fonction list_deps() pour lister tous les “packages” requis pour tous les rapports dans l’ensemble de la fabrique.Il y un “package” de support utilisé en de développement appelé rfextras qui offre plus de fonctions d’aide pour vous assister dans la construction des rapports, comme :\nload_scripts() - source/charge tous les scripts .R dans un dossier donné (le dossier “scripts” par défaut).\nfind_latest() - trouve la dernière version d’un fichier (par exemple, le dernier jeu de données).\nIl y un “package” de support utilisé en de développement appelé rfextras qui offre plus de fonctions d’aide pour vous assister dans la construction des rapports, comme :load_scripts() - source/charge tous les scripts .R dans un dossier donné (le dossier “scripts” par défaut).find_latest() - trouve la dernière version d’un fichier (par exemple, le dernier jeu de données).","code":""},{"path":"reportfactory.html","id":"ressources-24","chapter":"41 Organisation des rapports de routine","heading":"41.7 Ressources","text":"Voir la page Github du “package” reportfactoryVoir la page Github du package rfextras","code":""},{"path":"dashboards.html","id":"dashboards","chapter":"42 Tableaux de bord avec R Markdown","heading":"42 Tableaux de bord avec R Markdown","text":"Cette page couvre l’utilisation base du paquet flexdashboard. Ce paquet vous permet de formater facilement la sortie R Markdown comme un tableau de bord avec des panneaux et des pages. Le contenu du tableau de bord peut être du texte, des figures/tableaux statiques ou des graphiques interactifs.Avantages de flexdashboard :Il nécessite un codage R non standard minimal. Avec très peu de pratique, vous pouvez rapidement créer un tableau de bord.Le tableau de bord peut généralement être envoyé par e-mail à des collègues sous forme de fichier HTML autonome, aucun serveur n’est nécessaire.Vous pouvez combiner flexdashboard avec shiny, ggplotly et d’autres “widgets html” pour ajouter de l’interactivité.Inconvénients de flexdashboard :Moins de personnalisation par rapport à l’utilisation de shiny seul pour créer un tableau de bord.Des tutoriels assez complets sur l’utilisation de flexdashboard qui ont informé cette page se trouvent dans la section Ressources (fin de la page). Nous décrivons ci-dessous les fonctionnalités de base et donnons un exemple de construction d’un tableau de bord pour explorer une épidémie, en utilisant les données du cas linelist.","code":""},{"path":"dashboards.html","id":"préparation-25","chapter":"42 Tableaux de bord avec R Markdown","heading":"42.1 Préparation","text":"","code":""},{"path":"dashboards.html","id":"charger-les-paquets-2","chapter":"42 Tableaux de bord avec R Markdown","heading":"Charger les paquets","text":"Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire et le charge pour l’utiliser. Vous pouvez aussi charger les paquets installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les paquets R.","code":"\npacman::p_load(\n  rio, # import/export de données     \n  here, # localisation des fichiers\n  tidyverse, # gestion et visualisation des données\n  flexdashboard, # versions tableaux de bord des rapports R Markdown\n  shiny, # figures interactives\n  plotly # figures interactives\n)"},{"path":"dashboards.html","id":"importer-des-données-8","chapter":"42 Tableaux de bord avec R Markdown","heading":"Importer des données","text":"Nous importons le jeu de données des cas d’une épidémie d’Ebola simulée. Si vous voulez suivre, cliquez pour télécharger la liste de lignes “propre” (en tant que fichier .rds). Importez des données avec la fonction import() du paquet rio (elle gère de nombreux types de fichiers comme .xlsx, .csv, .rds - voir la page Importation et exportation pour plus de détails).Les 50 premières lignes de la linelist sont affichées ci-dessous.","code":"\n# Importez la liste de cas\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"dashboards.html","id":"créer-un-nouveau-r-markdown","chapter":"42 Tableaux de bord avec R Markdown","heading":"42.2 Créer un nouveau R Markdown","text":"Après avoir installé le package, créez un nouveau fichier R Markdown en cliquant sur Fichier > Nouveau fichier > R Markdown.Dans la fenêtre qui s’ouvre, sélectionnez “Template” et choisissez le modèle “Flex Dashboard”. Vous serez ensuite invité à nommer le document. Dans l’exemple de cette page, nous allons nommer notre R Markdown “outbreak_dashboard.Rmd”.","code":""},{"path":"dashboards.html","id":"le-script","chapter":"42 Tableaux de bord avec R Markdown","heading":"42.3 Le script","text":"Le script est un script R Markdown, et donc les mêmes composants et la même organisation que les scripts décrits dans la page sur les Rapports avec R Markdown. Nous allons brièvement les revoir et souligner les différences avec les autres formats de sortie R Markdown.","code":""},{"path":"dashboards.html","id":"yaml","chapter":"42 Tableaux de bord avec R Markdown","heading":"YAML","text":"En haut du script se trouve l’en-tête “YAML”. Il doit commencer par trois tirets --- et doit se terminer par trois tirets ---. Les paramètres YAML sont présentés par paires key: value. L’indentation et le placement des deux points dans YAML sont importants: les paires key: value sont séparées par des deux points (pas par des signes égaux !).Le fichier YAML doit commencer par les métadonnées du document. L’ordre de ces paramètres YAML primaires (non indentés) n’pas d’importance. Par exemple :Vous pouvez utiliser du code R dans des valeurs YAML en le mettant comme du code en ligne (précédé de r entre guillemets) mais aussi entre guillemets (voir ci-dessus pour Date).Un paramètre YAML obligatoire est output:, qui spécifie le type de fichier à produire (par exemple, html_document, pdf_document, word_document, ou powerpoint_presentation). Pour flexdashboard, la valeur de ce paramètre est un peu confuse - elle doit être définie comme output:flexdashboard::flex_dashboard. Notez les deux-points simples et doubles, et le trait de soulignement. Ce paramètre de sortie YAML est souvent suivi par un deux-points supplémentaire et des sous-paramètres indentés (voir les paramètres orientation: et vertical_layout: ci-dessous).Comme indiqué ci-dessus, des indentations (2 espaces) sont utilisées pour les sous-paramètres. Dans ce cas, n’oubliez pas de mettre un deux-points supplémentaire après le primaire, comme key:value:.Le cas échéant, les valeurs logiques doivent être données dans YAML en minuscules (true, false, null). Si un deux-points fait partie de votre valeur (par exemple, dans le titre), mettez la valeur entre guillemets. Voir les exemples dans les sections ci-dessous.","code":"\ntite: \"Mon document\"\nauthor: \"Moi\"\ndate: \"`r Sys.Date()`\"\ntitle: \"Mon tableau de bord\"\nauthor: \"Moi\"\ndate: \"`r Sys.Date()`\"\noutput:\n  flexdashboard::flex_dashboard:\n    orientation: rows\n    vertical_layout: scroll"},{"path":"dashboards.html","id":"morceaux-de-code-1","chapter":"42 Tableaux de bord avec R Markdown","heading":"Morceaux de code","text":"Un script R Markdown peut contenir plusieurs “chunks” de code - il s’agit de zones du script dans lesquelles vous pouvez écrire du code R sur plusieurs lignes et qui fonctionnent comme des mini-scripts R.Les morceaux de code sont créés à l’aide de trois crochets arrière et de parenthèses avec un “r” minuscule à l’intérieur. Le chunk est fermé par trois crochets arrière. Vous pouvez créer un nouveau chunk en le tapant vous-même, en utilisant le raccourci clavier “Ctrl + Alt + ” (ou Cmd + Shift + r sur Mac), ou en cliquant sur l’icône verte “insérer un nouveau chunk de code” en haut de votre éditeur de script. De nombreux exemples sont donnés ci-dessous.","code":""},{"path":"dashboards.html","id":"texte-narratif","chapter":"42 Tableaux de bord avec R Markdown","heading":"Texte narratif","text":"En dehors d’un “chunk” de code R, vous pouvez écrire un texte narratif. Comme décrit dans la page Rapports avec R Markdown, vous pouvez mettre du texte en italique en l’entourant d’un astérisque (texte italique), ou en gras en l’entourant de deux astérisques (texte gras). Rappelez-vous que les puces et les schémas de numérotation sont sensibles aux nouvelles lignes, à l’indentation et au fait de terminer une ligne par deux espaces.Vous pouvez également insérer du code R en ligne dans du texte, comme décrit à la page Rapports avec R Markdown, en entourant le code de barres obliques inversées et en commençant la commande par “r” : 2 (voir l’exemple avec la date ci-dessus).","code":""},{"path":"dashboards.html","id":"titres","chapter":"42 Tableaux de bord avec R Markdown","heading":"Titres","text":"Différents niveaux de titres sont établis avec différents nombres de symboles de hachage, comme décrit dans la page Rapports avec R Markdown.Dans flexdashboard, un titre primaire (#) crée une “page” du tableau de bord. Les titres de deuxième niveau (##) créent une colonne ou une ligne en fonction de votre paramètre orientation: (voir les détails ci-dessous). Les titres de troisième niveau (###) créent des panneaux pour les graphiques, les tableaux, le texte, etc.","code":"# Titre de premier niveau (page)\n\n## En-tête de deuxième niveau (ligne ou colonne)  \n\n### En-tête de troisième niveau (panneau pour le graphique, le tableau, etc.)"},{"path":"dashboards.html","id":"attributs-de-section","chapter":"42 Tableaux de bord avec R Markdown","heading":"42.4 Attributs de section","text":"Comme dans un markdown R normal, vous pouvez spécifier des attributs à appliquer aux parties de votre tableau de bord en incluant des options key=value après un titre, entre des accolades { }. Par exemple, dans un rapport HTML R Markdown typique, vous pouvez organiser les sous-titres en onglets avec ## Ma rubrique {.tabset}.Notez que ces attributs sont écrits après un titre dans une partie texte du script. Ils sont différents des options knitr insérées en haut des morceaux de code R, telles que .height =.Les attributs de section spécifiques à flexdashboard comprennent :{data-orientation=} Défini à rows ou columns. Si votre tableau de bord comporte plusieurs pages, ajoutez cet attribut à chaque page pour indiquer l’orientation (expliqué plus en détail dans la section de mise en page).{data-width=} et {data-height=} définissent la taille relative des graphiques, colonnes, lignes disposés dans la même dimension (horizontale ou verticale). Les tailles absolues sont ajustées pour remplir au mieux l’espace sur n’importe quel dispositif d’affichage grâce au moteur flexbox.\nLa hauteur des graphiques dépend également de la définition du paramètre YAML vertical_layout: fill ou vertical_layout: scroll. S’il est défini sur scroll, la hauteur des figures reflétera l’option traditionnelle fig.height = dans le chunk de code R.\nVoir la documentation complète sur la taille sur le flexdashboard website\nLa hauteur des graphiques dépend également de la définition du paramètre YAML vertical_layout: fill ou vertical_layout: scroll. S’il est défini sur scroll, la hauteur des figures reflétera l’option traditionnelle fig.height = dans le chunk de code R.Voir la documentation complète sur la taille sur le flexdashboard website{.hidden} Utilisez cette option pour exclure une page spécifique de la barre de navigation.{data-navbar=} Utilisez ceci dans un titre de niveau page pour l’imbriquer dans un menu déroulant de la barre de navigation. Indiquez le nom (entre guillemets) du menu déroulant. Voir l’exemple ci-dessous.","code":""},{"path":"dashboards.html","id":"layout","chapter":"42 Tableaux de bord avec R Markdown","heading":"42.5 Mise en page","text":"Ajustez la mise en page de votre tableau de bord de la manière suivante :Ajoutez des pages, des colonnes/lignes et des graphiques avec des titres R Markdown (par exemple, #, ## ou ###).Ajustez l’orientation: de paramètre YAML à rangees ou colonnes.Spécifiez si la mise en page remplit le navigateur ou permet le défilement.Ajouter des onglets à un titre de section particulier","code":""},{"path":"dashboards.html","id":"pages","chapter":"42 Tableaux de bord avec R Markdown","heading":"Pages","text":"Les titres de premier niveau (#) dans le R Markdown représentent les “pages” du tableau de bord. Par défaut, les pages apparaissent dans une barre de navigation en haut du tableau de bord.Vous pouvez regrouper des pages en un “menu” dans la barre de navigation supérieure en ajoutant l’attribut {data-navmenu=} au titre de la page. Attention, n’incluez pas d’espaces autour du signe égal, sinon cela ne fonctionnera pas !Voici ce que produit le script :Vous pouvez également convertir une page ou une colonne en une “barre latérale” sur le côté gauche du tableau de bord en ajoutant l’attribut {.sidebar}. Elle peut contenir du texte (visible de n’importe quelle page) ou, si vous avez intégré l’interactivité shiny, elle peut être utile pour contenir des commandes d’entrée utilisateur telles que des curseurs ou des menus déroulants.Voici ce que produit le script :","code":""},{"path":"dashboards.html","id":"orientation","chapter":"42 Tableaux de bord avec R Markdown","heading":"Orientation","text":"Définissez le paramètre YAML orientation: pour indiquer comment vos titres Markdown de second niveau (##) doivent être interprétés - comme orientation: colonnes ou orientation: lignes.Les titres de second niveau (##) seront interprétés comme de nouvelles colonnes ou lignes en fonction de ce paramètre orientation.Si vous définissez orientation: colonnes, les titres de second niveau créeront de nouvelles colonnes dans le tableau de bord. Le tableau de bord ci-dessous comporte une page, contenant deux colonnes, avec un total de trois panneaux. Vous pouvez ajuster la largeur relative des colonnes avec {data-width=} comme indiqué ci-dessous.Voici ce que produit le script :Si vous définissez orientation: lignes, les en-têtes de second niveau créeront de nouvelles lignes au lieu de colonnes. Voici le même script que ci-dessus, mais avec orientation: lignes pour que les en-têtes de second niveau produisent des lignes au lieu de colonnes. Vous pouvez ajuster la hauteur relative des lignes avec {data-height=} comme indiqué ci-dessous.Voici ce que produit le script :Si votre tableau de bord comporte plusieurs pages, vous pouvez désigner l’orientation pour chaque page spécifique en ajoutant l’attribut {data-orientation=} à l’en-tête de chaque page (spécifiez soit lignes soit colonnes sans les guillemets).","code":""},{"path":"dashboards.html","id":"onglets","chapter":"42 Tableaux de bord avec R Markdown","heading":"Onglets","text":"Vous pouvez diviser le contenu en onglets avec l’attribut {.tabset}, comme dans les autres sorties HTML R Markdown.Il suffit d’ajouter cet attribut après le titre souhaité. Les sous-titres sous ce titre seront affichés sous forme d’onglets. Par exemple, dans l’exemple de script ci-dessous, la colonne 2 à droite (##) est modifiée de manière à ce que les volets de la courbe épidémique et du tableau (###) soient affichés sous forme d’onglets.Vous pouvez faire de même avec les lignes si votre orientation est celle des lignes.Voici ce que produit le script :","code":""},{"path":"dashboards.html","id":"ajout-de-contenu","chapter":"42 Tableaux de bord avec R Markdown","heading":"42.6 Ajout de contenu","text":"Commençons à construire un tableau de bord. Notre tableau de bord simple aura 1 page, 2 colonnes, et 4 panneaux. Nous allons construire les panneaux pièce par pièce pour la démonstration.Vous pouvez facilement inclure des sorties R standard telles que du texte, des ggplots et des tableaux (voir la page Tableaux pour la présentation). Il suffit de les coder dans un chunk de code R comme vous le feriez pour tout autre script R Markdown.Remarque : vous pouvez télécharger le script Rmd terminé et la sortie du tableau de bord HTML - voir la page Télécharger le manuel et les données.","code":""},{"path":"dashboards.html","id":"texte-1","chapter":"42 Tableaux de bord avec R Markdown","heading":"Texte","text":"Vous pouvez saisir du texte Markdown et inclure du code en ligne comme pour toute autre sortie R Markdown. Voir la page Rapports avec R Markdown pour plus de détails.Dans ce tableau de bord, nous incluons un panneau de texte récapitulatif qui comprend un texte dynamique indiquant la dernière date d’hospitalisation et le nombre de cas signalés dans l’épidémie.","code":""},{"path":"dashboards.html","id":"tableaux-1","chapter":"42 Tableaux de bord avec R Markdown","heading":"Tableaux","text":"Vous pouvez inclure des morceaux de code R qui impriment des sorties telles que des tableaux. Mais la sortie sera plus belle et s’adaptera mieux à la taille de la fenêtre si vous utilisez la fonction kable() de knitr pour afficher vos tableaux. Les fonctions flextable peuvent produire des tableaux qui sont raccourcis / coupés.Par exemple, ci-dessous, nous faisons passer la fonction linelist() par une commande count() pour produire un tableau récapitulatif des cas par hôpital. Finalement, le tableau est envoyé à knitr::kable() et le résultat une barre de défilement sur la droite. Vous pouvez en savoir plus sur la personnalisation de votre tableau avec kable() et kableExtra ici.Voici ce que produit le script :Si vous voulez afficher un tableau dynamique qui permet à l’utilisateur de filtrer, trier et/ou cliquer sur les “pages” du cadre de données, utilisez le package DT et sa fonction datatable(), comme dans le code ci-dessous.Dans l’exemple de code ci-dessous, le cadre de données linelist est imprimé. Vous pouvez définir rownames = FALSE pour conserver l’espace horizontal, et filter = \"top\" pour avoir les filtres en haut de chaque colonne. Une liste d’autres spécifications peut être fournie à options =. Ci-dessous, nous avons défini pageLength = pour que 5 lignes apparaissent et scrollX = pour que l’utilisateur puisse utiliser une barre de défilement en bas pour faire défiler horizontalement. L’argument class = 'white-space: nowrap' garantit que chaque ligne ne comporte qu’une seule ligne (et non plusieurs). Vous trouverez d’autres arguments et valeurs possibles ici ou en entrant ?datatable.","code":"\nDT::datatable(linelist, \n              rownames = FALSE, \n              options = liste(pageLength = 5, scrollX = TRUE), \n              class = 'white-space: nowrap' )"},{"path":"dashboards.html","id":"tracés","chapter":"42 Tableaux de bord avec R Markdown","heading":"Tracés","text":"Vous pouvez imprimer les graphiques dans un tableau de bord comme vous le feriez dans un script R. Dans notre exemple, nous utilisons le paquet incidence2 pour créer une “courbe épidémique” par groupe d’âge avec deux commandes simples (voir la page Courbes épidémiques). Cependant, vous pourriez utiliser ggplot() et imprimer un graphique de la même manière.Voici ce que produit le script :","code":""},{"path":"dashboards.html","id":"graphiques-interactifs","chapter":"42 Tableaux de bord avec R Markdown","heading":"Graphiques interactifs","text":"Vous pouvez également passer un ggplot standard ou un autre objet de tracé à ggplotly() du paquet plotly (voir la page Graphiques interactifs). Cela rendra votre graphique interactif, permettra au lecteur de “zoomer” et affichera en surimpression la valeur de chaque point de données (dans ce scénario, le nombre de cas par semaine et le groupe d’âge dans la courbe).Voici à quoi cela ressemble dans le tableau de bord (gif). Cette fonctionnalité interactive fonctionnera même si vous envoyez le tableau de bord par courriel sous forme de fichier statique (pas en ligne sur un serveur).","code":"\nage_outbreak <- incidence(linelist, date_onset, \"week\", groups = age_cat)\nplot(age_outbreak, fill = age_cat, col_pal = muted, title = \"\") %>% \n  plotly::ggplotly()"},{"path":"dashboards.html","id":"widgets-html","chapter":"42 Tableaux de bord avec R Markdown","heading":"Widgets HTML","text":"Les widgets HTML pour R sont une classe spéciale de paquets R qui augmentent l’interactivité en utilisant des bibliothèques JavaScript. Vous pouvez les intégrer dans les sorties Markdown de R (comme un flexdashboard) et dans les tableaux de bord Shiny.Voici quelques exemples courants de ces widgets :Plotly (utilisé dans cette page du manuel et dans la page Graphiques interactifs).visNetwork (utilisé dans la page Chaînes de transmission de ce manuel)Leaflet (utilisé dans la page bases de GIS de ce manuel)digraphs (utile pour montrer de manière interactive des séries de données temporelles)DT (datatable()) (utilisé pour afficher des tableaux dynamiques avec des filtres, des tris, etc.)Ci-dessous, nous démontrons l’ajout d’une chaîne de transmission d’épidémie qui utilise visNetwork au tableau de bord. Le script ne montre que le nouveau code ajouté à la section “Column 2” du script R Markdown. Vous pouvez trouver le code dans la page Chaînes de transmission de ce manuel.Voici ce que produit le script :","code":""},{"path":"dashboards.html","id":"organisation-du-code","chapter":"42 Tableaux de bord avec R Markdown","heading":"42.7 Organisation du code","text":"Vous pouvez choisir d’avoir tout le code dans le script R Markdown flexdashboard. Alternativement, pour avoir un script de tableau de bord plus propre et concis, vous pouvez choisir de faire appel à du code/figures qui sont hébergés ou créés dans des scripts R externes. Ceci est décrit plus en détail dans la page Rapports avec R Markdown.","code":""},{"path":"dashboards.html","id":"shiny-1","chapter":"42 Tableaux de bord avec R Markdown","heading":"42.8 Shiny","text":"L’intégration du paquet R shiny peut rendre vos tableaux de bord encore plus réactifs aux entrées de l’utilisateur. Par exemple, vous pouvez demander à l’utilisateur de sélectionner une juridiction ou une plage de dates, et faire réagir les panneaux à son choix (par exemple, filtrer les données affichées). Pour intégrer la réactivité shiny dans flexdashboard, il vous suffit d’apporter quelques modifications à votre script Markdown R flexdashboard.Vous pouvez également utiliser shiny pour produire des applications ou des tableaux de bord sans flexdashboard. La page du manuel sur les tableaux de bord avec Shiny donne un aperçu de cette approche, y compris des conseils sur la syntaxe shiny, la structure des fichiers d’application et les options de partage et de publication (y compris les options de serveur libre). Ces conseils syntaxiques et généraux s’appliquent également au contexte flexdashboard.L’intégration de shiny dans flexdashboard constitue cependant un changement fondamental pour votre flexdashboard. Il ne produira plus une sortie HTML que vous pouvez envoyer par courriel et que tout le monde peut ouvrir et visualiser. Il s’agira plutôt d’une “application”. Le bouton “Knit” en haut du script sera remplacé par une icône “Run document”, qui ouvrira une instance du tableau de bord interactif localement sur votre ordinateur.Le partage de votre tableau de bord nécessitera maintenant que vous.. :Envoyer le script Rmd au spectateur, qu’il l’ouvre dans R sur son ordinateur et qu’il exécute l’application, ou bien…L’application/le tableau de bord est hébergé sur un serveur accessible à l’observateur.L’intégration de shiny présente donc des avantages, mais aussi des complications. Si le partage facile par email est une priorité et que vous n’avez pas besoin des capacités réactives de shiny, considérez l’interactivité réduite offerte par ggplotly() comme démontré ci-dessus.Nous donnons ci-dessous un exemple très simple utilisant le même “outbreak_dashboard.Rmd” que ci-dessus. Une documentation complète sur l’intégration de Shiny dans flexdashboard est disponible en ligne ici.","code":""},{"path":"dashboards.html","id":"paramètres","chapter":"42 Tableaux de bord avec R Markdown","heading":"Paramètres","text":"Activez shiny dans un flexdashboard en ajoutant le paramètre YAML runtime: shiny au même niveau d’indentation que output:, comme ci-dessous :Il est également pratique d’activer une “barre latérale” pour contenir les widgets de saisie shiny qui collecteront les informations de l’utilisateur. Comme expliqué ci-dessus, créez une colonne et indiquez l’option {.sidebar} pour créer une barre latérale sur le côté gauche. Vous pouvez ajouter du texte et des morceaux de R contenant les commandes input shiny dans cette colonne.Si votre application/ tableau de bord est hébergé sur un serveur et peut avoir plusieurs utilisateurs simultanés, nommez le premier morceau de code R comme global. Incluez les commandes pour importer/charger vos données dans ce chunk. Ce chunk au nom spécial est traité différemment, et les données qui y sont importées ne le sont qu’une fois (et non en continu) et sont disponibles pour tous les utilisateurs. Cela améliore la vitesse de démarrage de l’application.","code":"---\ntitle: \"Tableau de bord d'épidémie (Démo Shiny)\".\noutput: \n  flexdashboard::flex_dashboard :\n    orientation: columns\n    vertical_layout : fill\nruntime: shiny\n---"},{"path":"dashboards.html","id":"exemple-travaillé","chapter":"42 Tableaux de bord avec R Markdown","heading":"Exemple travaillé","text":"Ici, nous adaptons le script flexdashboard “outbreak_dashboard.Rmd” pour inclure shiny. Nous allons ajouter la possibilité pour l’utilisateur de sélectionner un hôpital dans un menu déroulant, et de faire en sorte que la courbe épidémique ne reflète que les cas de cet hôpital, avec un titre de graphique dynamique. Nous faisons ce qui suit :Ajouter runtime: shiny à la YAML.Re-nommer le chunk de configuration comme global.Créer une barre latérale contenant :\nDu code pour créer un vecteur de noms d’hôpitaux uniques\nUne commande selectInput() (menu déroulant shiny) avec le choix des noms d’hôpitaux. La sélection est sauvegardée sous le nom de hospital_choice, qui peut être référencé dans le code suivant comme input$hospital_choice.\nDu code pour créer un vecteur de noms d’hôpitaux uniquesUne commande selectInput() (menu déroulant shiny) avec le choix des noms d’hôpitaux. La sélection est sauvegardée sous le nom de hospital_choice, qui peut être référencé dans le code suivant comme input$hospital_choice.Le code de la courbe d’épidémie (colonne 2) est enveloppé dans renderPlot({ }), incluant :\nUn filtre sur l’ensemble de données qui restreint la colonne hospital à la valeur actuelle de input$hospital_choice.\nUn titre dynamique du tracé qui incorpore input$hospital_choice.\nUn filtre sur l’ensemble de données qui restreint la colonne hospital à la valeur actuelle de input$hospital_choice.Un titre dynamique du tracé qui incorpore input$hospital_choice.Notez que tout code faisant référence à une valeur input$ doit se trouver dans une fonction render({}) (pour être réactif).Voici le haut du script, incluant YAML, le chunk global, et la barre latérale :Voici la colonne 2, avec le tracé de l’épicurve réactive :Et voici le tableau de bord :","code":""},{"path":"dashboards.html","id":"autres-exemples","chapter":"42 Tableaux de bord avec R Markdown","heading":"Autres exemples","text":"Pour lire un exemple de tableau de bord Shiny-flexdashboard lié à la santé et utilisant l’interactivité shiny et le widget de cartographie leaflet, consultez ce chapitre du livre en ligne Geospatial Health Data : Modeling Visualization R-INLA Shiny.","code":""},{"path":"dashboards.html","id":"partage","chapter":"42 Tableaux de bord avec R Markdown","heading":"42.9 Partage","text":"Les tableaux de bord qui ne contiennent pas d’éléments Shiny produisent un fichier HTML (.html), qui peut être envoyé par courriel (si la taille le permet). Ceci est utile, car vous pouvez envoyer le rapport du “tableau de bord” sans avoir à configurer un serveur pour l’héberger en tant que site web.Si vous avez intégré shiny, vous ne pourrez pas envoyer une sortie par e-mail, mais vous pouvez envoyer le script lui-même à un utilisateur R, ou héberger le tableau de bord sur un serveur comme expliqué ci-dessus.","code":""},{"path":"dashboards.html","id":"ressources-25","chapter":"42 Tableaux de bord avec R Markdown","heading":"42.10 Ressources","text":"Les excellents tutoriels qui ont informé cette page se trouvent ci-dessous. Si vous les consultez, vous pourrez probablement créer votre propre tableau de bord en moins d’une heure.https://bookdown.org/yihui/rmarkdown/dashboards.htmlhttps://rmarkdown.rstudio.com/flexdashboard/https://rmarkdown.rstudio.com/flexdashboard/using.htmlhttps://rmarkdown.rstudio.com/flexdashboard/examples.html","code":""},{"path":"shiny.html","id":"shiny","chapter":"43 Tableaux de bord avec Shiny","heading":"43 Tableaux de bord avec Shiny","text":"Les tableaux de bord sont souvent une excellente méthode de partager les résultats d’analyses avec d’autres personnes. Produire un tableau de bord avec shiny nécessite une connaissance relativement avancée du langage R, mais vous offrez la personnalisation des tableaux et des possibilités incroyables.Il est recommandé qu’une personne apprenant les tableaux de bord avec shiny ait une bonne connaissance de la transformation et de la visualisation des données, et soit à l’aise pour déboguer du code et écrire des fonctions. Le travail avec les tableaux de bord n’est pas intuitif au début et est parfois difficile à comprendre, mais il s’agit d’une excellente compétence à apprendre qui devient beaucoup plus facile avec la pratique !Cette page donne un bref aperçu de la façon de créer des tableaux de bord avec shiny et ses extensions.\nPour une méthode alternative de création de tableaux de bord qui est plus rapide, plus facile, mais peut-être moins personnalisable, voir la page sur flextable (Rapports avec R Markdown).","code":""},{"path":"shiny.html","id":"préparation-26","chapter":"43 Tableaux de bord avec Shiny","heading":"43.1 Préparation","text":"","code":""},{"path":"shiny.html","id":"chargement-des-packages-2","chapter":"43 Tableaux de bord avec Shiny","heading":"Chargement des packages","text":"Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le package si nécessaire et le charge pour l’utiliser. Vous pouvez aussi charger les packages installés avec library() de base R. Voir la page sur bases de R pour plus d’informations sur les packages R.Nous commençons par installer le package R shiny :","code":"\npacman::p_load(\"shiny\")"},{"path":"shiny.html","id":"importer-des-données-9","chapter":"43 Tableaux de bord avec Shiny","heading":"Importer des données","text":"Si vous souhaitez suivre cette page, consultez la section du manuel pour le téléchargement des données. Il y des liens pour télécharger les scripts R et les fichiers de données qui produisent l’application Shiny finale.Si vous essayez de reconstruire l’application à l’aide de ces fichiers, veuillez tenir compte de la structure des dossiers du projet R qui est créée au cours de la démonstration (par exemple, des dossiers pour “data” et pour “funcs”).","code":""},{"path":"shiny.html","id":"la-structure-dune-application-shiny","chapter":"43 Tableaux de bord avec Shiny","heading":"43.2 La structure d’une application shiny","text":"","code":""},{"path":"shiny.html","id":"structures-de-fichiers-de-base","chapter":"43 Tableaux de bord avec Shiny","heading":"Structures de fichiers de base","text":"Pour comprendre shiny, nous devons d’abord comprendre comment fonctionne la structure des fichiers d’une application ! Nous devrions créer un tout nouveau répertoire avant de commencer. Cela peut être rendu plus facile en choisissant New project dans Rstudio, et en choisissant Shiny Web Application. Cela créera la structure de base d’une application shiny pour vous.En ouvrant ce projet, vous remarquerez qu’il y déjà un fichier .R appelé app.R. Il est essentiel que nous ayons une des deux structures de fichiers de base :Un seul fichier appelé app.R, ouDeux fichiers, l’un appelé ui.R et l’autre server.RDans cette page, nous utiliserons la première approche qui consiste à avoir un seul fichier appelé app.R. Voici un exemple de script :Si vous ouvrez ce fichier, vous remarquerez que deux objets sont définis, un appelé ui et l’autre appelé server. Ces objets doivent être définis dans toutes les applications shiny et sont essentiels à la structure de l’application elle-même ! En fait, la seule différence entre les deux structures de fichiers décrites ci-dessus est que dans la structure 1, ui et server sont définis dans un seul fichier, alors que dans la structure 2, ils sont définis dans des fichiers séparés. Note : nous pouvons aussi (et nous devrions si nous avons une application plus grande) avoir d’autres fichiers .R dans notre structure que nous pouvons sourcer avec source() dans notre application.","code":"\n# exemple de un script app.R\n\nlibrary(shiny)\n\nui <- fluidPage(\n\n    # titre de l'application \n    titlePanel(\"My app\"),\n\n    # Sidebar avec le widget slider input \n    sidebarLayout(\n        sidebarPanel(\n            sliderInput(\"input_1\")\n        ),\n\n        # afficher le graphique\n        mainPanel(\n           plotOutput(\"my_plot\")\n        )\n    )\n)\n\n\n# Définir la logique du serveur requise pour dessiner un histogramme\n\nserver <- function(input, output) {\n     \n     plot_1 <- reactive({\n          plot_func(param = input_1)\n     })\n     \n    output$my_plot <- renderPlot({\n       plot_1()\n    })\n}\n\n\n# Executer application \nshinyApp(ui = ui, server = server)"},{"path":"shiny.html","id":"le-serveur-et-linterface-utilisateur","chapter":"43 Tableaux de bord avec Shiny","heading":"Le serveur et l’interface utilisateur","text":"Nous devons maintenant comprendre ce que les objets server et ui font réellement. Pour faire simple, ce sont deux objets qui interagissent l’un avec l’autre à chaque fois que l’utilisateur interagit avec l’application shiny.L’élément UI d’une shiny app est, à la base, le code R qui crée une interface HTML. Cela signifie que tout ce qui est affiché dans l’interface utilisateur d’une application. Cela inclut généralement :Les “widgets”, par exemples les menus déroulants, cases à cocher, curseurs, etc. avec lesquels l’utilisateur peut interagir.Graphiques, tableaux, etc; toutes sorties générées par le code R.Les aspects de navigation d’une application, par exemples les onglets, volets, etc.Texte générique, liens hypertextes, etc.Éléments HTML et CSS (abordés plus tard)La chose la plus importante à comprendre au sujet de l’interface utilisateur est qu’elle reçoit des entrées de l’utilisateur et affiche des sorties du serveur. Aucun code actif n’est exécuté dans l’interface utilisateur à tout moment. Tous les changements vus dans l’interface utilisateur sont transmis au serveur (plus ou moins). Nous devons donc effectuer tous nos tracés, téléchargements, etc. dans le serveur.Le serveur de l’application shiny est l’endroit où tout le code est exécuté une fois que l’application démarre. La façon dont cela fonctionne est un peu complique. Le serveur va effectivement réagir à l’interface utilisateur et exécuter des bout de code en réponse. Si les choses changent dans le serveur, elles seront transmises à l’interface utilisateur, où les changements seront visibles. Il est important de noter que le code dans le serveur sera exécuté non consécutivement (ou il est préférable d’y penser de cette façon). En gros, chaque fois qu’une entrée de l’interface utilisateur affecte un bout de code dans le serveur, celui-ci s’exécutera automatiquement, et la sortie sera produite et affichée.Tout cela semble probablement très abstrait pour l’instant, nous allons donc travailler avec quelques exemples pour avoir une idée claire de la façon dont cela fonctionne réellement.","code":""},{"path":"shiny.html","id":"avant-de-commencer-à-construire-une-application","chapter":"43 Tableaux de bord avec Shiny","heading":"Avant de commencer à construire une application","text":"Avant de commencer à construire une application, il est extrêmement utile de savoir ce que vous voulez construire. Puisque votre interface utilisateur sera écrite en code, vous ne pouvez pas vraiment visualiser ce que vous construisez, sauf si vous visez quelque chose de spécifique. Pour cette raison, il est extrêmement utile de regarder de nombreux exemples d’applications shinys pour avoir une idée de ce que vous pouvez faire. Encore mieux, si vous pouvez regarder le code source derrière ces applications ! Voici quelques bonnes ressources pour cela :La galerie d’applications RstudioUne fois que vous avez une idée de ce qui est possible, il est également utile de dessiner ce à quoi vous voulez que votre application ressemble. Vous pouvez faire un dessin soit sur du papier ou dans un logiciel de dessin (PowerPoint, MS paint, etc.). Il est utile de commencer simplement pour votre première application ! Il n’y certainment pas d’honte à utiliser le code d’une belle application que vous trouvez en ligne comme modèle pour votre travail. C’est beaucoup plus facile que construire quelque chose à partir de zéro !","code":""},{"path":"shiny.html","id":"construire-une-interface-utilisateur","chapter":"43 Tableaux de bord avec Shiny","heading":"43.3 Construire une interface utilisateur","text":"Lorsque nous construisons notre application, il est plus facile de travailler d’abord sur l’interface utilisateur afin de voir ce que nous faisons, et de ne pas risquer que l’application échoue à cause d’erreurs de serveur. Comme mentionné précédemment, il est souvent bon d’utiliser un modèle pour travailler sur l’interface utilisateur. Il y un certain nombre de modèles standards qui peuvent être utilisés avec shiny et qui sont disponibles dans le package de base shiny, mais il est intéressant de noter qu’il y aussi un certain nombre d’extensions du package comme shinydashboard. Nous allons utiliser un exemple de la base shiny pour commencer.Une interface utilisateur shiny est généralement définie comme une série de fonctions imbriquées, dans l’ordre suivant:Une fonction définissant la mise en page générale (la plus basique est fluidPage(), mais d’autres sont disponibles)Des panneaux à l’intérieur de la mise en page tels que:\nune barre latérale (sidebarPanel())\nun panneau “principal” (mainPanel())\nun onglet (tabPanel())\nune “colonne” générique (column())\nune barre latérale (sidebarPanel())un panneau “principal” (mainPanel())un onglet (tabPanel())une “colonne” générique (column())Widgets et sorties : ils peuvent conférer des entrées au serveur (widgets) ou des sorties du serveur (outputs)\nLes widgets sont généralement appelés xxxInput(), par exemple selectInput().\nLes sorties sont généralement appelées xxxOutput(), par exemple plotOutput().\nLes widgets sont généralement appelés xxxInput(), par exemple selectInput().Les sorties sont généralement appelées xxxOutput(), par exemple plotOutput().Il est important de préciser que ces éléments ne peuvent pas être visualisés facilement de manière abstraite. Il est donc préférable de regarder un exemple ! Considérons la création d’une application de base qui visualise nos données de denombrement des equipemnts de lutte contre le paludisme par district. Ces données comportent un grand nombre de paramètres différents, et il serait formidable que l’utilisateur final puisse appliquer des filtres pour voir les données par groupe d’âge/district comme il l’entend ! Nous pouvons utiliser une mise en page shiny très simple pour commencer, la mise en page de la barre latérale. Il s’agit d’une mise en page où les widgets sont placés dans une barre latérale sur la gauche, et le graphique est placé sur la droite.Elaborons notre application: nous pouvons commencer par un sélecteur qui nous permet de choisir le district où nous voulons visualiser les données, et un autre qui nous permet de visualiser le groupe d’âge qui nous intéresse. Nous allons utiliser ces filtres pour afficher une épicurve qui reflète ces paramètres. Pour cela, nous avons besoin de:Deux menus déroulants qui nous permettent de choisir le district que nous voulons et le groupe d’âge qui nous intéresse.Une zone où nous pouvons montrer notre épicurve obtenue.Cela pourrait ressembler à quelque chose comme ceci:Lorsque app.R est exécuté avec le code d’interface utilisateur ci-dessus (sans code actif dans la partie server de app.R) le mise en page apparaît comme ceci. Notez qu’il n’y aura pas de tracé s’il n’y pas de serveur pour conduire à ce resultat, mais nos entrées fonctionnent !C’est une bonne occasion de discuter les fonctionnement des widgets. Notez que chaque widget accepte un inputId, un label, et une série d’autres options qui sont spécifiques au type de widget. Ce inputId est extrêmement important ! Ce sont les IDs qui sont utilisés pour passer les informations de l’IU au serveur. Pour cette raison, ils doivent être uniques. Vous devriez faire un effort pour les nommer de manière sensée et spécifique à ce avec quoi ils interagissent dans le cas de grandes applications.Vous devez lire attentivement la documentation pour obtenir tous les détails sur ce que font chacun de ces widgets. Les widgets transmettront des types de données spécifiques au serveur en fonction du type de widget, et cela doit être bien compris. Par exemple, selectInput() transmettra un type de caractère au serveur :Si nous sélectionnons Spring pour le premier widget ici, il transmettra l’objet caractère \"Spring\" au serveur.Si nous sélectionnons deux éléments dans le menu déroulant, ils seront transmis sous forme de vecteur de caractères (par exemple, c(\"Spring\", \"Bolo\")).D’autres widgets transmettront différents types d’objets au serveur ! Par exemplenumericInput() passera un objet de type numérique au serveur.checkboxInput() transmettra un objet de type logique au serveur (TRUE ou FALSE).Il est également intéressant de noter le vecteur nommé que nous avons utilisé pour les données d’âge ici. Pour de nombreux widgets, l’utilisation d’un vecteur nommé comme choix affichera les noms du vecteur comme choix d’affichage, mais passera la valeur sélectionnée du vecteur au serveur. Par exemple, ici quelqu’un peut sélectionner “15+” dans le menu déroulant, et l’interface utilisateur transmettra \"malaria_rdt_15\" au serveur - qui se trouve être le nom de la colonne qui nous intéresse !Il y beaucoup de widgets que vous pouvez utiliser dans votre application. Les widgets vous permettent également de télécharger des fichiers dans votre application, et de télécharger des sorties. Il existe également d’excellentes examples de shiny qui vous donnent accès à plus de widgets que le shiny de base. Le package shinyWidgets en est un excellent exemple. Pour voir quelques exemples, vous pouvez consulter les liens suivants :galerie de widgets de la base shinygalerie de widgets shinyWidgets","code":"\nlibrary(shiny)\n\nui <- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         # sélectionneur pour le district\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = c(\n                   \"All\",\n                   \"Spring\",\n                   \"Bolo\",\n                   \"Dingo\",\n                   \"Barnard\"\n              ),\n              selected = \"All\",\n              multiple = TRUE\n         ),\n         # sélecteur pour le groupe d'âge\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Sélectionnez le groupe d'âge\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         )\n\n    ),\n\n    mainPanel(\n      # epicurve va ici\n      plotOutput(\"malaria_epicurve\")\n    )\n    \n  )\n)"},{"path":"shiny.html","id":"chargement-des-données-dans-notre-application","chapter":"43 Tableaux de bord avec Shiny","heading":"43.4 Chargement des données dans notre application","text":"L’étape suivante dans le développement de notre application consiste à mettre en place le serveur et à le faire fonctionner. Pour ce faire, nous devons charger des données dans notre application, et déterminer tous les calculs que nous allons effectuer. Une application shiny n’est pas facile à déboguer, car ne sait pas toujours d’où viennent les erreurs. Il est donc idéal de faire fonctionner tout le code de traitement et de visualisation des données avant de commencer à créer le serveur lui-même.Ainsi, étant donné que nous voulons créer une application qui affiche des courbes épi qui changent en fonction de l’entrée de l’utilisateur, nous devons réfléchir au code dont nous aurions besoin pour l’exécuter dans un script R normal. Nous devrons :Charger nos packagesCharger nos donnéesTransformer nos donnéesDévelopper une fonction pour visualiser nos données en fonction des entrées de l’utilisateur.Cette liste est assez simple, et ne devrait pas être trop difficile à réaliser. Il est maintenant important de réfléchir aux parties de ce processus qui doivent être faites une seule fois et à celles qui doivent être exécutées en réponse aux entrées de l’utilisateur. En effet, les applications shiny exécutent généralement du code avant de s’exécuter, ce qui n’est fait qu’une seule fois. La performance de notre application sera améliorée si une grande partie de notre code peut être déplacée dans cette section. Pour cet exemple, nous n’avons besoin de charger nos données/packages et d’effectuer des transformations de base qu’une seule fois, nous pouvons donc placer ce code hors du serveur. Cela signifie que la seule chose dont nous aurons besoin dans le serveur est le code pour visualiser nos données. Développons d’abord tous ces composants dans un script. Cependant, puisque nous visualisons nos données à l’aide d’une fonction, nous pouvons également placer le code pour la fonction en dehors du serveur afin que notre fonction soit dans l’environnement lorsque l’application s’exécute !Commençons par charger nos données. Puisque nous travaillons avec un nouveau projet, et que nous voulons le rendre propre, nous pouvons créer un nouveau répertoire appelé data, et y ajouter nos données sur le paludisme. Nous pouvons exécuter ce code ci-dessous dans un script de test que nous supprimerons éventuellement lorsque nous aurons nettoyé la structure de notre application.Il sera plus facile de travailler avec ces données si nous utilisons des données ordonnées standards, nous devons donc également les transformer en un format de données plus long, où le groupe d’âge est une colonne, et les cas une autre colonne. Nous pouvons le faire facilement en utilisant ce que nous avons appris dans la page Pivoter les données.Et avec cela, nous avons fini de préparer nos données ! Cela raye les points 1, 2 et 3 de notre liste de choses à développer pour notre “script R de test”. La dernière tâche, et la plus difficile, sera de construire une fonction pour produire une épicurve basée sur des paramètres définis par l’utilisateur. Comme nous l’avons mentionné précédemment, il est hautement recommandé à toute personne apprenant shiny de regarder d’abord la section sur la programmation fonctionnelle (Écrire les fonctions) pour comprendre comment cela fonctionne !Lorsque nous définissons notre fonction, il peut être difficile de penser aux paramètres que nous voulons inclure. Dans le cadre de la programmation fonctionnelle avec shiny, chaque paramètre pertinent est généralement associé à un widget, ce qui facilite la réflexion ! Par exemple, dans notre application actuelle, nous voulons être en mesure de filtrer par district, et avoir un widget pour cela, donc nous pouvons ajouter un paramètre de district pour refléter cela. Nous n’avons pas de fonctionnalité d’application pour filtrer par établissement (pour l’instant), donc nous n’avons pas besoin de l’ajouter comme paramètre. Commençons par créer une fonction avec trois paramètres :L’ensemble de données de baseLe district de choixLe groupe d’âge choisiNous n’entrerons pas dans les détails de cette fonction, car elle est relativement simple dans son fonctionnement. Une chose à noter cependant, c’est que nous gérons les erreurs en retournant NULL alors qu’elle devrait entrainer une erreur. En effet, si le serveur shiny produit un objet NULL au lieu d’un objet plot, rien ne sera affiché dans l’interface utilisateur ! C’est important, car sinon les erreurs vont souvent provoquer l’arrêt du fonctionnement de votre application.Une autre chose à noter est l’utilisation de l’opérateur %% lors de l’évaluation de l’entrée district. Comme mentionné ci-dessus, cela pourrait arriver comme un vecteur de caractères avec plusieurs valeurs, donc l’utilisation de %% est plus flexible que disons, ==.Testons notre fonction !Maintenant que notre fonction fonctionne, nous devons comprendre comment tout cela va s’intégrer dans notre shiny application. Nous avons déjà mentionné le concept de startup code, mais voyons comment l’intégrer dans la structure de notre application. Il y deux façons de le faire !Placer ce code dans votre fichier app.R au début du script (au-dessus de l’interface utilisateur), ou bienCréer un nouveau fichier dans le répertoire de votre application appelé global.R, et placer le code de démarrage dans ce fichier.Il convient de noter à ce stade qu’il est généralement plus facile, en particulier pour les applications plus importantes, d’utiliser la deuxième structure de fichiers, car elle vous permet de séparer votre structure de fichiers d’une manière simple. Développons maintenant complètement ce script global.R. Voici à quoi il pourrait ressembler :Facile ! Une des grandes caractéristiques de shiny est qu’il comprend à quoi servent les fichiers nommés app.R, server.R, ui.R et global.R, il n’y donc pas besoin de les connecter entre eux par un quelconque code. Ainsi, il suffit d’avoir ce code dans global.R dans le répertoire pour qu’il s’exécute avant que nous démarrions notre application.Nous devons également noter que l’organisation de notre application serait améliorée si nous déplacions la fonction de traçage dans son propre fichier - cela sera particulièrement utile lorsque les applications deviendront plus grandes. Pour ce faire, nous pourrions créer un autre répertoire appelé funcs, et y placer cette fonction dans un fichier appelé plot_epicurve.R. Nous pourrions ensuite lire cette fonction via la commande suivante dans global.R.Notez que vous devriez toujours spécifier local = TRUE dans les applications shiny, car cela affectera le sourcing quand/si l’application est publiée sur un serveur.","code":"\npacman::p_load(\"tidyverse\", \"lubridate\")\n\n# read data\nmalaria_data <- rio::import(here::here(\"data\", \"malaria_facility_count_data.rds\")) %>% \n  as_tibble()\n\nprint(malaria_data)## # A tibble: 3,038 × 10\n##    location_name data_date  submitted_date Province District `malaria_rdt_0-4`\n##    <chr>         <date>     <date>         <chr>    <chr>                <int>\n##  1 Facility 1    2020-08-11 2020-08-12     North    Spring                  11\n##  2 Facility 2    2020-08-11 2020-08-12     North    Bolo                    11\n##  3 Facility 3    2020-08-11 2020-08-12     North    Dingo                    8\n##  4 Facility 4    2020-08-11 2020-08-12     North    Bolo                    16\n##  5 Facility 5    2020-08-11 2020-08-12     North    Bolo                     9\n##  6 Facility 6    2020-08-11 2020-08-12     North    Dingo                    3\n##  7 Facility 6    2020-08-10 2020-08-12     North    Dingo                    4\n##  8 Facility 5    2020-08-10 2020-08-12     North    Bolo                    15\n##  9 Facility 5    2020-08-09 2020-08-12     North    Bolo                    11\n## 10 Facility 5    2020-08-08 2020-08-12     North    Bolo                    19\n## # ℹ 3,028 more rows\n## # ℹ 4 more variables: `malaria_rdt_5-14` <int>, malaria_rdt_15 <int>,\n## #   malaria_tot <int>, newid <int>\nmalaria_data <- malaria_data %>%\n  select(-newid) %>%\n  pivot_longer(cols = starts_with(\"malaria_\"), names_to = \"age_group\", values_to = \"cases_reported\")\n\nprint(malaria_data)## # A tibble: 12,152 × 7\n##    location_name data_date  submitted_date Province District age_group    cases_reported\n##    <chr>         <date>     <date>         <chr>    <chr>    <chr>                 <int>\n##  1 Facility 1    2020-08-11 2020-08-12     North    Spring   malaria_rdt…             11\n##  2 Facility 1    2020-08-11 2020-08-12     North    Spring   malaria_rdt…             12\n##  3 Facility 1    2020-08-11 2020-08-12     North    Spring   malaria_rdt…             23\n##  4 Facility 1    2020-08-11 2020-08-12     North    Spring   malaria_tot              46\n##  5 Facility 2    2020-08-11 2020-08-12     North    Bolo     malaria_rdt…             11\n##  6 Facility 2    2020-08-11 2020-08-12     North    Bolo     malaria_rdt…             10\n##  7 Facility 2    2020-08-11 2020-08-12     North    Bolo     malaria_rdt…              5\n##  8 Facility 2    2020-08-11 2020-08-12     North    Bolo     malaria_tot              26\n##  9 Facility 3    2020-08-11 2020-08-12     North    Dingo    malaria_rdt…              8\n## 10 Facility 3    2020-08-11 2020-08-12     North    Dingo    malaria_rdt…              5\n## # ℹ 12,142 more rows\nplot_epicurve <- function(data, district = \"All\", agegroup = \"malaria_tot\") {\n  \n  if (!(\"All\" %in% district)) {\n    data <- data %>%\n      filter(District %in% district)\n    \n    plot_title_district <- stringr::str_glue(\"{paste0(district, collapse = ', ')} districts\")\n    \n  } else {\n    \n    plot_title_district <- \"all districts\"\n    \n  }\n  \n  # s'il n'y a pas de données restantes, retourne NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  data <- data %>%\n    filter(age_group == agegroup)\n  \n  \n  # s'il n'y a pas de données restantes, retourne NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  if (agegroup == \"malaria_tot\") {\n      agegroup_title <- \"All ages\"\n  } else {\n    agegroup_title <- stringr::str_glue(\"{str_remove(agegroup, 'malaria_rdt')} years\")\n  }\n  \n  \n  ggplot(data, aes(x = data_date, y = cases_reported)) +\n    geom_col(width = 1, fill = \"darkred\") +\n    theme_minimal() +\n    labs(\n      x = \"date\",\n      y = \"number of cases\",\n      title = stringr::str_glue(\"Malaria cases - {plot_title_district}\"),\n      subtitle = agegroup_title\n    )\n  \n  \n  \n}\nplot_epicurve(malaria_data, district = \"Bolo\", agegroup = \"malaria_rdt_0-4\")\n# global.R script\n\npacman::p_load(\"tidyverse\", \"lubridate\", \"shiny\")\n\n\n# lire les données\nmalaria_data <- rio::import(here::here(\"data\", \"malaria_facility_count_data.rds\")) %>% \n  as_tibble()\n\n# données nettoyées et  pivotées en longueur\n\nmalaria_data <- malaria_data %>%\n  select(-newid) %>%\n  pivot_longer(cols = starts_with(\"malaria_\"), names_to = \"age_group\", values_to = \"cases_reported\")\n\n\n# definir la fonction pour la representation graphique\nplot_epicurve <- function(data, district = \"All\", agegroup = \"malaria_tot\") {\n  \n  # creer le titre du graphe\n  if (!(\"All\" %in% district)) {            \n    data <- data %>%\n      filter(District %in% district)\n    \n    plot_title_district <- stringr::str_glue(\"{paste0(district, collapse = ', ')} districts\")\n    \n  } else {\n    \n    plot_title_district <- \"all districts\"\n    \n  }\n  \n  # s'il n'y a pas de données restantes, retourne NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  # filtrer par groupe d'âge\n  data <- data %>%\n    filter(age_group == agegroup)\n  \n  \n  # s'il n'y a pas de données restantes, retourne NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  if (agegroup == \"malaria_tot\") {\n      agegroup_title <- \"All ages\"\n  } else {\n    agegroup_title <- stringr::str_glue(\"{str_remove(agegroup, 'malaria_rdt')} years\")\n  }\n  \n  \n  ggplot(data, aes(x = data_date, y = cases_reported)) +\n    geom_col(width = 1, fill = \"darkred\") +\n    theme_minimal() +\n    labs(\n      x = \"date\",\n      y = \"number of cases\",\n      title = stringr::str_glue(\"Malaria cases - {plot_title_district}\"),\n      subtitle = agegroup_title\n    )\n  \n  \n  \n}\nsource(here(\"funcs\", \"plot_epicurve.R\"), local = TRUE)"},{"path":"shiny.html","id":"développer-un-serveur-dapplications","chapter":"43 Tableaux de bord avec Shiny","heading":"43.5 Développer un serveur d’applications","text":"Maintenant que nous avons la plupart de notre code, il nous reste à développer notre serveur. Il s’agit de la dernière pièce de notre application, et c’est probablement la plus difficile à comprendre. Le serveur est une grande fonction R, mais il est utile de le considérer comme une série de petites fonctions, ou de tâches que l’application peut exécuter. Il est important de comprendre que ces fonctions ne sont pas exécutées dans un ordre linéaire. Il existe un ordre, mais il n’est pas nécessaire de le comprendre lorsqu’débute avec Shiny. À un niveau très basique, ces tâches ou fonctions s’activent lorsqu’un changement dans les entrées de l’utilisateur les affecte, à moins que le développeur ne les ait configurées pour qu’elles se comportent différemment. Encore une fois, tout cela est assez abstrait, mais passons d’abord en revue les trois types d’objets shiny de baseLes sources réactives - c’est un autre terme pour les entrées de l’utilisateur. Le serveur shiny accès aux sorties de l’interface utilisateur par le biais des widgets que nous avons programmés. Chaque fois que les valeurs de ces derniers sont modifiées, elles sont transmises au serveur.Les sources réactives - c’est un autre terme pour les entrées de l’utilisateur. Le serveur shiny accès aux sorties de l’interface utilisateur par le biais des widgets que nous avons programmés. Chaque fois que les valeurs de ces derniers sont modifiées, elles sont transmises au serveur.Conducteurs réactifs - ce sont des objets qui existent seulement à l’intérieur du shiny server. Nous n’en avons pas vraiment besoin pour les applications simples, mais ils produisent des objets qui ne peuvent être vus qu’à l’intérieur du serveur, et utilisés dans d’autres opérations. Ils dépendent généralement de sources réactives.Conducteurs réactifs - ce sont des objets qui existent seulement à l’intérieur du shiny server. Nous n’en avons pas vraiment besoin pour les applications simples, mais ils produisent des objets qui ne peuvent être vus qu’à l’intérieur du serveur, et utilisés dans d’autres opérations. Ils dépendent généralement de sources réactives.Les points de terminaison - ce sont les sorties qui sont transmises du serveur à l’interface utilisateur. Dans notre exemple, il s’agit de la courbe épi que nous produisons.Les points de terminaison - ce sont les sorties qui sont transmises du serveur à l’interface utilisateur. Dans notre exemple, il s’agit de la courbe épi que nous produisons.Avec ceci en tête, construisons notre serveur étape par étape. Nous montrons à nouveau le code de l’interface utilisateur à titre de référence :De ce code UI nous avons :Deux entrées :\nSélecteur de district (avec un inputId de select_district)\nUn sélecteur de groupe d’âge (avec un inputId de select_agegroup)\nSélecteur de district (avec un inputId de select_district)Un sélecteur de groupe d’âge (avec un inputId de select_agegroup)Une sortie :\nL’épicurve (avec un outputId de malaria_epicurve)\nL’épicurve (avec un outputId de malaria_epicurve)Comme indiqué précédemment, ces noms uniques que nous avons attribués à nos entrées et sorties sont cruciaux. Ils doivent être uniques et sont utilisés pour transmettre des informations entre l’interface utilisateur et le serveur. Dans notre serveur, nous accédons à nos entrées via la syntaxe input$inputID et les sorties sont transmises à l’interface utilisateur via la syntaxe output$output_name Voyons un exemple, car encore une fois, c’est difficile à comprendre autrement !Le serveur pour une application simple comme celle-ci est en fait assez simple ! Vous remarquerez que le serveur est une fonction avec trois paramètres - input, output, et session - ce n’est pas très important à comprendre pour le moment, mais il est important de s’en tenir à cette configuration ! Dans notre serveur, nous n’avons qu’une seule tâche - elle rend un graphique basé sur la fonction que nous avons créée plus tôt, et les entrées du serveur. Remarquez que les noms des objets d’entrée et de sortie correspondent exactement à ceux de l’interface utilisateur.Pour comprendre les bases de la façon dont le serveur réagit aux entrées de l’utilisateur, vous devez noter que la sortie saura (grâce au package sous-jacent) quand les entrées changent, et réexécutera cette fonction pour créer un graphique à chaque fois qu’elles changent. Notez que nous utilisons également la fonction renderPlot() ici - c’est l’une des fonctions d’une famille de classes spécifiques qui passent ces objets à une sortie ui. Il existe un certain nombre de fonctions qui se comportent de manière similaire, mais vous devez vous assurer que la fonction utilisée correspond à la classe de l’objet que vous transmettez à l’interface utilisateur ! Par exemple :renderText() - envoie du texte à l’interface utilisateurrenderDataTable - envoie une table interactive à l’interface utilisateur.Rappelez-vous que ces fonctions doivent également correspondre à la fonction de sortie utilisée dans l’interface utilisateur - ainsi, renderPlot() est associé à plotOutput(), et renderText() est associé à textOutput().Nous avons enfin créé une application fonctionnelle ! Nous pouvons l’exécuter en appuyant sur le bouton Run App en haut à droite de la fenêtre du script dans Rstudio. Notez que vous pouvez choisir de lancer votre application dans votre navigateur par défaut (plutôt que dans Rstudio), ce qui reflétera plus fidèlement ce à quoi l’application ressemblera pour les autres utilisateurs.Il est amusant de noter que dans la console R, l’application est “à l’écoute” ! parle de réactivité !","code":"\nui <- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         # sélectionneur pour le district\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Sélectionnez le district\",\n              choices = c(\n                   \"All\",\n                   \"Spring\",\n                   \"Bolo\",\n                   \"Dingo\",\n                   \"Barnard\"\n              ),\n              selected = \"All\",\n              multiple = TRUE\n         ),\n         # sélectionnez le groupe d'âge\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Sélectionnez le groupe d'âge\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         )\n\n    ),\n\n    mainPanel(\n      # epicurve va ici\n      plotOutput(\"malaria_epicurve\")\n    )\n    \n  )\n)\nserver <- function(input, output, session) {\n  \n  output$malaria_epicurve <- renderPlot(\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  )\n  \n}"},{"path":"shiny.html","id":"ajout-de-fonctionnalités-supplémentaires","chapter":"43 Tableaux de bord avec Shiny","heading":"43.6 Ajout de fonctionnalités supplémentaires","text":"À ce stade, nous avons enfin une application qui fonctionne, mais nous avons très peu de fonctionnalités. De plus, nous n’avons pas encore touché à la surface de ce que shiny peut faire, il y donc encore beaucoup à apprendre ! Continuons à développer notre application existante en ajoutant quelques fonctionnalités supplémentaires. Voici quelques éléments qu’il serait bon d’ajouter :Un texte explicatifUn bouton de téléchargement pour notre parcelle - cela permettrait à l’utilisateur d’obtenir une version de haute qualité de l’image qu’il génère dans l’application.Un sélecteur pour des equipements particuliersUne autre page de tableau de bord - elle pourrait afficher un tableau de nos données.Cela fait beaucoup de choses à ajouter, mais nous pouvons l’utiliser pour en apprendre davantage sur un tas de prouesses différentes en cours. Il y tant à apprendre sur shiny (il peut être très avancé, mais il est à espérer qu’une fois que les utilisateurs ont une meilleure idée de la façon de l’utiliser, ils peuvent devenir plus à l’aise en utilisant des sources d’apprentissage externes aussi).","code":""},{"path":"shiny.html","id":"ajouter-du-texte-statique","chapter":"43 Tableaux de bord avec Shiny","heading":"Ajouter du texte statique","text":"Parlons d’abord de l’ajout de texte statique à notre application shiny. L’ajout de texte à notre application est extrêmement facile, une fois que vous en avez une connaissance de base. Puisque le texte statique ne change pas dans l’application shiny (si vous voulez qu’il change, vous pouvez utiliser les fonctions de rendu de texte dans le serveur ! Nous n’allons pas entrer dans les détails, mais vous pouvez ajouter un certain nombre d’éléments différents à votre interface utilisateur (et même des éléments personnalisés) en interfaçant R avec HTML et css.HTML et css sont des langages qui sont explicitement impliqués dans la conception de l’interface utilisateur. Nous n’avons pas besoin de trop les comprendre, mais HTML crée des objets dans l’IU (comme une boîte de texte, ou un tableau), et css est généralement utilisé pour changer le style et l’esthétique de ces objets. Shiny accès à un large éventail de balises HTML - celles-ci sont présentes pour les objets qui se comportent d’une manière spécifique, comme les en-têtes, les paragraphes de texte, les sauts de ligne, les tableaux, etc. Nous pouvons utiliser certains de ces exemples comme ceci :h1() - il s’agit d’une balise header, qui rendra le texte inclus automatiquement plus grand, et changera les valeurs par défaut en ce qui concerne la police, la couleur, etc (selon le thème général de votre application). Vous pouvez accéder à des sous-titres plus petits et plus petits avec h2() jusqu’à h6() également. L’utilisation ressemble à :\nh1(\"mon en-tête - section 1\")\nh1() - il s’agit d’une balise header, qui rendra le texte inclus automatiquement plus grand, et changera les valeurs par défaut en ce qui concerne la police, la couleur, etc (selon le thème général de votre application). Vous pouvez accéder à des sous-titres plus petits et plus petits avec h2() jusqu’à h6() également. L’utilisation ressemble à :h1(\"mon en-tête - section 1\")p() - il s’agit d’une balise paragraphe, qui rendra le texte inclus similaire à un texte dans un corps de texte. Ce texte sera automatiquement enveloppé, et sera d’une taille relativement petite (les pieds de page pourraient être plus petits par exemple.) Pensez-y comme le corps de texte d’un document Word. L’utilisation ressemble à :\np(\"Ceci est un corps de texte plus large où j'explique la fonction de mon application\")\np() - il s’agit d’une balise paragraphe, qui rendra le texte inclus similaire à un texte dans un corps de texte. Ce texte sera automatiquement enveloppé, et sera d’une taille relativement petite (les pieds de page pourraient être plus petits par exemple.) Pensez-y comme le corps de texte d’un document Word. L’utilisation ressemble à :p(\"Ceci est un corps de texte plus large où j'explique la fonction de mon application\")tags$b() et tags$() - elles sont utilisées pour créer des tags$b() en gras et des tags$() en italique avec le texte inclus !tags$b() et tags$() - elles sont utilisées pour créer des tags$b() en gras et des tags$() en italique avec le texte inclus !tags$ul(), tags$ol() et tags$li() - ce sont des balises utilisées pour créer des listes. Elles sont toutes utilisées dans la syntaxe ci-dessous, et permettent à l’utilisateur de créer une liste ordonnée (tags$ol(), c’est-à-dire numérotée) ou non ordonnée (tags$ul(), c’est-à-dire à puces). tags$li() est utilisé pour désigner les éléments de la liste, quel que soit le type de liste utilisé. par exemple :tags$ul(), tags$ol() et tags$li() - ce sont des balises utilisées pour créer des listes. Elles sont toutes utilisées dans la syntaxe ci-dessous, et permettent à l’utilisateur de créer une liste ordonnée (tags$ol(), c’est-à-dire numérotée) ou non ordonnée (tags$ul(), c’est-à-dire à puces). tags$li() est utilisé pour désigner les éléments de la liste, quel que soit le type de liste utilisé. par exemple :br() et hr() - ces balises créent respectivement des sauts de ligne et des lignes horizontales (avec un saut de ligne). Utilisez-les pour séparer les sections de votre application et de votre texte ! Il n’est pas nécessaire de passer des éléments à ces balises (les parenthèses peuvent rester vides).br() et hr() - ces balises créent respectivement des sauts de ligne et des lignes horizontales (avec un saut de ligne). Utilisez-les pour séparer les sections de votre application et de votre texte ! Il n’est pas nécessaire de passer des éléments à ces balises (les parenthèses peuvent rester vides).div() - c’est une balise générique qui peut contenir n’importe quoi, et peut être nommée n’importe comment. Une fois que vous aurez progressé dans la conception de l’IU, vous pourrez les utiliser pour compartimenter votre IU, donner des styles spécifiques à certaines sections et créer des interactions entre le serveur et les éléments de l’IU. Nous n’entrerons pas dans les détails, mais il vaut la peine de les connaître !div() - c’est une balise générique qui peut contenir n’importe quoi, et peut être nommée n’importe comment. Une fois que vous aurez progressé dans la conception de l’IU, vous pourrez les utiliser pour compartimenter votre IU, donner des styles spécifiques à certaines sections et créer des interactions entre le serveur et les éléments de l’IU. Nous n’entrerons pas dans les détails, mais il vaut la peine de les connaître !Notez que chacun de ces objets peut être accédé par tags$... ou pour certains, juste la fonction. Ce sont effectivement des synonymes, mais il peut être utile d’utiliser le style tags$... si vous préférez être plus explicite et ne pas écraser les fonctions accidentellement. Ceci n’est en aucun cas une liste exhaustive des balises disponibles. Il existe une liste complète de toutes les balises disponibles dans shiny ici et encore plus peuvent être utilisées en insérant du HTML directement dans votre interface !Si vous vous sentez confiant, vous pouvez également ajouter des éléments de style css à vos balises HTML avec l’argument style dans chacune d’entre elles. Nous n’allons pas entrer dans les détails de ce fonctionnement, mais une astuce pour tester les changements esthétiques d’une interface utilisateur est d’utiliser le mode inspecteur HTML dans chrome (de votre shiny application que vous exécutez dans le navigateur), et de modifier le style des objets vous-même !Ajoutons du texte à notre application","code":"\ntags$ol(\n  \n  tags$li(\"Item 1\"),\n  \n  tags$li(\"Item 2\"),\n  \n  tags$li(\"Item 3\")\n  \n)\nui <- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         h4(\"Options\"),\n         # sélectionneur pour le district\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = c(\n                   \"All\",\n                   \"Spring\",\n                   \"Bolo\",\n                   \"Dingo\",\n                   \"Barnard\"\n              ),\n              selected = \"All\",\n              multiple = TRUE\n         ),\n         # sélecteur pour le groupe d'âge\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         ),\n    ),\n\n    mainPanel(\n      # epicurve va ici\n      plotOutput(\"malaria_epicurve\"),\n      br(),\n      hr(),\n      p(\"Welcome to the malaria facility visualisation app! To use this app, manipulate the widgets on the side to change the epidemic curve according to your preferences! To download a high quality image of the plot you've created, you can also download it with the download button. To see the raw data, use the raw data tab for an interactive form of the table. The data dictionary is as follows:\"),\n    tags$ul(\n      tags$li(tags$b(\"location_name\"), \" - the facility that the data were collected at\"),\n      tags$li(tags$b(\"data_date\"), \" - the date the data were collected at\"),\n      tags$li(tags$b(\"submitted_daate\"), \" - the date the data were submitted at\"),\n      tags$li(tags$b(\"Province\"), \" - the province the data were collected at (all 'North' for this dataset)\"),\n      tags$li(tags$b(\"District\"), \" - the district the data were collected at\"),\n      tags$li(tags$b(\"age_group\"), \" - the age group the data were collected for (0-5, 5-14, 15+, and all ages)\"),\n      tags$li(tags$b(\"cases_reported\"), \" - the number of cases reported for the facility/age group on the given date\")\n    )\n    \n  )\n)\n)"},{"path":"shiny.html","id":"ajouter-un-lien","chapter":"43 Tableaux de bord avec Shiny","heading":"Ajouter un lien","text":"Pour ajouter un lien à un site Web, utilisez tags$() avec le lien et le texte à afficher comme indiqué ci-dessous. Pour avoir un paragraphe autonome, mettez-le dans p(). Pour que seuls quelques mots d’une phrase soient liés, divisez la phrase en plusieurs parties et utilisez tags$() pour la partie hyperliée. Pour que le lien s’ouvre dans une nouvelle fenêtre du navigateur, ajoutez target = \"_blank\" comme argument.","code":"\ntags$a(href = \"www.epiRhandbook.com\", \"Visit our website!\")"},{"path":"shiny.html","id":"ajout-dun-bouton-de-téléchargement","chapter":"43 Tableaux de bord avec Shiny","heading":"Ajout d’un bouton de téléchargement","text":"Passons à la deuxième des trois fonctions. Un bouton de téléchargement est une chose assez courante à ajouter à une application et est assez facile à réaliser. Nous devons ajouter un autre Widget à notre interface, et nous devons ajouter une autre sortie à notre serveur pour l’attacher. Nous pouvons également introduire des conducteurs réactifs dans cet exemple !Mettons d’abord à jour notre interface utilisateur - c’est facile car shiny est livré avec un widget appelé downloadButton() - donnons-lui un inputId et un label.Notez que nous avons également ajouté une balise hr() - celle-ci ajoute une ligne horizontale séparant nos widgets de contrôle de nos widgets de téléchargement. C’est une autre des balises HTML dont nous avons parlé précédemment.Maintenant que notre interface utilisateur est prête, nous devons ajouter le composant serveur. Les téléchargements sont effectués dans le serveur avec la fonction downloadHandler(). Comme pour notre plot, nous devons l’attacher à une sortie qui le même inputId que le bouton de téléchargement. Cette fonction prend deux arguments - filename et content - ce sont tous deux des fonctions. Comme vous pouvez le deviner, filename est utilisé pour spécifier le nom du fichier à télécharger, et content est utilisé pour spécifier ce qui doit être téléchargé. content contient une fonction que vous utiliserez pour sauvegarder des données localement - donc si vous téléchargez un fichier csv, vous pourrez utiliser rio::export(). Comme nous téléchargeons un graphique, nous utiliserons ggplot2::ggsave(). Voyons comment nous allons programmer ceci (nous ne l’ajouterons pas encore au serveur).Notez que la fonction content prend toujours un argument file, que nous mettons là où le nom du fichier de sortie est spécifié. Vous pouvez également remarquer que nous répétons du code ici - nous utilisons notre fonction plot_epicurve() deux fois dans ce serveur, une fois pour le téléchargement et une fois pour l’image affichée dans l’application. Bien que cela n’affecte pas massivement les performances, cela signifie que le code pour générer ce tracé devra être exécuté lorsque l’utilisateur change les widgets spécifiant le district et le groupe d’âge, et à nouveau lorsque vous voulez télécharger le tracé. Dans les grandes applications, les décisions sous-optimales comme celle-ci ralentiront de plus en plus les choses, il est donc bon d’apprendre comment rendre notre application plus efficace dans ce sens. Ce qui serait plus logique, c’est d’avoir un moyen d’exécuter le code epicurve lorsque les districts/groupes d’âge sont modifiés, et de laisser ce code être utilisé par les fonctions renderPlot() et downloadHandler(). C’est là que les conducteurs réactifs entrent en jeu !Les conducteurs réactifs sont des objets qui sont créés dans le serveur shiny de manière réactive, mais qui ne sont pas édités - ils peuvent simplement être utilisés par d’autres parties du serveur. Il existe un certain nombre de types différents de conducteurs réactifs, mais nous allons passer en revue les deux principaux.1.reactive() - c’est le conducteur réactif le plus basique - il réagira à chaque fois que les entrées utilisées à l’intérieur changeront (comme nos widgets de district/groupe d’âge).\n2. eventReactive() - ce conducteur réactif fonctionne de la même manière que reactive(), sauf que l’utilisateur peut spécifier les entrées qui le font réexécuter. Ceci est utile si votre conducteur réactif prend beaucoup de temps à traiter, mais ceci sera expliqué plus tard.Regardons les deux exemples :Lorsque nous utilisons la configuration eventReactive(), nous pouvons spécifier quelles entrées provoquent l’exécution de ce morceau de code - ce n’est pas très utile pour nous pour le moment, donc nous pouvons le laisser pour l’instant. Notez que vous pouvez inclure plusieurs entrées avec c().Voyons comment nous pouvons intégrer cela dans notre code serveur :Vous pouvez voir que nous faisons simplement appel à la sortie de notre réactif que nous avons défini dans nos fonctions de téléchargement et de rendu de tracé. Une chose à noter qui fait souvent trébucher les gens est que vous devez utiliser les sorties des réactifs comme s’il s’agissait de fonctions - vous devez donc ajouter des parenthèses vides à la fin de celles-ci (par exemple, malaria_plot() est correct, et malaria_plot ne l’est pas). Maintenant que nous avons ajouté cette solution, notre application est un peu plus ordonnée, plus rapide et plus facile à modifier puisque tout le code qui exécute la fonction epicurve se trouve à un seul endroit.","code":"\nui <- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         # sélectionneur pour le district\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = c(\n                   \"All\",\n                   \"Spring\",\n                   \"Bolo\",\n                   \"Dingo\",\n                   \"Barnard\"\n              ),\n              selected = \"All\",\n              multiple = FALSE\n         ),\n         # sélecteur pour le groupe d'âge\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         ),\n         # ligne horizontale\n         hr(),\n         downloadButton(\n           outputId = \"download_epicurve\",\n           label = \"Download plot\"\n         )\n\n    ),\n\n    mainPanel(\n      # epicurve va ici\n      plotOutput(\"malaria_epicurve\"),\n      br(),\n      hr(),\n      p(\"Welcome to the malaria facility visualisation app! To use this app, manipulate the widgets on the side to change the epidemic curve according to your preferences! To download a high quality image of the plot you've created, you can also download it with the download button. To see the raw data, use the raw data tab for an interactive form of the table. The data dictionary is as follows:\"),\n      tags$ul(\n        tags$li(tags$b(\"location_name\"), \" - the facility that the data were collected at\"),\n        tags$li(tags$b(\"data_date\"), \" - the date the data were collected at\"),\n        tags$li(tags$b(\"submitted_daate\"), \" - the date the data were submitted at\"),\n        tags$li(tags$b(\"Province\"), \" - the province the data were collected at (all 'North' for this dataset)\"),\n        tags$li(tags$b(\"District\"), \" - the district the data were collected at\"),\n        tags$li(tags$b(\"age_group\"), \" - the age group the data were collected for (0-5, 5-14, 15+, and all ages)\"),\n        tags$li(tags$b(\"cases_reported\"), \" - the number of cases reported for the facility/age group on the given date\")\n      )\n      \n    )\n    \n  )\n)\nserver <- function(input, output, session) {\n  \n  output$malaria_epicurve <- renderPlot(\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  )\n  \n  output$download_epicurve <- downloadHandler(\n    filename = function() {\n      stringr::str_glue(\"malaria_epicurve_{input$select_district}.png\")\n    },\n    \n    content = function(file) {\n      ggsave(file, \n             plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup),\n             width = 8, height = 5, dpi = 300)\n    }\n    \n  )\n  \n}\nmalaria_plot_r <- reactive({\n  \n  plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  \n})\n\n\n# ne s'exécute que lorsque le sélecteur de district change !\nmalaria_plot_er <- eventReactive(input$select_district, {\n  \n  plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  \n})\nserver <- function(input, output, session) {\n  \n  malaria_plot <- reactive({\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  })\n  \n  \n  \n  output$malaria_epicurve <- renderPlot(\n    malaria_plot()\n  )\n  \n  output$download_epicurve <- downloadHandler(\n    \n    filename = function() {\n      stringr::str_glue(\"malaria_epicurve_{input$select_district}.png\")\n    },\n    \n    content = function(file) {\n      ggsave(file, \n             malaria_plot(),\n             width = 8, height = 5, dpi = 300)\n    }\n    \n  )\n  \n}"},{"path":"shiny.html","id":"ajout-dun-sélecteur-dequipements","chapter":"43 Tableaux de bord avec Shiny","heading":"Ajout d’un sélecteur d’equipements","text":"Passons à la fonctionnalité suivante : un sélecteur d’equipements spécifiques. Nous allons implémenter un autre paramètre dans notre fonction afin de pouvoir le passer comme argument dans notre code. Voyons d’abord ce qu’il en est - il fonctionne sur les mêmes principes que les autres paramètres que nous avons mis en place. Mettons à jour et testons notre fonction.Testons ca:Avec tous les equipements présentes dans nos données, il n’est pas très clair quels equipements correspondent à quels districts - et l’utilisateur final ne le saura pas non plus. Cela pourrait rendre l’utilisation de l’application assez peu intuitive. Pour cette raison, nous devrions faire en sorte que les options des equipements dans l’interface utilisateur changent dynamiquement lorsque l’utilisateur change de district - de sorte que l’une filtre l’autre ! Puisque nous utilisons un grand nombre de variables dans les options, nous pourrions également vouloir générer certaines de nos options pour l’interface utilisateur dans notre fichier global.R à partir des données. Par exemple, nous pouvons ajouter ce morceau de code à global.R après avoir lu nos données :Let’s look :Nous pouvons passer ces nouvelles variables à l’interface utilisateur sans aucun problème, puisqu’elles sont globalement visibles à la fois par le serveur et l’interface utilisateur ! Mettons à jour notre interface utilisateur :Remarquez comment nous passons maintenant des variables pour nos choix au lieu de les coder en dur dans l’interface utilisateur ! Cela pourrait également rendre notre code plus compact ! Enfin, nous devrons mettre à jour le serveur. Il sera facile de mettre à jour notre fonction pour incorporer notre nouvelle entrée (nous devons juste la passer comme argument à notre nouveau paramètre), mais nous devons nous rappeler que nous voulons aussi que l’interface utilisateur soit mise à jour dynamiquement lorsque l’utilisateur change le district sélectionné. Il est important de comprendre ici que nous pouvons modifier les paramètres et le comportement des widgets pendant l’exécution de l’application, mais que cela doit être fait dans le serveur. Nous devons comprendre une nouvelle façon d’envoyer des données au serveur pour apprendre à le faire.Les fonctions dont nous avons besoin pour comprendre comment faire cela sont connues sous le nom de fonctions observatrices, et sont similaires aux fonctions réactives dans leur comportement. Elles présentent toutefois une différence essentielle :Les fonctions réactives n’affectent pas directement les sorties et produisent des objets qui peuvent être vus à d’autres endroits du serveur.Les fonctions d’observation peuvent affecter les sorties du serveur, mais le font via des effets secondaires d’autres fonctions. (Elles peuvent aussi faire d’autres choses, mais c’est leur principale fonction en pratique).Comme pour les fonctions réactives, il existe deux types de fonctions d’observation, qui sont divisées par la même logique que les fonctions réactives :observe() - cette fonction s’exécute à chaque fois que les entrées qu’elle contient changent.observeEvent() - cette fonction s’exécute lorsqu’une entrée spécifiée par l’utilisateur change.Nous devons également comprendre les fonctions fournies par Shiny qui mettent à jour les widgets. Elles sont assez simples à exécuter - elles prennent d’abord l’objet session de la fonction serveur (il n’est pas nécessaire de le comprendre pour l’instant), puis le inputId de la fonction à modifier. Nous passons ensuite de nouvelles versions de tous les paramètres qui sont déjà pris par selectInput() - ceux-ci seront automatiquement mis à jour dans le widget.Regardons un exemple isolé de la façon dont nous pourrions utiliser ceci dans notre serveur. Lorsque l’utilisateur change de district, nous voulons filtrer notre tableau d’installations par district, et mettre à jour les choix pour seulement refléter ceux qui sont disponibles dans ce district (et une option pour toutes les installations).Et voilà ! nous pouvons l’ajouter dans notre serveur, et ce comportement fonctionnera désormais. Voici à quoi devrait ressembler notre nouveau serveur :","code":"\nplot_epicurve <- function(data, district = \"All\", agegroup = \"malaria_tot\", facility = \"All\") {\n  \n  if (!(\"All\" %in% district)) {\n    data <- data %>%\n      filter(District %in% district)\n    \n    plot_title_district <- stringr::str_glue(\"{paste0(district, collapse = ', ')} districts\")\n    \n  } else {\n    \n    plot_title_district <- \"all districts\"\n    \n  }\n  \n\n  # si il n ya pas de données restantes, retourner NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  data <- data %>%\n    filter(age_group == agegroup)\n  \n  \n\n  # si il n ya pas de données restantes, retourner NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  if (agegroup == \"malaria_tot\") {\n      agegroup_title <- \"All ages\"\n  } else {\n    agegroup_title <- stringr::str_glue(\"{str_remove(agegroup, 'malaria_rdt')} years\")\n  }\n  \n    if (!(\"All\" %in% facility)) {\n    data <- data %>%\n      filter(location_name == facility)\n    \n    plot_title_facility <- facility\n    \n  } else {\n    \n    plot_title_facility <- \"all facilities\"\n    \n  }\n  \n  # s'il n'y a pas de données restantes, retourne NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n\n  \n  \n  ggplot(data, aes(x = data_date, y = cases_reported)) +\n    geom_col(width = 1, fill = \"darkred\") +\n    theme_minimal() +\n    labs(\n      x = \"date\",\n      y = \"number of cases\",\n      title = stringr::str_glue(\"Malaria cases - {plot_title_district}; {plot_title_facility}\"),\n      subtitle = agegroup_title\n    )\n  \n  \n  \n}\nplot_epicurve(malaria_data, district = \"Spring\", agegroup = \"malaria_rdt_0-4\", facility = \"Facility 1\")\nall_districts <- c(\"All\", unique(malaria_data$District))\n\n# base de données des noms de lieux par district\nfacility_list <- malaria_data %>%\n  group_by(location_name, District) %>%\n  summarise() %>% \n  ungroup()\nall_districts## [1] \"All\"     \"Spring\"  \"Bolo\"    \"Dingo\"   \"Barnard\"\nfacility_list## # A tibble: 65 × 2\n##    location_name District\n##    <chr>         <chr>   \n##  1 Facility 1    Spring  \n##  2 Facility 10   Bolo    \n##  3 Facility 11   Spring  \n##  4 Facility 12   Dingo   \n##  5 Facility 13   Bolo    \n##  6 Facility 14   Dingo   \n##  7 Facility 15   Barnard \n##  8 Facility 16   Barnard \n##  9 Facility 17   Barnard \n## 10 Facility 18   Bolo    \n## # ℹ 55 more rows\nui <- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         # selecteur pour district\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select dsitrict\",\n              choices = all_districts,\n              selected = \"All\",\n              multiple = FALSE\n         ),\n         # selecteur pour age group\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         ),\n         # selecteur poiur facility\n         selectInput(\n           inputId = \"select_facility\",\n           label = \"Select Facility\",\n           choices = c(\"All\", facility_list$location_name),\n           selected = \"All\"\n         ),\n         \n         # ligne horizontale\n         hr(),\n         downloadButton(\n           outputId = \"download_epicurve\",\n           label = \"Download plot\"\n         )\n\n    ),\n\n    mainPanel(\n      # epicurve va ici\n      plotOutput(\"malaria_epicurve\"),\n      br(),\n      hr(),\n      p(\"Welcome to the malaria facility visualisation app! To use this app, manipulate the widgets on the side to change the epidemic curve according to your preferences! To download a high quality image of the plot you've created, you can also download it with the download button. To see the raw data, use the raw data tab for an interactive form of the table. The data dictionary is as follows:\"),\n      tags$ul(\n        tags$li(tags$b(\"location_name\"), \" - the facility that the data were collected at\"),\n        tags$li(tags$b(\"data_date\"), \" - the date the data were collected at\"),\n        tags$li(tags$b(\"submitted_daate\"), \" - the date the data were submitted at\"),\n        tags$li(tags$b(\"Province\"), \" - the province the data were collected at (all 'North' for this dataset)\"),\n        tags$li(tags$b(\"District\"), \" - the district the data were collected at\"),\n        tags$li(tags$b(\"age_group\"), \" - the age group the data were collected for (0-5, 5-14, 15+, and all ages)\"),\n        tags$li(tags$b(\"cases_reported\"), \" - the number of cases reported for the facility/age group on the given date\")\n      )\n      \n    )\n    \n  )\n)\nobserve({\n  \n  if (input$select_district == \"All\") {\n    new_choices <- facility_list$location_name\n  } else {\n    new_choices <- facility_list %>%\n      filter(District == input$select_district) %>%\n      pull(location_name)\n  }\n  \n  new_choices <- c(\"All\", new_choices)\n  \n  updateSelectInput(session, inputId = \"select_facility\",\n                    choices = new_choices)\n  \n})\nserver <- function(input, output, session) {\n  \n  malaria_plot <- reactive({\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup, facility = input$select_facility)\n  })\n  \n  \n  \n  observe({\n    \n    if (input$select_district == \"All\") {\n      new_choices <- facility_list$location_name\n    } else {\n      new_choices <- facility_list %>%\n        filter(District == input$select_district) %>%\n        pull(location_name)\n    }\n    \n    new_choices <- c(\"All\", new_choices)\n    \n    updateSelectInput(session, inputId = \"select_facility\",\n                      choices = new_choices)\n    \n  })\n  \n  \n  output$malaria_epicurve <- renderPlot(\n    malaria_plot()\n  )\n  \n  output$download_epicurve <- downloadHandler(\n    \n    filename = function() {\n      stringr::str_glue(\"malaria_epicurve_{input$select_district}.png\")\n    },\n    \n    content = function(file) {\n      ggsave(file, \n             malaria_plot(),\n             width = 8, height = 5, dpi = 300)\n    }\n    \n  )\n  \n  \n  \n}"},{"path":"shiny.html","id":"ajout-dun-autre-onglet-avec-une-table","chapter":"43 Tableaux de bord avec Shiny","heading":"Ajout d’un autre onglet avec une table","text":"Nous allons maintenant passer au dernier composant que nous voulons ajouter à notre application. Nous voulons séparer notre interface utilisateur en deux onglets, dont l’un comportera un tableau interactif où l’utilisateur pourra voir les données avec lesquelles il réalise la courbe épidémique. Pour ce faire, nous pouvons utiliser les éléments d’interface intégrés qui sont fournis avec Shiny pour les onglets. À un niveau de base, nous pouvons enfermer la plupart de notre panneau principal dans cette structure générale :Appliquons cela à notre interface utilisateur. Nous voudrons également utiliser le package DT ici - c’est un excellent package pour créer des tableaux interactifs à partir de données préexistantes. Nous pouvons voir qu’il est utilisé pour DT::datatableOutput() dans cet exemple.Maintenant notre application est organisée en onglets ! Faisons également les modifications nécessaires sur le serveur. Puisque nous n’avons pas besoin de manipuler notre jeu de données avant de le rendre, c’est en fait très simple - nous rendons simplement le jeu de données malaria_data via DT::renderDT() à l’interface utilisateur !","code":"\n# ... le reste de l'ui\n\nmainPanel(\n  \n  tabsetPanel(\n    type = \"tabs\",\n    tabPanel(\n      \"Epidemic Curves\",\n      ...\n    ),\n    tabPanel(\n      \"Data\",\n      ...\n    )\n  )\n)\nui <- fluidPage(\n     \n     titlePanel(\"Malaria facility visualisation app\"),\n     \n     sidebarLayout(\n          \n          sidebarPanel(\n               # sélectionneur pour le district\n               selectInput(\n                    inputId = \"select_district\",\n                    label = \"Select district\",\n                    choices = all_districts,\n                    selected = \"All\",\n                    multiple = FALSE\n               ),\n               # selector for age group\n               selectInput(\n                    inputId = \"select_agegroup\",\n                    label = \"Select age group\",\n                    choices = c(\n                         \"All ages\" = \"malaria_tot\",\n                         \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                         \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                         \"15+ yrs\" = \"malaria_rdt_15\"\n                    ), \n                    selected = \"All\",\n                    multiple = FALSE\n               ),\n               # selector for facility\n               selectInput(\n                    inputId = \"select_facility\",\n                    label = \"Select Facility\",\n                    choices = c(\"All\", facility_list$location_name),\n                    selected = \"All\"\n               ),\n               \n               # horizontal line\n               hr(),\n               downloadButton(\n                    outputId = \"download_epicurve\",\n                    label = \"Download plot\"\n               )\n               \n          ),\n          \n          mainPanel(\n               tabsetPanel(\n                    type = \"tabs\",\n                    tabPanel(\n                         \"Epidemic Curves\",\n                         plotOutput(\"malaria_epicurve\")\n                    ),\n                    tabPanel(\n                         \"Data\",\n                         DT::dataTableOutput(\"raw_data\")\n                    )\n               ),\n               br(),\n               hr(),\n               p(\"Welcome to the malaria facility visualisation app! To use this app, manipulate the widgets on the side to change the epidemic curve according to your preferences! To download a high quality image of the plot you've created, you can also download it with the download button. To see the raw data, use the raw data tab for an interactive form of the table. The data dictionary is as follows:\"),\n               tags$ul(\n                    tags$li(tags$b(\"location_name\"), \" - the facility that the data were collected at\"),\n                    tags$li(tags$b(\"data_date\"), \" - the date the data were collected at\"),\n                    tags$li(tags$b(\"submitted_daate\"), \" - the date the data were submitted at\"),\n                    tags$li(tags$b(\"Province\"), \" - the province the data were collected at (all 'North' for this dataset)\"),\n                    tags$li(tags$b(\"District\"), \" - the district the data were collected at\"),\n                    tags$li(tags$b(\"age_group\"), \" - the age group the data were collected for (0-5, 5-14, 15+, and all ages)\"),\n                    tags$li(tags$b(\"cases_reported\"), \" - the number of cases reported for the facility/age group on the given date\")\n               )\n               \n               \n          )\n     )\n)\nserver <- function(input, output, session) {\n  \n  malaria_plot <- reactive({\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup, facility = input$select_facility)\n  })\n  \n  \n  \n  observe({\n    \n    if (input$select_district == \"All\") {\n      new_choices <- facility_list$location_name\n    } else {\n      new_choices <- facility_list %>%\n        filter(District == input$select_district) %>%\n        pull(location_name)\n    }\n    \n    new_choices <- c(\"All\", new_choices)\n    \n    updateSelectInput(session, inputId = \"select_facility\",\n                      choices = new_choices)\n    \n  })\n  \n  \n  output$malaria_epicurve <- renderPlot(\n    malaria_plot()\n  )\n  \n  output$download_epicurve <- downloadHandler(\n    \n    filename = function() {\n      stringr::str_glue(\"malaria_epicurve_{input$select_district}.png\")\n    },\n    \n    content = function(file) {\n      ggsave(file, \n             malaria_plot(),\n             width = 8, height = 5, dpi = 300)\n    }\n    \n  )\n  \n  # rendre le tableau de données à ui\n  output$raw_data <- DT::renderDT(\n    malaria_data\n  )\n  \n  \n}"},{"path":"shiny.html","id":"partager-les-applications-shiny","chapter":"43 Tableaux de bord avec Shiny","heading":"43.7 Partager les applications shiny","text":"Maintenant que vous avez développé votre application, vous voulez probablement la partager avec d’autres - c’est le principal avantage de shiny après tout ! Nous pouvons le faire en partageant le code directement, ou nous pouvons le publier sur un serveur. Si nous partageons le code, d’autres personnes pourront voir ce que vous avez fait et s’en inspirer, mais cela annulera l’un des principaux avantages de shiny - il peut éliminer le besoin pour les utilisateurs finaux de maintenir une installation R. Pour cette raison, si vous partagez votre application avec des utilisateurs qui ne sont pas à l’aise avec R, il est beaucoup plus facile de partager une application qui été publiée sur un serveur.Si vous préférez partager le code, vous pouvez créer un fichier .zip de l’application ou, mieux encore, publier votre application sur github et ajouter des collaborateurs.Cependant, si nous publions l’application en ligne, nous devons faire un peu plus de travail. En fin de compte, nous voulons que votre application soit accessible via une URL Web afin que d’autres puissent y accéder rapidement et facilement. Malheureusement, pour publier votre application sur un serveur, vous devez avoir accès à un serveur sur lequel la publier ! Il existe un certain nombre d’options d’hébergement à cet égard :shinyapps.io : c’est l’endroit le plus facile pour publier des applications shinys, car il nécessite le moins de travail de configuration possible et offre des licences gratuites, mais limitées.shinyapps.io : c’est l’endroit le plus facile pour publier des applications shinys, car il nécessite le moins de travail de configuration possible et offre des licences gratuites, mais limitées.RStudio Connect : il s’agit d’une version beaucoup plus puissante d’un serveur R, qui peut effectuer de nombreuses opérations, y compris la publication de shiny apps. Elle est cependant plus difficile à utiliser et moins recommandée pour les utilisateurs débutants.RStudio Connect : il s’agit d’une version beaucoup plus puissante d’un serveur R, qui peut effectuer de nombreuses opérations, y compris la publication de shiny apps. Elle est cependant plus difficile à utiliser et moins recommandée pour les utilisateurs débutants.Pour les besoins de ce document, nous utiliserons shinyapps.io, car il est plus facile pour les premiers utilisateurs. Vous pouvez créer un compte gratuit ici pour commencer - il y également différents plans de prix pour les licesnses de serveur si nécessaire. Plus vous prévoyez d’avoir d’utilisateurs, plus votre plan tarifaire devra être cher, alors tenez-en compte. Si vous cherchez à créer quelque chose à l’usage d’un petit groupe d’individus, une licence gratuite peut convenir parfaitement, mais une application destinée au public peut nécessiter plus de licences.Tout d’abord, nous devons nous assurer que notre application est adaptée à la publication sur un serveur. Dans votre application, vous devez redémarrer votre session R et vous assurer qu’elle fonctionne sans exécuter de code supplémentaire. C’est important, car une application qui nécessite le chargement de packages ou la lecture de données non définis dans le code de votre application ne fonctionnera pas sur un serveur. Notez également que vous ne pouvez pas avoir de chemins de fichiers explicites dans votre application - ceux-ci seront invalides dans le paramétrage du serveur - l’utilisation du package résout très bien ce problème. Enfin, si vous lisez des données à partir d’une source qui nécessite une authentification de l’utilisateur, comme les serveurs de votre organisation, cela ne fonctionnera généralement pas sur un serveur. Vous devrez vous mettre en relation avec votre service informatique pour savoir comment mettre le serveur shiny sur la whitelist.Création d’un compteUne fois que vous avez votre compte, vous pouvez naviguer vers la page des jetons sous Accounts. Ici, vous devriez ajouter un nouveau jeton - il sera utilisé pour déployer votre application.partir de là, vous devez noter que l’url de votre compte reflétera le nom de votre application - donc si votre application s’appelle mon_app, l’url sera ajouté comme xxx.io/mon_app/. Choisissez judicieusement le nom de votre application ! Maintenant que vous êtes prêt, cliquez sur deploy - si vous réussissez, votre application sera lancée sur l’url que vous avez choisi !Quelque chose sur la création d’applications dans des documents ?","code":""},{"path":"shiny.html","id":"lecture-complémentaire","chapter":"43 Tableaux de bord avec Shiny","heading":"43.8 Lecture complémentaire","text":"Jusqu’à présent, nous avons couvert beaucoup d’aspects de shiny, et nous avons à peine effleuré la surface de ce qui est offert pour shiny. Bien que ce guide serve d’introduction, il y beaucoup plus à apprendre pour comprendre pleinement shiny. Vous devriez commencer à créer des applications et ajouter progressivement de plus en plus de fonctionnalités.","code":""},{"path":"shiny.html","id":"packages-dextension-recommandés","chapter":"43 Tableaux de bord avec Shiny","heading":"43.9 packages d’extension recommandés","text":"Ce qui suit représente une sélection d’extensions de haute qualité pour shiny qui peuvent vous aider à obtenir beaucoup plus de shiny. Sans ordre particulier :shinyWidgets - ce package vous donne beaucoup plus de widgets qui peuvent être utilisés dans votre application. Lancez shinyWidgets::shinyWidgetsGallery() pour voir une sélection des widgets disponibles avec ce package. Voir des exemples icishinyWidgets - ce package vous donne beaucoup plus de widgets qui peuvent être utilisés dans votre application. Lancez shinyWidgets::shinyWidgetsGallery() pour voir une sélection des widgets disponibles avec ce package. Voir des exemples icishinyjs - c’est un excellent package qui donne à l’utilisateur la possibilité d’étendre considérablement l’utilité de shiny via une série de javascript. Les applications de ce package vont de très simples à très avancées, mais vous voudrez peut-être l’utiliser d’abord pour manipuler l’interface utilisateur de manière simple, comme cacher/afficher des éléments, ou activer/désactiver des boutons. En savoir plus icishinyjs - c’est un excellent package qui donne à l’utilisateur la possibilité d’étendre considérablement l’utilité de shiny via une série de javascript. Les applications de ce package vont de très simples à très avancées, mais vous voudrez peut-être l’utiliser d’abord pour manipuler l’interface utilisateur de manière simple, comme cacher/afficher des éléments, ou activer/désactiver des boutons. En savoir plus icishinydashboard - ce package étend massivement l’interface utilisateur disponible qui peut être utilisée dans shiny, en particulier en permettant à l’utilisateur de créer un tableau de bord complexe avec une variété de mises en page complexes. Voir plus icishinydashboard - ce package étend massivement l’interface utilisateur disponible qui peut être utilisée dans shiny, en particulier en permettant à l’utilisateur de créer un tableau de bord complexe avec une variété de mises en page complexes. Voir plus icishinydashboardPlus - Obtenez encore plus de fonctionnalités du framework shinydashboard ! En savoir plus icishinydashboardPlus - Obtenez encore plus de fonctionnalités du framework shinydashboard ! En savoir plus icishinythemes - changez le thème css par défaut de votre application shiny avec une large gamme de modèles prédéfinis ! En savoir plus icishinythemes - changez le thème css par défaut de votre application shiny avec une large gamme de modèles prédéfinis ! En savoir plus iciIl existe également un certain nombre de packages qui peuvent être utilisés pour créer des sorties interactives compatibles avec shiny.DT est semi-incorporé dans base-shiny, mais fournit un grand ensemble de fonctions pour créer des tableaux interactifs.DT est semi-incorporé dans base-shiny, mais fournit un grand ensemble de fonctions pour créer des tableaux interactifs.plotly est un package pour créer des graphiques interactifs que l’utilisateur peut manipuler dans l’application. Vous pouvez également convertir vos graphiques en versions interactives via plotly::ggplotly() ! Comme alternatives, dygraphs et highcharter sont également excellents.plotly est un package pour créer des graphiques interactifs que l’utilisateur peut manipuler dans l’application. Vous pouvez également convertir vos graphiques en versions interactives via plotly::ggplotly() ! Comme alternatives, dygraphs et highcharter sont également excellents.","code":""},{"path":"shiny.html","id":"ressources-recommandées","chapter":"43 Tableaux de bord avec Shiny","heading":"43.10 Ressources recommandées","text":"","code":""},{"path":"writing_functions.html","id":"writing_functions","chapter":"44 Fonctions d’écriture","heading":"44 Fonctions d’écriture","text":"","code":""},{"path":"writing_functions.html","id":"préparation-27","chapter":"44 Fonctions d’écriture","heading":"44.1 Préparation","text":"","code":""},{"path":"writing_functions.html","id":"load-packages","chapter":"44 Fonctions d’écriture","heading":"Load packages","text":"Ce morceau de code montre le chargement des paquets nécessaires aux analyses. Dans ce manuel, nous mettons l’accent sur p_load() de pacman, qui installe le paquet si nécessaire et le charge pour l’utiliser. Vous pouvez aussi charger les paquets installés avec library() de base R. Voir la page sur [R basics] pour plus d’informations sur les paquets R.","code":""},{"path":"writing_functions.html","id":"importer-des-données-10","chapter":"44 Fonctions d’écriture","heading":"Importer des données","text":"Nous importons le jeu de données des cas d’une épidémie d’Ebola simulée. Si vous souhaitez télécharger les données pour les suivre pas à pas, consultez les instructions de la page Télécharger le manuel et les données. Le jeu de données est importé à l’aide de la fonction import() du paquet rio. Voir la page Importer et exporter des données pour les différentes manières d’importer des données.Nous utiliserons également dans la dernière partie de cette page des données sur la grippe H7N9 de 2013.","code":""},{"path":"writing_functions.html","id":"fonctions","chapter":"44 Fonctions d’écriture","heading":"44.2 Fonctions","text":"Les fonctions sont utiles en programmation car elles permettent de rendre les codes plus faciles à comprendre, plus courts et moins sujets aux erreurs (à condition qu’il n’y ait pas d’erreurs dans la fonction elle-même).Si vous êtes arrivé jusqu’à ce manuel, cela signifie que vous avez rencontré d’innombrables fonctions, car en R, chaque opération est un appel de fonction.\n+, , , [, $, { â¦. Par exemple, x + y est la même chose que '+'(x, y).R est l’un des langages qui offre le plus de possibilités de travailler avec des fonctions et qui donne suffisamment d’outils à l’utilisateur pour les écrire facilement. Nous ne devrions pas penser aux fonctions comme étant fixées au sommet ou à la fin de la chaîne de programmation, R offre la possibilité de les utiliser comme s’il s’agissait de vecteurs et même de les utiliser à l’intérieur d’autres fonctions, listes…Il existe de nombreuses ressources très avancées sur la programmation fonctionnelle et nous ne donnerons ici qu’un aperçu pour vous aider à démarrer avec la programmation fonctionnelle avec de courts exemples pratiques. Nous vous encourageons ensuite à visiter les liens sur les références pour en savoir plus.","code":""},{"path":"writing_functions.html","id":"pourquoi-utiliser-une-fonction","chapter":"44 Fonctions d’écriture","heading":"44.3 Pourquoi utiliser une fonction ?","text":"Avant de répondre à cette question, il est important de noter que vous avez déjà eu des conseils pour écrire vos toutes premières fonctions R dans la page sur [l’itération, les boucles et les listes] de ce manuel. En fait, l’utilisation de “/else” et de boucles est souvent au cour de bon nombre de nos fonctions car elles permettent d’élargir l’application de notre code en autorisant des conditions multiples ou d’itérer des codes pour des tâches répétitives.Je répète plusieurs fois le même bloc de code pour l’appliquer à une variable ou à des données différentes ?Je répète plusieurs fois le même bloc de code pour l’appliquer à une variable ou à des données différentes ?Si je m’en débarrasse, cela raccourcira-t-il considérablement mon code global et le rendra-t-il plus rapide ?Si je m’en débarrasse, cela raccourcira-t-il considérablement mon code global et le rendra-t-il plus rapide ?Est-il possible que le code que j’ai écrit soit réutilisé mais avec une valeur différente à plusieurs endroits du code ?Est-il possible que le code que j’ai écrit soit réutilisé mais avec une valeur différente à plusieurs endroits du code ?Si la réponse à l’une des questions précédentes est “OUI”, alors vous avez probablement besoin d’écrire une fonction","code":""},{"path":"writing_functions.html","id":"comment-r-construit-il-les-fonctions","chapter":"44 Fonctions d’écriture","heading":"44.4 Comment R construit-il les fonctions ?","text":"Les fonctions dans R ont trois composants principaux :le formals() qui est la liste d’arguments qui contrôle la façon dont nous pouvons appeler la fonction.le formals() qui est la liste d’arguments qui contrôle la façon dont nous pouvons appeler la fonction.le body() qui est le code à l’intérieur de la fonction, c’est-à-dire entre les parenthèses ou à la suite des parenthèses, selon la façon dont l’écrit.le body() qui est le code à l’intérieur de la fonction, c’est-à-dire entre les parenthèses ou à la suite des parenthèses, selon la façon dont l’écrit.et,l’ environnement() qui aide à localiser les variables de la fonction et détermine comment la fonction trouve sa valeur.Une fois que vous avez créé votre fonction, vous pouvez vérifier chacun de ces composants en appelant la fonction associée.","code":""},{"path":"writing_functions.html","id":"syntaxe-et-structure-de-base","chapter":"44 Fonctions d’écriture","heading":"44.5 Syntaxe et structure de base","text":"Une fonction devra être nommée correctement afin que son travail soit facilement compréhensible dès que l’lit son nom. En fait, c’est déjà le cas avec la majorité de l’architecture R de base. Des fonctions comme mean(), print(), summary() ont des noms qui sont très simples.Une fonction devra être nommée correctement afin que son travail soit facilement compréhensible dès que l’lit son nom. En fait, c’est déjà le cas avec la majorité de l’architecture R de base. Des fonctions comme mean(), print(), summary() ont des noms qui sont très simples.Une fonction besoin d’arguments, comme les données sur lesquelles elle travaille et d’autres objets qui peuvent être des valeurs statiques, entre autres options.Une fonction besoin d’arguments, comme les données sur lesquelles elle travaille et d’autres objets qui peuvent être des valeurs statiques, entre autres options.Et enfin, une fonction donnera une sortie basée sur sa tâche principale et les arguments qui lui ont été donnés. Habituellement, nous utilisons les fonctions intégrées telles que print(), return()… pour produire la sortie. La sortie peut être une valeur logique, un nombre, un caractère, un cadre de données… en bref, tout type d’objet R.Et enfin, une fonction donnera une sortie basée sur sa tâche principale et les arguments qui lui ont été donnés. Habituellement, nous utilisons les fonctions intégrées telles que print(), return()… pour produire la sortie. La sortie peut être une valeur logique, un nombre, un caractère, un cadre de données… en bref, tout type d’objet R.En gros, c’est la composition d’une fonction :Nous pouvons créer notre première fonction qui sera appelée `contain_covid19()``.Nous pouvons ensuite vérifier les composants de notre fonction nouvellement créée.Maintenant, nous allons tester notre fonction. Pour appeler notre fonction écrite, vous l’utilisez comme vous utilisez toutes les fonctions R, c’est-à-dire en écrivant le nom de la fonction et en ajoutant les arguments requis.Par précaution, nous pouvons réécrire le nom de chaque argument. Mais sans les préciser, le code devrait fonctionner puisque R en mémoire le positionnement de chaque argument. Ainsi, tant que vous mettez les valeurs des arguments dans le bon ordre, vous pouvez éviter d’écrire les noms des arguments lors de l’appel des fonctions.Voyons ensuite ce qui se passe si l’une des valeurs est \"\" ou pas \"yes\".Si nous fournissons un argument qui n’est pas reconnu, nous obtenons une erreur:`Erreur dans contain_covid19(barrier_gest = “sometimes”, wear_mask = “yes”, :\nImpossible de trouver la fonction “contain_covid19”``.NOTE: Certaines fonctions (la plupart du temps très courtes et simples) peuvent ne pas avoir besoin de nom et peuvent être utilisées directement sur une ligne de code ou à l’intérieur d’une autre fonction pour effectuer une tâche rapide. Elles sont appelées fonctions anonymes .Par exemple ci-dessous est une première fonction anonyme qui ne garde que les variables de caractères le jeu de données.Ensuite, une autre fonction qui sélectionne une observation sur deux de notre ensemble de données (cela peut être utile lorsque nous avons des données longitudinales avec de nombreux enregistrements par patient, par exemple après avoir été classés par date ou par visite).\nDans ce cas, la fonction à écrire en dehors de dplyr serait function (x) (x%%2 == 0) pour s’appliquer au vecteur contenant tous les numéros de ligne.Un code R de base possible pour la même tâche serait le suivant :CAUTION: S’il est vrai que l’utilisation de fonctions peut nous aider dans notre code, il peut néanmoins être long d’écrire certaines fonctions ou d’en corriger une si elle n’pas été pensée en profondeur, écrite de manière adéquate et qu’elle renvoie des erreurs en conséquence. C’est pour cette raison qu’il est souvent recommandé d’écrire d’abord le code R, de s’assurer qu’il fait ce que nous voulons qu’il fasse, puis de le transformer en une fonction avec ses trois composants principaux tels que listés ci-dessus. ","code":"\nnom_fonction <- function(argument_1, argument_2, argument_3){\n  \n           function_task\n  \n           return(output)\n}\ncontain_covid19 <- function(barrier_gest, wear_mask, get_vaccine){\n  \n                            if(barrier_gest == \"yes\" & wear_mask == \"yes\" & get_vaccine == \"yes\" ) \n       \n                            return(\"success\")\n  \n  else(\"please make sure all are yes, this pandemic has to end!\")\n}\nformals(contain_covid19)## $barrier_gest\n## \n## \n## $wear_mask\n## \n## \n## $get_vaccine\nbody(contain_covid19)## {\n##     if (barrier_gest == \"yes\" & wear_mask == \"yes\" & get_vaccine == \n##         \"yes\") \n##         return(\"success\")\n##     else (\"please make sure all are yes, this pandemic has to end!\")\n## }\nenvironment(contain_covid19)## <environment: R_GlobalEnv>\ncontain_covid19(barrier_gest = \"yes\", wear_mask = \"yes\", get_vaccine = \"yes\")## [1] \"success\"\ncontain_covid19(\"yes\", \"yes\", \"yes\")## [1] \"success\"\ncontain_covid19(barrier_gest = \"yes\", wear_mask = \"yes\", get_vaccine = \"no\")## [1] \"please make sure all are yes, this pandemic has to end!\"\ncontain_covid19(barrier_gest = \"sometimes\", wear_mask = \"yes\", get_vaccine = \"no\")\nlinelist %>% \n  dplyr::slice_head(n=10) %>% #équivalent à la fonction \"head\" de base de R et qui renvoie les n premières observations de l'ensemble de données.\n  select(function(x) is.character(x)) \nlinelist %>%   \n   slice_head(n=20) %>% \n   tibble::rownames_to_column() %>% # ajoute les indices de chaque obs comme rownames pour voir clairement la sélection finale\n   filter(row_number() %%2 == 0)\nlinelist_firstobs <- head(linelist, 20)\n\nlinelist_firstobs[base::Filter(function(x) (x%%2 == 0), seq(nrow(linelist_firstobs))),]"},{"path":"writing_functions.html","id":"exemples-2","chapter":"44 Fonctions d’écriture","heading":"44.6 Exemples","text":"","code":""},{"path":"writing_functions.html","id":"retourner-les-tableaux-de-proportion-pour-plusieurs-colonnes","chapter":"44 Fonctions d’écriture","heading":"Retourner les tableaux de proportion pour plusieurs colonnes","text":"Oui, nous avons déjà de belles fonctions dans de nombreux paquets permettant de résumer des informations d’une manière très simple et agréable. Mais nous allons tout de même essayer de créer nos propres fonctions, lors de nos premiers pas dans l’écriture de fonctions.Dans cet exemple, nous voulons montrer comment l’écriture d’une simple fonction vous évitera de copier-coller le même code plusieurs fois.TIP: Comme indiqué ci-dessus, il est très important de commenter vos fonctions comme vous le feriez pour la programmation générale. Gardez à l’esprit que le d’une fonction est de rendre un code facile à lire, plus court et plus efficace. Alors devrait être capable de comprendre ce que fait la fonction juste en lisant son nom et avoir plus de détails en lisant les commentaires.Une deuxième option est d’utiliser cette fonction dans une autre via une boucle pour faire le processus en une fois :Une manière plus simple serait d’utiliser la base R “appliquer” au lieu d’une “boucle ” comme exprimé ci-dessous :TIP: R est souvent défini comme un langage de programmation fonctionnel et presque chaque fois que vous exécutez une ligne de code, vous utilisez certaines fonctions intégrées. Une bonne habitude pour être plus à l’aise avec l’écriture de fonctions est d’avoir souvent un regard interne sur la façon dont les fonctions de base que vous utilisez quotidiennement sont construites. Le raccourci pour le faire est de sélectionner le nom de la fonction puis de cliquer sur Ctrl+F2 ou fn+F2 ou Cmd+F2 (selon votre ordinateur) .","code":"\nproptab_multiple <- function(my_data, var_to_tab){\n  \n  #imprimez le nom de chaque variable d'intérêt avant de faire la tabulation\n  print(var_to_tab)\n\n  with(my_data,\n       rbind( #liez les résultats des deux fonctions suivantes par ligne\n        #tabuler la variable d'intérêt: ne donne que des nombres\n          table(my_data[[var_to_tab]], useNA = \"no\"),\n          #calculer les proportions pour chaque variable d'intérêt et arrondir la valeur à 2 décimales\n         round(prop.table(table(my_data[[var_to_tab]]))*100,2)\n         )\n       )\n}\n\n\nproptab_multiple(linelist, \"gender\")## [1] \"gender\"##            f       m\n## [1,] 2807.00 2803.00\n## [2,]   50.04   49.96\nproptab_multiple(linelist, \"age_cat\")## [1] \"age_cat\"##          0-4     5-9  10-14  15-19   20-29 30-49 50-69 70+\n## [1,] 1095.00 1095.00 941.00 743.00 1073.00   754 95.00 6.0\n## [2,]   18.87   18.87  16.22  12.81   18.49    13  1.64 0.1\nproptab_multiple(linelist, \"outcome\")## [1] \"outcome\"##        Death Recover\n## [1,] 2582.00 1983.00\n## [2,]   56.56   43.44\nfor(var_to_tab in c(\"gender\", \"age_cat\", \"outcome\")){\n  \n  print(proptab_multiple(linelist, var_to_tab))\n  \n}## [1] \"gender\"\n##            f       m\n## [1,] 2807.00 2803.00\n## [2,]   50.04   49.96\n## [1] \"age_cat\"\n##          0-4     5-9  10-14  15-19   20-29 30-49 50-69 70+\n## [1,] 1095.00 1095.00 941.00 743.00 1073.00   754 95.00 6.0\n## [2,]   18.87   18.87  16.22  12.81   18.49    13  1.64 0.1\n## [1] \"outcome\"\n##        Death Recover\n## [1,] 2582.00 1983.00\n## [2,]   56.56   43.44"},{"path":"writing_functions.html","id":"utilisation-de-purrr-écrire-des-fonctions-qui-peuvent-être-appliquées-de-manière-itérative.","chapter":"44 Fonctions d’écriture","heading":"44.6.1 Utilisation de purrr : écrire des fonctions qui peuvent être appliquées de manière itérative.","text":"","code":""},{"path":"writing_functions.html","id":"modifier-la-classe-de-plusieurs-colonnes-dans-un-ensemble-de-données","chapter":"44 Fonctions d’écriture","heading":"Modifier la classe de plusieurs colonnes dans un ensemble de données","text":"Disons que de nombreuses variables de caractère dans les données originales linelist doivent être changées en “factor” pour des raisons d’analyse et de traçage. Au lieu de répéter l’étape plusieurs fois, nous pouvons juste utiliser lapply() pour faire la transformation de toutes les variables concernées sur une seule ligne de code.CAUTION: lapply() renvoie une liste, donc son utilisation peut nécessiter une modification supplémentaire en dernière étape.La même étape peut être effectuée en utilisant la fonction map_if() du paquet purrr.","code":"\nlinelist_factor2 <- linelist %>%\n  purrr::map_if(is.character, as.factor)\n\nlinelist_factor2 %>%\n        glimpse()## List of 30\n##  $ case_id             : Factor w/ 5888 levels \"00031d\",\"00086d\",..: 2134 3022 396 4203 3084 4347 179 1241 5594 430 ...\n##  $ generation          : num [1:5888] 4 4 2 3 3 3 4 4 4 4 ...\n##  $ date_infection      : Date[1:5888], format: \"2014-05-08\" NA ...\n##  $ date_onset          : Date[1:5888], format: \"2014-05-13\" \"2014-05-13\" ...\n##  $ date_hospitalisation: Date[1:5888], format: \"2014-05-15\" \"2014-05-14\" ...\n##  $ date_outcome        : Date[1:5888], format: NA \"2014-05-18\" ...\n##  $ outcome             : Factor w/ 2 levels \"Death\",\"Recover\": NA 2 2 NA 2 2 2 1 2 1 ...\n##  $ gender              : Factor w/ 2 levels \"f\",\"m\": 2 1 2 1 2 1 1 1 2 1 ...\n##  $ age                 : num [1:5888] 2 3 56 18 3 16 16 0 61 27 ...\n##  $ age_unit            : Factor w/ 2 levels \"months\",\"years\": 2 2 2 2 2 2 2 2 2 2 ...\n##  $ age_years           : num [1:5888] 2 3 56 18 3 16 16 0 61 27 ...\n##  $ age_cat             : Factor w/ 8 levels \"0-4\",\"5-9\",\"10-14\",..: 1 1 7 4 1 4 4 1 7 5 ...\n##  $ age_cat5            : Factor w/ 18 levels \"0-4\",\"5-9\",\"10-14\",..: 1 1 12 4 1 4 4 1 13 6 ...\n##  $ hospital            : Factor w/ 6 levels \"Central Hospital\",..: 4 3 6 5 2 5 3 3 3 3 ...\n##  $ lon                 : num [1:5888] -13.2 -13.2 -13.2 -13.2 -13.2 ...\n##  $ lat                 : num [1:5888] 8.47 8.45 8.46 8.48 8.46 ...\n##  $ infector            : Factor w/ 2697 levels \"00031d\",\"002e6c\",..: 2594 NA NA 2635 180 1799 1407 195 NA NA ...\n##  $ source              : Factor w/ 2 levels \"funeral\",\"other\": 2 NA NA 2 2 2 2 2 NA NA ...\n##  $ wt_kg               : num [1:5888] 27 25 91 41 36 56 47 0 86 69 ...\n##  $ ht_cm               : num [1:5888] 48 59 238 135 71 116 87 11 226 174 ...\n##  $ ct_blood            : num [1:5888] 22 22 21 23 23 21 21 22 22 22 ...\n##  $ fever               : Factor w/ 2 levels \"no\",\"yes\": 1 NA NA 1 1 1 NA 1 1 1 ...\n##  $ chills              : Factor w/ 2 levels \"no\",\"yes\": 1 NA NA 1 1 1 NA 1 1 1 ...\n##  $ cough               : Factor w/ 2 levels \"no\",\"yes\": 2 NA NA 1 2 2 NA 2 2 2 ...\n##  $ aches               : Factor w/ 2 levels \"no\",\"yes\": 1 NA NA 1 1 1 NA 1 1 1 ...\n##  $ vomit               : Factor w/ 2 levels \"no\",\"yes\": 2 NA NA 1 2 2 NA 2 2 1 ...\n##  $ temp                : num [1:5888] 36.8 36.9 36.9 36.8 36.9 37.6 37.3 37 36.4 35.9 ...\n##  $ time_admission      : Factor w/ 1072 levels \"00:10\",\"00:29\",..: NA 308 746 415 514 589 609 297 409 387 ...\n##  $ bmi                 : num [1:5888] 117.2 71.8 16.1 22.5 71.4 ...\n##  $ days_onset_hosp     : num [1:5888] 2 1 2 2 1 1 2 1 1 2 ..."},{"path":"writing_functions.html","id":"produire-itérativement-des-graphiques-pour-différents-niveaux-dune-variable","chapter":"44 Fonctions d’écriture","heading":"Produire itérativement des graphiques pour différents niveaux d’une variable","text":"Nous allons produire ici un graphique circulaire pour examiner la distribution des résultats des patients en Chine pendant l’épidémie de H7N9 pour chaque province. Au lieu de répéter le code pour chacun d’entre eux, nous allons simplement appliquer une fonction que nous allons créer.","code":"\n#Préciser les options pour l'utilisation de highchart\noptions(highcharter.theme =  highcharter::hc_theme_smpl(tooltip = list(valueDecimals = 2)))\n\n\n#créer une fonction appelée \"chart_outcome_province\" qui prend comme argument l'ensemble de données et le nom de la province pour laquelle on veut tracer la distribution du résultat.\n\nchart_outcome_province <- function(data_used, prov){\n  \n  tab_prov <- data_used %>% \n    filter(province == prov,\n           !is.na(outcome))%>% \n    group_by(outcome) %>% \n    count() %>%\n    adorn_totals(where = \"row\") %>% \n    adorn_percentages(denominator = \"col\", )%>%\n    mutate(\n        perc_outcome= round(n*100,2))\n  \n  \n  tab_prov %>%\n    filter(outcome != \"Total\") %>% \n  highcharter::hchart(\n    \"pie\", hcaes(x = outcome, y = perc_outcome),\n    name = paste0(\"Distribution du résultat en :\", prov)\n    )\n  \n}\n\nchart_outcome_province(flu_china, \"Shanghai\")\nchart_outcome_province(flu_china, \"Zhejiang\")\nchart_outcome_province(flu_china, \"Jiangsu\")"},{"path":"writing_functions.html","id":"produire-itérativement-des-tableaux-pour-différents-niveaux-dune-variable","chapter":"44 Fonctions d’écriture","heading":"Produire itérativement des tableaux pour différents niveaux d’une variable","text":"Ici, nous allons créer trois indicateurs à résumer dans un tableau et nous voudrions produire ce tableau pour chacune des provinces. Nos indicateurs sont le délai entre l’apparition et l’hospitalisation, le pourcentage de guérison et l’âge médian des cas.Indicateurs pour la province de : ShanghaiIndicateursEstimationDélai moyen d'apparition hôpital4.0Pourcentage de récupération46.7Âge médian des cas67.0Indicateurs pour la province de : JiangsuIndicateursEstimationDélai moyen d'apparition hôpital6.0Pourcentage de récupération71.4Âge médian des cas55.0","code":"\nindic_1 <- flu_china %>% \n  group_by(province) %>% \n  mutate(\n    date_hosp= strptime(date_of_hospitalisation, format = \"%m/%d/%Y\"),\n    date_ons= strptime(date_of_onset, format = \"%m/%d/%Y\"), \n    delay_onset_hosp= as.numeric(date_hosp - date_ons)/86400,\n    mean_delay_onset_hosp = round(mean(delay_onset_hosp, na.rm=TRUE ), 0)) %>%\n  select(province, mean_delay_onset_hosp) %>% \n  distinct()\n     \n\nindic_2 <- flu_china %>% \n            filter(!is.na(outcome)) %>% \n            group_by(province, outcome) %>% \n            count() %>%\n            pivot_wider(names_from = outcome, values_from = n) %>% \n    adorn_totals(where = \"col\") %>% \n    mutate(\n        perc_recovery= round((Recover/Total)*100,2))%>% \n  select(province, perc_recovery)\n    \n    \n    \nindic_3 <- flu_china %>% \n            group_by(province) %>% \n            mutate(\n                    median_age_cases = median(as.numeric(age), na.rm = TRUE)\n            ) %>% \n  select(province, median_age_cases) %>% \n  distinct()## Warning: There was 1 warning in `mutate()`.\n## ℹ In argument: `median_age_cases = median(as.numeric(age), na.rm = TRUE)`.\n## ℹ In group 11: `province = \"Shanghai\"`.\n## Caused by warning in `median()`:\n## ! NAs introduced by coercion\n#Joindre les trois ensembles de données d'indicateurs\n\ntable_indic_all <- indic_1 %>% \n  dplyr::left_join(indic_2, by = \"province\") %>% \n        left_join(indic_3, by = \"province\")\n\n\n#Imprimez les indicateurs dans un tableau mobile\n\n\nprint_indic_prov <- function(table_used, prov){\n  \n  #d'abord transformer un peu le dataframe pour faciliter l'impression.\n  indic_prov <- table_used %>%\n    filter(province==prov) %>%\n    pivot_longer(names_to = \"Indicateurs\", cols = 2:4) %>% \n   mutate( indic_label = factor(Indicateurs,\n   levels= c(\"mean_delay_onset_hosp\", \"perc_recovery\", \"median_age_cases\"),\n   labels=c(\"Délai moyen d'apparition hôpital\", \"Pourcentage de récupération\", \"Âge médian des cas\"))\n   ) %>% \n    ungroup(province) %>% \n    select(indic_label, value)\n  \n\n    tab_print <- flextable(indic_prov) %>%\n    theme_vanilla() %>% \n    flextable::fontsize(part = \"body\", size = 10) \n    \n    \n     tab_print <- tab_print %>% \n                  autofit() %>%\n                  set_header_labels( \n                indic_label= \"Indicateurs\", value= \"Estimation\") %>%\n    flextable::bg( bg = \"darkblue\", part = \"header\") %>%\n    flextable::bold(part = \"header\") %>%\n    flextable::color(color = \"white\", part = \"header\") %>% \n    add_header_lines(values = paste0(\"Indicateurs pour la province de : \", prov)) %>% \nbold(part = \"header\")\n \n tab_print <- set_formatter_type(tab_print,\n   fmt_double = \"%.2f\",\n   na_str = \"-\")\n\ntab_print \n    \n}\n\n\n\n\nprint_indic_prov(table_indic_all, \"Shanghai\")\nprint_indic_prov(table_indic_all, \"Jiangsu\")"},{"path":"writing_functions.html","id":"conseils-et-meilleures-pratiques-pour-des-fonctions-bien-rodées","chapter":"44 Fonctions d’écriture","heading":"44.7 Conseils et meilleures pratiques pour des fonctions bien rodées","text":"La programmation fonctionnelle pour d’alléger le code et d’en faciliter la lecture. Elle devrait produire le contraire. Les conseils ci-dessous vous aideront à avoir un code propre et facile à lire.","code":""},{"path":"writing_functions.html","id":"nommage-et-syntaxe","chapter":"44 Fonctions d’écriture","heading":"Nommage et syntaxe","text":"Evitez d’utiliser des caractères qui auraient pu être facilement pris par d’autres fonctions déjà existantes dans votre environnement.Evitez d’utiliser des caractères qui auraient pu être facilement pris par d’autres fonctions déjà existantes dans votre environnement.Il est recommandé que le nom de la fonction soit court et facile à comprendre pour un autre lecteur.Il est recommandé que le nom de la fonction soit court et facile à comprendre pour un autre lecteur.Il est préférable d’utiliser des verbes pour le nom de la fonction et des noms pour les noms des arguments.Il est préférable d’utiliser des verbes pour le nom de la fonction et des noms pour les noms des arguments.","code":""},{"path":"writing_functions.html","id":"noms-de-colonnes-et-évaluation-ordonnée","chapter":"44 Fonctions d’écriture","heading":"Noms de colonnes et évaluation ordonnée","text":"Si vous voulez savoir comment référencer les noms de colonnes qui sont fournis à votre code en tant qu’arguments, lisez ce guide de programmation tidyverse. Parmi les sujets abordés figurent l’évaluation tidée et l’utilisation de l’accolade double {{ }}.Par exemple, voici un squelette de code rapide tiré du tutoriel de la page mentionnée juste au-dessus :","code":"var_summary <- function(data, var) {\n  data %>%\n    summarise(n = n(), min = min({{ var }}), max = max({{ var }})))\n}\nmtcars %>% \n  group_by(cyl) %>% \n  var_summary(mpg)"},{"path":"writing_functions.html","id":"test-et-gestion-des-erreurs","chapter":"44 Fonctions d’écriture","heading":"Test et gestion des erreurs","text":"Plus la tâche d’une fonction est compliquée, plus la possibilité d’erreurs est élevée. Il est donc parfois nécessaire d’ajouter une vérification dans la fonction pour aider à comprendre rapidement d’où vient l’erreur et trouver un moyen de la corriger.Il peut être plus que recommandé d’introduire une vérification de l’absence d’un argument en utilisant missing(argument). Cette simple vérification peut retourner la valeur “VRAI” ou “FAUX”.Utilisez stop() pour les erreurs plus faciles à détecter.Comme nous le voyons lorsque nous exécutons la plupart des fonctions intégrées, des messages et des avertissements peuvent apparaître dans certaines conditions. Nous pouvons les intégrer dans nos fonctions écrites en utilisant les fonctions message() et warning().Comme nous le voyons lorsque nous exécutons la plupart des fonctions intégrées, des messages et des avertissements peuvent apparaître dans certaines conditions. Nous pouvons les intégrer dans nos fonctions écrites en utilisant les fonctions message() et warning().Nous pouvons également gérer les erreurs en utilisant la fonction safely() qui prend une fonction en argument et l’exécute de manière sûre. En fait, la fonction s’exécutera sans s’arrêter si elle rencontre une erreur. safely() retourne en sortie une liste avec deux objets qui sont les résultats et l’erreur qu’elle “sautée”.Nous pouvons également gérer les erreurs en utilisant la fonction safely() qui prend une fonction en argument et l’exécute de manière sûre. En fait, la fonction s’exécutera sans s’arrêter si elle rencontre une erreur. safely() retourne en sortie une liste avec deux objets qui sont les résultats et l’erreur qu’elle “sautée”.Nous pouvons vérifier en exécutant d’abord la fonction mean(), puis en l’exécutant avec safely().Comme dit précédemment, bien commenter nos codes est déjà un bon moyen d’avoir de la documentation dans notre travail.","code":"\ncontain_covid19_missing <- function(barrier_gest, wear_mask, get_vaccine){\n  \n  if (missing(barrier_gest)) (print(\"please provide arg1\"))\n  if (missing(wear_mask)) print(\"please provide arg2\")\n  if (missing(get_vaccine)) print(\"please provide arg3\")\n\n\n  if (!barrier_gest == \"yes\" | wear_mask == \"yes\" | get_vaccine == \"yes\" ) \n       \n       return (\"you can do better\")\n  \n  else(\"please make sure all are yes, this pandemic has to end!\")\n}\n\n\ncontain_covid19_missing(get_vaccine = \"yes\")## [1] \"please provide arg1\"\n## [1] \"please provide arg2\"## Error in contain_covid19_missing(get_vaccine = \"yes\"): argument \"barrier_gest\" is missing, with no default\ncontain_covid19_stop <- function(barrier_gest, wear_mask, get_vaccine){\n  \n  if(!is.character(barrier_gest)) (stop(\"arg1 should be a character, please enter the value with `yes`, `no` or `sometimes`\"))\n  \n  if(barrier_gest == \"yes\" & wear_mask == \"yes\" & get_vaccine == \"yes\" ) \n       \n       return (\"success\")\n  \n  else(\"please make sure all are yes, this pandemic has to end!\")\n}\n\n\ncontain_covid19_stop(barrier_gest=1, wear_mask=\"yes\", get_vaccine = \"no\")## Error in contain_covid19_stop(barrier_gest = 1, wear_mask = \"yes\", get_vaccine = \"no\"): arg1 should be a character, please enter the value with `yes`, `no` or `sometimes`\nmap(linelist, mean)## $case_id\n## [1] NA\n## \n## $generation\n## [1] 16.56165\n## \n## $date_infection\n## [1] NA\n## \n## $date_onset\n## [1] NA\n## \n## $date_hospitalisation\n## [1] \"2014-11-03\"\n## \n## $date_outcome\n## [1] NA\n## \n## $outcome\n## [1] NA\n## \n## $gender\n## [1] NA\n## \n## $age\n## [1] NA\n## \n## $age_unit\n## [1] NA\n## \n## $age_years\n## [1] NA\n## \n## $age_cat\n## [1] NA\n## \n## $age_cat5\n## [1] NA\n## \n## $hospital\n## [1] NA\n## \n## $lon\n## [1] -13.23381\n## \n## $lat\n## [1] 8.469638\n## \n## $infector\n## [1] NA\n## \n## $source\n## [1] NA\n## \n## $wt_kg\n## [1] 52.64487\n## \n## $ht_cm\n## [1] 124.9633\n## \n## $ct_blood\n## [1] 21.20686\n## \n## $fever\n## [1] NA\n## \n## $chills\n## [1] NA\n## \n## $cough\n## [1] NA\n## \n## $aches\n## [1] NA\n## \n## $vomit\n## [1] NA\n## \n## $temp\n## [1] NA\n## \n## $time_admission\n## [1] NA\n## \n## $bmi\n## [1] 46.89023\n## \n## $days_onset_hosp\n## [1] NA\nsafe_mean <- safely(mean)\nlinelist %>% \n  map(safe_mean)## $case_id\n## $case_id$result\n## [1] NA\n## \n## $case_id$error\n## NULL\n## \n## \n## $generation\n## $generation$result\n## [1] 16.56165\n## \n## $generation$error\n## NULL\n## \n## \n## $date_infection\n## $date_infection$result\n## [1] NA\n## \n## $date_infection$error\n## NULL\n## \n## \n## $date_onset\n## $date_onset$result\n## [1] NA\n## \n## $date_onset$error\n## NULL\n## \n## \n## $date_hospitalisation\n## $date_hospitalisation$result\n## [1] \"2014-11-03\"\n## \n## $date_hospitalisation$error\n## NULL\n## \n## \n## $date_outcome\n## $date_outcome$result\n## [1] NA\n## \n## $date_outcome$error\n## NULL\n## \n## \n## $outcome\n## $outcome$result\n## [1] NA\n## \n## $outcome$error\n## NULL\n## \n## \n## $gender\n## $gender$result\n## [1] NA\n## \n## $gender$error\n## NULL\n## \n## \n## $age\n## $age$result\n## [1] NA\n## \n## $age$error\n## NULL\n## \n## \n## $age_unit\n## $age_unit$result\n## [1] NA\n## \n## $age_unit$error\n## NULL\n## \n## \n## $age_years\n## $age_years$result\n## [1] NA\n## \n## $age_years$error\n## NULL\n## \n## \n## $age_cat\n## $age_cat$result\n## [1] NA\n## \n## $age_cat$error\n## NULL\n## \n## \n## $age_cat5\n## $age_cat5$result\n## [1] NA\n## \n## $age_cat5$error\n## NULL\n## \n## \n## $hospital\n## $hospital$result\n## [1] NA\n## \n## $hospital$error\n## NULL\n## \n## \n## $lon\n## $lon$result\n## [1] -13.23381\n## \n## $lon$error\n## NULL\n## \n## \n## $lat\n## $lat$result\n## [1] 8.469638\n## \n## $lat$error\n## NULL\n## \n## \n## $infector\n## $infector$result\n## [1] NA\n## \n## $infector$error\n## NULL\n## \n## \n## $source\n## $source$result\n## [1] NA\n## \n## $source$error\n## NULL\n## \n## \n## $wt_kg\n## $wt_kg$result\n## [1] 52.64487\n## \n## $wt_kg$error\n## NULL\n## \n## \n## $ht_cm\n## $ht_cm$result\n## [1] 124.9633\n## \n## $ht_cm$error\n## NULL\n## \n## \n## $ct_blood\n## $ct_blood$result\n## [1] 21.20686\n## \n## $ct_blood$error\n## NULL\n## \n## \n## $fever\n## $fever$result\n## [1] NA\n## \n## $fever$error\n## NULL\n## \n## \n## $chills\n## $chills$result\n## [1] NA\n## \n## $chills$error\n## NULL\n## \n## \n## $cough\n## $cough$result\n## [1] NA\n## \n## $cough$error\n## NULL\n## \n## \n## $aches\n## $aches$result\n## [1] NA\n## \n## $aches$error\n## NULL\n## \n## \n## $vomit\n## $vomit$result\n## [1] NA\n## \n## $vomit$error\n## NULL\n## \n## \n## $temp\n## $temp$result\n## [1] NA\n## \n## $temp$error\n## NULL\n## \n## \n## $time_admission\n## $time_admission$result\n## [1] NA\n## \n## $time_admission$error\n## NULL\n## \n## \n## $bmi\n## $bmi$result\n## [1] 46.89023\n## \n## $bmi$error\n## NULL\n## \n## \n## $days_onset_hosp\n## $days_onset_hosp$result\n## [1] NA\n## \n## $days_onset_hosp$error\n## NULL"},{"path":"writing_functions.html","id":"ressources-26","chapter":"44 Fonctions d’écriture","heading":"44.8 Ressources","text":"Lien vers R pour la science des donnéesCheatsheet advance R programmingCheatsheet purr PackageVideo-ACM talk Hadley Wickham : Les joies de la programmation fonctionnelle (comment fonctionne map_dbl)","code":""},{"path":"directories.html","id":"directories","chapter":"45 Interactions avec les répertoires","heading":"45 Interactions avec les répertoires","text":"Dans cette page, nous couvrons les scénarios courants où vous créez, interagissez avec, enregistrez et importez avec des répertoires (dossiers).","code":""},{"path":"directories.html","id":"préparation-28","chapter":"45 Interactions avec les répertoires","heading":"45.1 Préparation","text":"","code":""},{"path":"directories.html","id":"paquet-fs","chapter":"45 Interactions avec les répertoires","heading":"Paquet fs","text":"Le paquet fs est un paquet tidyverse qui facilite les interactions avec les répertoires, en améliorant certaines des fonctions base de R. Dans les sections ci-dessous, nous utiliserons souvent des fonctions de fs.","code":"\npacman::p_load(\n  fs, # interactions fichiers/répertoires\n  rio, # importation/exportation\n  here, # chemins d'accès relatifs aux fichiers\n  tidyverse) # gestion et visualisation des données"},{"path":"directories.html","id":"imprimer-le-répertoire-comme-un-arbre-de-dendrogramme","chapter":"45 Interactions avec les répertoires","heading":"Imprimer le répertoire comme un arbre de dendrogramme","text":"Utilisez la fonction dir_tree() de fs.Fournissez le chemin d’accès au dossier dans path = et décidez si vous voulez afficher un seul niveau (recurse = FALSE) ou tous les fichiers de tous les sous-niveaux (recurse = TRUE). Ci-dessous, nous utilisons () comme raccourci pour le projet R et spécifions son sous-dossier “data”, qui contient toutes les données utilisées pour ce manuel R. Nous le paramétrons pour afficher tous les fichiers contenus dans “data” et ses sous-dossiers (par exemple “cache”, “modèles épidémiques”, “population”, “shp” et “weather”).","code":"\nfs::dir_tree(path = here(\"data\"), recurse = TRUE)## C:/Users/neale/Documents/Applied Epi/repos/epirhandbook_fr/data\n## ├── cache\n## │   └── epidemic_models\n## │       ├── 2015-04-30\n## │       │   ├── estimated_reported_cases_samples.rds\n## │       │   ├── estimate_samples.rds\n## │       │   ├── latest_date.rds\n## │       │   ├── reported_cases.rds\n## │       │   ├── summarised_estimated_reported_cases.rds\n## │       │   ├── summarised_estimates.rds\n## │       │   └── summary.rds\n## │       ├── epinow_res.rds\n## │       ├── epinow_res_small.rds\n## │       ├── generation_time.rds\n## │       └── incubation_period.rds\n## ├── case_linelists\n## │   ├── cleaning_dict.csv\n## │   ├── fluH7N9_China_2013.csv\n## │   ├── linelist_cleaned.rds\n## │   ├── linelist_cleaned.xlsx\n## │   └── linelist_raw.xlsx\n## ├── example\n## │   ├── Central Hospital.csv\n## │   ├── district_weekly_count_data.xlsx\n## │   ├── fluH7N9_China_2013.csv\n## │   ├── hospital_linelists.xlsx\n## │   ├── linelists\n## │   │   ├── 20201007linelist.csv\n## │   │   ├── case_linelist20201006.csv\n## │   │   ├── case_linelist_2020-10-02.csv\n## │   │   ├── case_linelist_2020-10-03.csv\n## │   │   ├── case_linelist_2020-10-04.csv\n## │   │   ├── case_linelist_2020-10-05.csv\n## │   │   └── case_linelist_2020-10-08.xlsx\n## │   ├── Military Hospital.csv\n## │   ├── Missing.csv\n## │   ├── Other.csv\n## │   ├── Port Hospital.csv\n## │   └── St. Mark's Maternity Hospital (SMMH).csv\n## ├── flexdashboard\n## │   ├── outbreak_dashboard.html\n## │   ├── outbreak_dashboard.Rmd\n## │   ├── outbreak_dashboard_shiny.Rmd\n## │   ├── outbreak_dashboard_test.html\n## │   └── outbreak_dashboard_test.Rmd\n## ├── gis\n## │   ├── africa_countries.geo.json\n## │   ├── covid_incidence.csv\n## │   ├── covid_incidence_map.R\n## │   ├── linelist_cleaned_with_adm3.rds\n## │   ├── population\n## │   │   ├── sle_admpop_adm3_2020.csv\n## │   │   └── sle_population_statistics_sierraleone_2020.xlsx\n## │   └── shp\n## │       ├── README.txt\n## │       ├── sle_adm3.CPG\n## │       ├── sle_adm3.dbf\n## │       ├── sle_adm3.prj\n## │       ├── sle_adm3.sbn\n## │       ├── sle_adm3.sbx\n## │       ├── sle_adm3.shp\n## │       ├── sle_adm3.shp.xml\n## │       ├── sle_adm3.shx\n## │       ├── sle_hf.CPG\n## │       ├── sle_hf.dbf\n## │       ├── sle_hf.prj\n## │       ├── sle_hf.sbn\n## │       ├── sle_hf.sbx\n## │       ├── sle_hf.shp\n## │       └── sle_hf.shx\n## ├── godata\n## │   ├── cases_clean.rds\n## │   ├── contacts_clean.rds\n## │   ├── followups_clean.rds\n## │   └── relationships_clean.rds\n## ├── likert_data.csv\n## ├── linelist_cleaned.xlsx\n## ├── make_evd_dataset.R\n## ├── malaria_app\n## │   ├── app.R\n## │   ├── data\n## │   │   └── facility_count_data.rds\n## │   ├── funcs\n## │   │   └── plot_epicurve.R\n## │   ├── global.R\n## │   ├── malaria_app.Rproj\n## │   ├── server.R\n## │   └── ui.R\n## ├── malaria_facility_count_data.rds\n## ├── phylo\n## │   ├── sample_data_Shigella_tree.csv\n## │   ├── Shigella_subtree_2.nwk\n## │   ├── Shigella_subtree_2.txt\n## │   └── Shigella_tree.txt\n## ├── rmarkdown\n## │   ├── outbreak_report.docx\n## │   ├── outbreak_report.html\n## │   ├── outbreak_report.pdf\n## │   ├── outbreak_report.pptx\n## │   ├── outbreak_report.Rmd\n## │   ├── report_tabbed_example.html\n## │   └── report_tabbed_example.Rmd\n## ├── standardization\n## │   ├── country_demographics.csv\n## │   ├── country_demographics_2.csv\n## │   ├── deaths_countryA.csv\n## │   ├── deaths_countryB.csv\n## │   └── world_standard_population_by_sex.csv\n## ├── surveys\n## │   ├── population.xlsx\n## │   ├── survey_data.xlsx\n## │   └── survey_dict.xlsx\n## └── time_series\n##     ├── campylobacter_germany.xlsx\n##     └── weather\n##         ├── germany_weather2002.nc\n##         ├── germany_weather2003.nc\n##         ├── germany_weather2004.nc\n##         ├── germany_weather2005.nc\n##         ├── germany_weather2006.nc\n##         ├── germany_weather2007.nc\n##         ├── germany_weather2008.nc\n##         ├── germany_weather2009.nc\n##         ├── germany_weather2010.nc\n##         └── germany_weather2011.nc"},{"path":"directories.html","id":"lister-les-fichiers-dun-répertoire","chapter":"45 Interactions avec les répertoires","heading":"45.2 Lister les fichiers d’un répertoire","text":"Pour lister uniquement les noms de fichiers d’un répertoire, vous pouvez utiliser dir() à partir de base R. Par exemple, cette commande liste les noms des fichiers contenus dans le sous-dossier “population” du dossier “data” d’un projet R. Le chemin de fichier relatif est fourni en utilisant (). (dont vous trouverez plus d’informations sur la page Importer et exporter des données ).Pour lister les chemins complets des fichiers du répertoire, vous pouvez utiliser dir_ls() de fs. Une alternative R base est list.files().Pour obtenir toutes les informations sur les métadonnées de chaque fichier d’un répertoire (par exemple le chemin, la date de modification, etc.), vous pouvez utiliser dir_info() de fs.Cela peut être particulièrement utile si vous voulez extraire la date de dernière modification du fichier, par exemple si vous voulez importer la version la plus récente d’un fichier. Pour un exemple de ceci, voir la page Importer et exporter des données.Voici le cadre de données renvoyé. Faites défiler vers la droite pour voir toutes les colonnes.","code":"\n# noms de fichiers\ndir(here(\"data\", \"gis\", \"population\"))## [1] \"sle_admpop_adm3_2020.csv\"                       \n## [2] \"sle_population_statistics_sierraleone_2020.xlsx\"\n# chemins d'accès aux fichiers\ndir_ls(here(\"data\", \"gis\", \"population\"))## C:/Users/neale/Documents/Applied Epi/repos/epirhandbook_fr/data/gis/population/sle_admpop_adm3_2020.csv\n## C:/Users/neale/Documents/Applied Epi/repos/epirhandbook_fr/data/gis/population/sle_population_statistics_sierraleone_2020.xlsx\n# informations sur le fichier\ndir_info(here(\"data\", \"gis\", \"population\"))"},{"path":"directories.html","id":"informations-sur-les-fichiers","chapter":"45 Interactions avec les répertoires","heading":"45.3 Informations sur les fichiers","text":"Pour extraire des informations de métadonnées sur un fichier spécifique, vous pouvez utiliser file_info()de fs (ou file.info()de base R).Ici, nous utilisons le $ pour indexer le résultat et retourner uniquement la valeur modification_time.","code":"\nfile_info(here(\"data\", \"case_linelists\", \"linelist_cleaned.rds\"))\nfile_info(here(\"data\", \"case_linelists\", \"linelist_cleaned.rds\"))$modification_time## [1] \"2023-05-21 16:49:10 CEST\""},{"path":"directories.html","id":"vérifier-sil-existe","chapter":"45 Interactions avec les répertoires","heading":"45.4 Vérifier s’il existe","text":"","code":""},{"path":"directories.html","id":"objets-r","chapter":"45 Interactions avec les répertoires","heading":"Objets R","text":"Vous pouvez utiliser exists() de base R pour vérifier si un objet R existe dans R (fournir le nom de l’objet entre guillemets).Notez que certains paquets R base utilisent des noms d’objets génériques comme “data” en coulisse, qui apparaîtront comme VRAIS à moins que inherit = FALSE soit spécifié. C’est une des raisons pour ne pas nommer votre jeu de données “data”.Si vous écrivez une fonction, vous devriez utiliser missing() de base R pour vérifier si un argument est présent ou non, au lieu de exists().","code":"\nexists(\"linelist\")## [1] TRUE\nexists(\"data\")## [1] TRUE\nexists(\"data\", inherit = FALSE)## [1] FALSE"},{"path":"directories.html","id":"répertoires","chapter":"45 Interactions avec les répertoires","heading":"Répertoires","text":"Pour vérifier si un répertoire existe, fournissez le chemin du fichier (et son nom) à is_dir() de fs. Faites défiler vers la droite pour voir que TRUE est imprimé.Une alternative est file.exists() de base R.","code":"\nis_dir(here(\"data\"))## C:/Users/neale/Documents/Applied Epi/repos/epirhandbook_fr/data \n##                                                            TRUE"},{"path":"directories.html","id":"les-fichiers","chapter":"45 Interactions avec les répertoires","heading":"Les fichiers","text":"Pour vérifier si un fichier spécifique existe, utilisez is_file() de fs. Faites défiler vers la droite pour voir que TRUE est imprimé.Une alternative base R est file.exists().","code":"\nis_file(here(\"data\", \"case_linelists\", \"linelist_cleaned.rds\"))## C:/Users/neale/Documents/Applied Epi/repos/epirhandbook_fr/data/case_linelists/linelist_cleaned.rds \n##                                                                                                TRUE"},{"path":"directories.html","id":"créer","chapter":"45 Interactions avec les répertoires","heading":"45.5 Créer","text":"","code":""},{"path":"directories.html","id":"répertoires-1","chapter":"45 Interactions avec les répertoires","heading":"Répertoires","text":"Pour créer un nouveau répertoire (dossier), vous pouvez utiliser dir_create() de fs. Si le répertoire existe déjà, il ne sera pas écrasé et aucune erreur ne sera retournée.Une alternative est dir.create() de base R, qui affichera une erreur si le répertoire existe déjà. En revanche, dir_create() dans ce scénario sera silencieux.","code":"\ndir_create(here(\"data\", \"test\"))"},{"path":"directories.html","id":"fichiers","chapter":"45 Interactions avec les répertoires","heading":"Fichiers","text":"Vous pouvez créer un fichier (vide) avec file_create() à partir de fs. Si le fichier existe déjà, il ne sera pas écrasé ou modifié.Une alternative R base est file.create(). Mais si le fichier existe déjà, cette option le tronquera. Si vous utilisez file_create(), le fichier sera laissé inchangé.","code":"\nfile_create(here(\"data\", \"test.rds\"))"},{"path":"directories.html","id":"créer-si-nexiste-pas","chapter":"45 Interactions avec les répertoires","heading":"Créer si n’existe pas","text":"EN COURS DE CONSTRUCTION","code":""},{"path":"directories.html","id":"supprimer","chapter":"45 Interactions avec les répertoires","heading":"45.5.1 Supprimer","text":"","code":""},{"path":"directories.html","id":"objets-r-1","chapter":"45 Interactions avec les répertoires","heading":"Objets R","text":"Utilisez rm() de base R pour supprimer un objet R.","code":""},{"path":"directories.html","id":"répertoires-2","chapter":"45 Interactions avec les répertoires","heading":"45.5.2 Répertoires","text":"Utilisez dir_delete() de fs.","code":""},{"path":"directories.html","id":"fichiers-1","chapter":"45 Interactions avec les répertoires","heading":"45.5.3 Fichiers","text":"Vous pouvez supprimer des fichiers avec file_delete() de fs.","code":""},{"path":"directories.html","id":"exécuter-dautres-fichiers","chapter":"45 Interactions avec les répertoires","heading":"45.5.4 Exécuter d’autres fichiers","text":"","code":""},{"path":"directories.html","id":"source","chapter":"45 Interactions avec les répertoires","heading":"source()","text":"Pour exécuter un script R à partir d’un autre script R, vous pouvez utiliser la commande source() (de base R).Cela revient à afficher le script R ci-dessus et à cliquer sur le bouton “Source” en haut à droite du script. Ceci exécutera le script mais le fera silencieusement (pas de sortie sur la console R) sauf si cela est spécifiquement prévu. Voir la page Graphiques interactifs pour des exemples d’utilisation de source() pour interagir avec un utilisateur via la console R en mode question-réponse.","code":"\nsource(here(\"scripts\", \"cleaning_scripts\", \"clean_testing_data.R\"))"},{"path":"directories.html","id":"render","chapter":"45 Interactions avec les répertoires","heading":"render()","text":"render() est une variation de source() le plus souvent utilisée pour les scripts R markdown. Vous fournissez le input = qui est le fichier R markdown, et aussi le output_format = (typiquement soit “html_document”, “pdf_document”, “word_document”, ““).Voir la page sur les Production de rapports avec R Markdown pour plus de détails. Consultez également la documentation de render() ici ou en entrant ?render.","code":""},{"path":"directories.html","id":"exécuter-des-fichiers-dans-un-répertoire","chapter":"45 Interactions avec les répertoires","heading":"Exécuter des fichiers dans un répertoire","text":"Vous pouvez créer une boucle et l’utiliser pour source() chaque fichier d’un répertoire, tel qu’identifié avec dir().Si vous ne voulez exécuter que certains scripts, vous pouvez les identifier par leur nom comme ceci :Voici une comparaison des fonctions R fs et base.","code":"\nfor(script in dir(here(\"scripts\"), pattern = \".R$\")) { # pour chaque nom de script dans le dossier \"scripts\" du projet R (avec l'extension .R)\n  source(here(\"scripts\", script))                        # source le fichier avec le nom correspondant qui existe dans le dossier scripts\n}\nscripts_to_run <- c(\n     \"epicurves.R\",\n     \"demographic_tables.R\",\n     \"survival_curves.R\"\n)\n\nfor(script in scripts_to_run) {\n  source(here(\"scripts\", script))\n}"},{"path":"directories.html","id":"importer-des-fichiers-dans-un-répertoire","chapter":"45 Interactions avec les répertoires","heading":"Importer des fichiers dans un répertoire","text":"Voir la page Importer et exporter des données pour importer et exporter des fichiers individuels.Consultez également la page Importer et exporter des données pour connaître les méthodes permettant d’importer automatiquement le fichier le plus récent, en fonction d’une date figurant dans le nom du fichier ou en examinant les métadonnées du fichier.Voir la page Itération, boucles et listes pour un exemple avec le paquet purrr démontrant :La division d’un cadre de données et son enregistrement dans plusieurs fichiers CSV.Division d’un cadre de données et enregistrement de chaque partie comme une feuille séparée dans un classeur Excel.Importer plusieurs fichiers CSV et les combiner en un seul cadre de données.Importer un classeur Excel avec plusieurs feuilles et les combiner dans un cadre de données.","code":""},{"path":"directories.html","id":"base-r-3","chapter":"45 Interactions avec les répertoires","heading":"45.6 base R","text":"Voir ci-dessous les fonctions list.files() et dir(), qui effectuent la même opération de listage des fichiers dans un répertoire spécifié. Vous pouvez spécifier ignore.case = ou un motif spécifique à rechercher.Si un fichier est actuellement “ouvert”, il s’affiche dans votre dossier avec un tilde devant, comme “~$hospital_linelists.xlsx”.","code":"\nlist.files(path = ici(\"data\"))\n\nlist.files(path = ici(\"data\"), pattern = \".csv\")\n# dir(path = ici(\"data\"), pattern = \".csv\")\n\nlist.files(path = ici(\"data\"), pattern = \"evd\", ignore.case = TRUE)"},{"path":"directories.html","id":"ressources-27","chapter":"45 Interactions avec les répertoires","heading":"45.7 Ressources","text":"https://cran.r-project.org/web/packages/fs/vignettes/function-comparisons.html","code":""},{"path":"collaboration.html","id":"collaboration","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"46 Contrôle de version et collaboration avec Git et Github","text":"Ce chapitre présente un aperçu de l’utilisation de Git pour collaborer avec d’autres personnes. Des tutoriels plus complets peuvent être en bas de page dans la section Ressources.","code":""},{"path":"collaboration.html","id":"quest-ce-que-git","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"46.1 Qu’est-ce que Git ?","text":"Git est un logiciel de contrôle de version qui permet de suivre les modifications dans un dossier. Il peut être utilisé comme l’option “track change” dans Word, LibreOffice ou Google docs, mais pour tous les types de fichiers. C’est l’une des options les plus puissantes et les plus utilisées pour le contrôle de version.Pourquoi n’en ai-je jamais entendu parler?\nLes personnes ayant une formation de développeur\ndéveloppeurs apprennent couramment à utiliser un logiciel de contrôle de version (Git,\nMercurial, Subversion ou autres), peu d’entre nous issus de disciplines\ndisciplines quantitatives sont enseignés ces compétences. Par conséquent, la plupart des épidémiologistes n’en\nPar conséquent, la plupart des épidémiologistes n’en ont jamais entendu parler au cours de leurs études, et doivent l’apprendre à la volée.Attendez, j’ai entendu parler de Github, c’est la même chose?\nPas exactement, mais vous les utilisez souvent ensemble, et nous vous montrerons comment faire. En bref :Git est le système de contrôle de version, un logiciel. Vous pouvez l’utiliser\nlocalement sur votre ordinateur ou pour synchroniser un dossier avec un\nhôte site web. Par défaut, utilise un terminal pour donner à Git\nen ligne de commande.Git est le système de contrôle de version, un logiciel. Vous pouvez l’utiliser\nlocalement sur votre ordinateur ou pour synchroniser un dossier avec un\nhôte site web. Par défaut, utilise un terminal pour donner à Git\nen ligne de commande.Vous pouvez utiliser un client/interface Git pour éviter la ligne de commande et\net effectuer les mêmes actions (au moins pour les actions simples et super courantes).\ncourantes).Vous pouvez utiliser un client/interface Git pour éviter la ligne de commande et\net effectuer les mêmes actions (au moins pour les actions simples et super courantes).\ncourantes).Si vous souhaitez stocker votre dossier dans un site web hôte pour\ncollaborer avec d’autres, vous pouvez créer un compte sur Github,\nGitlab, Bitbucket ou autres.Si vous souhaitez stocker votre dossier dans un site web hôte pour\ncollaborer avec d’autres, vous pouvez créer un compte sur Github,\nGitlab, Bitbucket ou autres.Ainsi, vous pouvez utiliser le client/interface Github Desktop, qui utilise\nGit en arrière-plan pour gérer vos fichiers, à la fois localement sur votre\nordinateur, et à distance sur un serveur Github.","code":""},{"path":"collaboration.html","id":"pourquoi-utiliser-le-combo-git-et-github","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"46.2 Pourquoi utiliser le combo Git et Github ?","text":"L’utilisation de Git facilite :L’archivage des versions documentées avec des modifications incrémentielles de sorte que vous\nafin que vous puissiez facilement revenir en arrière à n’importe quel état antérieur.Avoir des branches parallèles, c’est-à-dire des versions de développement/“de travail” avec\ndes moyens structurés pour intégrer les changements après révisionCela peut être fait localement sur votre ordinateur, même si vous ne collaborez pas avec d’autres personnes.\navec d’autres personnes. Avez-vous déjà :regretté d’avoir supprimé une section du code, pour réaliser deux mois plus tard que mois plus tard que vous en aviez réellement besoin ?regretté d’avoir supprimé une section du code, pour réaliser deux mois plus tard que mois plus tard que vous en aviez réellement besoin ?revenir sur un projet qui avait été mis en pause et tenter de se rappeler si vous aviez fait cette modification délicate dans l’un des éléments du projet. de vous rappeler si vous aviez fait cette modification délicate dans l’un des modèles ?revenir sur un projet qui avait été mis en pause et tenter de se rappeler si vous aviez fait cette modification délicate dans l’un des éléments du projet. de vous rappeler si vous aviez fait cette modification délicate dans l’un des modèles ?aviez un fichier model_1.R et un autre fichier model_1_test.R et un fichier\nmodel_1_not_working.R pour faire des essais ?aviez un fichier model_1.R et un autre fichier model_1_test.R et un fichier\nmodel_1_not_working.R pour faire des essais ?avait un fichier report.Rmd, un fichier report_full.Rmd, un fichier\nreport_true_final.Rmd, un fichier report_final_20210304.Rmd, un fichier\nreport_final_20210402.Rmd et maudit vos compétences en archivage ?avait un fichier report.Rmd, un fichier report_full.Rmd, un fichier\nreport_true_final.Rmd, un fichier report_final_20210304.Rmd, un fichier\nreport_final_20210402.Rmd et maudit vos compétences en archivage ?Git vous aidera dans tout cela, et vaut la peine d’être appris pour cette seule raison.Cependant, il devient encore plus puissant lorsqu’il est utilisé avec un référentiel en ligne\ntel que Github pour soutenir des projets collaboratifs. Cela facilite :la collaboration : d’autres personnes peuvent examiner, commenter, et accepter/refuser des modificationsla collaboration : d’autres personnes peuvent examiner, commenter, et accepter/refuser des modificationsLe partage de votre code, de vos données et de vos résultats, et l’invitation à faire des commentaires\ndu public (ou en privé, avec votre équipe)Le partage de votre code, de vos données et de vos résultats, et l’invitation à faire des commentaires\ndu public (ou en privé, avec votre équipe)et évite :“Oups, j’ai oublié d’envoyer la dernière version et maintenant vous devez\nrefaire deux jours de travail sur ce nouveau fichier”.“Oups, j’ai oublié d’envoyer la dernière version et maintenant vous devez\nrefaire deux jours de travail sur ce nouveau fichier”.Mina, Henry et Oumar ont tous travaillé en même temps sur un script et doivent\ndoivent fusionner manuellement leurs modificationsMina, Henry et Oumar ont tous travaillé en même temps sur un script et doivent\ndoivent fusionner manuellement leurs modificationsDeux personnes tentent de modifier le même fichier sur Dropbox et Sharepoint\net cela crée une erreur de synchronisation.Deux personnes tentent de modifier le même fichier sur Dropbox et Sharepoint\net cela crée une erreur de synchronisation.","code":""},{"path":"collaboration.html","id":"cela-semble-compliqué-je-ne-suis-pas-un-programmeur","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Cela semble compliqué, je ne suis pas un programmeur","text":"Cela peut l’être. Les exemples d’utilisations avancées peuvent être assez effrayants. Cependant, un peu comme R, ou même Excel, vous n’avez pas besoin de devenir un expert pour profiter des avantages de l’outil. L’apprentissage d’un petit nombre de fonctions et de notions vous permet de suivre vos modifications, de synchroniser vos fichiers sur un référentiel en ligne et de collaborer avec vos collègues en très peu de temps.En raison de la courbe d’apprentissage, le contexte d’urgence n’est peut-être pas le meilleur moment pour apprendre ces outils. Mais l’apprentissage peut se faire par étapes. Une fois que vous aurez acquis quelques notions, votre flux de travail peut être assez efficace et rapide. Si vous ne travaillez pas sur un projet où la collaboration avec des personnes peut-etre Git n’est pas une nécessité, mais c’est en fait un bon moment pour devenir l’utiliser en solo avant de vous lancer dans la collaboration.","code":""},{"path":"collaboration.html","id":"installation-1","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"46.3 Installation","text":"","code":""},{"path":"collaboration.html","id":"installer-git","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Installer Git","text":"Git est le moteur qui se cache derrière les coulisses de votre ordinateur, qui suit\nles changements, les branches (versions), les fusions et les retours en arrière. Vous pouvez d’abord\ninstaller Git de le lien ici: https://git-scm.com/downloads.","code":""},{"path":"collaboration.html","id":"installer-une-interface-facultatif-mais-recommandé","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Installer une interface (facultatif mais recommandé)","text":"Git possède son propre langage de commandes, qui peuvent être tapées dans un terminal de ligne de commande. Cependant, il existe de nombreux clients/interfaces et en tant que non-développeur, dans votre utilisation quotidienne, vous aurez rarement besoin d’interagir directement avec Git.\nL’interface Git fournit généralement des outils de visualisation agréables pour les modifications de fichiers ou les branches.De nombreuses options existent, sur tous les systèmes d’exploitation, de plus simples aux plus complexes. Parmi les bonnes options pour les débutants, citons le volet Git de RStudio et le Github Desktop, que nous présenterons dans ce chapitre. Les options intermédiaires (plus puissantes, mais plus complexes) comprennent Source Tree, Gitkracken, Smart Git et d’autres programmes.Trouvez un explication rapide sur les clients Git.Remarque : comme les interfaces utilisent toutes Git en interne, vous pouvez en essayer plusieurs, passer de l’une à l’autre en fonction de vos besoins.Comme indiqué ci-dessous, vous aurez occasionnellement avoir besoin d’écrire des commandes Git dans un terminal tel que le volet terminal de RStudio (un onglet adjacent à la Console R) ou le terminal Git Bash.","code":""},{"path":"collaboration.html","id":"compte-github","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Compte Github","text":"Créez un compte gratuit sur github.com.Il se peut que l’vous propose de configurer une authentification à deux facteurs avec une application sur votre téléphone. Pour en savoir plus, consultez le document Github help documents.Si vous utilisez Github Desktop, vous pouvez entrer vos informations d’identification Gitub après l’installation en suivant ces étapes. Si vous ne le faites pas, les informations d’identification vous seront demandées ultérieurement lorsque vous tenterez de cloner un projet à partir de Github.","code":""},{"path":"collaboration.html","id":"vocabulaire-concepts-et-fonctions-de-base","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"46.4 Vocabulaire, concepts et fonctions de base","text":"Comme lors de l’apprentissage de R, il y un peu de vocabulaire à retenir pour comprendre Git. Voici les bases pour vous aider à démarrer/ tutoriel interactif. Dans les prochaines sections, nous montrerons comment utiliser les interfaces.","code":""},{"path":"collaboration.html","id":"référentiel","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Référentiel","text":"Un référentiel Git (“repo”) est un dossier qui contient tous les sous-dossiers et fichiers de votre projet (données, code, images, etc.) et l’historique de leurs révisions. Lorsque vous commencez à suivre les changements dans le dépôt, Git créera un dossier caché qui contient toutes les informations de suivi. Un référentiel Git typique est votre dossier R Project (voir la page du manuel sur les Projets R).Nous allons montrer comment créer (initialiser) un dépôt Gitub, Github Desktop ou Rstudio dans les sections suivantes.","code":""},{"path":"collaboration.html","id":"commits","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Commits","text":"Un commit est un snapshot du projet à un moment donné. Lorsque vous apportez un changement au projet, vous faites un nouveau commit pour suivre les modifications (le delta) apportées à vos fichiers. Par exemple, vous avez peut-être édité quelques lignes de code et mis à jour une jeu de données associé. Une fois que vos modifications sont enregistrées, vous pouvez regrouper ces changements en un seul “commit”.Chaque commit un ID unique (un hash). À des fins de contrôle de version, vous pouvez revenir en arrière dans votre projet en vous basant sur les commits, pars les garder relativement petits et cohérents. Vous joindrez également une brève description des modifications appelée “message de validation”.Modifications organisées ? Mettre en scène les changements, c’est les ajouter à la zone de mise en scène en préparation pour le prochain commit. L’idée est que vous pouvez finement décider quels changements inclure dans un commit. Par exemple, si vous avez travaillé sur la spécification d’un modèle dans un\nun autre script, il serait judicieux d’avoir deux commits différents (ce serait plus facile au cas où vous voudriez annuler les changements sur la figure mais pas sur le modèle).","code":""},{"path":"collaboration.html","id":"branches","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Branches","text":"Une branche représente une ligne indépendante de changements dans votre repo, une version parallèle et alternative des fichiers de votre projet.Les branches sont utiles pour tester les modifications avant qu’elles soient incorporées dans la branche principale, qui est généralement la version principale/finale/“live” de votre projet. Lorsque vous avez fini d’expérimenter sur une branche, vous pouvez apporter les changements dans votre branche principle, en la fusionnant, ou la supprimer, si les changements n’ont pas été couronnés de succès.Note : vous n’avez pas besoin de collaborer avec d’autres personnes pour utiliser les branches, ni d’avoir un référentiel en ligne distant.","code":""},{"path":"collaboration.html","id":"dépôts-locaux-et-distants","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Dépôts locaux et distants","text":"Cloner consiste à créer une copie d’un dépôt Git à un autre endroit.Par exemple, vous pouvez cloner un dépôt en ligne de Github localement sur votre ordinateur, ou commencer par un dépôt local et le cloner en ligne en ligne sur Github.Lorsque vous avez cloné un référentiel, les fichiers du projet existent à deux endroits :le référentiel LOCAL sur votre ordinateur physique. C’est là que vous apportez les modifications réelles aux fichiers/codes.le référentiel LOCAL sur votre ordinateur physique. C’est là que vous apportez les modifications réelles aux fichiers/codes.le référentiel ROMPU, en ligne : les versions de vos fichiers de projet dans le dépôt Github (ou sur tout autre hébergeur).le référentiel ROMPU, en ligne : les versions de vos fichiers de projet dans le dépôt Github (ou sur tout autre hébergeur).Pour synchroniser ces dépôts, nous allons utiliser d’autres fonctions. En effet , contrairement à Sharepoint, Dropbox ou autre logiciel de synchronisation, Git ne met pas automatiquement à jour votre dépôt local en fonction de ce qui est en ligne,ou vice-versa. C’est vous qui choisissez quand et comment synchroniser.git fetch télécharge les nouvelles modifications depuis le dépôt distant mais ne modifie pas votre dépôt local. Pensez-y comme une vérification de l’état du dépôt distant.git fetch télécharge les nouvelles modifications depuis le dépôt distant mais ne modifie pas votre dépôt local. Pensez-y comme une vérification de l’état du dépôt distant.git pull télécharge les nouvelles modifications depuis les dépôts distants et met à jour votre dépôt local.git pull télécharge les nouvelles modifications depuis les dépôts distants et met à jour votre dépôt local.Lorsque vous avez fait un ou plusieurs commits localement, vous pouvez utiliser git push pour faire les commits vers le dépôt distant. Ceci envoie vos modifications sur Github afin que d’autres personnes puissent les voir et les tirer s’ils le souhaitent.Lorsque vous avez fait un ou plusieurs commits localement, vous pouvez utiliser git push pour faire les commits vers le dépôt distant. Ceci envoie vos modifications sur Github afin que d’autres personnes puissent les voir et les tirer s’ils le souhaitent.","code":""},{"path":"collaboration.html","id":"démarrer-créer-un-nouveau-dépôt","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"46.5 Démarrer : créer un nouveau dépôt","text":"Il y plusieurs façons de créer de nouveaux dépôts. Vous pouvez le faire à partir de la console, de Github, ou d’une interface.Deux approches générales sont possibles :Créer un nouveau projet R à partir d’un dépôt Github existant ou nouveau. (préféré pour les débutants), ou bienCréer un dépôt Github pour un projet R existant.","code":""},{"path":"collaboration.html","id":"fichiers-de-démarrage","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Fichiers de démarrage","text":"Lorsque vous créez un nouveau référentiel, vous pouvez éventuellement créer tous les fichiers ci-dessous, ou vous pouvez les ajouter à votre référentiel à un stade ultérieur. Ils se trouvent généralement dans le dossier “racine” du référentiel.Un fichier README est un fichier que quelqu’un peut lire pour comprendre pourquoi votre projet existe et ce qu’il doit savoir pour l’utiliser. Il sera vide au début, mais vous pouvez le compléter plus tard.Un fichier README est un fichier que quelqu’un peut lire pour comprendre pourquoi votre projet existe et ce qu’il doit savoir pour l’utiliser. Il sera vide au début, mais vous pouvez le compléter plus tard.Un fichier .gitignore est un fichier texte dont chaque ligne contient des dossiers ou fichiers que Git devrait ignorer (ne pas suivre les modifications). Lisez plus sur ce sujet et voir des exemples ici.Un fichier .gitignore est un fichier texte dont chaque ligne contient des dossiers ou fichiers que Git devrait ignorer (ne pas suivre les modifications). Lisez plus sur ce sujet et voir des exemples ici.Vous pouvez choisir une licence pour votre travail, afin que les autres personnes sachent sous quelles conditions elles peuvent utiliser ou reproduire votre travail. Pour de plus amples informations, consultez la page Creative Commons licenses.Vous pouvez choisir une licence pour votre travail, afin que les autres personnes sachent sous quelles conditions elles peuvent utiliser ou reproduire votre travail. Pour de plus amples informations, consultez la page Creative Commons licenses.","code":""},{"path":"collaboration.html","id":"créer-un-nouveau-référentiel-dans-github","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Créer un nouveau référentiel dans Github","text":"Pour créer un nouveau dépôt, connectez-vous à Github et cherchez le bouton vert. Ce dépôt vide peut être cloné localement sur votre ordinateur (voir la section suivante).Vous devez choisir si vous voulez que votre dépôt soit public (visible par tout le monde sur Internet) ou privé (seulement visible pour ceux qui ont la permission acceder le dépôt). Cela des implications importantes si vos données sont sensibles. Si votre référentiel est privé, vous rencontrerez certains quotas dans des circonstances particulières, par exemple si vous utilisez les actions de Github pour exécuter automatiquement votre code dans le nuage.","code":""},{"path":"collaboration.html","id":"clone-à-partir-dun-dépôt-github","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Clone à partir d’un dépôt Github","text":"Vous pouvez cloner un référentiel Github existant pour créer un nouveau projet R local sur votre ordinateur.Le dépôt Github peut être un dépôt qui existe déjà et contient du contenu, ou un dépôt vide que vous venez de créer. Dans ce dernier cas, vous créez essentiellement le repo Github et le projet local R en même temps (voir les instructions ci-dessus).Remarque : si vous n’avez pas de droits de contribution sur un dépôt Github, il est possible de d’abord “forker” (creer une copie) le dépôt vers votre profil, et ensuite de procéder aux autres actions. La bifurcation est expliquée à la fin de ce chapitre, mais nous vous recommandons de lire les autres sections en premier.Etape 1 : Naviguez dans Github jusqu’au dépôt, cliquez sur le bouton vert “Code”. et copier l’URL HTTPS clone (voir image ci-dessous)L’étape suivante peut être effectuée dans n’importe quelle interface. Nous allons illustrer avec Rstudio et le bureau Github.","code":""},{"path":"collaboration.html","id":"dans-rstudio","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Dans Rstudio","text":"Dans RStudio, démarrez un nouveau projet R en cliquant sur Fichier > Nouveau projet > Contrôle de version > Git.Lorsque vous êtes invité à saisir l’“URL du dépôt”, collez l’URL HTTPS de Github.Attribuez au projet R un nom court et informatif.Choisissez l’endroit où le nouveau projet R sera enregistré localement.Cochez “Ouvrir dans une nouvelle session” et cliquez sur “Créer un projet”.Vous êtes maintenant dans un nouveau projet RStudio local qui est un clone du dépôt Github. Ce projet local et le dépôt Github sont maintenant liés.","code":""},{"path":"collaboration.html","id":"dans-le-bureau-de-github","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Dans le bureau de Github","text":"Cliquez sur Fichier > Cloner un référentiel.Cliquez sur Fichier > Cloner un référentiel.Sélectionnez l’onglet URLSélectionnez l’onglet URLCollez l’URL HTTPS de Github dans la première case.Collez l’URL HTTPS de Github dans la première case.Sélectionnez le dossier dans lequel vous voulez avoir votre dépôt local.Sélectionnez le dossier dans lequel vous voulez avoir votre dépôt local.Cliquez sur “CLONE”.Cliquez sur “CLONE”.","code":""},{"path":"collaboration.html","id":"nouveau-repo-github-à-partir-dun-projet-r-existant","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Nouveau repo Github à partir d’un projet R existant","text":"Un autre scénario de configuration est que vous avez un projet R existant avec du contenu, et que vous voulez créer un dépôt Github pour celui-ci.Créez un nouveau dépôt Github vide pour le projet (cf. instructions ci-dessus).Clonez ce dépôt localement (voir les instructions HTTPS ci-dessus).Copiez tout le contenu de votre projet R (codes, données, etc.) dans ce nouveau dépôt local vide (utilisez le copier-coller, par exemple).Ouvrez votre nouveau projet dans RStudio, et allez dans le volet Git. Les nouveaux fichiers devraient s’enregistrer comme des modifications de fichiers, désormais suivies par Git. Par conséquent, vous pouvez regrouper ces modifications sous forme de commit et les pousser (push) vers Github. Une fois poussé (pushed), le dépôt sur Github reflétera tous les fichiers.Voir la section sur le flux de travail Github ci-dessous pour plus de détails sur ce processus.","code":""},{"path":"collaboration.html","id":"a-quoi-cela-ressemble-t-il-maintenant","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"A quoi cela ressemble-t-il maintenant ?","text":"","code":""},{"path":"collaboration.html","id":"dans-rstudio-1","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Dans RStudio","text":"Une fois que vous avez cloné un dépôt Github vers un nouveau projet R, vous voyez maintenant dans RStudio un onglet “Git”. Cet onglet apparaît dans le même volet de RStudio que votre environnement R :Veuillez noter les boutons encerclés dans l’image ci-dessus, puisqu’ils seront référencés plus tard (de gauche à droite) :Bouton pour commettre (commit) les modifications du fichier sauvegardé dans la branche locale (cela ouvrira une nouvelle fenêtre)Flèche bleue pour tirer (pull, mettre à jour votre version locale de la branche avec avec les changements effectués sur la version distante/Github de cette branche)Flèche verte pour pousser (push, envoyer tous les commits/modifications de votre version version locale de la branche vers la version distante/Github de cette branche)L’onglet Git dans RStudioBouton pour créer une NOUVELLE branche en utilisant comme base la branche locale affichée. Vous voulez presque toujours créer une branche à partir de la branche principale (après la première extraction).La branche dans laquelle vous travaillez actuellementLes modifications que vous avez apportées au code ou à d’autres fichiers apparaissent ci-dessous","code":""},{"path":"collaboration.html","id":"dans-github-desktop","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"dans Github Desktop","text":"Github Desktop est une application indépendante qui vous permet de gérer tous vos dépôts. Lorsque vous l’ouvrez, l’interface vous permet de choisir le dépôt sur lequel vous souhaitez travailler, puis d’effectuer les actions Git à partir de là.","code":""},{"path":"collaboration.html","id":"flux-de-travail-git-github","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"46.5.1 Flux de travail Git + Github","text":"","code":""},{"path":"collaboration.html","id":"aperçu-du-processus","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Aperçu du processus","text":"Une fois que vous avez terminé la configuration (décrite ci-dessus), vous aurez un Github qui est connecté (cloné) à un projet R local. La branche principale (créée par défaut) est la version dite “live” de tous les fichiers. Lorsque vous voulez faire des modifications, il est bon de créer une pratique de créer une nouvelle branche à partir de la branche principale (comme “créer une copie”). Il s’agit d’un flux de travail typique de Git, car la création d’une branche est facile et rapide.Un flux de travail typique est le suivant :Assurez-vous que votre dépôt local est à jour, mettez-le à jour si ce n’est pasAssurez-vous que votre dépôt local est à jour, mettez-le à jour si ce n’est pasAllez sur la branche sur laquelle vous travailliez précédemment, ou créez une nouvelle brancheAllez sur la branche sur laquelle vous travailliez précédemment, ou créez une nouvelle brancheTravaillez sur les fichiers localement sur votre ordinateur, faites un ou plusieurs commits à cette brancheTravaillez sur les fichiers localement sur votre ordinateur, faites un ou plusieurs commits à cette brancheMettre à jour la version distante de la branche avec vos modifications (push)Mettre à jour la version distante de la branche avec vos modifications (push)Lorsque vous êtes satisfait de votre branche, vous pouvez fusionner la version en ligne de la branche de travail avec la branche “principale” afin de créer une nouvelle branche.Lorsque vous êtes satisfait de votre branche, vous pouvez fusionner la version en ligne de la branche de travail avec la branche “principale” afin de créer une nouvelle branche.Les autres membres de l’équipe peuvent faire la même chose avec leurs propres branches, ou peut contribuer des commits dans votre branche de travail aussi.Nous détaillons ci-dessous le processus, étape par étape.Voici un schéma que nous avons développé - il se présente sous la forme d’un tableau à double sens, ce qui devrait aider les épidémiologistes à comprendre.Voici un autre diagramme.*Note : jusqu’à récemment, le terme de branche “master” était utilisé, mais parle maintenant de branche “principale” (“master”).Image source","code":""},{"path":"collaboration.html","id":"créer-une-nouvelle-branche","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"46.6 Créer une nouvelle branche","text":"Lorsque vous sélectionnez une branche sur laquelle travailler, Git réinitialise votre répertoire de travail comme il était la dernière fois que vous étiez sur cette branche.","code":""},{"path":"collaboration.html","id":"dans-le-volet-git-de-rstudio","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Dans le volet Git de Rstudio","text":"Assurez-vous que vous êtes dans la branche “principale”, puis cliquez sur l’icône violette pour créer une nouvelle branche (voir image ci-dessus).Vous serez invité à nommer votre branche avec un nom descriptif en un mot (vous pouvez utiliser des caractères de soulignement si nécessaire).Vous verrez que, localement, vous êtes toujours dans le même projet R, mais que vous ne travaillez plus sur la branche “principale”.Une fois créée, la nouvelle branche apparaîtra également sur le site Github comme une branche.Vous pouvez visualiser les branches dans le volet Git de Rstudio après avoir cliqué sur “Historique” (“History”).","code":""},{"path":"collaboration.html","id":"dans-le-bureau-de-github-1","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Dans le bureau de Github","text":"Le processus est très similaire, il vous est demandé de donner un nom à votre branche.Ensuite, il vous sera demandé de “Publier votre branche sur Github” pour que la nouvelle branche apparaisse également dans le dépôt distant.","code":""},{"path":"collaboration.html","id":"dans-la-console","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Dans la console","text":"Ce qui se passe en réalité dans les coulisses est que vous créez une nouvelle branche avec git branch, puis vous allez dans la branche avec git checkout ( .e. dites à Git que vos prochains commits se feront là). Dans votre dépôt git :Pour plus d’informations sur l’utilisation de la console, voir la section sur les Commandes Git à la fin.","code":"git branch my-new-branch # Créez la nouvelle branche\ngit checkout my-new-branch # Aller sur la branche\ngit checkout -b ma-nouvelle-branche # Les deux à la fois (raccourci)"},{"path":"collaboration.html","id":"valider-les-changements","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"46.7 Valider les changements","text":"Vous pouvez maintenant modifier le code, ajouter de nouveaux fichiers, mettre à jour les ensembles de données, etc.Chacune de vos modifications est suivie, une fois que le fichier respectif est sauvegardé. Les fichiers modifiés apparaîtront dans l’onglet Git de RStudio, dans Github Desktop, ou en utilisant la commande git status dans le terminal (voir ci-dessous).Chaque fois que vous effectuez des modifications substantielles (par exemple, l’ajout ou la mise à jour d’une section de code), faites une pause et committez ces changements. Pensez à un commit comme un “partie” de changements liés à un objectif commun. Vous pouvez toujours continuer à réviser un fichier après y avoir apporté des modifications.Conseil sur les commits : en général, il est préférable de faire de petits commits, qui peuvent être facilement annulées si un problème survient, pour commiter ensemble des modifications liées à un objectif commun. Pour y parvenir, vous trouverez que vous devez commiter souvent. Au début, vous allez probablement oublier de commiter souvent, mais ensuite l’habitude s’installe.","code":""},{"path":"collaboration.html","id":"dans-rstudio-2","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Dans Rstudio","text":"L’exemple ci-dessous montre que, depuis le dernier commit, le script R Markdown “collaboration.Rmd” été modifié, et plusieurs images PNG ont été ajoutées.Vous vous demandez peut-être ce que représentent les carrés jaunes, bleus, verts et rouges à côté de les noms de fichiers. Voici un instantané de la feuille de route RStudio cheatsheet qui explique leur signification. Notez que les changements avec des ” ?” jaunes peuvent toujours être mises en scène, validées et poussées.Cliquez sur le bouton “Commit” dans l’onglet Git, ce qui ouvrira une nouvelle fenêtre (voir ci-dessous).Cliquez sur le bouton “Commit” dans l’onglet Git, ce qui ouvrira une nouvelle fenêtre (voir ci-dessous).Cliquez sur le nom d’un fichier dans le cadre supérieur gauche.Cliquez sur le nom d’un fichier dans le cadre supérieur gauche.Passez en revue les modifications que vous avez apportées à ce fichier (surlignées en vert ou en rouge ci-dessous).Passez en revue les modifications que vous avez apportées à ce fichier (surlignées en vert ou en rouge ci-dessous).“Mettez en scène” le fichier, ce qui inclura ces modifications dans le commit. Faites en cochant la case à côté du nom du fichier. Alternativement, vous pouvez mettre en surbrillance plusieurs noms de fichiers, puis cliquer sur “Stage”.“Mettez en scène” le fichier, ce qui inclura ces modifications dans le commit. Faites en cochant la case à côté du nom du fichier. Alternativement, vous pouvez mettre en surbrillance plusieurs noms de fichiers, puis cliquer sur “Stage”.Rédigez un message de validation court mais descriptif (obligatoire).Rédigez un message de validation court mais descriptif (obligatoire).Appuyez sur le bouton “Commit”. Une boîte de dialogue apparaîtra, indiquant le succès ou un message d’erreur.Appuyez sur le bouton “Commit”. Une boîte de dialogue apparaîtra, indiquant le succès ou un message d’erreur.Vous pouvez maintenant effectuer d’autres modifications et d’autres livraisons, autant de fois que vous le souhaitez.","code":""},{"path":"collaboration.html","id":"dans-le-bureau-de-github-2","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Dans le bureau de Github","text":"Vous pouvez voir la liste des fichiers qui ont été modifiés sur la gauche. Si vous sélectionnez un fichier texte, vous verrez un résumé des modifications qui ont été apportées dans le volet de droite (cette vue ne fonctionnera pas sur des fichiers plus complexes comme les .docs ou les .xlsx).Pour mettre en scène les changements, il suffit de cocher la petite case à côté des noms de fichiers. Lorsque vous avez sélectionné les fichiers que vous voulez ajouter à cette livraison, donnez un nom à la livraison, une description, puis cliquez sur le bouton commit.","code":""},{"path":"collaboration.html","id":"dans-la-console-1","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Dans la console","text":"Les deux fonctions utilisées dans les coulisses sont git add pour sélectionner/établir et git commit pour effectuer la livraison.","code":"git status # voir les changements \n\ngit add new_pages/collaboration.Rmd # sélectionner les fichiers à livrer (= mettre en scène les changements)\n\ngit commit -m \"Describe commit from Github Desktop\" # livrer les changements avec un message\n\ngit log # affiche les informations sur les commits passés"},{"path":"collaboration.html","id":"modifier-un-commit-précédent","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Modifier un commit précédent","text":"Que se passe-t-il si vous commettez des changements, continuez à travailler et réalisez que vous avez fait des changements qui devraient “appartenir” au commit précédent (à votre avis)? N’ayez crainte ! Vous pouvez ajouter ces changements à votre validation précédente.Dans Rstudio, cela devrait être assez évident puisqu’il y une case “Amend previous commit” sur la même ligne que le bouton COMMIT.Pour une raison peu claire, la fonctionnalité n’pas été implémentée en tant que telle dans Github Desktop, mais il existe une\nmoyen de la contourner. Si vous avez validé mais pas encore poussé vos changements, un bouton “UNDO” apparaît juste en dessous du bouton COMMIT. Cliquez dessus et il annulera votre validation (mais conservera vos fichiers indexés et votre message de validation). Sauvegardez vos changements, ajoutez de nouveaux fichiers à la livraison si nécessaire et livrez à nouveau.Dans la console :Note : réfléchissez avant de modifier des commits qui sont déjà publics et partagés avec vos collaborateurs.","code":"git add [YOUR FILES] # Ajoute vos nouvelles modifications\n\ngit commit --amend # Modifie le commit précédent\n\ngit commit --amend -m \"An updated commit message\" # Modifie la livraison précédente ET met à jour le message de livraison."},{"path":"collaboration.html","id":"tirez-et-poussez-les-modifications-vers-github","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"46.8 Tirez et poussez les modifications vers Github","text":"“D’abord TIREZ, ensuite POUSSER”C’est une bonne pratique de aller chercher et de tirez avant de commencer à travailler sur votre projet, afin de mettre à jour la version de la branche sur votre ordinateur local avec toutes les modifications qui ont été apportées dans la version distante/Github.TIREZ souvent. N’hésitez pas. Tirez toujours avant de pousser.Lorsque vos modifications sont effectuées et validées et que vous êtes satisfait de l’état de votre projet, vous pouvez pousser vos commits vers la version distante/Github de votre branche.Rincez et répétez pendant que vous travaillez sur le référentiel.Note: il est beaucoup plus facile de revenir sur des modifications qui ont été commises mais pas poussées (c’est-à-dire qu’elles sont toujours en cours de traitement) que de revenir sur des changements qui ont été poussés vers le dépôt distant (et peut-être déjà extraites par quelqu’un d’autre).","code":""},{"path":"collaboration.html","id":"dans-rstudio-3","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Dans Rstudio","text":"TIREZ - Cliquez d’abord sur l’icône “Tirez” (flèche vers le bas) qui récupère et tire en même temps.POUSSER - Cliquez sur l’icône verte “Tirez” (flèche vers le haut). Il peut vous être demandé\nd’entrer votre nom d’utilisateur et votre mot de passe Github.La première fois, vous devrez peut-être entrer deux lignes de commande Git dans le Terminal:git config –global utilisateur.email ” @example.com “ (votre adresse électronique Github\n), etgit config –global user.name “Votre nom d’utilisateur Github”Pour en savoir plus sur la façon de saisir ces commandes, consultez la section ci-dessous sur les commandes Git.TIP: vous demande trop souvent de fournir votre mot de passe ? Consultez les chapitres 10 & 11 de ce tutoriel pour se connecter à un référentiel en utilisant une clé SSH (plus compliqué).","code":""},{"path":"collaboration.html","id":"dans-le-bureau-de-github-3","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Dans le bureau de Github","text":"Cliquez sur le bouton “Récupérer l’origine” pour vérifier s’il y de nouveaux commits sur le dépôt distant.Si Git trouve de nouveaux commits sur le dépôt distant, le bouton se se transformera en bouton “Pull”. Comme le même bouton est utilisé pour pousser et tirer, vous ne pouvez pas pousser vos modifications si vous ne tirez pas auparavant.Vous pouvez aller dans l’onglet “History” (près de l’onglet “Changes”) pour voir toutes les commits (les vôtres et ceux des autres). C’est un bon moyen de savoir ce que vos collaborateurs ont fait. Vous pouvez lire le message du commit, la description s’il y en une, et comparer le code des deux fichiers en utilisant le volet diff.Une fois que toutes les modifications distantes ont été tirées, et qu’au moins une modification locale été validée, vous pouvez pousser en cliquant sur le même bouton.","code":""},{"path":"collaboration.html","id":"console","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Console","text":"Sans surprise, les commandes sont chercher (fetch), tirez (pull) et pousser (push).","code":"git fetch # Y a-t-il de nouveaux commits dans le répertoire distant ?\ngit pull # Apporte les commits distants dans votre branche locale\ngit push # Pousse les commits locaux de cette branche vers la branche distante"},{"path":"collaboration.html","id":"je-veux-tirer-mais-jai-du-travail-local","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Je veux tirer mais j’ai du travail local","text":"Cela peut arriver parfois : vous avez effectué des modifications sur votre dépôt local, mais le dépôt distant des commits que vous n’avez pas tirés.Git refusera de les extraire car cela pourrait écraser vos modifications. Il existe plusieurs stratégies pour conserver vos modifications, bien décrites dans Happy Git R, parmi lesquelles les deux principales sont :livrer vos modifications, récupérer les modifications distantes, les tirer, résoudre les conflits si nécessaire (voir la section ci-dessous), et pousser le tout en lignestash vos changements, ce qui les met en quelque sorte de côté, les tirer, les déstocker (restauration), puis commit, résolution des conflits, et push.Si les fichiers concernés par les modifications distantes et les fichiers concernés par vos modifications locales ne se chevauchent pas, Git peut résoudre les conflits automatiquement.Dans Github Desktop, cela peut être fait avec des boutons. Pour mettre en cache, allez dans Branch > Stash changes.","code":""},{"path":"collaboration.html","id":"fusionner-la-branche-dans-main","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"46.9 Fusionner la branche dans Main","text":"Si vous avez fini de faire des changements, vous pouvez commencer le processus de fusionner ces changements dans la branche principale. En fonction de votre situation, cela peut être rapide, ou vous pouvez avoir des étapes délibérées de révision et d’approbation impliquant des coéquipiers.","code":""},{"path":"collaboration.html","id":"localement-dans-github-desktop","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Localement dans Github Desktop","text":"peut fusionner des branches localement en utilisant Github Desktop. Tout d’abord, allez dans (checkout) la branche qui sera le destinataire des commits, en d’autres termes, la branche que vous voulez mettre à jour. Ensuite, allez dans le menu Branche > Fusionner en branche actuelle et cliquez. Une boîte vous permet de sélectionner la branche à partir de laquelle vous souhaitez importer.","code":""},{"path":"collaboration.html","id":"dans-la-console-2","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Dans la console","text":"Revenez d’abord à la branche qui sera le destination des changements. C’est généralement master, mais cela peut être une autre branche si vous le souhaite. Fusionnez votre branche de travail dans master.Cette page montre un exemple plus avancé de branchement et explique un peu ce qui se passe en coulisses.","code":"git checkout master # Retournez à master (ou à la branche que vous voulez déplacer)\ngit merge this_fancy_new_branch"},{"path":"collaboration.html","id":"dans-github-soumettre-des-demandes-de-pull-tirer","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Dans Github : soumettre des demandes de pull (tirer)","text":"S’il est tout à fait possible de fusionner deux branches localement, ou sans en informer qui que ce soit, une fusion peut être discutée ou étudiée par plusieurs personnes avant d’être intégrée à la branche master. Pour aider à ce processus, Github propose des fonctionnalités de discussion autour de la fusion : la pull request.Une pull request (une “PR”) est une demande de fusion d’une branche dans une autre (en d’autres termes, une demande pour que votre branche de travail soit intégrée à la branche “principale”). Une pull request implique généralement plusieurs commits. Une pull request commence généralement une conversation et un processus de révision avant qu’elle soit acceptée et que la branche soit fusionnée. Par exemple, vous pouvez lire les discussions sur les demandes de téléchargement sur le site dplyr’s github.Vous pouvez soumettre une demande de modification (PR) directement à partir du site Web (comme illustré ci-dessous) ou à partir de Github.Accéder au dépôt Github (en ligne)Affichez l’onglet “demande de retrait” et cliquez sur le bouton “New pull request”.Choisissez dans le menu déroulant de fusionner votre branche avec la branche principale.Rédigez un commentaire détaillé de la Pull Request et cliquez sur “Create Pull Request”.Dans l’image ci-dessous, la branche “forests” été sélectionnée pour être fusionnée dans “main” :Maintenant vous devriez être capable de voir la pull request (image d’exemple ci-dessous) :Passez en revue l’onglet “Fichiers modifiés” pour voir comment la branche “principale” changerait si la branche était fusionnée.Sur la droite, vous pouvez demander une révision aux membres de votre équipe en marquant leur identifiant Github. Si vous le souhaitez, vous pouvez définir les paramètres du référentiel pour qu’une révision approuvée soit nécessaire afin de fusionner avec la branche master.Une fois la demande de retrait est approuvée, un bouton permettant de “Merge pull request” devient actif. Cliquez dessus.Une fois terminé, supprimez votre branche comme expliqué ci-dessous.","code":""},{"path":"collaboration.html","id":"résolution-des-conflits","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Résolution des conflits","text":"Lorsque deux personnes modifient la ou les mêmes lignes au même moment, un conflit de fusion se produit. En effet, Git refuse de prendre une décision quant à version à conserver, mais il vous aide à trouver où se trouve le conflit. NE PANIQUEZ PAS. La plupart du temps, il est assez simple à résoudre.Par exemple, sur Github :Après que la fusion ait soulevé un conflit, ouvrez le fichier dans votre éditeur préféré. Le conflit sera indiqué par une série de caractères :Le texte entre <<<<<<< HEAD et ======= provient de votre dépôt local, et celui entre ======= et >>>>>>> de l’autre branche (qui peut être origin, main ou toute autre branche de votre choix).Vous devez décider quelle version du code vous préférez (ou même écrire une troisième, en incluant les changements des deux côtés si cela est pertinent), effacer le reste et retirer toutes les marques que Git ajoutées ((<<<<<<< HEAD, =======, >>>>>>> origin/master/your_branch_name).Ensuite, sauvegardez le fichier, mettez-le en scène et commitez-le : c’est le commit qui rend la version fusionnée “officielle”. N’oubliez pas de pousser (push) ensuite.Plus vous et vos collaborateurs tirent et poussent souvent, plus les conflits seront réduits.*Remarque : Si vous vous sentez à l’aise avec la console, il existe des outils plus avancés de fusionner options (par exemple, ignorer les espaces, donner la priorité à un collaborateur, etc.)","code":""},{"path":"collaboration.html","id":"supprimer-votre-branche","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Supprimer votre branche","text":"Une fois qu’une branche été fusionnée dans master et n’est plus nécessaire, vous pouvez la supprimer.","code":""},{"path":"collaboration.html","id":"github-rstudio","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"46.9.0.1 Github + Rstudio","text":"Allez sur le dépôt sur Github et cliquez sur le bouton pour afficher toutes les branches (à côté de la liste déroulante pour les branches). Trouvez maintenant votre branche et cliquez sur l’icône de la corbeille à côté d’elle. Lisez plus de détails sur la suppression d’une branche ici.Assurez-vous de supprimer également la branche localement sur votre ordinateur. Cela ne se fera pas automatiquement.Dans RStudio, assurez-vous que vous êtes dans la branche Main.Passez à la saisie de commandes Git dans le “Terminal” de RStudio (l’onglet adjacent à la console R), et tapez : git branch -d nom_branche, où “nom_branche” est le nom de la branche à supprimer.Rafraîchissez votre onglet Git et la branche devrait avoir disparu.","code":""},{"path":"collaboration.html","id":"dans-github","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"46.9.0.2 Dans Github","text":"Vérifiez simplement la branche que vous voulez supprimer ce retrouve maintenant dans le menu Branche > Supprimer.","code":""},{"path":"collaboration.html","id":"forking","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Forking","text":"Vous pouvez bifurquer d’un projet si vous souhaitez contribuer mais que vous n’avez pas les droits pour le faire, ou si vous voulez simplement le modifier pour votre usage personnel. Une courte description de la bifurcation se trouve ici.Sur Github, cliquez sur le bouton “Fork” :Ceci clonera le dépôt original, mais dans votre propre profil. Donc maintenant, il y deux versions du dépôt sur Github : l’original, que vous ne pouvez pas modifier, et la version clonée dans votre profil.Ensuite, vous pouvez procéder au clonage de votre version du dépôt en ligne en local sur votre ordinateur, en utilisant l’une des méthodes décrites dans les sections précédentes. Ensuite, vous pouvez créer une nouvelle branche, faire des changements, les livrer et les pousser vers votre dépôt distant.Une fois que vous êtes satisfait du résultat, vous pouvez créer une Pull Request à partir de Github ou de Github Desktop pour entamer la conversation avec les propriétaires/mainteneurs du dépôt d’origine.Et si vous avez besoin de commits plus récents du dépôt officiel?Imaginez que quelqu’un apporte une modification critical au dépôt officiel, que vous voulez inclure dans votre version clonée. Il est possible de synchroniser votre fork avec le dépôt officiel. Cela implique l’utilisation du terminal, mais ce n’est pas trop compliqué. Vous devez surtout vous rappeler que :upstream = le dépôt officiel, celui que vous n’avez pas pu modifierorigin = votre version du dépôt sur votre profil GithubVous pouvez lire ce tutoriel ou suivre les instructions ci-dessous :Tout d’abord, tapez dans votre terminal Git (à l’intérieur de votre repo) :Si vous n’avez pas encore configuré le référentiel amont, vous devriez voir deux lignes, commençant par origin. Elles montrent le dépôt distant vers lequel chercher et pousser pointent. Rappelez-vous, origin est le surnom conventionnel pour votre propre version du dépôt sur Github. Par exemple :Maintenant, ajoutez un nouveau dépôt distant :Ici, l’adresse est l’adresse que Github génère lorsque vous clonez un dépôt (voir la section sur le clonage). Vous aurez maintenant quatre pointeurs distants :Maintenant que la configuration est faite, chaque fois que vous voulez obtenir les changements de le dépôt original (upstream), il suffit d’aller (checkout) dans la branche la branche que vous voulez mettre à jour et taper :S’il y des conflits, vous devrez les résoudre, comme expliqué dans la section Résoudre les conflits.Résumé : forker est un clonage, mais du côté du serveur Github. Le reste des actions sont des actions typiques du flux de travail de collaboration (cloner, pousser, tirer, commettre, fusionner, soumettre des demandes de tirage…).Remarque : si la bifurcation est un concept et non une commande Git, elle existe aussi sur d’autres hôtes Web, comme Bitbucket.","code":"git remote -vgit remote add upstream https://github.com/epirhandbook/Epi_R_handbook.gitgit fetch upstream # Obtenir les nouveaux commits du dépôt distant\ngit checkout la_branche_que_vous_voulez_mettre_à_jour\ngit merge upstream/the_branch_you_want_to_update # Fusionne la branche amont dans votre branche.\ngit push # Mettez à jour votre propre version du dépôt distant."},{"path":"collaboration.html","id":"ce-que-nous-avons-appris","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"46.10 Ce que nous avons appris","text":"Vous avez appris à :paramétrer Git pour suivre les modifications dans vos dossiers,connecter votre référentiel local à un référentiel en ligne distant,livrer les changements,synchroniser vos dépôts local et distant.Tout cela devrait vous permettre de démarrer et de répondre à la plupart de vos besoins en tant qu’épidémiologistes. Nous n’avons généralement pas un usage aussi avancé que les développeurs.Cependant, sachez que si vous voulez (ou devez) aller plus loin, Git offre plus de puissance pour simplifier l’historique des commits, le retour en arrière d’un ou plusieurs commits, le cherry-pick des commits, etc. Tout cela peut sembler de la pure magie, mais maintenant que vous avez les bases, il est plus facile de s’appuyer dessus.Notez que si le volet Git de Rstudio et Github Desktop sont bons pour les débutants / l’utilisation quotidienne dans notre travail, ils n’offrent pas une interface pour certaines des fonctions intermédiaires/avancées de Git. Certaines interfaces plus complètes vous permettent d’en faire plus en pointant et en cliquant (généralement au prix d’une mise en page plus complexe).Rappelez-vous que puisque vous pouvez utiliser n’importe quel outil à n’importe quel moment pour suivre votre dépôt, vous pouvez très facilement installer une interface pour l’essayer parfois, ou pour effectuer occasionnellement une tâche complexe moins courante, tout en préférant une interface simplifiée le reste du temps (par exemple en utilisant Github Desktop la plupart du temps, et passer à SourceTree ou Gitbash pour certaines tâches spécifiques).","code":""},{"path":"collaboration.html","id":"git","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"46.10.1 Commandes Git","text":"","code":""},{"path":"collaboration.html","id":"apprentissage-recommandé","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Apprentissage recommandé","text":"Pour apprendre les commandes Git à l’aide d’un tutoriel interactif, voir ce site web.","code":""},{"path":"collaboration.html","id":"où-entrer-les-commandes","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Où entrer les commandes","text":"Vous entrez les commandes dans un shell Git.Option 1 Vous pouvez ouvrir un nouveau Terminal dans RStudio. Cet onglet se trouve à côté de la Console R. Si vous ne parvenez pas à y taper du texte, cliquez sur le menu déroulant sous “Terminal” et sélectionnez “Nouveau terminal”. Tapez les dans l’espace clignotant situé devant le symbole du dollar “$”.Option 2 Vous pouvez également ouvrir un shell (un terminal pour entrer des commandes) en cliquant sur l’icône bleue “gears” dans l’onglet Git (près de l’environnement RStudio). Sélectionnez “Shell” dans le menu déroulant. Une nouvelle fenêtre s’ouvre dans laquelle vous pouvez saisir les commandes après le signe du dollar “$”.Option 3 Cliquez avec le bouton droit de la souris pour ouvrir “Git Bash ”, qui ouvrira le même type de terminal, ou ouvrez Git Bash depuis votre liste d’applications. Plus d’informations pour les débutants sur Git Bash, comment le trouver et quelques commandes bash dont vous aurez besoin.","code":""},{"path":"collaboration.html","id":"exemples-de-commandes","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"Exemples de commandes","text":"Nous présentons ci-dessous quelques commandes git courantes. Lorsque vous les utilisez, gardez à l’esprit quelle branche est active (check-), car cela changera l’action !Dans les commandes ci-dessous,  représente un nom de branche et  représente l’ID de hachage d’un commit spécifique.  représente un nombre. Ne tapez pas les symboles < ou >>.","code":""},{"path":"collaboration.html","id":"ressources-28","chapter":"46 Contrôle de version et collaboration avec Git et Github","heading":"46.11 Ressources","text":"Une grande partie de cette page été informée de ce site “Happy Git R” site web par Jenny Bryan. Il y une section très utile qui vous aide à résoudre les erreurs courantes liées à Git et à R.Le Guide de documentation et de démarrage de Github.com guide.La fiche technique de RStudio “IDE” cheatsheet qui comprend des conseils sur Git avec RStudio.https://ohi-science.org/news/github-going-back--timeLes commandes Git pour les débutantsUn tutoriel didacticiel pour apprendre les commandes Git.https://www.freecodecamp.org/news/-introduction--git--absolute-beginners-86fa1d32ff71/ : bon pour apprendre les bases absolues pour suivre les changements dans un dossier sur votre propre ordinateur.De beaux schémas pour comprendre les branches : https://speakerdeck.com/alicebartlett/git--humansTutoriels couvrant les sujets de base et plus avancés.https://tutorialzine.com/2016/06/learn-git--30-minuteshttps://dzone.com/articles/git-tutorial-commands--operations--git\nhttps://swcarpentry.github.io/git-novice/ (cours court)\nhttps://rsjakob.gitbooks.io/git/content/chapter1.htmlLe livre Pro Git est considéré comme une référence officielle. Bien que certains chapitres soient corrects, il est généralement un peu technical. C’est probablement une bonne ressource une fois que vous avez utilisé Git un peu et quand vous voulez apprendre un peu plus précisément ce qui se passe et comment aller plus loin avec Git.","code":""},{"path":"errors.html","id":"errors","chapter":"47 Erreurs fréquentes","heading":"47 Erreurs fréquentes","text":"Cette page contient une liste d’erreurs les plus fréquentes et propose des solutions pour les résoudre.","code":""},{"path":"errors.html","id":"interprétation-des-messages-derreurs","chapter":"47 Erreurs fréquentes","heading":"47.1 Interprétation des messages d’erreurs","text":"Les messages d’erreurs en R peuvent parfois être compliqués, c’est la raison pour laquelle Google sera votre partenaire. Recherchez le message d’erreur avec “R” et cherchez des messages récents dans StackExchange.com, stackoverflow.com, community.rstudio.com, twitter(#rstats) et d’autres forums utilisés par les programmeurs pour poser des questions et obtenir des réponses. Essayez de trouver des messages récents qui ont résolu des problèmes similaires.Si, après nombreuses recherches, vous ne trouvez pas de réponse à votre problème, envisagez créer un exemple reproductible (“reprex”) et poser la question vous-même. Consultez la page obtenir de l’aide pour des conseils sur comment créer et publier un exemple reproductible sur les forums.","code":""},{"path":"errors.html","id":"erreurs-fréquentes","chapter":"47 Erreurs fréquentes","heading":"47.2 Erreurs fréquentes","text":"Nous énumérons ci-dessous quelques erreurs courantes et les explications/solutions possibles. Certaines d’entre elles sont tirées de l’analyse de Noam Ross, qui analysé les messages de forum les plus courants sur Stack Overflow concernant les messages d’erreur en R (voir l’analyse ici).","code":""},{"path":"errors.html","id":"erreurs-de-typographie","chapter":"47 Erreurs fréquentes","heading":"Erreurs de typographie","text":"Si vous voyez unexpected symbol, vérifiez qu’il ne manque pas de virgules","code":"Error: unexpected symbol in:\n\"  geom_histogram(stat = \"identity\")+\n  tidyquant::geom_ma(n=7, size = 2, color = \"red\" lty\""},{"path":"errors.html","id":"erreurs-de-packages","chapter":"47 Erreurs fréquentes","heading":"Erreurs de packages","text":"Ceci signifie probablement que vous avez mal saisi le nom de la fonction, ou bien vous avez oublié d’installer ou de lancer un package.Vous pensez que vous utilisez dplyr::select() mais la fonction select() été masquée par MASS::select() - spécifiez dplyr:: ou réordonnez le chargement de votre package pour que dplyr soit après tous les autres.D’autres erreurs de cache communes proviennent de : plyr::summarise() et stats::filter(). Considérez l’utilisation du conflicted package.Si vous obtenez une erreur indiquant que vous devez supprimer un fichier “00LOCK”, allez dans votre bibliothèque “R” dans le répertoire de votre ordinateur (par exemple, R/win-library/) et cherchez un dossier nommé “00LOCK”. Supprimez-le manuellement et essayez d’installer à nouveau le package. Un processus d’installation précédent probablement été interrompu, ce qui mené à cela.","code":"could not find function \"x\"...Error in select(data, var) : unused argument (var)Error in install.packages : ERROR: failed to lock directory ‘C:\\Users\\Name\\Documents\\R\\win-library\\4.0’ for modifying\nTry removing ‘C:\\Users\\Name\\Documents\\R\\win-library\\4.0/00LOCK’"},{"path":"errors.html","id":"erreurs-dobjet","chapter":"47 Erreurs fréquentes","heading":"Erreurs d’objet","text":"Si vous voyez une erreur comme celle-ci lorsque vous essayez d’exporter ou d’importer : Vérifiez l’orthographe du fichier et de son chemin d’accès, et si le chemin d’accès contient des barres obliques, assurez-vous qu’il s’agit bien d’une barre oblique en avant / et non d’une barre oblique en arrière \\. Vérifiez également que vous avez utilisé la bonne extension de fichier (par exemple, .csv, .xlsx).Ceci signifie que l’objet que vous référencez n’existe pas. Peut-être que le code ci-dessus ne s’est pas correctement exécuté ?Ceci signifie que vous avez essayé d’accéder à quelque chose (un élément d’un vecteur ou d’une liste) qui n’existe pas.","code":"No such file or directory:object 'x' not found Error in 'x': subscript out of bounds"},{"path":"errors.html","id":"erreurs-de-syntaxe-des-fonctions","chapter":"47 Erreurs fréquentes","heading":"Erreurs de syntaxe des fonctions","text":"L’erreur ci-dessus (argument .x missing, default) est fréquente dans mutate() si vous fournissez une fonction comme recode() ou replace_na() où l’s’attend à ce que vous fournissiez le nom de la colonne comme premier argument. Ceci est facile à oublier.","code":"# ran recode without re-stating the x variable in mutate(x = recode(x, OLD = NEW)\nError: Problem with `mutate()` input `hospital`.\nx argument \".x\" is missing, with no default\ni Input `hospital` is `recode(...)`."},{"path":"errors.html","id":"erreurs-de-logique","chapter":"47 Erreurs fréquentes","heading":"Erreurs de logique","text":"Ceci signifie probablement qu’une instruction été appliquée à quelque chose qui n’était ni VRAI ni FAUX.","code":"Error in if"},{"path":"errors.html","id":"erreurs-de-facteur","chapter":"47 Erreurs fréquentes","heading":"Erreurs de facteur","text":"Si vous voyez cette erreur concernant des niveaux de facteur invalides, vous avez probablement une colonne de la classe Factor (qui contient des niveaux prédéfinis) et vous avez essayé d’y ajouter une nouvelle valeur. Convertissez-la en classe Character avant d’ajouter une nouvelle valeur.","code":"#Tried to add a value (\"Missing\") to a factor (with replace_na operating on a factor)\nProblem with `mutate()` input `age_cat`.\ni invalid factor level, NA generated\ni Input `age_cat` is `replace_na(age_cat, \"Missing\")`.invalid factor level, NA generated"},{"path":"errors.html","id":"erreurs-graphique","chapter":"47 Erreurs fréquentes","heading":"Erreurs graphique","text":"Error: Insufficient values manual scale. 3 needed 2 provided. ggplot() scale_fill_manual() values = c(“orange”, “purple”) … insuffisant pour le nombre de niveaux de facteurs … considérer si NA est maintenant un niveau de facteur…Vous avez probablement un + supplémentaire à la fin d’une commande ggplot que vous devez supprimer.","code":"Can't add x object"},{"path":"errors.html","id":"erreurs-r-markdown","chapter":"47 Erreurs fréquentes","heading":"Erreurs R Markdown","text":"Si le message d’erreur est de type Error options[[sprintf(\"fig.%s\", )]], vérifiez que vos options knitr en haut de chaque chunk utilisent correctement .width = ou .height = et pas fig.width= et fig.height=.","code":""},{"path":"errors.html","id":"autres-1","chapter":"47 Erreurs fréquentes","heading":"Autres","text":"Vérifiez si vous avez réorganisé les verbes dplyr en pipe et si vous n’avez pas remplacé un pipe au milieu, ou si vous n’avez pas retiré un pipe de la fin après avoir réorganisé.","code":""},{"path":"errors.html","id":"ressources-29","chapter":"47 Erreurs fréquentes","heading":"47.3 Ressources","text":"Voici un autre article de blog qui recense les R programming errors faced beginners","code":""},{"path":"help.html","id":"help","chapter":"48 Obtenir de l’aide","heading":"48 Obtenir de l’aide","text":"Cette page explique comment obtenir de l’aide en postant un problème sur Github ou en publiant un exemple reproductible (“reprex”) sur un forum en ligne.","code":""},{"path":"help.html","id":"github-issues","chapter":"48 Obtenir de l’aide","heading":"48.1 Github issues","text":"Plusieurs packages et projets en R ont leur code sur le site Github.com. Vous pouvez communiquer directement avec les auteurs sur ce site en postant un “Issue”.Pour en savoir plus sur comment sauvegarder vos travaux sur Github, consultez la page Collaboration et Github.Sur Github, chaque projet est contenu dans un repository. Chaque repository contient du code, des données, des résultats, la documentation d’aide, etc. Il existe également un moyen de communiquer avec les auteurs dénommé “Issues”.Ci-dessous, la page Github pour le package incidence2 (utilisé pour créer des courbes épidémiques). Vous pouvez voir l’onglet “Issues” surligné en jaune. Vous pouvez voir qu’il y 5 issues ouvertes.Une fois dans l’onglet Issues, vous pouvez voir les questions ou issues ouvertes. Lisez-les pour vous assurer que votre question n’est pas déjà abordée. Vous pouvez ouvrir un nouveau issue en cliquant sur le bouton vert à droite. Vous aurez besoin d’un compte Github pour le faire.Dans votre question, suivez les instructions ci-dessous pour fournir un exemple minimal et reproductible. Et soyez gentil! La plupart des personnes qui développent des packages et des projets R le font pendant leur temps libre (comme ce manuel!).Pour en savoir plus sur la gestion des questions dans votre propre repository Github, consultez la documentation sur les issues sur Github.","code":""},{"path":"help.html","id":"exemple-reproductible","chapter":"48 Obtenir de l’aide","heading":"48.2 Exemple reproductible","text":"Fournir un exemple reproductible (“reprex”) est essentiel pour obtenir de l’aide lorsque vous postez un message dans un forum ou dans un issue Github. Les gens veulent vous aider, mais vous devez leur donner un exemple avec lequel ils peuvent travailler sur leur propre ordinateur. L’exemple doit :Démontrer le problème que vous avez rencontréÊtre minimal, c’est-à-dire qu’il ne doit contenir que les données et le code nécessaires à la reproduction du problème.Être reproductible, c’est-à-dire que tous les objets (par exemple les données) et les requêtes sur les packages (par exemple library() ou p_load()) sont inclus.Aussi, assurez-vous de ne pas poster de données confidentielles avec le reprex! Vous pouvez créer des tableaux de données exemplaires, ou utiliser l’un des tableaux de données intégrés à R (entrez data() pour ouvrir une liste de ces ensembles de données).","code":""},{"path":"help.html","id":"le-package-reprex","chapter":"48 Obtenir de l’aide","heading":"Le package reprex","text":"Le package reprex peut vous aider à créer un exemple reproduisible :reprex est installé avec tidyverse, donc chargez l’un ou l’autre des packagesCommencez un script R qui crée votre problème, étape par étape, en commençant par le chargement des packages et des données.Copiez tout le code sur votre clipboard, et exécutez la commande suivante :Vous verrez une fenêtre HTML apparaître dans la fenêtre viewer de RStudio. Elle contiendra l’ensemble de votre code et tous les messages, les erreurs, ou les résultats de graphique. Ce résultat est également copié sur votre presse-papier, de façon à ce que vous pouvez le poster directement dans un issue Github ou un poste de forum.Si vous définissez session_info = TRUE, le resultat de sessioninfo::session_info() avec votre version de R et du package R sera inclus.Vous pouvez spécifier un répertoire de travail avec wd =.Vous pouvez en lire plus sur les arguments et les variations possibles dans la documentation ou en saisissant ?reprex.Dans l’exemple ci-dessus, la commande ggplot() ne s’est pas exécutée car l’argument date_format = n’est pas correcte - il devrait être date_labels =.","code":"\n# installer/charger tidyverse (qui inclut reprex)\npacman::p_load(tidyverse)\n# charger les packages\npacman::p_load(\n     tidyverse,  # gestion des donnees et visualisation \n     outbreaks)  # exemple de données sur les épidémies\n\n# Liste des cas d'épidémie de grippe\noutbreak_raw <- outbreaks::fluH7N9_china_2013 # récupérer les données à partir du package outbreaks \n\n# nettoyage des données\noutbreak <- outbreak_raw %>% \n     mutate(across(contains(\"date\"), as.Date))\n\n# graphique de l'epidémie \n\nggplot(data = outbreak)+\n     geom_histogram(\n          mapping = aes(x = date_of_onset),\n          binwidth = 7\n     )+\n  scale_x_date(\n    date_format = \"%d %m\"\n  )\nreprex::reprex()"},{"path":"help.html","id":"données-minimales","chapter":"48 Obtenir de l’aide","heading":"Données minimales","text":"Les aidants doivent être en mesure d’utiliser vos données - idéalement, ils doivent pouvoir les créer avec du code.Pour créer un ensemble de données minimales, considérez anonymer et utiliser seulement un sous-ensemble des observations.EN CONSTRUCTION - vous pouvez également utiliser la fonction dput() pour créer un ensemble de données minimales.","code":""},{"path":"help.html","id":"poster-sur-un-forum","chapter":"48 Obtenir de l’aide","heading":"48.3 Poster sur un forum","text":"Lisez beaucoup de messages de forum. Essayez de comprendre quels messages sont bien rédigés et lesquels ne sont pas.Tout d’abord, décidez si vous devez poser la question. Avez-vous parcouru le site web du forum, en essayant divers termes de recherche, pour voir si votre question n’pas déjà été posée ?Tout d’abord, décidez si vous devez poser la question. Avez-vous parcouru le site web du forum, en essayant divers termes de recherche, pour voir si votre question n’pas déjà été posée ?Choisissez un titre informatif pour votre question (pas “Au secours ! ça ne marche pas”).Choisissez un titre informatif pour votre question (pas “Au secours ! ça ne marche pas”).Rédigez votre question :Rédigez votre question :Présentez votre situation et votre problèmeLiez aux posts de problèmes similaires et expliquez pourquoi ils ne répondent pas à votre questionIncluez toute information pertinente pour aider quelqu’un qui ne connaît pas le contexte de votre travail.Donnez un exemple minimal reproductible avec les informations de votre session R.Utilisez la propre orthographe, grammaire et ponctuation, et divisez votre question en paragraphes pour faciliter la lecture.surveillez votre question une fois qu’elle est publiée pour pouvoir répondre à toute demande de clarification. Soyez gentil et aimable - souvent, les personnes qui répondent vous aident volontairement. Si vous avez une question complémentaire, demandez-vous si elle doit faire l’objet d’une question différente.surveillez votre question une fois qu’elle est publiée pour pouvoir répondre à toute demande de clarification. Soyez gentil et aimable - souvent, les personnes qui répondent vous aident volontairement. Si vous avez une question complémentaire, demandez-vous si elle doit faire l’objet d’une question différente.Marquez la question comme ayant reçu une réponse, si vous obtenez une réponse qui répond à la demande originale. Cela permet aux autres personnes de reconnaître rapidement la solution.Marquez la question comme ayant reçu une réponse, si vous obtenez une réponse qui répond à la demande originale. Cela permet aux autres personnes de reconnaître rapidement la solution.Lisez ces articles sur comment poser une bonne question et le code de conduite de Stack overflow.","code":""},{"path":"help.html","id":"resources-10","chapter":"48 Obtenir de l’aide","heading":"48.4 Resources","text":"Page Tidyverse sur comment obtenir de l’aideAstuces pour produire un ensemble de données minimalDocumentation de la fonction dput","code":""},{"path":"network_drives.html","id":"network_drives","chapter":"49 R sur les lecteurs réseau","heading":"49 R sur les lecteurs réseau","text":"","code":""},{"path":"network_drives.html","id":"aperçu-6","chapter":"49 R sur les lecteurs réseau","heading":"49.1 Aperçu","text":"L’utilisation de R sur des lecteurs partagés du réseau ou de “l’entreprise” peut présenter des défis supplémentaires. Cette page contient des approches, des erreurs courantes et des suggestions de dépannage tirées de notre expérience de travail sur ces questions. Cela inclut des conseils pour les situations particulièrement délicates impliquant R Markdown.Utilisation de R sur des lecteurs réseau : Principes générauxVous devez obtenir un accès administrateur pour votre ordinateur. Configurez RStudio spécifiquement pour qu’il s’exécute en tant qu’administrateur.Enregistrez les paquets dans une bibliothèque située sur un lecteur portant une lettre (par exemple, “C :”) lorsque cela est possible. Utilisez le moins possible une bibliothèque de paquets dont le chemin commence par “\\\".Le paquet rmarkdown ne doit pas être dans une bibliothèque de paquets “\\\", car alors il ne peut pas se connecter à TinyTex ou Pandoc.","code":""},{"path":"network_drives.html","id":"rstudio-en-tant-quadministrateur","chapter":"49 R sur les lecteurs réseau","heading":"49.2 RStudio en tant qu’administrateur","text":"Lorsque vous cliquez sur l’icône RStudio pour ouvrir RStudio, faites-le avec un clic droit. Selon votre machine, vous verrez peut-être une option “Exécuter en tant qu’administrateur”. Sinon, vous verrez peut-être une option permettant de sélectionner Propriétés (une fenêtre devrait alors apparaître avec l’option “Compatibilité”, et vous pourrez cocher la case “Exécuter en tant qu’administrateur”).","code":""},{"path":"network_drives.html","id":"commandes-utiles","chapter":"49 R sur les lecteurs réseau","heading":"49.2.1 Commandes utiles","text":"Vous trouverez ci-dessous quelques commandes utiles lorsque vous essayez de résoudre des problèmes en utilisant R sur des lecteurs réseau.Vous pouvez renvoyer le(s) chemin(s) des bibliothèques de paquets que R utilise. Ils seront listés dans l’ordre que R utilise pour installer/charger/rechercher les paquets. Ainsi, si vous voulez que R utilise une autre bibliothèque par défaut, vous pouvez changer l’ordre de ces chemins (voir ci-dessous).Vous pouvez vouloir changer l’ordre des bibliothèques de paquets utilisées par R. Par exemple, si R récupère un emplacement de bibliothèque qui commence par “\\\" et un autre qui commence par une lettre, par exemple”D :“. Vous pouvez ajuster l’ordre de .libPaths() avec le code suivant.Si vous avez des difficultés à connecter R Markdown à Pandoc, commencez par ce code pour savoir où RStudio pense que votre installation Pandoc se trouve.Si vous voulez voir à partir de quelle bibliothèque un paquet est chargé, essayez le code suivant :","code":"\n# Recherche de bibliothèques\n.libPaths() # Vos chemins de bibliothèques, listés dans l'ordre d'installation/de recherche de R. \n                              # Note : toutes les bibliothèques seront listées, mais pour en installer certaines (par exemple C :), vous devrez peut-être exécuter RStock. \n                              # devrez peut-être exécuter RStudio en tant qu'administrateur (cela n'apparaîtra pas dans le menu déroulant \n                              # menu déroulant des bibliothèques d'installation des paquets) \n# Changer l'ordre des bibliothèques\n# Ceci peut affecter la priorité de R à trouver un paquet. Par exemple, vous pouvez vouloir que votre bibliothèque C : soit listée en premier.\nmyPaths <- .libPaths() # obtenir les chemins d'accès\nmyPaths <- c(myPaths[2], myPaths[1]) # les commuter\n.libPaths(myPaths) # les réaffecter\n# Trouver Pandoc\nSys.getenv(\"RSTUDIO_PANDOC\") # Trouver où RStudio pense que votre installation Pandoc se trouve\n# Trouver un paquetage\n# donne le premier emplacement du paquet (notez l'ordre de vos bibliothèques)\nfind.package(\"rmarkdown\", lib.loc = NULL, quiet = FALSE, verbose = getOption(\"verbose\")) "},{"path":"network_drives.html","id":"dépannage-des-erreurs-courantes","chapter":"49 R sur les lecteurs réseau","heading":"49.3 Dépannage des erreurs courantes","text":"“Failed compile…tex rmarkdown”\n* Vérifiez l’installation de TinyTex, ou installez TinyTex à l’emplacement C :. Voir la page R - les basespour savoir comment installer TinyTex.Les routines Internet ne peuvent pas être chargées.Par exemple, Erreur dans tools::startDynamicHelp() : les routines internet ne peuvent pas être chargées.Essayez de sélectionner la version 32 bits de RStudio via Tools/Global Options.\nNote : si la version 32 bits n’apparaît pas dans le menu, assurez-vous que vous n’utilisez pas RStudio v1.2.\nNote : si la version 32 bits n’apparaît pas dans le menu, assurez-vous que vous n’utilisez pas RStudio v1.2.Alternativement, essayez de désinstaller R et de le réinstaller avec une version différente (32 au lieu de 64).C : la bibliothèque n’apparaît pas comme une option lorsque j’essaie d’installer les paquets manuellement.Lancez RStudio en tant qu’administrateur, cette option apparaîtra alors.Pour configurer RStudio pour qu’il soit toujours exécuté en tant qu’administrateur (avantageux lorsque vous utilisez un projet R où vous ne cliquez pas sur l’icône RStudio pour l’ouvrir)… cliquez avec le bouton droit de la souris sur l’icône Rstudio.L’image ci-dessous montre comment vous pouvez sélectionner manuellement la bibliothèque dans laquelle installer un paquet. Cette fenêtre apparaît lorsque vous ouvrez le volet Packages RStudio et cliquez sur “Installer”.Pandoc 1 erreurSi vous obtenez “pandoc error 1” lorsque vous tricotez des scripts R Markdowns sur des lecteurs réseau :Sur plusieurs emplacements de bibliothèque, faites en sorte que celui qui un lecteur avec une lettre soit listé en premier (voir les codes ci-dessus).La solution ci-dessus fonctionné lors du tricotage sur le lecteur local, mais lors d’une connexion Internet en réseau.Voir plus de conseils ici : https://ciser.cornell.edu/rmarkdown-knit--html-word-pdf/Erreur Pandoc 83L’erreur ressemblera à quelque chose comme ceci : Impossible de trouver le fichier...rmarkdown...lua.... Cela signifie qu’il n’pas pu trouver ce fichier.Voir https://stackoverflow.com/questions/58830927/rmarkdown-unable--locate-lua-filter--knitting--wordPossibilités :Le paquet Rmarkdown n’est pas installéLe paquet Rmarkdown n’est pas trouvableUn problème de droits d’administration.Il est possible que R ne soit pas capable de trouver le fichier du paquet rmarkdown, donc vérifiez dans quelle bibliothèque se trouve le paquet rmarkdown (voir le code ci-dessus). Si le paquet est installé dans une bibliothèque inaccessible (par exemple, commençant par “\\\"), pensez à le déplacer manuellement vers C : ou une autre bibliothèque de lecteur nommée. Soyez conscient que le paquet rmarkdown doit pouvoir se connecter à l’installation de TinyTex, et ne peut donc pas être installé dans une bibliothèque sur un lecteur réseau.Erreur Pandoc 61Par exemple : Erreur : la conversion du document pandoc échoué avec l'erreur 61 ou Impossible d'aller chercher....Essayez d’exécuter RStudio en tant qu’administrateur (cliquez avec le bouton droit de la souris sur l’icône, sélectionnez exécuter en tant qu’administrateur, voir les instructions ci-dessus).Voir également si le paquet spécifique qui n’pas pu être atteint peut être déplacé vers la bibliothèque C :.Erreur LaTex (voir ci-dessous).Une erreur du type : ! Paquet pdftex.def Erreur : File 'cict_qm2_2020-06-29_files/figure-latex/unnamed-chunk-5-1.png' non trouvé : utilisation de la fonction brouillon. ou Erreur : LaTeX n'pas réussi à compiler file_name.tex..Voir https://yihui.org/tinytex/r/#debugging pour des conseils de débogage.Voir file_name.log pour plus d’informations.Erreur Pandoc 127Cela peut être un problème de RAM (espace). Redémarrez votre session R et réessayez.Mappage de lecteurs réseauLe mappage d’un lecteur réseau peut être risqué. Consultez votre service informatique avant d’essayer.Un conseil emprunté à cette discussion du forum :Comment ouvrir un fichier “via un lecteur réseau mappé” ?Tout d’abord, vous devez connaître l’emplacement réseau auquel vous essayez d’accéder.Ensuite, dans le gestionnaire de fichiers de Windows, vous devez cliquer avec le bouton droit de la souris sur “Ce PC” dans le volet de droite, et sélectionner “Mapper un lecteur réseau”.Passez par la boîte de dialogue pour définir l’emplacement réseau de tout à l’heure comme un lecteur de lettres.Maintenant, vous avez deux façons d’accéder au fichier que vous ouvrez. L’utilisation du chemin d’accès par lettre du lecteur devrait fonctionner.Erreur dans install.packages()Si vous obtenez une erreur qui inclut la mention d’un répertoire “verrouillé”, par exemple : `Erreur dans install.packages : ERROR : échec du verrouillage du répertoire…``Regardez dans votre bibliothèque de paquets et vous verrez un répertoire dont le nom commence par “00LOCK”. Essayez les astuces suivantes :Supprimez manuellement le répertoire du dossier “00LOCK” de votre bibliothèque de paquets. Essayez d’installer à nouveau le paquetage.Vous pouvez aussi essayer la commande pacman::p_unlock() (vous pouvez aussi mettre cette commande dans le Rprofile pour qu’elle s’exécute à chaque fois que le projet s’ouvre). Ensuite, essayez à nouveau d’installer le paquet. Cela peut prendre plusieurs essais.Essayez d’exécuter RStudio en mode Administrateur, et essayez d’installer les paquets un par un.Si tout le reste échoue, installez le paquet dans une autre bibliothèque ou un autre dossier (par exemple Temp), puis copiez manuellement le dossier du paquet dans la bibliothèque souhaitée.","code":"\n# vérifiez/installez tinytex, à l'emplacement C :.\ntinytex::install_tinytex()\ntinytex:::is_tinytex() # devrait retourner VRAI (notez les trois deux points)"},{"path":"data_table.html","id":"data_table","chapter":"50 Tableau de données","heading":"50 Tableau de données","text":"Le manuel se concentre sur les fonctions verbales dplyr et l’opérateur pipe magrittr %>% comme méthode pour nettoyer et regrouper les données, mais le paquet data.table offre une méthode alternative que vous pourriez rencontrer dans votre carrière R.","code":""},{"path":"data_table.html","id":"intro-aux-tableaux-de-données","chapter":"50 Tableau de données","heading":"50.1 Intro aux tableaux de données","text":"Une table de données est une structure de données bidimensionnelle comme un cadre de données qui permet d’effectuer des opérations de regroupement complexes. La syntaxe data.table est structurée de manière à ce que les opérations puissent être effectuées sur les lignes, les colonnes et les groupes.La structure est DT[, j, ], séparée par 3 parties : les arguments , j et . L’argument permet de sous-dimensionner les lignes requises, l’argument j permet d’opérer sur les colonnes et l’argument permet d’opérer sur les colonnes par groupes.Cette page abordera les sujets suivants :Importation de données et utilisation de fread() et fwrite().Sélection et filtrage des lignes en utilisant l’argument .Utilisation des fonctions d’aide %like%, %chin%, %%.Sélection et calcul sur les colonnes à l’aide de l’argument j.Calculer par groupes avec l’argument byAjouter et mettre à jour des données dans des tableaux de données en utilisant :=","code":""},{"path":"data_table.html","id":"load-packages-and-import-data","chapter":"50 Tableau de données","heading":"50.2 Load packages and import data","text":"","code":""},{"path":"data_table.html","id":"chargement-des-paquets-et-importation-des-données","chapter":"50 Tableau de données","heading":"50.3 Chargement des paquets et importation des données","text":"","code":""},{"path":"data_table.html","id":"charger-des-paquets","chapter":"50 Tableau de données","heading":"Charger des paquets","text":"En utilisant la fonction p_load() de pacman, nous chargeons (et installons si nécessaire) les paquets nécessaires à cette analyse.","code":"\npacman::p_load(\n  rio, # pour importer les données\n  data.table, # pour regrouper et nettoyer les données\n  tidyverse, # permet d'utiliser la fonction pipe (%>%) dans ce chapitre\n  here \n  ) "},{"path":"data_table.html","id":"importer-les-données-5","chapter":"50 Tableau de données","heading":"Importer les données","text":"Cette page va explorer certaines des fonctions principales de data.table en utilisant la liste de cas référencée tout au long du manuel.Nous importons le jeu de données des cas d’une épidémie d’Ebola simulée. Si vous souhaitez télécharger les données pour les suivre pas à pas, consultez les instructions de la page [Donwload book data]. L’ensemble de données est importé à l’aide de la fonction import() du paquet rio. Voir la page [Import export] pour les différentes manières d’importer des données. partir de là, nous utilisons data.table() pour convertir le cadre de données en un tableau de données.La fonction fread() est utilisée pour importer directement des fichiers délimités réguliers, tels que les fichiers .csv, vers un format de table de données. Cette fonction, et sa contrepartie, fwrite(), utilisée pour écrire les tables de données comme des fichiers délimités réguliers, sont des options très rapides et efficaces en termes de calcul pour les grandes bases de données.Les 20 premières lignes de linelist :Les commandes de base de R, telles que dim(), utilisées pour les cadres de données, peuvent également être utilisées pour les tableaux de données.","code":"\nlinelist <- rio::import(here(\"data\", \"linelist_cleaned.xlsx\")) %>% data.table()\ndim(linelist) #donne le nombre de lignes et de colonnes du tableau de données## [1] 5888   30"},{"path":"data_table.html","id":"largument-i-sélection-et-filtrage-des-lignes","chapter":"50 Tableau de données","heading":"50.4 L’argument i: sélection et filtrage des lignes","text":"En rappelant la structure DT[, j, ], nous pouvons filtrer les lignes en utilisant soit des numéros de ligne, soit des expressions logiques. L’argument est le premier ; par conséquent, la syntaxe DT[] ou DT[,] peut être utilisée.Le premier exemple récupère les 5 premières lignes de la table de données, le deuxième exemple sous-entend que les cas sont âgés de 18 ans ou plus, et le troisième exemple sous-entend que les cas âgés de 18 ans ou plus mais non diagnostiqués à l’hôpital central :L’utilisation de .N dans l’argument représente le nombre total de lignes dans la table de données. Cela peut être utilisé pour effectuer un sous-ensemble sur le nombre de lignes :","code":"\nlinelist[1:5] #renvoie la 1ère à la 5ème ligne\nlinelist[age >= 18] #sous-entend les cas égaux ou supérieurs à 18 ans\nlinelist[age >= 18 & hospital != \"Central Hospital\"] #subset les cas égaux ou supérieurs à 18 ans mais non diagnostiqués à Central Hospital\nlinelist[.N] #renvoie la dernière ligne\nlinelist[15 :.N] #renvoie la 15ème à la dernière ligne"},{"path":"data_table.html","id":"utilisation-de-fonctions-daide-pour-le-filtrage","chapter":"50 Tableau de données","heading":"Utilisation de fonctions d’aide pour le filtrage","text":"Le tableau de données utilise des fonctions d’aide qui facilitent le sous-ensemble des lignes. La fonction %like% est utilisée pour faire correspondre un motif dans une colonne, %chin% est utilisée pour faire correspondre un caractère spécifique, et la fonction d’aide %% est utilisée pour faire correspondre des colonnes numériques dans une plage prédéfinie.Dans les exemples suivants, nous :\n* filtrons les lignes où la variable hospital contient “Hospital”.\n* filtrons les lignes où le résultat est “Recover” ou “Death”.\n* filtrons les lignes dans la tranche d’âge 40-60 ans","code":"\nlinelist[hospital %like% \"Hospital\"] #filtre les lignes où la variable hospital contient \"Hospital\"\nlinelist[outcome %chin% c(\"Recover\", \"Death\")] #filtre les lignes où l'issue est \"Recover\" ou \"Death\".\nlinelist[age %between% c(40, 60)] #filtre les lignes dans la tranche d'âge 40-60\n\n#%between% doit prendre un vecteur de longueur 2, tandis que %chin% peut prendre des vecteurs de longueur >= 1"},{"path":"data_table.html","id":"largument-j-sélection-et-calcul-sur-les-colonnes","chapter":"50 Tableau de données","heading":"50.5 L’argument j: sélection et calcul sur les colonnes","text":"En utilisant la structure DT[, j, ], nous pouvons sélectionner des colonnes en utilisant des nombres ou des noms. L’argument j est le second ; utilise donc la syntaxe DT[, j]. Pour faciliter les calculs sur l’argument j, la colonne est enveloppée en utilisant soit list() soit .().","code":""},{"path":"data_table.html","id":"sélection-de-colonnes","chapter":"50 Tableau de données","heading":"Sélection de colonnes","text":"Le premier exemple récupère les première, troisième et cinquième colonnes de la table de données, le deuxième exemple sélectionne toutes les colonnes à l’exception des colonnes taille, poids et sexe. Le troisième exemple utilise la terminaison .() pour sélectionner les colonnes identification du cas et résultat.","code":"\nlinelist[ , c(1,3,5)]\nlinelist[ , -c(\"gender\", \"age\", \"wt_kg\", \"ht_cm\")]\nlinelist[ , list(case_id, outcome)] #linelist[ , .(case_id, outcome)] fonctionne tout aussi bien"},{"path":"data_table.html","id":"calcul-sur-les-colonnes","chapter":"50 Tableau de données","heading":"Calcul sur les colonnes","text":"En combinant les arguments et j, il est possible de filtrer les lignes et de calculer sur les colonnes. L’utilisation de .N dans l’argument j représente également le nombre total de lignes dans le tableau de données et peut être utile pour retourner le nombre de lignes après le filtrage des lignes.Dans les exemples suivants, nous :\n* Comptons le nombre de cas qui sont restés plus de 7 jours à l’hôpital.\n* Calculer l’âge moyen des cas qui sont décédés à l’hôpital militaire.\n* Calculer l’écart-type, la médiane et l’âge moyen des cas qui se sont rétablis à l’hôpital central.N’oubliez pas que l’utilisation de la terminaison .() dans l’argument j facilite le calcul, renvoie un tableau de données et permet de nommer les colonnes.","code":"\nlinelist[days_onset_hosp > 7 , .N]## [1] 189\nlinelist[hospital %like% \"Military\" & outcome %chin% \"Death\", .(mean(age, na.rm = T))] #na.rm = T supprime les valeurs N/A##         V1\n## 1: 15.9084\nlinelist[hospital == \"Central Hospital\" & outcome == \"Recover\", \n                 .(mean_age = mean(age, na.rm = T),\n                   median_age = median(age, na.rm = T),\n                   sd_age = sd(age, na.rm = T))] #cette syntaxe n'utilise pas les fonctions d'aide mais fonctionne tout aussi bien##    mean_age median_age   sd_age\n## 1: 16.85185         14 12.93857"},{"path":"data_table.html","id":"largument-by-calcul-par-groupes","chapter":"50 Tableau de données","heading":"50.6 L’argument by : calcul par groupes","text":"L’argument est le troisième argument de la structure DT[, j, ]. L’argument accepte à la fois un vecteur de caractères et la syntaxe list() ou .(). L’utilisation de la syntaxe .() dans l’argument permet de renommer les colonnes à la volée.Dans les exemples suivants, nous :\n* regroupons le nombre de cas par hôpital\n* dans les cas de 18 ans ou plus, calculer la taille et le poids moyens des cas selon le sexe et selon qu’ils sont guéris ou décédés\n* dans les admissions qui ont duré plus de 7 jours, compter le nombre de cas selon le mois d’admission et l’hôpital où ils ont été admis.Data.table permet également d’enchaîner les expressions comme suit :Dans ces exemples, nous partons du principe qu’une ligne du tableau de données correspond à un nouveau cas, et nous pouvons donc utiliser la fonction .N pour représenter le nombre de lignes du tableau de données. Une autre fonction utile pour représenter le nombre de cas uniques est uniqueN(), qui retourne le nombre de valeurs uniques dans une entrée donnée. Ceci est illustré ici :La réponse est 3, car les valeurs uniques de la colonne sexe sont m, f et N/. Comparez avec la fonction R de base unique(), qui renvoie toutes les valeurs uniques dans une entrée donnée :Pour trouver le nombre de cas uniques dans un mois donné, nous écririons ce qui suit :","code":"\nlinelist[, .N, .(hospital)] #le nombre de cas par hôpital##                                hospital    N\n## 1:                                Other  885\n## 2:                              Missing 1469\n## 3: St. Mark's Maternity Hospital (SMMH)  422\n## 4:                        Port Hospital 1762\n## 5:                    Military Hospital  896\n## 6:                     Central Hospital  454\nlinelist[age > 18, .(mean_wt = mean(wt_kg, na.rm = T),\n                             mean_ht = mean(ht_cm, na.rm = T)), .(gender, outcome)] #NAs représentent les catégories pour lesquelles les données sont manquantes##    gender outcome  mean_wt  mean_ht\n## 1:      m Recover 71.90227 178.1977\n## 2:      f   Death 63.27273 159.9448\n## 3:      m   Death 71.61770 175.4726\n## 4:      f    <NA> 64.49375 162.7875\n## 5:      m    <NA> 72.65505 176.9686\n## 6:      f Recover 62.86498 159.2996\n## 7:   <NA> Recover 67.21429 175.2143\n## 8:   <NA>   Death 69.16667 170.7917\n## 9:   <NA>    <NA> 70.25000 175.5000\nlinelist[days_onset_hosp > 7, .N, .(month = month(date_hospitalisation), hospital)]##     month                             hospital  N\n##  1:     5                    Military Hospital  3\n##  2:     6                        Port Hospital  4\n##  3:     7                        Port Hospital  8\n##  4:     8 St. Mark's Maternity Hospital (SMMH)  5\n##  5:     8                    Military Hospital  9\n##  6:     8                                Other 10\n##  7:     8                        Port Hospital 10\n##  8:     9                        Port Hospital 28\n##  9:     9                              Missing 27\n## 10:     9                     Central Hospital 10\n## 11:     9 St. Mark's Maternity Hospital (SMMH)  6\n## 12:    10                              Missing  2\n## 13:    10                    Military Hospital  3\n## 14:     3                        Port Hospital  1\n## 15:     4                    Military Hospital  1\n## 16:     5                                Other  2\n## 17:     5                     Central Hospital  1\n## 18:     5                              Missing  1\n## 19:     6                              Missing  7\n## 20:     6 St. Mark's Maternity Hospital (SMMH)  2\n## 21:     6                    Military Hospital  1\n## 22:     7                    Military Hospital  3\n## 23:     7                                Other  1\n## 24:     7                              Missing  2\n## 25:     7 St. Mark's Maternity Hospital (SMMH)  1\n## 26:     8                     Central Hospital  2\n## 27:     8                              Missing  6\n## 28:     9                                Other  9\n## 29:     9                    Military Hospital 11\n## 30:    10                        Port Hospital  3\n## 31:    10                                Other  4\n## 32:    10 St. Mark's Maternity Hospital (SMMH)  1\n## 33:    10                     Central Hospital  1\n## 34:    11                              Missing  2\n## 35:    11                        Port Hospital  1\n## 36:    12                        Port Hospital  1\n##     month                             hospital  N\nlinelist[, .N, .(hospital)][order(-N)][1:3] #La première sélectionne tous les cas par hôpital, la deuxième ordonne les cas par ordre décroissant, la troisième sous-ensemble les 3 hôpitaux ayant le plus grand nombre de cas.##             hospital    N\n## 1:     Port Hospital 1762\n## 2:           Missing 1469\n## 3: Military Hospital  896\nlinelist[, .(uniqueN(gender))] #souvenez-vous que .() dans l'argument j renvoie un tableau de données##    V1\n## 1:  3\nlinelist[, .(unique(gender))]##      V1\n## 1:    m\n## 2:    f\n## 3: <NA>\nlinelist[, .(uniqueN(case_id)), .(month = month(date_hospitalisation))]##     month   V1\n##  1:     5   62\n##  2:     6  100\n##  3:     7  198\n##  4:     8  509\n##  5:     9 1170\n##  6:    10 1228\n##  7:    11  813\n##  8:    12  576\n##  9:     1  434\n## 10:     2  310\n## 11:     3  290\n## 12:     4  198"},{"path":"data_table.html","id":"ajout-et-mise-à-jour-des-tables-de-données","chapter":"50 Tableau de données","heading":"50.7 Ajout et mise à jour des tables de données","text":"L’opérateur := est utilisé pour ajouter ou mettre à jour des données dans une table de données. L’ajout de colonnes à votre table de données peut se faire de la manière suivante :Des agrégations plus complexes dépassent le cadre de ce chapitre d’introduction, mais l’idée est de fournir une alternative populaire et viable à dplyr pour regrouper et nettoyer les données. Le package data.table est un excellent package qui permet d’obtenir un code soigné et lisible.","code":"\nlinelist[, adult := age >= 18] #ajoute une colonne\nlinelist[, c(\"child\", \"wt_lbs\") := .(age < 18, wt_kg*2.204)] #pour ajouter plusieurs colonnes, il faut utiliser la syntaxe c(\"\") et list() ou .()\nlinelist[, `:=` (bmi_in_range = (bmi > 16 & bmi < 40),\n                         no_infector_source_data = is.na(infector) | is.na(source))] #Cette méthode utilise := comme un opérateur fonctionnel `:=`.\nlinelist[, adult := NULL] #supprime la colonne"},{"path":"data_table.html","id":"ressources-30","chapter":"50 Tableau de données","heading":"50.8 Ressources","text":"Voici quelques ressources utiles pour plus d’informations :\n* https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html\n* https://github.com/Rdatatable/data.table\n* https://s3.amazonaws.com/assets.datacamp.com/img/blog/data+table+cheat+sheet.pdf\n* https://www.machinelearningplus.com/data-manipulation/datatable--r-complete-guide/\n* https://www.datacamp.com/community/tutorials/data-table-r-tutorialVous pouvez exécuter n’importe quelle fonction de synthèse sur des données groupées ; voir la Cheat Sheet ici pour plus d’informations :\nhttps://s3.amazonaws.com/assets.datacamp.com/blog_assets/datatable_Cheat_Sheet_R.pdf","code":""}]
